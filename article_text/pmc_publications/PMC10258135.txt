LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


7503062
4443
J Am Geriatr Soc
J Am Geriatr Soc
Journal of the American Geriatrics Society
0002-8614
1532-5415

36762513
10258135
10.1111/jgs.18271
NIHMS1869430
Article
Telehealth Equivalence of the Montreal Cognitive Assessment (MoCA): Results from the Emory Healthy Brain Study (EHBS)
Loring David W. PhD 12
Lah James J. MD, PhD 1
Goldstein Felicia C. PhD 1
1 Department of Neurology, Emory University School of Medicine
2 Department of Pediatrics, Emory University School of Medicine
Author Contributions

Dr. Loring performed all statistical analyses. Drs. Loring, Lah, and Goldstein all contributed to the study design, interpretation of statistical findings, and preparing the manuscript for publication.

Corresponding author: David W. Loring, Emory Brain Health Center, 12 Executive Park, Atlanta, GA 30329-2206. dloring@emory.edu
30 1 2023
6 2023
10 2 2023
01 6 2024
71 6 19311936
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Background.

We investigated potential differences between in-person cognitive testing and video telehealth administration of the Montreal Cognitive Assessment (MoCA). In addition to the MoCA, the Patient Health Questionnaire-8 (PHQ-8) and Generalized Anxiety Disorder-7 (GAD-7) were administered.

Methods.

MoCA scores from participants in the Emory Health Brain Study (EHBS) were contrasted based upon whether they were administered the MoCA in the standard face-to-face (F2F) assessment setting (n=1205) or using a video telehealth administration (n=491). All EHBS participants were self-reported to be cognitively normal.

Results.

MoCA scores did not differ across administration method (F2F MoCA=26.6, SD=2.4; telehealth MoCA=26.5, SD=2.4). The 95% confidence interval for difference in administration was small (CI= −0.16 – 0.34). When examining MoCA domain scores, administration differences were either associated with no statistically significant effect, or if present due to large sample sizes, were associated with small effects and differences &lt; 0.5 point. Telehealth patients reported slightly lower PHQ-8 scores (F2F PHQ-8=2.0, SD=2.5; telehealth PHQ-8=1.6, SD=2.1), although these scores are well within the normal range. No group difference in GAD-7 scores was present (F2F GAD-7=1.4, SD=2.4; telehealth PHQ-8=1.4, SD=2.4).

Discussion.

This report with its large sample size and between subject cohort provides complementary evidence to smaller test-retest studies, further supporting equivalence of MoCA telehealth testing to F2F MoCA administration. These findings provide additional reassurance that administration mode does not introduce systematic performance differences for MoCA test administration, thereby permitting telehealth MoCA testing to be applied confidently for both clinical and research applications.


pmcAlthough telehealth video cognitive assessment existed prior to the COVID-19 pandemic1,2, restrictions designed to minimize COVID spread limited many aspects for face-to-face (F2F) clinical care, accelerating the modification of many clinical methods for telehealth use3,4. The numerous advantages associated with remote testing include reduced travel time and increased access to clinical expertise outside of local availability5. However, practical telehealth considerations include adequacy of in-home technology and internet access in addition to computer proficiency and comfort with electronic media. Questions also arise whether telehealth results can be considered strictly equivalent to F2F clinic assessments given differences in administration format, potential decreased task engagement associated with video evaluation, and unknown effects associated with testing in a less well controlled home testing environment where caretaker support may be needed6.

Video telehealth cognitive assessment is considered to be generally reliable and valid4,7,8. Because of the rapid implementation of video telehealth in response to the COVID-19 pandemic, empirical support of telehealth equivalence to standard administration methods is limited, although several systematic reviews report its clinical utility9,10. Telehealth administration for cognitive screening measures including the Mini Mental Status Examination11 and the Montreal Cognitive Assessment12 have greater empirical support compared to more specialized cognitive measures8.

Several small test-retest studies contrasting telehealth MoCA administration with F2F assessment in clinical samples exist using cross-over experimental designs. Within subject designs allow intraclass coefficients to be calculated, and although such designs incur carry-over practice effects, counterbalanced administration order allows difference score between conditions to be characterized. In 28 patients with mild-to-severe dementia who were tested with both telehealth and F2F MoCA administrations, the average MoCA telehealth score was 0.9 points higher with telehealth testing (F2F MoCA=12.2, telehealth MoCA=13.1), and was associated with a large intra class coefficient reliability (ICC=.93)13. However, in 48 stroke patients with higher MoCA scores (in-person MoCA=24.2, telehealth MoCA=24.0), the Intraclass Coefficient (ICC) was much lower (ICC=.62)14. ICCs may vary based upon clinical disease severity, with lower ICCs in healthy volunteers (F2F MoCA = 25.6, telehealth MoCA=24.1, ICC=.53) compared to MCI (F2F MoCA = 19.5, telehealth MoCA=18.4, ICC=.82) or dementia (F2F MoCA = 15.2, telehealth MoCA=15.1, ICC=.82)15. In a small sample of 17 patients with either a Parkinson Disease or Huntington disease diagnosis with an average F2F MoCA = 25.1, a telehealth MoCA=25.2, and an ICC=.59 were obtained, however16, and the ICC from a sample of 130 community living middle aged and older volunteers tested on two F2F occasions (1st MoCA=24.8, 2nd MoCA=25.2) was .8117, suggesting that level of cognition alone cannot account for variability in reported reliability across F2F vs. telehealth MoCA reports.

Administration equivalence of performance levels is relevant in the context of patient evaluation where cognitive difficulty, if present, is relatively mild and for longitudinal follow-up to monitor interval disease progression. Patients with advanced neurologic disease associated with low cognitive scores have a limited performance range, and good diagnostic agreement across assessment methods would be expected. As noted in a Cochrane review10, telehealth may be less accurate for diagnosing mild cognitive impairment compared to diagnostic accuracy in patients with dementia.

The COVID pandemic not only affected the clinical care delivery, but also altered clinical research involving human subject participation. Because the COVID pandemic prevented face-to-face clinical contact for non-critical research due to safety considerations, clinical research protocols including the National Alzheimer’s Coordinating Center Uniform Data Set18 and the Emory Heathy Brain Study (EHBS)19 modified their cognitive assessment protocols to permit telephone and video telehealth testing. This EHBS protocol change to video telehealth provided the opportunity to contrast telehealth vs. F2F MoCA assessment in two large healthy volunteer cohorts using the same enrollment criteria.

Methods

Participants.

Participants were drawn from the EHBS, an Alzheimer Disease (AD) biomarker discovery project to detect early conversion from normal age-related cognitive performance in a large community-based prospectively enrolled cohort19. EHBS involves deep clinical phenotyping of participants via longitudinal collection of cognitive testing, vascular physiology, blood and CSF, and brain MRI. EHBS was approved by the Emory University Institutional Review Board and all participants provided written informed consent.

Participants are self-declared as cognitively normal without a diagnosis of mild cognitive impairment or dementia. Exclusion criteria include cancer not in remission, kidney disease on dialysis, active TB, untreated hepatitis B or C, stroke or transient ischemic attack, on anticoagulation, or an unwillingness to undergo blood draw, MRI, or LP.

Cognitive and Psychological Screening.

EHBS testing includes the MoCA12, Patient Health Questionnaire-8 (PHQ-8) depression scale20, and Generalized Anxiety Disorder-7 (GAD-7) questionnaire21. In addition to the traditional summary score with a maximum of 30 points (or 31 following single point education correction for high school education or less), we evaluated MoCA index scores designed to reflect individual cognitive domains22,23. The Memory Index reflects the number of words recalled across delayed free, category-cued, and multiple-choice (0–15 points). The Executive Index includes Trail-Making, clock drawing, digit span, letter A vigilance, serial 7 subtraction, letter fluency, and abstraction (0–13 points). The Visuospatial Index consists of cube copy, clock drawing, and naming (0–7 points). The Language Index is based upon naming, sentence repetition, and letter fluency (0–6 points). Attention is calculated from digit span, letter A vigilance, serial 7 subtraction, sentence repetition, and the number of words correctly recalled during both learning trials (0–18 points). Orientation reflects knowledge of date, day, month, year, place, and city (0–6 points). Individual items may contribute to more than one index score.

Administration.

Testing was conducted with standard F2F assessment until March 2020, when all in-person clinical research activities were stopped in response to the pandemic. Over the next 6 months, both clinic and research cognitive assessment procedures were modified for telehealth administration24. EHBS study testing resumed in August 2020 using remote cognitive testing employing a HIPAA compliant Zoom (Business Associate Agreement) with visual stimuli presented from individual PDF files24.

Telehealth Modification.

Full details of our modified telehealth MoCA protocol, including specific administration instructions and text, are detailed in Supplementary Text S1. Changes were made to minimize deviations from standard F2F administration while accommodating the restrictions associated with stimulus display and participant responding with video telehealth communication. Six MoCA items (3 visuospatial, 3 naming) were presented individually from a scanned PDF using the share screen zoom option, and all items were scanned and presented in full frame/full screen format. For Trails, participants were asked to say the number-letter sequence aloud rather than drawing lines to connect the circle. The Necker cube stimulus PDF contained “Cube copy” next to the figure to closely mimic the paper and pencil presentation. Similarly, “Draw CLOCK (Ten past eleven)” was presented on the screen during clock drawing. Following clock drawing, participants were instructed to put all sheets of paper and writing utensils aside. Naming stimuli were presented individually on the screen. For vigilance (Letter A), the task was modified from a hand tap to a hand raise, and participants were reminded to lower their hand completely after each response. Orientation for place and city asked for the name and location of the institution (Emory), not the participant’s location.

Analysis.

MoCA and domain scores were contrasted between administration groups with independent t-tests. We made no correction for multiple comparisons since in this context of trying to demonstrate equivalence, we considered Type II errors more serious than Type I errors25. The primary metrics of equivalence were effect sizes (η2) and 95% confidence intervals (CIs) for difference scores between administration format. CIs were based upon homogeneity of variance assumptions unless otherwise indicated by Levene’s test. This same analytic approach was also used for both PHQ-8 and GAD-7.

Results

Sample.

There were 1696 persons studied, which included 1155 females and 541 males. There were 1205 participants who were administered the MoCA in the standard in-person F2F condition and 491 who were administered the MoCA via telehealth. Both groups had comparable representation across biological sex at birth, with 832 females (69.0%) in the F2F condition and 323 females (65.8%) assessed with telehealth. Administration groups did not differ in age (F2F=62.8, SD=7.0, R=45.2–76.0; telehealth=63.4, SD=6.5, R=50.3–77.0), or years of education (F2F=16.6, SD=2.1, R=10–20); telehealth=16.9, SD=2.1, R=11–22). Both groups were predominantly White (F2F n=1050, 87.1%; telehealth n=329, 67.0%), Black participation ranged from n=119 (12.0%) for F2F to n=134 (27.3%) for telehealth. No other race was greater than 5% in either group, and the number of participants identifying as Hispanic was less the 5% in each group.

MoCA.

Performance levels including 95% CIs of the differences between administration and effects sizes (η2) for the MoCA summary score and domain measures are presented in Table 1. Combined MoCA scores across all participants ranged from 20–30, with an average MoCA=26.5 (SD=2.4) and did not differ based upon administration mode (F2F MoCA=26.6, SD=2.4, R=16–31 (reflects education adjustment); telehealth MoCA=26.5, SD=2.4, R=18–30). Across domains, significant differences in scores were observed for Language (p=.022) and Orientation (p&lt;.001). Importantly, all η2 effects sizes are small, including those for both Language (η2=.003) and Orientation (η2=.010). By convention, η2 ≥ .01 is considered a small effect, η2 ≥ .06 is considered a medium effect, and η2 ≥ .14 is considered a large effect.

Mood.

Average PHQ-8 across all participants ranged from 0–23, with an average PHQ-8=1.9 (SD=2.4). Telehealth patients reported slightly lower PHQ-8 scores (F2F PHQ-8=2.0, SD=2.5; telehealth PHQ-8=1.6, SD=2.1) although these scores are within the normal range. No difference in GAD-7 between groups was present (F2F GAD-7=1.4, SD=2.4; telehealth PHQ-8=1.4, SD=2.4). Using cutoffs of 10 or greater on either scale to identify clinically meaningful symptoms identified elevated PHQ-8 scores in 4 participants and elevated GAD-7 scores on 8 participants. The low levels of clinical endorsement are sufficiently infrequent to be statistically significant contributors to MoCA performances.

Discussion

This report provides additional evidence of telehealth MoCA assessment equivalence compared to traditional in-person F2F testing in a large sample of self-declared cognitively normal individuals. No significant group MoCA difference was present, with the average difference score between administration conditions only 0.10 point. Administration equivalence was also observed across MoCA domain scores. When statistically significant administration differences were present, they were associated with small effect sizes that are not considered to be clinically meaningful. The 95% CIs of the difference scores between administration conditions for all MoCA domain were 0.36 points or less. Future studies are needed to evaluate remote vs in-person MoCA use with smaller or demographically very different samples than the current study as these may result in different findings about the two modes of administration.

Options other than video telehealth MoCA testing are available to characterize cognitive status when F2F testing cannot be obtained including a telephone MoCA modification.26 Telephone assessment has important practical advantages over video telehealth since it can be administered without the need for video presentation, thereby expanding the pool of participants for whom testing can be conducted due to fewer technology requirements. As with other telephone based cognitive evaluations, however, telephone evaluation is likely most helpful in identifying patients for whom more detailed testing may be appropriate7,27.

The primary strength of this report is its robust sample size employing an independent group design. Obtaining the same results as those obtained with test-retest design but employing a different study design, each of which has specific advantages and disadvantages28, increases confidence that approaches provide the same outcome. Finally, this report includes a range of MoCA scores in patients without MCI or dementia diagnoses where overall performance variability is greater compared to patients with clearly established disease, who will have a narrower performance range due to disease related cognitive effects.

Supplementary Material

SUPINFO

Acknowledgements

Funding:

National Institute of Aging; R01 AG070937

Sponsor’s Role

This study was supported by Emory Healthy Brain Study R01 AG070937 awarded to Dr. Lah.

Other

We thank Najé Simama, Katherine Sanders, and Stephen Bowden for their assistance in manuscript preparation.

Table 1. Performance levels (standard deviations), Confidence Intervals, and Effect Sizes for MoCA Total, MoCA Domain scores, PHQ-8, and GAD-7

	F2F	Telehealth	95% CI	η	η 2	
MoCA Total	26.6 (2.4)	26.5 (2.4)	−0.16 – 0.34	.016	.000	
Memory	13.0 (2.4)	12.8 (1.2)	−0.13 – 0.36	.022	.000	
Executive	11.6 (1.4)	11.7 (1.3)	−0.25 – 0.03	.037	.001	
Attention/Concentration	16.9 (5.4)	16.9 (5.3)	−0.12 – 0.15	.004	.000	
Language	5.4 (0.8)	5.3 (0.8)	0.01 – 0.18	.056	.003	
Visuospatial	6.4 (0.8)	6.3 (0.9)	−0.01 – 0.17	.044	.002	
Orientation	5.9 (0.3)	5.8 (0.4)	0.03 – 0.11	.100	.010	
PHQ-8	2.0 (2.5)	1.6 (2.1)	0.16 – 0.62	.020	.000	
GAD-7	1.4 (2.4)	1.4 (2.4)	−0.15–0.35	.002	.000	
NOTE: Confidence Intervals for Visual Spatial and Orientation MoCA domains and for PHQ-8 are calculated based upon unequal variance assumptions due to significant Levene’s differences of variance inequality.

Key Point:

Zoom video telehealth administration of the MoCA did not introduce systematic performance differences compared to in-person testing in a group of demographically homogeneous older individuals who are self-identified as cognitively normal.

Why this study is important:

Telehealth patient care has increased during the pandemic and will likely continue to be an option after pandemic risks have receded since it provides improved patient access while simultaneously reducing travel burden. While there are multiple reports of successful telehealth cognitive patient evaluations, empirical support of equivalence between administration methods for specific tests is limited. Results from this large community cohort provide reassurance that administration mode does not introduce systematic performance differences for MoCA test administration, thereby permitting MoCA testing to be applied confidently for both clinical and research applications. Replication in more diverse samples is needed to determine whether these conclusions generalize to other groups and settings.

Supplementary Information Legends

Supplementary Text S1.

Conflict of Interest

Dr. Lah serves as a consultant for Roche Diagnostics. The other authors report no conflicts of interest.


References

1. Powers BB , Homer MC , Morone N , Edmonds N , Rossi MI . Creation of an Interprofessional Teledementia Clinic for Rural Veterans: Preliminary Data. J Am Geriatr Soc. May 2017;65 (5 ):1092–1099. doi:10.1111/jgs.14839 28295142
2. Cullum CM , Hynan LS , Grosch M , Parikh M , Weiner MF . Teleneuropsychology: evidence for video teleconference-based neuropsychological assessment. J Int Neuropsychol Soc. Nov 2014;20 (10 ):1028–33. doi:10.1017/s1355617714000873 25343269
3. Dupraz J , Le Pogam MA , Peytremann-Bridevaux I . Early impact of the COVID-19 pandemic on in-person outpatient care utilisation: a rapid review. BMJ Open. Mar 3 2022;12 (3 ):e056086. doi:10.1136/bmjopen-2021-056086
4. Geddes MR , O’Connell ME , Fisk JD , Gauthier S , Camicioli R , Ismail Z . Remote cognitive and behavioral assessment: Report of the Alzheimer Society of Canada Task Force on dementia care best practices for COVID-19. Alzheimer’s &amp; dementia (Amsterdam, Netherlands). 2020;12 (1 ):e12111. doi:10.1002/dad2.12111
5. Barbosa W , Zhou K , Waddell E , Myers T , Dorsey ER . Improving Access to Care: Telemedicine Across Medical Domains. Annu Rev Public Health. Apr 1 2021;42 :463–481. doi:10.1146/annurev-publhealth-090519-093711 33798406
6. Hewitt KC , Rodgin S , Loring DW , Pritchard AE , Jacobson LA . Transitioning to telehealth neuropsychology service: Considerations across adult and pediatric care settings. The Clinical Neuropsychologist. Oct-Nov 2020;34 (7–8 ):1335–1351. doi:10.1080/13854046.2020.1811891 32842849
7. Bilder RM , Postal KS , Barisa M , Inter Organizational Practice Committee Recommendations/Guidance for Teleneuropsychology in Response to the COVID-19 Pandemic†. Arch Clin Neuropsychol. Aug 28 2020;35 (6 ):647–659. doi:10.1093/arclin/acaa046 32666093
8. Marra DE , Hamlet KM , Bauer RM , Bowers D . Validity of teleneuropsychology for older adults in response to COVID-19: A systematic and critical review. Clin Neuropsychol. Oct-Nov 2020;34 (7–8 ):1411–1452. doi:10.1080/13854046.2020.1769192 32519594
9. Elbaz S , Cinalioglu K , Sekhon K , A Systematic Review of Telemedicine for Older Adults With Dementia During COVID-19: An Alternative to In-person Health Services? Frontiers in neurology. 2021;12 :761965. doi:10.3389/fneur.2021.761965 34970210
10. McCleery J , Laverty J , Quinn TJ . Diagnostic test accuracy of telehealth assessment for dementia and mild cognitive impairment. Cochrane Database Syst Rev. Jul 20 2021;7 (7 ):Cd013786. doi:10.1002/14651858.CD013786.pub2 34282852
11. Folstein MF , Folstein SE , McHugh PR . “Mini-mental state”. A practical method for grading the cognitive state of patients for the clinician. J Psychiatr Res. Nov 1975;12 (3 ):189–98. doi:10.1016/0022-3956(75)90026-6 1202204
12. Nasreddine ZS , Phillips N , Chertkow H , Normative data for the Montreal Cognitive Assessment (MoCA) in a population-based sample. Neurology. Mar 6 2012;78 (10 ):765–6. doi:78/10/765-a [pii]
13. Lindauer A , Seelye A , Lyons B , Dementia Care Comes Home: Patient and Caregiver Assessment via Telemedicine. Gerontologist. Oct 1 2017;57 (5 ):e85–e93. doi:10.1093/geront/gnw206
14. Chapman JE , Cadilhac DA , Gardner B , Ponsford J , Bhalla R , Stolwyk RJ . Comparing face-to-face and videoconference completion of the Montreal Cognitive Assessment (MoCA) in community-based survivors of stroke. J Telemed Telecare. Sep 2021;27 (8 ):484–492. doi:10.1177/1357633×19890788 31813317
15. Iiboshi K , Yoshida K , Yamaoka Y , A Validation Study of the Remotely Administered Montreal Cognitive Assessment Tool in the Elderly Japanese Population. Telemed J E Health. Jul 2020;26 (7 ):920–928. doi:10.1089/tmj.2019.0134 31746697
16. Abdolahi A , Bull MT , Darwin KC , A feasibility study of conducting the Montreal Cognitive Assessment remotely in individuals with movement disorders. Health Informatics J. Jun 2016;22 (2 ):304–11. doi:10.1177/1460458214556373 25391849
17. Feeney J , Savva GM , O’Regan C , King-Kallimanis B , Cronin H , Kenny RA . Measurement Error, Reliability, and Minimum Detectable Change in the Mini-Mental State Examination, Montreal Cognitive Assessment, and Color Trails Test among Community Living Middle-Aged and Older Adults. J Alzheimers Dis. May 31 2016;53 (3 ):1107–14. doi:10.3233/jad-160248 27258421
18. Weintraub S , Besser L , Dodge HH , Version 3 of the Alzheimer Disease Centers’ Neuropsychological Test Battery in the Uniform Data Set (UDS). Alzheimer Dis Assoc Disord. Jan-Mar 2018;32 (1 ):10–17. doi:10.1097/wad.0000000000000223 29240561
19. Goetz ME , Hanfelt JJ , John SE , Rationale and design of the Emory Healthy Aging and Emory Healthy Brain Studies. Neuroepidemiology. 2019;53 (3–4 ):187–200. doi:10.1159/000501856 31454799
20. Kroenke K , Strine TW , Spitzer RL , Williams JB , Berry JT , Mokdad AH . The PHQ-8 as a measure of current depression in the general population. J Affect Disord. Apr 2009;114 (1–3 ):163–73. doi:10.1016/j.jad.2008.06.026 18752852
21. Spitzer RL , Kroenke K , Williams JB , Löwe B . A brief measure for assessing generalized anxiety disorder: the GAD-7. Arch Intern Med. May 22 2006;166 (10 ):1092–7. doi:10.1001/archinte.166.10.1092 16717171
22. Julayanont P , Brousseau M , Chertkow H , Phillips N , Nasreddine ZS . Montreal Cognitive Assessment Memory Index Score (MoCA-MIS) as a predictor of conversion from mild cognitive impairment to Alzheimer’s disease. Journal of the American Geriatrics Society. Apr 2014;62 (4 ):679–84. doi:10.1111/jgs.12742 24635004
23. Goldstein FC , Milloy A , Loring DW . Incremental Validity of Montreal Cognitive Assessment Index Scores in Mild Cognitive Impairment and Alzheimer Disease. Dementia and Geriatric Cognitive Disordorders. Apr 11 2018;45 (1–2 ):49–55. doi:10.1159/000487131
24. Hewitt KC , Loring DW . Emory University telehealth neuropsychology development and implementation in response to the COVID-19 pandemic. The Clinical Neuropsychologist. Oct-Nov 2020;34 (7–8 ):1352–1366. doi:10.1080/13854046.2020.1791960 32660335
25. Perneger TV . What’s wrong with Bonferroni adjustments. BMJ. Apr 18 1998;316 (7139 ):1236–8. doi:10.1136/bmj.316.7139.1236 9553006
26. Klil-Drori S , Phillips N , Fernandez A , Solomon S , Klil-Drori AJ , Chertkow H . Evaluation of a Telephone Version for the Montreal Cognitive Assessment: Establishing a Cutoff for Normative Data From a Cross-Sectional Study. J Geriatr Psychiatry Neurol. May 2022;35 (3 ):374–381. doi:10.1177/08919887211002640 33858238
27. Carlew AR , Fatima H , Livingstone JR , Cognitive Assessment via Telephone: A Scoping Review of Instruments. Arch Clin Neuropsychol. Nov 19 2020;35 (8 ):1215–1233. doi:10.1093/arclin/acaa096 33106856
28. Winer BJ . Statistical Principles in Experimental Design. McGraw-Hill; 1962:672.
