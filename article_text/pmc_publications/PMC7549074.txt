LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


0370625
1170
Biometrics
Biometrics
Biometrics
0006-341X
1541-0420

32010968
7549074
10.1111/biom.13219
NIHMS1633908
Article
Partial least squares for functional joint models with applications to the Alzheimer’s disease neuroimaging initiative study
Wang Yue http://orcid.org/0000-0002-4847-8826
1
Ibrahim Joseph G. 2
Zhu Hongtu http://orcid.org/0000-0002-6781-2690
2
1 Department of Biostatistics, University of Washington, Seattle, Washington
2 Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina
Correspondence Yue Wang, Department of Biostatistics, University of Washington, Seattle, WA 98195. taryue@gmail.com
5 10 2020
03 2 2020
12 2020
01 12 2021
76 4 11091119
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Many biomedical studies have identified important imaging biomarkers that are associated with both repeated clinical measures and a survival outcome. The functional joint model (FJM) framework, proposed by Li and Luo in 2017, investigates the association between repeated clinical measures and survival data, while adjusting for both high-dimensional images and low-dimensional covariates based on the functional principal component analysis (FPCA). In this paper, we propose a novel algorithm for the estimation of FJM based on the functional partial least squares (FPLS). Our numerical studies demonstrate that, compared to FPCA, the proposed FPLS algorithm can yield more accurate and robust estimation and prediction performance in many important scenarios. We apply the proposed FPLS algorithm to a neuroimaging study. Data used in preparation of this article were obtained from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database.

high-dimensional data
longitudinal data
neuroimaging data
survival data

1 ∣ INTRODUCTION

Many prospective cohort studies and clinical trials investigating neurodegenerative diseases such as Alzheimer’s disease (AD) collect repeated measurements of clinical variables, event history, and biomedical imaging data. A motivating example is the Alzheimer’s Disease Neuroimaging Initiative (ADNI) study. ADNI currently has four phases: ADNI1, ADNI-GO, ADNI2, and ADNI3, and the primary goal is to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), and neuropsychological assessments can be used to measure the progression of AD. Participants were assessed at multiple visits. At each visit, various clinical measures, brain images, and neuropsychological assessments were collected.

As mild cognition impairment (MCI) is known as a transitional stage between normal cognition and AD, it is of great interest to predict the progression from MCI to AD. Thus, we selected 236 patients who had been diagnosed with MCI from ADNI1 without missing data in the covariates of interest. The selected patients had at least one Alzheimer’s Disease Assessment Scale-Cognitive (ADAS-Cog) score after the baseline measurement. The ADAS-Cog score measures cognition functions and ranges from 0 to 70, with a higher score indicating poorer cognitive function. We consider the AD diagnosis as the survival event of interest. Among the 236 individuals, 92 individuals progressed to AD before the completion of ADNI1 and the remaining 144 individuals did not. Thus, the time of conversion from MCI to AD can be treated as right censored time-to-event data and the censoring is non-informative about the progression to AD. Demographic information of the selected 236 patients and summary statistics of the ADAS-Cog score can be found in the Supporting Information.

Figure 1 displays the average ADAS-Cog score at each follow-up time separately for the MCI and AD group. It can be seen that the ADAS-Cog score increases with time for the AD group, whereas for the MCI group, the trend is not evident. The AD group tends to have higher ADAS-Cog scores, indicating that the ADAS-Cog score may be predictive to the progression of AD. Moreover, a lot of existing work reported the association between brain imaging predictors with the progression of AD. For example, AD and MCI patients were shown to have 27% and 11% smaller hippocampal volumes, respectively, as compared with normal controls (Du et al., 2001). Lee et al. (2015) and Kong et al. (2018) both demonstrated the predictive value of the hippocampus surface data to the progression of AD.

Thus, it is of great interest to examine the association between longitudinal ADAS-Cog scores and the progression of AD while adjusting for high-dimensional imaging predictors. Li and Luo (2017) proposed a functional joint model (FJM) for this purpose. FJM integrates functional regression models with joint models of longitudinal and time-to-event data. There is a rich literature in both areas. For instance, in the past decades, generalized functional linear models (GFLM) have been widely discussed and applied in various areas including finance, biology, and sociology. Please see Cardot et al. (1999, 2003), Müller and Stadtmüller (2005), and the references therein for an extensive review of GFLM. Then, Yao et al. (2005) extended GFLM to longitudinal data, and Lee et al. (2015) and Kong et al. (2018) both extended GFLM to the proportional hazards model. Some of the earliest work on joint models of longitudinal and time to event data is in Tsiatis et al. (1995) and Wulfsohn and Tsiatis (1997).

The major challenge of fitting a functional model, including FJM, is the ultrahigh dimensionality of the functional predictor. A common strategy is to find the “best” low-dimensional features that approximate the high-dimensional functional predictor, which is also known as dimension reduction. The functional principal component analysis (FPCA) has been a popular dimension-reduction tool for functional data over decades. See extensive reviews and applications of FPCA in Besse and Ramsay (1986), Ramsay and Dalzell (1991), Boente and Fraiman (2000), James et al. (2000), Hall and Hosseini-Nasab (2006), Müller and Yao (2010), Li and Luo (2017), and the references therein. Based on the eigen-decomposition of the covariance kernel of the functional data, FPCA finds the low-dimensional space that preserves most of the variation in the functional data; that is, the space spanned by top eigenfunctions. Although FPCA serves as a promising tool for exploring functional data, there are two major concerns when it comes to regression. First, as the unknown slope function may not necessarily lie in the space spanned by top eigenfunctions, the estimation and prediction accuracy may suffer if the number of eigenfunctions used for regression is underestimated. Second, it is well known that consistent estimation of eigenvectors is highly challenging in ultrahigh-dimensional settings (Jung and Marron, 2009), especially for tail eigenvectors. These two concerns bring up a natural question: if (part of) the unknown slope function lies in the space spanned by some tail eigenfunctions, which cannot be accurately estimated due to the limited sample size, is there an alternative and better approach to estimate the unknown slope function?

To address this question, we consider the functional partial least squares (FPLS), first proposed by Preda and Leveder (2005) for functional linear models (FLM). Compared to FPCA, FPLS has two major advantages. First, FPLS does not depend on accurate estimates of eigenfunctions. Second, FPLS incorporates information from the outcome so that the top FPLS basis functions are always the most predictive to the outcome. However, due to its computational and theoretical complexity, FPLS has not gained enough popularity until the recent work by Delaigle and Hall (2012) that proposes a simplified FPLS algorithm for FLM, called alternative PLS (APLS). Through numerical studies, Delaigle and Hall (2012) demonstrates that APLS can capture the interaction between the functional predictor and the outcome using a fewer number of components than FPCA.

Motivated by the encouraging performance of APLS, in this article, we propose an FPLS algorithm for the estimation and prediction of FJM. Our specific contributions include: (a) We extend APLS to the complex FJM framework in a rigorously mathematical manner; (b) we show by numerical studies that the proposed FPLS algorithm can yield considerably more accurate, robust estimation and prediction results than FPCA in many important scenarios; and (c) unlike the FPCA-based algorithm in Li and Luo (2017) that only handles baseline imaging data, our FPLS algorithm can deal with longitudinal imaging data; this allows to dynamically predict disease progression. The rest of the paper is organized as follows. Section 2 introduces the FPLS algorithm for FJM. Section 3 discusses the details of the implementation of the FPLS algorithm. Section 4 presents a simulation study with ultrahigh-dimensional images in various settings. Section 5 presents a thorough analysis of the selected 236 ADNI patients. Concluding remarks and discussions are presented in Section 6.

2 ∣ METHODS

In this section, we first introduce the FJM proposed by Li and Luo (2017). Then, we review APLS for FLM proposed by Delaigle and Hall (2012). Next, we extend APLS for FJM.

2.1 ∣ FJM

For each subject i = 1, … , n at visit k = 1, … , Ki, we observe {yik, xi, zik, ωi, Ti, Δi}, where yik is the outcome of interest observed at time tik, zik is a pz × 1 vector observed at tik, and ωi is a pω × 1 vector of time-invariant covariates, which may overlap with zik. The xi=(xi(s):s∈S) is baseline imaging (functional) data observed at a set of grid points in an nondegenerate, compact space S⊂RK for the ith subject, where K &gt; 0 is a positive integer. Ti is the observed survival time, defined as Ti=min{Ti∗,Ci}, where Ti∗ and Ci are, respectively, the true event time and censoring time. The event is observed if Δi = 1, and censored otherwise. It is assumed throughout the paper that the censoring mechanism is independent of the true event process.

The FJM in Li and Luo (2017) consists of a longitudinal model and a survival model. The longitudinal model is given by (1) yik=mi(tik)+ϵik=β0+zikTβ1+qikTui+∫Sxi(s)b0(s)ds+ϵik,

where mi(tik) is the unobserved true longitudinal trajectory of the ith subject at tik, qik is a subset of zik, β0 is the intercept, β1 is a pz × 1 vectors of regression coefficients, and b0(s) is the functional parameter that characterizes the association between xi(s) and yik. We also assume ui∼i.i.dN(0,Σu) and ϵik∼i.i.dN(0,σϵ2). The survival model is given by (2) λi(t∣ωi,xi(s),ui)=λ0(t)exp(ωiTγ+∫Sxi(s)b1(s)ds+αmi(t)),

where λ0(t) is an unknown baseline hazard function, γ is a pω × 1 vector of regression coefficients, and b1(s) is the functional parameter that characterizes the association between xi(s) and the survival outcome. The scalar parameter α quantifies the association between the true longitudinal trajectory and the survival process at the same time.

Remark 1. We discuss our assumptions on FJM (1) and (2). First, the longitudinal marker yik in (1) is assumed to be normally distributed, which is a standard assumption in the literature. The association between the longitudinal and time-to-event processes is represented by the proportional hazards model (2), in which mi(t) is assumed to be continuous. For definiteness, the conditional hazards function λi(t∣ωi, xi(s), ui) is taken to depend linearly on the longitudinal marker through the current mi(t).

Remark 2. The FJM (1) and (2) can be extended to a more general FJM framework as follows: (3) yik=mi(tik)+ϵik=β0+zikTβ1+qikTui+∫Sxi(l)(s,tik)b0(s)ds+ϵik

and (4) λi(t∣ωi,xi(s),ui)=λ0(t)exp(ωiTγ+∫Sxi(s)(s)b1(s)ds+αmi(t)).

Note that compared with (1), the longitudinal model (3) involves longitudinal imaging data. This extension is appealing in many applications because it allows dynamic prediction of disease progression. It is worth noting that the FPLS algorithm that will be introduced later can be seamlessly applied to this general FJM framework (3) and (4). But to simplify the notation, we stick to the FJM (1) and (2) in the following sections for illustrating our key ideas.

2.2 ∣ The APLS algorithm

We review APLS proposed by Delaigle and Hall (2012) for the following FLM: (5) y=a0+∫Sx(s)b(s)ds+ϵ,

where ϵ is a scalar random variable with E(ϵ∣x) = 0, a0 is an intercept, and b(s) is an unknown coefficient function. Let K(ψ)(t)=∫SK(s,t)ψ(s)ds be a functional operator where K(s,t) = Cov(x(s), x(t)). The first p APLS basis functions can be constructed as K(b), … , Kp(b), where Kj+1(b)(s)=∫SKj(b)(t)K(s,t)dt. Compared to the FPCA basis functions, that is, the eigenfunctions of K(s,t), the APLS basis functions have two important features. First, the APLS basis functions involve the unknown parameter b(s), indicating that the APLS basis functions incorporate information from both the functional predictor and the outcome. Second, the APLS basis functions are not orthonormal. To see the latter feature clearly, consider an example that x(s)=∑j=1∞θjξjϕj(s), where ξj∼i.i.dN(0,1). The θ1 ≥ θ2 ⋯ ≥ 0 is a sequence of nonincreasing eigenvalues and ϕ1(·), ϕ2(·), … are their corresponding orthonormal eigenfunctions. It can be seen that K(s,t)=Cov(x(s),x(t))=∑j=1∞θjϕj(s)ϕj(t). Write b(s)=∑j=1∞bjϕj(s), where bj=∫Sb(s)ϕj(s)ds. Then, it can be seen that the pth APLS basis function is given by Kp(b)(s)=∑j=1∞θjpbjϕj(s). Therefore, it can be checked that ∫SKk(b)(s)Kl(b)(s)ds=∑j=1∞θjk+lbj2&gt;0 for any k ≠ l, indicating that any two APLS basis functions are not orthogonal to each other.

Although b(s) is unknown, a consistent estimator of K(b)=∫SK(s,t)b(s)ds is given by (6) K(b)^(s)=n−1∑i=1n{xi(s)−x¯(s)}{yi−y¯},

where y¯=n−1∑i=1nyi and x¯(s)=n−1∑i=1nxi(s). Then, we can sequentially estimate all APLS basis functions by using Kj+1(b)^(t)=∫SKj(b)^(s)K^(s,t)ds for j ≥ 1, where K^(s,t)=n−1∑i=1n{xi(s)−x¯(s)}{xi(t)−x¯(t)}. Then, an estimator of b(s) in (5) using p APLS basis functions is given by b^p(s)=∑j=1pt^jKj(b)^(s), where (7) (t^1,…,t^p)=argmint1,…,tp∑i=1n{yi−y¯}−{∑j=1ptj∫SKj(b)^(s)[xi(s)−x¯(s)]ds}2.

2.3 ∣ The RAPLS algorithm

The APLS algorithm cannot be directly applied to FJM (1) and (2) due to two reasons. First, it does not adjust for additional scalar covariates. Second, the estimator K^(b)(s) in (6) is not a good estimator of K(b)(s) when the relationship between x(s) and y is nonlinear. To bridge the gap, we first extend the APLS algorithm to the following model: (8) yi=ziTα+∫Sxi(s)b(s)ds+ϵi,

where α is a pz × 1 vector of regression coefficients and ϵi is an error term with E(ϵi∣xi, zi) = 0 and E(ϵi2∣xi,zi)&lt;∞. It is assumed that zi includes a constant 1. To estimate b(s) and α, we develop a residual-based APLS (RAPLS) algorithm. Specifically, model (8) can be rewritten in the following matrix form: (9) Y=Zα+∫SX(s)b(s)ds+ϵ,

where ϵ = (ϵ1, … , ϵn)T, Y = (y1, … , yn)T, Z = [z1, … , zn]T, and X(s) = (x1(s), … , xn(s))T. Let HZ = Z(ZT Z)−1ZT be the orthogonal projection matrix onto the column space of Z and MZ = In − HZ, where In denotes an n × n identity matrix. By multiplying both sizes of (9) by MZ, we have (10) YZ⊥=MZY=∫SMZX(s)b(s)ds+MZϵ=∫SXZ⊥(s)b(s)ds+ϵZ⊥,

where ϵZ⊥=MZϵ. Model (10) can be regarded as a special case of model (5) with the response vector YZ⊥ and the functional covariate XZ⊥(s). In this case, we need to introduce a new functional operator as follows: KZ⊥(ψ)(t)=∫SKZ⊥(s,t)ψ(s)ds=∫S[K(s,t)−tr{[E(z⊗2)]−1E[zx(t)]E[zTx(s)]}]ψ(s)ds.

The operator KZ⊥(ψ)(t) corrects the correlation between z and x(s). If z and x(s) are independent, then KZ⊥(ψ) reduces to K(ψ). Therefore, the first p RAPLS basis functions for model (10) are given by (KZ⊥)(b),…,(KZ⊥)p(b). A consistent estimator of (KZ⊥)(b)(t) is given by (KZ⊥)(b)^(t)=n−1YZ⊥TXZ⊥(t).

Then, we can sequentially estimate all RAPLS basis functions by using (KZ⊥)j+1(b)^(t)=∫S(KZ⊥)j(b)^(s)KZ⊥^(s,t)dsfor1≤j≤p−1,

where K^Z⊥(s,t)=n−1XZ⊥T(s)XZ⊥T(t). Given (KZ⊥)(b)^(t),…,(KZ⊥)p(b)^(t), we define (t^1,z,…,t^p,z)=argmin(t1,…,tp)‖YZ⊥−∑j=1ptj∫S(KZ⊥)j(b)^(t)XZ⊥(t)ds‖2,

where ∥a∥2 = aTa for any column vector a. Therefore, one can estimate b(s) and α, respectively, by b^p(s)=∑j=1pt^j,z(KZ⊥)j(b)^(s) and α^p=(ZTZ)−1ZT[Y−∫SX(s)b^p(s)ds].

2.4 ∣ The FPLS algorithm for FJM

We develop an FPLS algorithm for the FJM (1) and (2) in an iterative way by integrating RAPLS with the iterative reweighted least squares (IRLS; Green, 1984). Before discussing the details, we introduce some additional notations. Let yi = (yi1, … , yiKi)T, zi = (zi1, … , ziKi), and qi = (qi1, … , qiKi). We define δi=qiTui+ϵi, where ϵi = (ϵi1, … , ϵiKi)T. Let 1Ki, denote a Ki × 1 vector of ones and Λ0(t)=∫0tλ0(u)du denote the cumulative baseline hazard function. Denote Θ = {β0, β1, γ, α, Σu, σϵ2} and let p0 and p1 be the number of RAPLS basis functions used for the estimation of b0(s) and b1(s), respectively. We further denote Θp0,p1(m), b0,p0(m)(s), b1,p1(m)(s) and Λ0,p0,p1(m)(⋅) as the evaluation of Θ, b0(s), b1(s), and Λ0(·), respectively, at the mth iteration for m ≥ 1. In the following discussion, we elaborate on how to obtain Θp0,p1(m), b0,p0(m)(s), b1,p1(m)(s), and Λ0,p0,p1(m)(⋅) given their values at the previous iteration for m ≥ 1 in three steps.

Step 1: We first rewrite model (1) as follows: (11) yi=1Kiβ0+ziTβ1+1Ki∫Sxi(s)b0(s)ds+δi.

It can be seen that Cov(δi∣zi,xi(s),qi)=qiΣuqiT+σϵ2IKi, referred to as Vi hereafter. Hence, given Θp0,p1(m), Vi can be evaluated as Vi(m) at the mth iteration. By multiplying {Vi(m)}−1∕2 to the left on both sides of (11), (11) can be reformulated as an ordinary least squares (OLS) problem, given by (12) {Vi(m)}−1∕2yi={Vi(m)}−1∕2(1Kiβ0+ziTβ1)+{Vi(m)}−1∕21Ki∫Sxi(s)b0(s)ds+{Vi(m)}−1∕2δi.

Note that (12) has the same form as (8), and thus we can calculate the top p0 RAPLS basis functions for (12). To simplify the notation, we denote these RAPLS basis functions by ψ1(m)(s),…,ψp(m)(s). Then, model (1) can be approximated by (13) yik=β0+zikTβ1+qikTui+∑j=1p0b0,j(∫Sxi(s)ψj(m)(s)ds)+ϵik,

and b0(s) can be approximated by ∑j=1p0b0,jψj(m)(s).

Step 2: We define μi=Λ0(Ti)exp(ωiTγ+∫Sxi(s)b1(s)ds+αmi(Ti))) for i = 1, … , n. Given Θp0,p1(m), b1,p1(m)(s) and Λ0,p0,p1(m)(⋅), μi, still cannot be evaluated because of the unobserved random effects ui in mi(Ti). To deal with this, for any integrable function h(ui), we define Ei(m){h(ui)}=E{h(ui)∣yi,Ti,Δi,Θp0,p1(m),b0,p0(m)(s),b1,p1(m)(s),Λ0,p0,p1(m)(⋅)}

as the posterior expectation of h(ui) at the mth iteration. Then, we can evaluate μi as μi(m)=Λ0,p0,p1(m)(Ti)×Ei(m){exp(ωiTγ+∫Sxi(s)b1(s)ds+αmi(Ti)))}.

Following IRLS, for i = 1, … , n, we can define the pseudoresponse y~i(m) for subject i at the mth iteration as (14) y~i(m)=∫Sxi(s)b1,p1(m)(s)ds+{μi(m)}−1(Δi−μi(m)).

We provide the details for deriving (14) in the Supporting Information. Next, we consider the following model: (15) {μi(m)}1∕2y~i(m)={μi(m)}1∕2∫Sxi(s)b1(s)ds+δi(m),fori=1,…,n.

Note that (15) has the same form as (8), and thus we calculate the top p1 RAPLS basis functions for (15), denoted by ζ1(m)(s),…,ζp(m)(s). Similar to Step 1, model (2) can be approximated by (16) λi(t∣ωi,xi(s),ui)=λ0(t)exp(ωiTγ+∑j=1p1b1,j(∫Sxi(s)ζj(m)(s)ds)+αmi(t)),

and b1(s) can be approximated by ∑j=1p1b1,jζj(m)(s).

Step 3: Note that FJM (1) and (2) are now, respectively, approximated by the standard joint model with low-dimensional covariates (13) and (16). Due to the unobserved random effects ui, we propose to fit (13) and (16) by the EM algorithm (Dempster et al., 1977). The details of the EM algorithm are given in the Supporting Information. Let Θp0,p1(m+1), Λ0,p0,p1(m+1)(⋅), b0,j(m+1), and b1,j(m+1) denote the EM estimates of Θ, Λ0(·), b0,j, and b1,j, respectively. Then, b0,p0(m+1)(s) and b1,p1(m+1)(s) are, respectively, given by (17) b0,p0(m+1)(s)=∑j=1p0b0,j(m+1)ψj(m)(s)andb1,p1(m+1)(s)=∑j=1p1b1,j(m+1)ζj(m)(s).

With appropriate initial values, the proposed FPLS algorithm for FJM is done by iterating between Steps 1- 3 until ∫S(b0,p0(m+1)(s)−b0,p0(m)(s))2ds+∫S(b1,p1(m+1)(s)−b1,p1(m)(s))2ds is less than a given threshold κ0, which is set to be 10−6 in the following numerical studies.

3 ∣ IMPLEMENTATION

3.1 ∣ Convergence

Based on our experience in numerical studies, we make several comments for facilitating the convergence of the proposed FPLS algorithm.

The stability of the proposed FPLS algorithm may suffer from the nonorthogonality of the RAPLS basis functions. As the key idea of the proposed FPLS algorithm is to find the low-dimensional space spanned by the RAPLS basis functions, we suggest orthogonalizing the RAPLS basis functions in Steps 1 and 2 before running the EM algorithm in Step 3.

As in most regression problems, it may be helpful to put all covariates on comparable scales. In particular, singular Hessian matrix may appear during the EM iterations (Step 3) if the two integrals ∫Sxi(s)ψj(m)(s)ds and ∫Sxi(s)ζj(m)(s)ds are vastly different from the scalar predictors. This may happen in practice if xi(s) is not appropriately scaled because these two integrals are approximated by summing over millions of grid points. We elaborate on the scaling process as follows. As suggested in the first comment, we can orthogonalize ψj(m)(s) and ζj(m)(s) such that ∫Sψj1(m)(s)ψj2(m)(s)ds=∫Sζj1(m)(s)ζj2(m)(s)ds=I(j1−j2). Then, by using the Cauchy-Schwarz inequality, it is easy to show that

∣∫Sx¯(s)ψj(m)(s)ds∣≤‖x¯(s)‖2and∣∫Sx¯(s)ζj(m)(s)ds∣≤‖x¯(s)‖2,

where ‖x¯(s)‖2=(∫Sx¯2(s)ds)1∕2. This implies that a sensible way to scale xi(s) is to multiply xi(s) by a constant such that ‖x¯i(s)‖2 has comparable size to the scalar predictors.

As for most iterative algorithms, an appropriate choice of initial values is critical for the convergence of the algorithm. We use the FPCA estimates as the initial values for the proposed FPLS algorithm. The key to finding the FPCA estimates is estimating the eigenfunctions. Unlike Li and Luo (2017), which advocates the fpca.sc function in the refund package (Goldsmith et al., 2018) or fpca.mle and fpca.score functions in the fpca package (Peng and Paul, 2011) in R, we use the method based on the singular value decomposition (SVD) proposed by Zipunnikov et al. (2011). The reason is that the two R packages advocated by Li and Luo (2017) can be computationally intensive with ultrahigh-dimensional images. For example, to perform FPCA for a data set with 200 subjects, each having a 300 × 300 image (the simulation study in Section 4), fpca.sc and fpca.mle require at least 60 GB of RAM memory and take hours to run, whereas the SVD method only requires less than 6 GB of RAM memory and finishes in seconds. Once the eigenfunctions are estimated, one can follow the method in Li and Luo (2017) to obtain the FPCA estimators.

We also suggest a step of stochastic approximation to accelerate the convergence. Specifically, instead of using (17) to obtain the updates b0,p0(m+1)(s) and b1,p1(m+1)(s), we consider b0,p0(m+1)(s)=(1−a(m))b0,p0(m)(s)+a(m)∑j=1p0b0,j(m+1)ψj(m)(s) and b1,p1(m+1)(s)=(1−a(m))b1,p1(m)(s)+a(m)∑j=1p1b1,j(m+1)ζj(m)(s). Here, a(m) is called the step size at the mth iteration. As demonstrated in Walk (1978), Yin and Zhu (1990), and the references therein, flexible step sizes can accelerate the convergence of the algorithm as well as stabilize the performance. In our numerical studies, we use a(m) = 1/m.

To apply the proposed FPLS algorithm to 2D or 3D images, one can vectorize them in any way as the proposed algorithm is invariant with respect to arbitrary vectorization of the images. In our real data analysis where each image has more than 500 000 voxels, each iteration of the proposed algorithm takes less than 1 min to run, and the entire algorithm becomes stable in a few steps.

3.2 ∣ Choice of p0 and p1

So far we have discussed the algorithm with predetermined p0 and p1. As demonstrated in Li and Luo (2017), changing p0 and p1 can have a large effect on the estimation accuracy of the parameters in FJM. Generally, smaller p0 and p1 may lead to a larger bias, whereas larger p0 and p1 may lead to a larger variance. To balance bias and variance, we use the Bayesian information criterion (BIC) to choose p0 and p1. Specifically, let Θ^p0,p1, b^0,p0(s), b^1,p1(s), and Λ^0,p0,p1(⋅) be the estimates of Θ, b0(s), b1(s), and Λ0(·). Then, the BIC statistic is defined as (24) BIC(p0,p1)=log(n)(p0+p1)−2∫log(Ln,com(Θ^p0,p1,b^0,p0(s),b^1,p1(s),))((Λ^0,p0,p1(⋅)))du1⋯un,

where Ln,com(Θ^p0,p1, b^0,p0(s), b^1,p1(s), Λ^0,p0,p1(⋅)) is the complete data likelihood, of which the explicit from is given in the Supporting Information. Numerically, we can use a grid search to find the optimal p0 and p1 that minimize BIC(p0, p1).

4 ∣ SIMULATION STUDY

In this section, we carry out a simulation study to compare the proposed FPLS algorithm with FPCA for FJM (1) and (2). For i = 1, … , n, we first independently simulated Xi(s) according to the generating process Xi(s)=∑k=19k−1∕4ξikϕk(s),ξik∼i.i.dN(0,1),s∈S,

where the eigenimages ϕk(s) are displayed in Figure 2 and S=[1,300]×[1,300]. These eigenimages can be thought of as 2D grayscale images with pixel intensities on the [0,1] scale. The black pixels are set to 1 and the white ones are set to 0. We generated Zi from a normal distribution with mean 0 and variance ξi22∕9. This indicates that Zi and Xi(s) are correlated. We denote mi(t)=β0+β1tij+Ziβ2+∫SXi(s)b0(s)ds+ui, where ui∼i.i.dN(0,1). Then, the true event time Ti was generated based on the proportional hazards model as follows: (18) λi(t∣Zi,Xi(s),ui)=exp{αmi(t)+∫SXi(s)b1(s)ds+Ziγ}.

Next, we independently generated the censoring time Ci from a uniform distribution U(0, c0), where c0 &gt; 0 controls the censoring rate. Instead of observing both Ti and Ci, we only observed T~i=min(Ti,Ci) and Δi = I(Ti ≤ Ci). Next, the longitudinal follow up time {tij}j=1,2,3 was simulated from a uniform distribution in (0,T~i), as only the measurements that are collected before the observed survival time can be used to predict the survival event. Then, the longitudinal outcome yij was generated by yi(tij)=mi(tij)+ϵij,

where ϵij∼i.i.dN(0,0.42). We set β0 = 0.7, β1 = 1, β2 = 2, α = 2, and γ = 2, and consider two scenarios of b0(s) and b1(s): (a) b0(s)=b1(s)=∑k=15k−3∕2ϕk(s) and (b) b0(s)=∑k=59(k−4)−1∕2ϕk(s), b1(s)=∑k=15k−1∕2ϕk(s).

We consider n = 200 and 500. The c0 is selected for each scenario to yield a censoring rate of 60% that mimics our real data analysis. For each pair of n and c0, we generated 1000 independent data sets. For simplicity, here we consider the same number of basis functions to estimate b0(s) and b1(s), that is, p0 = p1 = p. In practice, p0 and p1 can be different; this will be considered in the real data analysis in Section 5. The optimal p was then selected by the BIC statistic, given in Section 3.2. For the implementation of both FPLS and FPCA, generated images Xi(s)’s were unfolded to obtain vectors of size d = 300 × 300 = 90 000. As mentioned in Section 3.1, our implementation of FPCA is different from that in Li and Luo (2017), and the FPLS algorithm uses the FPCA estimates as the initial values.

We examined the mean squared error (MSE) for both functional parameters according to MSEbj=∫S(b^j(s)−bj(s))2ds, where b^j(s) is the FPCA or FPLS estimator of bj(s) for j = 0 and 1. Figure 3 shows results for scenario (a). In this scenario, both b0(s) and b1(s) are only informed by the top five eigenimages. The weight of the jth eigenimage, j−1.5, decreases fast as j increases; this further favors FPCA. It can be seen that the proposed FPLS algorithm performs comparably to FPCA: FPLS yields a more accurate estimate of b0(s), whereas FPCA performs slightly better in terms of estimating b1(s). This is sensible because the IRLS procedure used for the survival model may introduce more error. In scenario (b) that does not favor FPCA, as shown in Figure 4, the proposed FPLS algorithm has considerably higher estimation accuracy than FPCA for both b0(s) and b1(s). In particular, it can be seen from Figure 4C that our FPLS algorithm yields accurate estimation of b0(s), whereas FPCA yields an MSE over 2. A straightforward calculation yields that ∫Sb02(s)ds=2.28, indicating that FPCA can barely capture any information from b0(s). To see the reason clearly, we first note that b0(s) lies in the span of the fifth to the ninth eigenimages. Unfortunately, these eigenimages cannot be consistently estimated in such an ultrahigh-dimensional setting (d ≫ n). Thus, BIC tends to select small p (p &lt; 5) for FPCA, indicating that the resulting FPCA estimator is very close to 0. In contrast, as the FPLS basis functions incorporate information from the outcome, which contains information on b0(s), the FPLS algorithm can still yield an accurate estimate of b0(s) regardless of inconsistent estimation of the eigenimages. In practice, as we never know how the functional predictor informs the outcome, the proposed FPLS algorithm may be a more robust and accurate prediction tool, especially in neuroimaging studies with high-dimensional images and limited sample size.

5 ∣ ANALYSIS OF ADNI DATA

In this section, we jointly model the longitudinal trajectory of the ADAS-Cog score and the time of conversion from MCI to AD using the selected 236 subjects. Specifically, we consider yij=mi(tij)+ϵijwithmi(tij)=β0+ziTβ1+β2tij+∫Sxi(s)b0(s)ds+ui

and λi(t∣zi,xi(s))=λ0(t)exp(ziTγ+∫Sxi(s)b1(s)ds+αmi(t)).

Here, tij is the follow-up time for the ith subject at the jth visit and yij is the ADAS-Cog score of the ith subject at the jth visit. The scalar covariate vector zi includes gender (1 = male; 0 = female), handedness (1 = right; 0 = left), and age at the first MCI diagnosis. The functional predictor xi(s) is the PET imaging data measured on 160 × 160 × 96 voxels. PET directly measures the regional use of glucose, which indirectly reflects the brain activity of different brain regions. The PET images we used here underwent four preprocessing steps, which are introduced in detail in the Supporting Information. We also removed the background regions outside the skull, so around 500 000 voxels remained. The parameter α links the two models. If α is nonzero, then there may be an unobserved association between the longitudinal and survival outcome. The random intercept ui is assumed to be normally distributed with mean 0 and variance σu2. Given ui, ϵij follows a normal distribution with mean 0 and variance σϵ2. The implementation of FPCA and FPLS is the same as that in Section 4.

We first used cross validation to compare the proposed FPLS algorithm with FPCA in terms of prediction accuracy of the survival time. To examine the predictive value of the longitudinal ADAS-Cog scores, we also predicted the survival time based on the following functional linear Cox regression model (FLCRM; Kong et al., 2018): λi(t∣zi,xi(s))=λ0(t)exp(ziTγ+∫Sxi(s)b1(s)ds).

The prediction accuracy was examined according to the concordance index (C-index; Harrell et al., 1996), which can be calculated using the function "concordance.index()" in the R package "survcomp" (Schroeder et al., 2011). More specifically, we randomly selected 118 subjects as the training set and the remaining 118 subjects form the test set. We repeated this procedure 100 times. For each method in each replication, we fitted the FJM using the training set with the optimal number of basis functions, that is, p0 and p1, selected by BIC, and then computed the C-index using the test set. Inspecting Figure 5A shows that FPLS yields higher prediction accuracy than FPCA. Moreover, both FPLS and FPCA substantially outperform FLCRM, demonstrating that the ADAS-Cog score may be an important predictor of the progression from MCI to AD.

To examine the predictive value of PET imaging data, two reduced models are considered. The first reduced model excludes the imaging predictor from the longitudinal model, and the second one excludes the imaging predictor from the survival model, denoted by R1 and R2, respectively. Using the same training and testing data sets, we fitted these two reduced models using our FPLS algorithm with the optimal p0 or p1 selected by BIC and calculated the C-index. Figure 5B shows that two reduced models yield lower prediction accuracy than the FPLS in Figure 5A, demonstrating the predictive value of the PET imaging data in terms of jointly predicting ADAS-Cog scores and the progression to AD. Moreover, as we aim at predicting the survival outcome, the prediction accuracy suffers more when the imaging predictor is removed from the survival model.

Finally, we considered the complete cohort of 236 subjects to estimate the unknown parameters using our FPLS algorithm. The optimal p0 and p1 selected by BIC are 18 and 10, respectively. The estimated α is 2.8, indicating that patients with higher ADAS-Cog score may be more likely to progress to AD. Figure 6 displays the positive regions of the estimates of b0(s) and b1(s). It can be seen that several functional regions over the brain, such as the hippocampus, frontal lobe, and temporal horn of the lateral ventricle are identified to be positively associated with the progression from MCI to AD.

6 ∣ DISCUSSIONS

In this article, we developed a novel FPLS algorithm for the estimation and prediction of FJM. We examined its performance in simulation studies and an application to ADNI. As shown in the numerical studies, FPLS can yield comparable results to FPCA in the setting that strongly favors FPCA, whereas it yields accurate estimates in the setting where FPCA completely fails. Hence, the proposed FPLS algorithm may be a more robust and powerful prediction tool for FJM than FPCA when massive neuroimaging data are involved.

It should be noted, however, that it is very challenging to theoretically derive (asymptotic) confidence intervals of any FPLS-based estimators. The reason may be inherent to the key feature of FPLS; that is, the FPLS basis functions depend on the outcome. Consequently, the design matrix in FPLS regressions also involves the error term. Thus, bootstrapping methods have been suggested for constructing confidence intervals of PLS type of estimators (Wold et al., 2001). Further studies of the inferential problems associated with the proposed FPLS algorithm may be a fruitful area of future research.

Supplementary Material

Supp. material 2

Supp. Material 1

ACKNOWLEDGMENTS

Dr. Zhu’s work was partially supported by NIH grants R01MH086633 and R01MH116527. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH. Data used in preparation of this article were obtained from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database (http://adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf.

Funding information

NSF, Grant/Award Numbers: DMS-1407655, SES-1357666; NIH, Grant/Award Numbers: R01MH086633, R01MH116527

FIGURE 1 The ADAS-Cog score at year 0, 0.5, 1, 1.5, 2, 3, and 4 for both MCI and AD patients. At each time point, the score is averaged on those subjects who have not dropped out before this time point. This figure appears in color in the electronic version of this article, and any mention of color refers to that version

FIGURE 2 True grayscale eigenimages used in the simulation study

FIGURE 3 The boxplot of the MSE for scenario (a) over 1000 replications: A, n = 200 and MSEb0; B, n = 200 and MSEb1; C, n = 500 and MSEb0; D, n = 500 and MSEb1

FIGURE 4 The boxplot of the MSE for scenario (b) over 1000 replications: A, n = 200 and MSEb0; B, n = 200 and MSEb1; C, n = 500 and MSEb0; D, n = 500 and MSEb1

FIGURE 5 Boxplots of the C-index over 100 replications for the FPLS, FPCA, FLCRM, R1, and R2

FIGURE 6 Positive regions of the estimated coefficient images obtained from the FPLS algorithm with p0 = 18 and p1 = 10: The top and bottom rows display the positive regions of the estimated b0(s) and b1(s), respectively. From left to right, each coefficient is displayed in the views of transverse, coronal and sagittal planes. The slices are located at (48,80,80). This figure appears in color in the electronic version of this article, and any mention of color refers to that version

SUPPORTING INFORMATION

Web Appendices, Tables and Figures referenced in Sections 2.4 are available with this paper at the Biometrics website on Wiley Online Library. Our code and example data for implementing the FPLS algorithm are also available at the Biometrics website on Wiley Online Library.


REFERENCES

Besse P and Ramsay JO (1986) Principal components analysis of sampled functions. Psychometrika, 51 , 285–311.
Boente G and Fraiman R (2000) Kernel-based functional principal components. Statistics Probability Letters, 48 , 335–345.
Cardot H , Ferraty F , Mas A and Sarda P (2003) Testing hypotheses in the functional linear model. Scandinavian Journal of Statistics, 30 , 241–255.
Cardot H , Ferraty F and Sarda P (1999) Functional linear model. Statistics Probability Letters, 45 , 11–22.
Delaigle A and Hall P (2012) Methodology and theory for partial least squares applied to functional data. The Annals of Statistics, 34 , 2159–2179.
Dempster AP , Laird NM and Rubin DB (1977) Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, Series B, 39 , 1–38.
Du AT , Schuff N , Amend D , Laakso MP , Hsu YY , Jagust WJ , Yaffe K , Kramer JH , Reed B , Norman D , Chui HC and Weiner MW (2001) Magnetic resonance imaging of the entorhinal cortex and hippocampus in mild cognitive impairment and Alzheimer’s disease. The Journal of Neurology, Neurosurgery, and Psychiatry, 71 , 441–447.
Goldsmith J , Scheipl F , Huang L , Wrobel J , Gellar J , Harezlak J , McLean MW , Swihart B , Xiao L , Crainiceanu C and Reiss PT (2018) refund: Regression with Functional Data. R package version 0. 1–17.
Green PJ . (1984) Iteratively reweighted least squares for maximum likelihood estimation, and some robust and resistant alternatives. Journal of the Royal Statistical Society. Series B, 46 , 149–192.
Hall P and Hosseini-Nasab M (2006) On properties of functional principal components analysis. Journal of the Royal Statistical Society, Series B, 68 , 109–126.
Harrell FE , Lee KL and Mark DB (1996) Tutorial in biostatistics multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors. Statistics in Medicine, 15 , 361–387.8668867
James G , Hastie T and Sugar C (2000) Principal component models for sparse functional data. Biometrika, 87 , 587.
Jung S and Marron JS (2009) PCA consistency in high dimension, low sample size context. The Annals of Statistics, 37 , 4104–4130.
Kong D , Ibrahim JG , Lee E and Zhu H (2018) FLCRM: functional linear cox regression model. Biometrics, 74 , 109–117.28863246
Lee E , Zhu H , Kong D , Wang Y , Giovanello KS and Ibrahim JG (2015) Bflcrm: A Bayesian functional linear cox regression model for predicting time to conversion to Alzheimer’s disease. The Annals of Applied Statistics, 9 , 2153–2178.26900412
Li K and Luo S (2017) Functional joint model for longitudinal and time-to-event data: an application to Alzheimer’s disease. Statistics in Medicine, 36 , 3560–3572.28664662
Müller H-G and Stadtmüller U (2005) Generalized functional linear models. The Annals of Statistics, 33 , 774–805.
Müller H-G and Yao F (2010) Methodology and theory for partial least squares applied to functional data. Biometrika, 97 , 791–805.
Peng J and Paul D (2011) fpca: Restricted MLE for Functional Principal Components Analysis. R package version 0.2–1.
Preda C , Saporta G and Leveder C (2005) PLS classification of functional data. Computational Statistics and Data Analysis, 49 , 223–235.
Ramsay JO and Dalzell CJ (1991) Some tools for functional data analysis (with discussion). Journal of the Royal Statistical Society, 53 , 539–572.
Schroeder MS , Culhan AC , Quackenbush J and Haibe-Kains B (2011) survcomp: an R/Bioconductor package for performance assessment and comparison of survival models. Bioinformatics, 27 (22 ), 3206–3208.21903630
Tsiatis AA , DeGruttola V and Wulfsohn MS (1995) Modeling the relationship of survival to longitudinal data measured with error. Applications to survival and CD4 counts in patients with aids. Journal of the American Statistical Association, 90 , 27–37.
Walk H (1978) Martingales and the Robbins-Monro procedure in D[0, 1]. Journal of Multivariate Analysis, 8 , 430–452.
Wold S , Sjöström M and Eriksson L (2001) PLS-regression: a basic tool of chemometrics. Chemometrics and Intelligent Laboratory Systems, 58 , 109–130.
Wulfsohn MS and Tsiatis AA (1997) A joint model for survival and longitudinal data measured with error. Biometrics, 53 , 330–339.9147598
Yao F , Muller HG and Wang JL (2005) Functional linear regression analysis for longitudinal data. The Annals of Statistics, 33 , 2873–2903.
Yin G and Zhu Y (1990) On H-valued Robbins-Monro processes. Journal of Multivariate Analysis, 34 , 116–140.
Zipunnikov V , Caffo B , Yousem D , Davatzikos C , Schwartz B and Crainiceanu C (2011) Functional principal components model for high-dimensional brain imaging. Neuroimage, 58 , 772–784.21798354
