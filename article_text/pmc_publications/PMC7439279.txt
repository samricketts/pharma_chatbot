LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


0012737
4157
IEEE Trans Biomed Eng
IEEE Trans Biomed Eng
IEEE transactions on bio-medical engineering
0018-9294
1558-2531

31825859
7439279
10.1109/TBME.2019.2957921
NIHMS1613553
Article
Spatial-Temporal Dependency Modeling and Network Hub Detection for Functional MRI Analysis via Convolutional-Recurrent Network
Wang Mingliang
Lian Chunfeng
Yao Dongren
Zhang Daoqiang *
Liu Mingxia Senior Member IEEE *
Shen Dinggang Fellow IEEE *
M. Wang and D. Zhang are with the College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, Nanjing 211106, China. D. Yao is with Brainnetome Center and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China. C. Lian, M. Liu and D. Shen are with the Department of Radiology and BRIC, University of North Carolina at Chapel Hill, North Carolina 27599, USA. D. Shen is also with the Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, Republic of Korea.
* Corresponding authors: M. Liu (mxliu@med.unc.edu), D. Zhang (dqzhang@nuaa.edu.cn), and D. Shen (dgshen@med.unc.edu).
25 7 2020
06 12 2019
8 2020
01 8 2021
67 8 22412252
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Early identification of dementia at the stage of mild cognitive impairment (MCI) is crucial for timely diagnosis and intervention of Alzheimer’s disease (AD). Although several pioneering studies have been devoted to automated AD diagnosis based on resting-state functional magnetic resonance imaging (rs-fMRI), their performance is somewhat limited due to non-effective mining of spatial-temporal dependency. Besides, few of these existing approaches consider the explicit detection and modeling of discriminative brain regions (i.e., network hubs) that are sensitive to AD progression. In this paper, we propose a unique Spatial-Temporal convolutional-recurrent neural Network (STNet) for automated prediction of AD progression and network hub detection from rs-fMRI time series. Our STNet incorporates the spatial-temporal information mining and AD-related hub detection into an end-to-end deep learning model. Specifically, we first partition rs-fMRI time series into a sequence of overlapping sliding windows. A sequence of convolutional components are then designed to capture the local-to-global spatially-dependent patterns within each sliding window, based on which we are able to identify discriminative hubs and characterize their unique contributions to disease diagnosis. A recurrent component with long short-term memory (LSTM) units is further employed to model the whole-brain temporal dependency from the spatially-dependent pattern sequences, thus capturing the temporal dynamics along time. We evaluate the proposed method on 174 subjects with 563 rs-fMRI scans from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database, with results suggesting the effectiveness of our method in both tasks of disease progression prediction and AD-related hub detection.

Index Terms

Spatial-temporal dependency
neural network
Alzheimer’s disease
hub detection
resting-state functional MRI

I. Introduction

ALZHEIMER’S disease (AD), characterized by progressive cognitive and functional deficits, is one of the most common types of neurodegenerative disorders in the aging population [1]. As reported by the Alzheimer’s Association, AD has been the sixth-leading cause of death in the United States, and the death per year caused by AD is still increasing [2]. Although the progression of AD is irreversible, alleviation of specific symptoms is possible through timely diagnosis and intervention at the early stages, e.g., mild cognitive impairment (MCI). The Alzheimer’s disease Neuroimaging Initiative (ADNI) subdivides MCI subjects as early MCI (eMCI) and late MCI (lMCI), and various studies have proven that lMCI patients are relatively at a higher risk of progression to AD [3]–[7]. Reliable diagnosis across the full spectrum of AD progression (i.e., differentiating between eMCI, lMCI, and AD) is for sure of great clinical value (e.g., for timely intervention). However, it is a challenging task in practice, due to the insidious onset and diverse symptoms during the disease progression [8]–[10].

Resting-state functional magnetic resonance imaging (rs-fMRI) has been widely used in the assessment of AD progression [11]–[15], by providing a noninvasive way to sensitively detect functional changes in the brain before individuals progress to meet clinical criteria for dementia. Using rs-fMRI data, various learning-based methods have been proposed for automated AD diagnosis. Most of these methods typically use Pearson’s correlation based functional connectivity (FC) to characterize the temporal relationships between different brain regions during resting states [16], [17], under an implicit assumption that FC of the human brain is stationary throughout the whole fMRI recording period. Recent studies have shown that FC is dynamic rather than stationary [18], [19], and hence, many new efforts have shifted toward dynamic connectivity analysis. However, existing dynamic-connectivity based methods either focus on modeling local spatial dependency (i.e., between a given pair of regions-of-interest) or local temporal dynamic properties (i.e., longitudinal patterns of a specific brain region), without considering the global spatial-temporal patterns. It’s highly desired to capture the local-to-global spatial-temporal dependency from rs-fMRI time series, which may help explore how connections change in brain networks throughout the AD progression [20].

Apart from the modeling of stationary/dynamic FC properties, network hub connectivity uncovered by rs-fMRI is also drawing increasing attention in the neuroscience community as a dementia biomarker. Throughout the paper, the term “hub” denotes a node (w.r.t. a specific brain region) in a brain FC network that occupies a central position to reflect the global structure of this network [21], [22]. In practice, network hubs are crucial for optimal information flow in the brain, by effectively revealing communication and information integration across different brain regions [21], [23]. Recent studies suggest that brain hub connectivity is preferentially affected by AD [23], [24], considering that several hub regions in the brain (e.g., right precuneus and left hippocampus) have been shown to reveal significant abnormalities during the disease progression [25], [26]. Intuitively, explicitly exploring and modeling these AD-related hubs in brain FC networks could bring additional knowledge for the automated prediction of AD progression, while such kind of information is improperly ignored by most of the existing learning-based methods.

To this end, a novel deep learning architecture, i.e., Spatial-Temporal convolutional-recurrent neural Network (STNet), is proposed in this paper for end-to-end AD progression prediction and network hub detection using rs-fMRI time series. Our STNet can not only learn the local-to-global spatial dependencies between different brain regions (in terms of the functional time series of blood oxygen level-dependent signals) to explicitly detect AD-related network hubs, but also can model the dynamic FC patterns of the whole brain in temporal sequences. Fig. 1 shows the schematic diagram of our STNet model, which consists of three components, i.e., (a) partition of regional time series, (b) convolutional network component, and (c) recurrent network component. Specifically, to characterize the temporal variability of functional time series associated with a given brain region (see Fig. 1 (a)), we first divide rs-fMRI time series into multiple overlapping segments using fixed-size sliding windows. For each time-series segment (e.g., Seg 1), a specific convolutional component (ConvCom, see Fig. 1 (b)) is designed to sequentially model both the local node-centralized properties and the global high-level spatial properties of time series within each segment. To detect the disease-related hub regions, each node-based convolutional operator is accompanied by a unique kernel. Also, a channel-wise fusion strategy is employed to derive a holistic feature representation for each segment by integrating the local-to-global spatial properties. Furthermore, a recurrent component (see Fig. 1 (c)) is stacked on the longitudinally ordered holistic features for all time-series segments to capture the long-term temporal dynamics. In each RNN layer, the long short-term memory (LSTM) units are adopted to characterize the sequential dependency between those holistic features. Finally, a fully-connected layer, followed by softmax activation, is used to predict disease progression with the temporal-dynamic features produced by the recurrent network component. We have evaluated the proposed method on 174 subjects with 563 rs-fMRI scans from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database, with experimental results suggesting its effectiveness in both the tasks of disease progression prediction and AD-related hub detection.

The major contributions of this work are three-fold. First, a convolutional-recurrent network is designed to capture both the local (i.e., brain regions) and global (i.e., whole-brain) spatial-temporal dependency patterns from rs-fMRI time series. This is different from previous studies that ignore the essential global spatial-temporal information. Second, the proposed method can explicitly detect discriminative brain regions (i.e., network hubs) from brain FC networks, thereby providing a flexible solution to explore changes in functional connectivity throughout disease progression. Besides, the proposed method has been evaluated in both tasks of disease progression prediction and AD-related network hub detection using rs-fMRI time series, with results suggesting its effectiveness in comparison to state-of-the-art methods.

The remainder of this paper is organized as follows. In Section II, we first review related work on functional connectivity, and hub detection in the field of computer-aided brain disease diagnosis. Then, we describe the dataset used in this study, and present the STNet method in Section III. Experimental results and discussion are presented in Sections IV and V, respectively. Finally, we conclude this paper in Section VI.

II. Related Work

A. Functional Connectivity based Disease Diagnosis

Many efforts have been dedicated to investigating automated AD diagnosis based on rs-fMRI based functional connectivity (FC) networks. Functional connectivity is generally constructed based on pair-wise temporal correlation (typically quantified by Pearson’s correlation coefficient [27]) between blood oxygen level-dependent (BOLD) signals of different brain regions. Conventional methods usually assume that FC is temporally stationary within the entire scan period. For example, Jie et al. [28] introduced a graph-kernel-based approach by measuring the topological similarity between FCs to identify MCI patients from normal controls (NCs). Bi et al. [29] designed a random support vector machine (SVM) cluster method for AD identification. This method randomly selects samples and FC features to establish multiple SVMs, based on which an ensemble strategy is employed for the final prediction. Through the analysis of stationary FC, these conventional methods have shown great potential in understanding the functional abnormalities caused by AD/MCI [28]–[31]. However, growing evidence suggests that FC is in fact not stationary and the dynamic FC properties can more reliably monitor the changes of macroscopic neural activities underlying cognitive and behavioral decline [18], [19].

Recently, many efforts have shifted toward the dynamic FC analysis in AD progression prediction. To quantify dynamic FC changes over time, one common strategy is using sliding windows along the time axis [19], i.e., calculating FC in terms of observations (time-series segments) lying within a time window with a fixed length, and shifting this window to generate dynamic FCs. For example, Wee et al. [32] proposed a fused Lasso based sparse learning algorithm to jointly estimate the temporal dynamic FCs and extract local clustering coefficient (CC) of these FCs for eMCI identification via a linear SVM. Jie et al. [33] proposed to extract both local temporal and spatial variability from dynamic FCs as features, based on which a manifold regularized multi-task feature learning model is applied to jointly select the most important spatial-temporal features to construct a multi-kernel SVM for the prediction of AD progression. Although existing dynamic FC-based methods consider both spatial dependencies and temporal dynamics in the prediction of disease progression, those methods fail to capture the global temporal changing patterns of the whole brain (i.e., the longitudinal network-level patterns), and they also ignore the global spatial dependency (e.g., the spatial dependency between a specific region and all the other regions).

B. Hub Detection for Functional Connectivity Networks

In the literature of FC analysis, several studies have suggested that exploring hub regions can bring additional information to improve diagnosis performance and help understand the pathological mechanisms of brain diseases. For instance, Ma et al. [34] proposed an auto-weighted framework, i.e., multi-view graph embedding with hub detection (MVGE-HD), for brain FC analysis based on multi-modality data (i.e., fMRI and diffusion tensor imaging). This method learns a unified graph embedding across all views (i.e., modalities) while reducing the potential influence of the hubs on blurring the boundaries between node clusters in the graph, and thus hubs can be identified from the data. Wang et al. [35] proposed a connectivity network analysis method with discriminative hub detection (CNHD) for schizophrenia identification. They make trials to incorporate feature selection, classifier training, and hub detection into a unified framework, by which these three tasks could benefit each other. However, previous methods are designed for stationary FC analysis, which cannot model the dynamic property of functional connectivity networks.

III. Materials and Method

In this section, we first introduce the materials used in this work, and then present the proposed STNet as well as implementation details.

A. Materials

1) Data Acquisition:

The rs-fMRI time-series data collected from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database1 were studied in this paper. There are a total of 563 scans from 174 subjects, including 48 normal controls (NCs), 95 MCI, and 31 AD subjects. Notably, participants in this study were scanned at one or more visits, separated by at least half year, due to which these 563 scans can be categorized as 154 NC cases, 310 MCI (165 eMCI and 145 lMCI) cases, and 99 AD cases, respectively. For each scan, the in-plane image resolution is 2.29 – 3.31mm, slice thickness is 3.31mm, TE (echo time) is 30 ms, TR (repetition time) is 2.2 – 3.1 s, and the scanning time for each subject is 7 min (resulting in 140 volumes). The demographic information of these 563 scans is summarized in Table I.

2) Data Pre-processing:

The rs-fMRI scans for all studied subjects were pre-processed by a standard procedure using the FSL FEAT software2. Specifically, we first discarded the first 3 volumes for magnetization equilibrium before preprocessing, and then processed the remaining 137 volumes following a standard pipeline, including slice timing correction, head motion estimation, bandpass filtering, and regression of nuisance covariates (i.e., white matter, cerebrospinal fluid, and motion parameters). The subjects with a head motion &gt; 2.0 mm of maximal translation or 2.0° of maximal rotation were excluded. After that, we performed the structural skull stripping based on T1-weighted MRI and aligned the skull-stripped fMRIs onto the Montreal Neurological Institute (MNI) space. The fMRI data were then further spatially smoothed by a Gaussian kernel with full-width-at-half-maximum (FWHM) of 6 mm. Note that we did not perform scrubbing to data with a frame-wise displacement larger than 0.5 mm, since this would introduce additional artifacts. The subjects with more than 2.5 min of frame-wise displacement (FD&gt; 0.5) were excluded from further analysis. Finally, we extracted the mean rs-fMRI time series (with band-pass filtered 0.015 – 0.15 Hz) of a set of 116 pre-defined regions-of-regions (ROIs) based on the Automated Anatomical Labeling (AAL) template. Finally, the time series of BOLD signals from all ROIs were used as the input data of the proposed method.

B. Spatial-Temporal Convolutional-Recurrent Neural Network

As shown in Fig. 1, our proposed model consists of three components, including 1) generation of network input, i.e., rs-fMRI time series partition via sliding windows, 2) a convolutional component, and 3) a recurrent component. In this section, we introduce each module in detail.

We assume that the rs-fMRI time-series data for a subject is X=(x1,…,xN)T∈ℝN×M, where each vector xn∈ℝM contains the blood oxygen level dependent (BOLD) measurements of the n-th ROI at M successive time points. Here, N = 116 and M = 137 are the numbers of ROIs and time points (i.e., with each time point corresponding to a specific volume), respectively. Based on time-series data X, we construct a learning model to predict the disease progression by explicitly modeling the spatial-temporal information and detecting discriminative network hubs (i.e., ROIs) in X.

1) Partition of rs-fMRI Time Series: We first normalize the BOLD time series for each ROI as: (1) g(xn)=(xn−μn)/σn,

where μn and σn (n = 1, ⋯, N) denote the mean and standard deviation of the time-series signals for the n-th ROI, respectively. To characterize the temporal variability of the functional architecture associated with a set of given regions (Fig. 1 (a)), we then segment all rs-fMRI time series into T overlapping windows with the constant length of L. Specifically, we set the window size L as 30 time points and the overlap between two adjacent windows as 2 time points, by which S={Xt∈ℝN×L}t=1T denote the resulting time-series segments with T = 54. For each subject, a sequence of T time-series segments S will be treated as the input of the proposed network.

2) Convolutional Component: Using the time-series segments S as the input, our STNet model employs T convolutional components (ConvCom) to learn local-to-global spatial properties from time-series data, with each ConvCom corresponding to a specific segment. As shown in the right part of Fig. 1 (b), each ConvCom adopts three successive convolutional layers (with different roles) to learn a sequence of high-level holistic feature representations for each segment. It explicitly incorporates both local/global spatial properties to detect AD-related discriminative hub regions of the temporal functional connectivity at different time steps (i.e., for each Xt ⊂ S). Specifically, for the t-th segment, we regard each ROI as the center node, and the 1st layer in the proposed convolutional component employs local node-centralized convolution (with K channels) on Xt to learn the correlations between the time series of each central ROI (e.g., the i-th row of Xt) and any other ROIs (e.g., the j-th row of Xt). The k-th (k = 1, ⋯, K) channel for the t-th segment in this convolutional operation can be defined as: (2) Fi,jk=σ(Wik*xit*xjt)=σ(∑l=0L−1Wi,lkxi,ltxj,lt)

where Wik represents the learnable weights (size: 1 × L) for the k-th convolutional kernel, xit and xjt are the time-series segments for the i-th and j-th ROIs, respectively, the operation * denotes the dot product, and Fi,jk is the learned correlation between the i-th and j-th ROIs. Considering that hub regions often make specific contributions to the overall distribution of the functional connectivity [36], we thus learn a unique set of filters for each central ROI and share these filters (for the same central ROI) across all time steps to automatically identify and differentiate these hub regions. Given K channels at each segment, we can construct K dynamic functional connectivity (FC) networks, where the connectivities between each ROI and all the remaining N − 1 ROIs are learned in a data-driven manner (via Eq. 2) and the connectivity between a specific ROI and itself is set to be 0.

Based on the local spatial patterns (for an ROI) learned from the 1st layer, i.e., an (N − 1) × K matrix learned by Eq. 2, the 2nd layer applies global node-centralized convolution to further mining the higher-level spatial property of each central ROI, i.e., the joint spatial dependency between the central ROI and all remaining ROIs. Here, the global node-centralized convolutional filters (with C channels) for each central ROI are also unique and shared across time steps, aiming to identify AD-related hub regions with specific contributions in the whole brain network. Different from the 1st layer, the filters in this 2nd layer are general convolutional kernels with the size of (N − 1) × 1, and the output of the 2nd layer for each ROI is a 1 × C tensor. Given N ROIs, we can generate a tensor F∈ℝN×C via the 2nd layer.

In the 3rd layer, we integrate the global spatial patterns of all ROIs (i.e., F derived from the 2nd layer) to derive a high-level holistic feature representation (i.e., an N × H tensor) for each time-series segment Xt. Considering that the rs-fMRI time-series signals are usually noisy, a specific fusion strategy with a channel-wise sparse-constraint is designed to this end, instead of treating all input C channels equally. Specifically, for the feature F generated by the 2nd layer, the channel-wise feature aggregation in the 3rd layer is performed as follows (3) u=V*F

where V is a to-be-learned kernel with the size of 1 × 1. For simplicity, V is penalized by the ℓ1-norm sparse constraint on each channel, which helps to reduce the negative influence of noisy input channels on the holistic feature representation. Therefore, the output of the 3rd layer for each segment is a holistic feature representation, i.e., a N × H tensor. Given T segments, we can finally obtain the holistic feature representation for each subject, i.e., N × T × H tensor.

3) Recurrent Component: To model the temporal dynamical patterns of brain activity, we cast the holistic feature representation (i.e., the output of the convolutional component) into a longitudinally ordered sequence, which is then processed by the recurrent component of our STNet model (Fig. 1 (c)). In this component, we use long short-term memory (LSTM) units to capture the temporal sequential patterns, considering that they can properly address exploding and vanishing gradient issues of traditional RNN [37], [38]. The architecture of the LSTM RNN used in this study is illustrated in Fig. 1 (c), including three stacked LSTM layers and one fully-connected layer. The stacked LSTM layers (with 16, 8, and 4 neurons, respectively) are used to encode the holistic functional feature representation for the learning of the temporal dynamics along time steps. Each of these LSTMs is followed by batch normalization and tanh activation. Finally, the fully-connected layer (with P neurons and followed by softmax) is employed to learn a mapping between the dynamical feature representation and the disease progression prediction (with P categories).

C. Implementation Details

The proposed network was implemented using Python based on the Keras package3, and the model was trained on a single GPU (NVIDIA GeForce GTX TITAN) with 12GB of memory. In each convolutional component, the numbers of channels for the three convolutional layers were set as K = 16, C = 8, and H = 1, respectively, to control the number of learnable parameters. Each convolutional layer was followed by batch normalization, rectified linear unit (ReLU) activation, and 0.5 dropout. In the recurrent component, the numbers of neurons for each LSTM unit of the three layers were 16, 8, and 4, respectively. Each recurrent layer was followed by batch normalization, tanh activation, and 0.5 dropout. Based on the output of the stacked RNN, a fully-connected layer with P neurons (corresponding to the number of categories) was employed to predict the progression of AD. The sigmoid and softmax were used as the activation functions of the last fully-connected layer for the binary and multi-class classification tasks, respectively. The Adam optimizer with recommended parameters was used for training, and the number of epochs and batch size were empirically set as 200 and 16, respectively.

IV. Experiments

A. Methods for Comparison

In the experiments, we compare our STNet method with the following six methods, including three baseline methods and three variants of the proposed model.

Clustering Coefficient (CC) [39]: In this method, a stationary functional connectivity (FC) network/matrix (size: 116×116) was first constructed for each subject by computing the Pearson correlation coefficient between the time series of any pair of ROIs. Then, local clustering coefficients of the stationary FC network were extracted as features, by measuring the degree of each node in the FC network. The vectorized local clustering coefficients extracted from all nodes/ROIs were then concatenated and fed into a support vector machine (SVM) for disease progression prediction.

Lasso [40]: In this method, a stationary FC network was first constructed for each subject. Then, the upper triangle and diagonal elements (i.e., correlation of an ROI to itself) were removed from the stationary FC matrix, and the remaining parts were converted into a vectorized feature representation for each subject. To reduce feature dimension, Lasso was used to select a discriminative subset of features from the vectorized feature representation, followed by SVM for AD prediction. The parameter for the sparsity constraint in Lasso was chosen from the range of {2−3, ⋯, 23} via cross-validation.

CNN: In this method, the stationary FC matrix for each subject was directly used as the input to construct a CNN model [41]. Specifically, the CNN model was implemented to contain three convolutional layers and three fully-connected layers. The three convolutional layers had 16, 8 and 1 channel(s), and the corresponding filters had the size of 11 × 11, 5 × 5, and 3 × 3, respectively. The first two fully-connected layers contained 64 and 32 neurons, respectively. Similar to our STNet model, the last fully-connected layer (with P neurons) of this CNN model was followed by the sigmoid/softmax normalization for binary/multi-class disease prediction.

STNet-T: As a variant of STNet, STNet-T was implemented without considering the temporal dynamics along time steps. That is, we replaced the stacked RNN layers in STNet with two fully-connected layers with 64 and 32 neurons, respectively.

STNet-D: To evaluate the influence of our constructed dynamic FC networks in STNet (via the 1st Conv layer in the proposed convolutional component), the STNet-D method was implemented by using pre-constructed dynamic FCs [18] as the input data, while the remaining network architecture was the same as that in STNet.

STNet-C: This variant employed the same architecture as our STNet model, but without using the proposed channel-wise sparse-constraint fusion strategy. Specifically, STNet-C did not activate the channel-wise sparse constraint (i.e., V in Eq. 3 without ℓ1-norm constraint) for the fusion operation in the 3rd convolutional layer of each convolutional component.

Note that these methods (i.e., CC, Lasso, CNN and STNet-D) relied on a pre-defined stationary/dynamic FC network(s) (size: 116 × 116) for each subject, with each element in this matrix denoting the Pearson correlation coefficient between the time series of any pair of ROIs. In contrast, our STNet and its two variants (i.e., STNet-T and STNet-C) worked directly on the rs-fMRI time-series data, without the need for pre-computing FC matrices. The SVM classifiers used in CC and Lasso adopted a linear kernel with default parameters.

B. Experimental Settings

In this study, we employed a 5-fold cross-validation strategy [42] to evaluate the performances of different methods. Specifically, all subjects were partitioned into 5 subsets (with each subset having a roughly equal size). Each subset was sequentially selected as the test set, while remaining subsets were combined to construct the training set. In addition, we further randomly spit 15% training subjects as the validation data to determine the optimal parameters for each method. Such process was repeated five times independently to avoid any bias introduced by the random partitioning of the data in the cross-validation process. Note that, no test data was used in such cross-validation process. The classification results were finally averaged over all iterations.

To evaluate the efficacy of the proposed STNet model, we conducted experiments on both binary and multi-class classification tasks, including 1) AD vs. NC classification, 2) lMCI vs. eMCI classification, 3) AD vs. MCI vs. NC classification, and 4) AD vs. lMCI vs. eMCI vs. NC classification. The binary classification performance was measured by seven criteria, i.e., classification accuracy (ACC), sensitivity (SEN), specificity (SPE), balanced accuracy (BAC), positive predictive value (PPV), negative predictive value (NPV), and the area under the receiver operating characteristic (ROC) curve (AUC) [43]. Let TP, TN, FP and FN be True Positive, True Negative, False Positive, and False Negative, respectively. Those evaluation metrics can be defined as: ACC=(TP+TN)/(TP+TN+FP+FN), SEN=TP/(TP+FN), SPE=TN/(TN+FP), BAC=(SEN+SPE)/2, PPV=TP/(TP+FP), and NPV=TN/(TN+FN), respectively. The performance of multi-class disease classification was evaluated by the overall accuracy for multiple categories and the accuracy for each category. For these metrics, higher values indicate better classification performance.

C. Classification Performance

The quantitative results achieved by different methods in the binary and multi-class classification tasks are reported in Table II and Table III, respectively. The ROC curves in the binary classification task are further plotted in Fig. 2. In the Supplementary Materials, we further report the running time of different methods and the confusion matrices for multi-class classification.

From Tables II–III and Fig. 2, one could have three main observations. First, our proposed method and its variants (i.e., STNet-T, STNet-D, and STNet-C) generally achieved better performance, compared to the baseline methods (i.e., CC, Lasso, and CNN) in both binary and multi-class tasks. For example, in terms of ACC values, STNet achieved the improvement of 9.72% and 9.15%, compared with the best baseline method (i.e., CNN) in AD vs. NC classification and lMCI vs. eMCI classification, respectively. The proposed method also yielded the best overall ACC of 71.76% and 60.67% for AD vs. MCI vs. NC and AD vs. lMCI vs. eMCI vs. NC classification, respectively, which largely outperformed the best baseline methods (with 68.66% and 53.18% for the two tasks, respectively). These results demonstrate that explicitly modeling the spatial-temporal information inherent in rs-fMRI time series to capture AD-related hub regions in brain FC is beneficial in the prediction of disease progression. Second, our proposed STNet and its variants STNet-D and STNet-C outperformed those methods without considering the temporal dynamics (e.g., CNN and STNet-T) in terms of most metrics. In particular, the SEN values produced by our STNet for AD vs. NC and lMCI vs. eMCI classification are 96.67% and 80.95%, respectively, which are higher than other competing methods. These results suggest that the recurrent component of our STNet can effectively capture dynamic changes in rs-fMRI time series measurements. Note that high SEN values should be a practically meaningful advantage for timely diagnosis at the early stage of AD (e.g., the identification of eMCI). Finally, our STNet generally achieved better performance than its variants STNet-D and STNet-C, especially in terms of ACC values. These results imply that the data-driven construction of dynamic FCs and the channel-wise feature fusion strategies help boost the learning performance of STNet.

D. Constructed Functional Connectivity

The proposed method can construct dynamic FC networks in a data-driven manner, which is different from previous studies that rely on pre-defined FC networks (e.g., via Pearson’s correlation) [32], [33], [35]. We now further investigated the FC networks constructed by the proposed STNet method. Specifically, the output of the first covolutional layer in the proposed convolutional component (see Fig. 1 (b)) denotes the local node-centralized connection between each central node/ROI and all the remaining N − 1 ROIs. Therefore, we can construct a fully-connected FC network based on the connectivity vector (i.e., the learned node-centralized connection) for each central ROI, where the connectivity between a specific ROI and itself is set to 0. Since there are K = 16 channels in the local node-centralized convolutional layer, we can construct K = 16 FC networks for each subject, with each network corresponding to a specific channel. For simplicity, we averaged the FC networks across all time periods for each channel. It is worth noting that, since the constructed FCs are different in each 5-fold cross-validation, we calculated the cumulative weight as the functional connectivity value. Finally, using the standard t-test, we measured the group difference of lMCI vs. eMCI and AD vs. NC, with p-values shown in Fig. 3 and Fig. 4, respectively. For comparison, in Figs. 3–4, we also report the group difference of the stationary FC network (in terms of the Pearson correlation coefficients for rs-fMRI time-series signals of different brain ROIs [16]) and averaged dynamic FCs (generated by separating time series into multiple overlapping segments to calculate the Pearson correlation for each segment [18]), respectively. In Figs. 3–4, the obtained p-values were binarized (i.e., setting p-values more than 0.05 to 1; and 0, otherwise) for clarity.

From Figs. 3–4, we can derive several interesting observations by comparing the FCs learned by our STNet with the traditional stationary FC and dynamic FCs. First, there are more discriminative functional connectivities (i.e., the green parts) in both inter-group analyses, which indicates that our proposed STNet can identify more AD-related discriminative connectivities. Second, there is a significant difference of the connectivity patterns between the two groups. For example, the discriminative connectivities for the AD vs. NC groups focus on the hippocampus, middle frontal gyrus, thalamus, and medial orbital part of superior frontal gyrus etc., while those for the lMCI vs. eMCI groups focus on the supplementary motor area, posterior cingulate gyrus, cuneus, and precuneus etc. These findings are consistent with previous studies on AD/MCI classification [29], [44]–[46], and the difference between two groups also demonstrates that the functional connectivity is increasingly affected by AD along the disease progression. Finally, there are few discriminative functional connectivities between the cerebellum region (index of ROIs located in the interval [91, 116] within the AAL template) and other brain regions, which indicate that the cerebellum might also be associated with AD and thus can provide useful information for the prediction of AD progression [47], [48].

E. Comparison with State-of-the-Art Methods

We also compare the results achieved by our method with several state-of-the-art results reported in the literature on the ADNI dataset. Since very few works report multi-class classification results, we only report the results of AD vs. NC and lMCI vs. eMCI in Table IV, where we also list the details of each method, including the imaging modality and number of subjects that have been used. From Table IV, we can see that our STNet method generally outperforms state-of-the-art studies in both two classification tasks. More specifically, STNet yields the best accuracy (i.e., 90.28% and 79.36%) and sensitivity (i.e., 96.67% and 80.95%) in AD vs. NC and lMCI vs. eMCI tasks, respectively. Although researchers in [33], [49] reported higher specificity and AUC, their results were quantified on a relatively smaller dataset. Note that our method is the first one to mine and utilize the spatial-temporal information and underlying hub structure for time-series-based brain disease diagnosis, while previous methods simply ignore this valuable information or only focus on one aspect of these characterizes. It is also worth noting that the results in Table IV are not fully comparable, since these compared methods were performed using different numbers of subjects and data modalities.

V. Discussion

In this section, we first analyze the discriminative functional connectivities and hub regions discovered by the proposed method, and then discuss the limitations of this work and the possible future research directions.

A. Discriminative Functional Connectivity Patterns

We now investigate the effectiveness of our STNet method in identifying discriminative FC patterns that are strongly correlative with AD progression. Since we employed a 5-fold cross-validation strategy, we chose the cumulative absolute weight on all folds as the contribution indicator for each FC. Specifically, with 16 FC matrices (the outputs of the local node-centralized convolutional layer), we first compute the average FCs among multiple segments for each subject, and treat these values as the contribution indicator of each connectivity pattern for two classification tasks (i.e., AD vs. NC and lMCI vs. eMIC). For both tasks, we show the top 10 identified FC patterns in Fig. 5, and list the names of the corresponding brain ROIs in Table V.

From Fig. 5 and Table V, we can see that several brain regions, including the left medial orbital part of the superior frontal gyrus (ORBsupmed.L), left caudate nucleus (CAU.L), right middle frontal gyrus (MFG.R), hippocampus (HIP), left orbital part of the Inferior frontal gyrus (ORBinf.L), left triangular part of inferior frontal gyrus (IFGtriang.L) and left inferior temporal gyrus (ITG.L), were highlighted by our method in AD vs. NC classification. In previous studies [29], [44], [54], [55], these regions have also been reported to be highly associated with AD progression. For example, the hippocampal atrophy has been confirmed to be relevant to AD in various studies [56]–[58]. On the other hand, in the task of lMCI vs. eMCI classification, several brain regions were frequently identified by our method, including the median cingulate and paracingulate gyri (DCG), right calcarine fissure and surrounding cortex (CAL.R), left posterior cingulate gyrus (PCG.L), left superior occipital gyrus (SOG.L), left precuneus (PCUN.L) and lingual gyrus (LING). These findings are consistent with the clinical knowledge regarding the pathological pathway of AD, suggesting that our method is effective in identifying AD-related FC patterns [45], [55]. To sum up, the FC patterns identified by our method are highly suggestive and effective for tracking the progression of AD/MCI, and strongly agree with existing research findings.

B. Detected Network Hubs

We further study the efficacy of our STNet method in identifying FC hub regions that are informative in AD/MCI diagnosis. As shown in Fig. 1 (c), the input of the recurrent component is a N-dimensional vector for each segment, with each element in this vector denoting the holistic feature learned from a specific ROI. That is, such kind of feature can be used as a measure to evaluate the contribution of each ROI. Therefore, in this work, we can regard ROIs with larger contributions along all time-series segments as hub regions. In Fig. 6 (a), we show the contributions of different ROIs in each time-series segment, where the horizontal and vertical axis denote the index of ROIs and time-series segments, respectively, and different colors indicate specific contributions of different brain regions for disease progression prediction. Correspondingly, the overall contribution of each brain region among all time-series segments is calculated in Fig. 6 (b), where the horizontal and vertical axis denote index of ROIs and corresponding contribution value, respectively.

As can be seen from Fig. 6 (a), several hub regions show their constant importance along the whole time series, including the right middle frontal gyrus (MFG.R), left anterior cingulate and paracingulate gyri (ACG.L), left hippocampus (HIP.L), left lingual gyrus (LING.L), right inferior occipital gyrus (IOG.R), right angular gyrus (ANG.R) and right precuneus (PCUN.R). The importance of these hub regions in AD diagnosis has been reported in previous studies [24]–[26], [59], suggesting that our method can produce reliable results in hub detection from functional time-series data. The relatively high contribution values of these discriminative hub regions are also demonstrated in Fig. 6 (b).

C. Limitations and Future Work

Several technical issues need to be considered in the future to further improve the performance of the proposed method. First, we currently extract time series from the 116 ROIs partitioned based on the AAL template, while there are still many other types of templates that are commonly used in AD disease progression prediction. It is interesting to investigate whether other ROI partition strategies can influence the final performance. Second, following previous studies [33], we focus on using only rs-fMRI data for automated identification of AD/MCI in this work. Actually, different image modalities (e.g., structural MRI and fluorodeoxyglucose PET) can provide complementary information for AD/MCI diagnosis [60]. It’s also interesting to take advantage of multi-modality information for AD/MCI analysis, which will be our future work. Third, although we use all rs-fMRI scans of all subjects from ADNI, the size of the dataset is still limited. As the future work, we will evaluate the proposed method on larger dataset with other brain diseases, such as autism spectrum disorder.

VI. Conclusion

In this paper, we propose an end-to-end Spatial-Temporal convolutional-recurrent neural Network (STNet) for AD progression prediction using rs-fMRI time-series data. Specifically, a convolutional component is used to model the spatial dependency between the time-series segments of different brain regions. It not only learns the high-level spatial dependency patterns but also identify hub regions to guide the learning of spatial relationships. After that, we further employ a recurrent component with the long short-term memory (LSTM) units to capture the temporal dynamics patterns of functional connectivities along multiple time segments. Experimental results on 563 rs-fMRI scans from the ADNI database demonstrate that our method can not only improve the classification performance compared with state-of-the-art methods, but also provide new insights into the underlying pathological cascade in AD.

Supplementary Material

supp1-2957921

M. Wang and D. Zhang were supported in part by the National Natural Science Foundation of China (Nos. 61732006, 61876082, 61861130366, and 61703301), the Royal Society-Academy of Medical Sciences Newton Advanced Fellowship (No. NAF\R1\180371), the Fundamental Research Funds for the Central Universities (No. NP2018104), the National Key R&amp;D Program of China under Grant (Nos. 2018YFC2001600, 2018YFC2001602). C. Lian, M. Liu and D. Shen were supported in part by NIH grants (Nos. AG041721, EB022880).

Fig. 1. Illustration of our spatial-temporal convolutional-recurrent neural network with rs-fMRI time series (blood oxygen level-dependent signals from N brain regions), containing 3 components: (a) partitioning rs-fMRI time series into T segments via overlapped sliding windows; (b) T convolutional components (ConvCom), where each ConvCom contains three cascaded convolutional layers to hierarchically capture local node-centralized properties and global spatial properties of functional connectivity within each time window, as well as to automatically detect disease-related network hubs; and (c) a recurrent component to capture global/whole-brain temporal dynamics of the complete time series. With the output of the recurrent component, a fully-connected layer is further used to perform disease classification (with P denoting the number of categories).

Fig. 2. ROC curves achieved by seven different methods in (a) AD vs. NC classification, and (b) lMCI vs. eMCI classification.

Fig. 3. Group difference (i.e., p-values in t-test) based on functional connectivity networks constructed using different methods in AD vs. NC groups. Here, brain regions denoted as green means that there is significant difference (i.e., p &lt; 0.05 in t-test) between AD and NC groups. The term F1I(i=1,⋯,16) corresponds to the group difference based on dynamic functional connectivities learned by the i-th channel in the first layer of the proposed convolutional component in STNet. The sub-figure named “Stationary FC” denote the group difference based on networks constructed using the method in [16], while the sub-figure named “Dynamic FC” represents the group difference based on networks constructed using the method in [18].

Fig. 4. Group difference (i.e., p-values in t-test) based on functional connectivity networks constructed using different methods in lMCI vs. eMCI groups. Here, brain regions denoted as green means that there is significant difference (i.e., p &lt; 0.05 in t-test) between lMCI and eMCI groups. The term F1I(i=1,⋯,16) corresponds to the group difference based on dynamic functional connectivities learned by the i-th channel in the first layer of the proposed convolutional component in STNet. The sub-figure named “Stationary FC” denote the group difference based on networks constructed using the method in [16], while the sub-figure named “Dynamic FC” represents the group difference based on networks constructed using the method in [18].

Fig. 5. Top 10 brain functional connectivity patterns identified by STNet in the tasks of (a) AD vs. NC and (b) lMCI vs. eMCI classification.

Fig. 6. Heat maps (i.e., contributions) of different ROIs along all time-series segments (a) and overall contributions of ROIs among all segments (b) learned by our STNet method in AD vs. NC classification. The blue color denotes smaller contribution of each brain region for classification, while the yellow color denotes larger contribution. Regions with large contributions are regarded as hub regions in this work.

TABLE I Demographic information of the studied 563 rs-fMRI scans from the ADNI Database. The values are denoted as mean±standard deviation. M/F: Male/Female.

Category	Scan #	Age (Years)	Gender (M/F)	
AD	99	75.04 ± 7.71	55/44	
eMCI	165	72.03 ± 7.26	73/92	
lMCI	145	71.99 ± 7.67	95/50	
NC	154	75.36 ± 6.16	67/87	

TABLE II Performance of binary disease identification with rs-fMRI time series data

Task	Method	ACC (%)	SEN (%)	SPE (%)	AUC (%)	BAC (%)	PPV (%)	NPV (%)	
	CC	74.17	89.33	46.67	72.00	68.00	75.52	73.33	
	Lasso	76.11	88.67	53.33	83.33	71.00	77.38	80.00	
AD vs. NC	CNN	80.56	85.33	73.33	84.89	79.33	88.57	84.00	
STNet-T	78.33	84.67	66.67	84.89	75.67	85.29	80.33	
	STNet-D	78.33	81.33	73.33	88.89	77.33	84.67	68.33	
	STNet-C	82.78	88.00	73.33	84.00	80.67	87.43	85.33	
	STNet (Ours)	90.28	96.67	80.00	89.78	88.33	90.00	95.00	
	CC	57.72	52.86	65.00	53.43	58.93	67.62	50.67	
	Lasso	65.09	74.29	52.00	72.64	63.14	68.33	68.00	
lMCI vs. eMCI	CNN	70.21	68.10	74.00	74.52	71.05	77.79	66.43	
STNet-T	71.21	60.48	87.00	81.14	73.73	90.95	63.93	
	STNet-D	72.88	66.19	82.00	77.60	74.10	87.43	66.00	
	STNet-C	74.52	72.86	77.00	77.05	74.93	84.10	69.78	
	STNet (Ours)	79.36	80.95	77.00	83.21	78.98	83.81	73.67	

TABLE III Performance of multi-class disease identification with rs-fMRI time series data. For each task, the first column is the the overall accuracy performance and each of the remaining columns reports the classification accuracy for each individual class.

Method		AD vs. MCI vs. NC (%)			AD vs. lMCI vs. eMCI vs. NC (%)		
ACC	ACC nc	ACC mci	ACC ad	ACC	ACCnc	ACC eMCI	ACC imci	ACC ad	
CC	52.47	22.00	74.52	26.67	38.78	40. 00	34.29	51.00	26.67	
Lasso	60.03	32.00	82.67	26.67	43.60	28.67	52.86	55.00	33.33	
CNN	68.66	50.67	83.83	46.67	53.18	50.00	69.05	35.00	53.33	
STNet-T	65.33	47.33	77.00	53.33	52.13	54.67	47.62	42.00	73.33	
STNet-D	69.67	58.00	83.36	46.67	57.55	46.67	62.86	57.00	66.67	
STNet-C	68.81	38.00	88.52	53.33	56.40	66.00	56.67	41.00	60.00	
STNet (Ours)	71.76	51.33	85.33	60.00	60.67	66.67	60.00	47.00	73.33	

TABLE IV Comparison with state-of-the-art methods for binary classification task (i.e., AD vs. NC and lMCI VS. eMCI). sMRI: Structural MRI; PET: Positron Emission Tomography. VAE: Variational Auto-encoder; AE: Auto-encoder; DBN: Deep Belief Networks; MLP: Multi-Layer Perceptron; SLRM: Stepwise Linear Regression Model; LDA: Linear Discriminant Analysis; STVF: Spatial Temporal Variability Feature.

Task	Method	Data Modality	Subject #	ACC (%)	SEN (%)	SPE (%)	AUC (%)	
	VoxCNN [50]	sMRI	50 NC + 61 AD	79.00	-	-	88.00	
	ResNet [50]	sMRI	50 NC + 61 AD	80.00	-	-	87.00	
	VAE+MLP [51]	sMRI	90 NC + 150 AD	84.00	73.00	89.00	-	
AD vs. NC	
	AE+SVM [52]	sMRI	65 NC + 77 AD	87.76	88.57	87.22	-	
	DBN+SVM [49]	sMRI, PET	70 NC + 68 AD	90.00	86.00	94.00	95.00	
	STNet (Ours)	rs-fMRI	99 NC + 154 AD	90.28	96.67	80.00	89.78	
lMCI vs. eMCI	ResNet [50]	sMRI	77 eMCI + 43 lMCI	52.00	-	-	52.00	
VoxCNN [50]	sMRI	77 eMCI + 43 lMCI	56.00	-	-	47.00	
VAE+MLP [51]	sMRI	160 eMCI + 160 lMCI	63.00	62.00	66.00		
SLRM+LDA [53]	sMRI, Cognitive scores	114 eMCI + 91 lMCI	73.60	74.30	72.70	-	
STVF+SVM [33]	rs-fMRI	56 eMCI + 41 lMCI	78.80	74.40	82.10	78.30	
STNet (Ours)	rs-fMRI	165 eMCI + 145 lMCI	79.36	80.95	77.00	83.21	

TABLE V Names of brain ROIs in the top ten connectivity patterns of AD vs. NC groups and lMCI vs. eMCI groups. ROI: Region-of-interest.

Task	Index of Pairwise ROIs	ROI Names	
	15 &amp; 75	ORBinf.L &amp; PAL.L	
	71 &amp; 8	CAU.L &amp; MFG.R	
	71 &amp; 13	CAU.L &amp; IFGtriang.L	
	64 &amp; 25	SMG.R &amp; ORBsupmed.L	
	60 &amp; 37	SPG.R &amp; HIP.L	
AD vs. NC	
	25 &amp; 8	ORBsupmed.L &amp; MFG.R	
	38 &amp; 60	HIP.R &amp; SPG.R	
	23 &amp; 8	SFGmed.L &amp; MFG.R	
	89 &amp; 26	ITG.L &amp; ORBsupmed.R	
	66 &amp; 48	ANG.R &amp; LING.R	
lMCI vs. eMCI	15 &amp; 75	ORBinf.L &amp; PAL.L	
71 &amp; 8	CAU.L &amp; MFG.R	
71 &amp; 13	CAU.L &amp; IFGtriang.L	
64 &amp; 25	SMG.R &amp; ORBsupmed.L	
60 &amp; 37	SPG.R &amp; HIP.L	
25 &amp; 8	ORBsupmed.L &amp; MFG.R	
38 &amp; 60	HIP.R &amp; SPG.R	
23 &amp; 8	SFGmed.L &amp; MFG.R	
89 &amp; 26	ITG.L &amp; ORBsupmed.R	
66 &amp; 48	ANG.R &amp; LING.R	

1 http://adni.loni.usc.edu/

2 http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FEAT

3 https://github.com/fchollet/keras


References

[1] Tarawneh R and Holtzman DM , “The clinical problem of symptomatic Alzheimer disease and mild cognitive impairment,” Cold Spring Harbor Perspectives in Medicine, vol. 2 , no. 5 , p. a006148, 2012.22553492
[2] Association A , “2016 Alzheimer’s disease facts and figures,” Alzheimer’s and Dementia, vol. 12 , no. 4 , pp. 459–509, 2016.
[3] Fan Y , Rao H , Hurt H , Giannetta J , Korczykowski M , Shera D , Avants BB , Gee JC , Wang J , and Shen D , “Multivariate examination of brain abnormality using both structural and functional MRI,” NeuroImage, vol. 36 , no. 4 , pp. 1189–1199, 2007.17512218
[4] Aisen PS , Petersen RC , Donohue M , and Weiner MW , “ADNI 2 clinical core: Progress and plans,” Alzheimer’s Dementia, vol. 11 , no. 7 , pp. 734–739, 2015.
[5] Anderson ND , Murphy KJ , and Troyer AK , Living with mild cognitive impairment: A guide to maximizing brain health and reducing risk of dementia Oxford University Press, 2012.
[6] Liu M , Zhang J , Adeli E , and Shen D , “Joint classification and regression via deep multi-task multi-channel learning for Alzheimer’s disease diagnosis,” IEEE Transactions on Biomedical Engineering, vol. 66 , no. 5 , pp. 1195–1206, 2018.30222548
[7] Liu M , Zhang J , Nie D , Yap P-T , and Shen D , “Anatomical landmark based deep feature representation for MR images in brain disease diagnosis,” IEEE Journal of Biomedical and Health Informatics, vol. 22 , no. 5 , pp. 1476–1485, 2018.29994175
[8] Robinson L , Tang E , and Taylor J-P , “Dementia: Timely diagnosis and early intervention,” BMJ, vol. 350 , pp. 1–6, 2015.
[9] Lian C , Zhang J , Liu M , Zong X , Hung S-C , Lin W , and Shen D , “Multi-channel multi-scale fully convolutional network for 3d perivascular spaces segmentation in 7T MR images,” Medical Image Analysis, vol. 46 , pp. 106–117, 2018.29518675
[10] Liu M , Zhang D , and Shen D , “Relationship induced multi-template learning for diagnosis of Alzheimer’s disease and mild cognitive impairment,” IEEE Transactions on Medical Imaging, vol. 35 , no. 6 , pp. 1463–1474, 2016.26742127
[11] Rombouts S , Barkhof F , Van Meel C , and Scheltens P , “Alterations in brain activation during cholinergic enhancement with rivastigmine in Alzheimer’s disease,” Journal of Neurology, Neurosurgery and Psychiatry, vol. 73 , no. 6 , pp. 665–671, 2002.
[12] Damoiseaux JS , “Resting-state fMRI as a biomarker for Alzheimer’s disease?” Alzheimer’s Research and Therapy, vol. 4 , no. 8 , pp. 1–2, 2012.
[13] Machulda M , Ward H , Borowski B , Gunter J , Cha R , Obrien P , Petersen R , Boeve B , Knopman D , Tang-Wai D , “Comparison of memory fMRI response among normal, MCI, and Alzheimer’s patients,” Neurology, vol. 61 , no. 4 , pp. 500–506, 2003.12939424
[14] Jie B , Zhang D , Gao W , Wang Q , Wee C-Y , and Shen D , “Integration of network topological and connectivity properties for neuroimaging classification,” IEEE Transactions on Biomedical Engineering, vol. 61 , no. 2 , pp. 576–589, 2013.
[15] Wee C-Y , Yap P-T , Zhang D , Wang L , and Shen D , “Group-constrained sparse fMRI connectivity modeling for mild cognitive impairment identification,” Brain Structure and Function, vol. 219 , no. 2 , pp. 641–656, 2014.23468090
[16] Jie B , Liu M , Zhang D , and Shen D , “Sub-network kernels for measuring similarity of brain connectivity networks in disease diagnosis,” IEEE Transactions on Image Processing, vol. 27 , no. 5 , pp. 2340–2353, 2018.29470170
[17] Wang M , Zhang D , Huang J , Yap P-T , Shen D , and Liu M , “Identifying autism spectrum disorder with multi-site fMRI via low-rank domain adaptation,” IEEE Transactions on Medical Imaging, 2019.
[18] Zhang J , Cheng W , Liu Z , Zhang K , Lei X , Yao Y , Becker B , Liu Y , Kendrick KM , Lu G , “Neural, electrophysiological and anatomical basis of brain-network variability and its characteristic changes in mental disorders,” Brain, vol. 139 , no. 8 , pp. 2307–2321, 2016.27421791
[19] Hutchison RM , Womelsdorf T , Allen EA , Bandettini PA , Calhoun VD , Corbetta M , Della Penna S , Duyn JH , Glover GH , Gonzalez-Castillo J , “Dynamic functional connectivity: Promise, issues, and interpretations,” NeuroImage, vol. 80 , pp. 360–378, 2013.23707587
[20] Si S , Wang B , Liu X , Yu C , Ding C , and Zhao H , “Brain network modeling based on mutual information and graph theory for predicting the connection mechanism in the progression of Alzheimer’s disease,” Entropy, vol. 21 , no. 3 , p. 300, 2019.
[21] van den Heuvel MP and Sporns O , “Network hubs in the human brain,” Trends in Cognitive Sciences, vol. 17 , no. 12 , pp. 683–696, 2013.24231140
[22] Dai ZJ , Bi YC , and He Y , “With great brain hub connectivity comes great vulnerability,” CNS Neuroscience and Therapeutics, vol. 21 , no. 7 , pp. 541–542, 2015.26096045
[23] Stam CJ , “Modern network science of neurological disorders,” Nature Reviews Neuroscience, vol. 15 , no. 10 , pp. 683–695, 2014.25186238
[24] Buckner RL , Sepulcre J , Talukdar T , Krienen FM , Liu H , Hedden T , Andrews-Hanna JR , Sperling RA , and Johnson KA , “Cortical hubs revealed by intrinsic functional connectivity: Mapping, assessment of stability, and relation to Alzheimer’s disease,” Journal of Neuroscience, vol. 29 , no. 6 , pp. 1860–1873, 2009.19211893
[25] Dai Z , Yan C , Li K , Wang Z , Wang J , Cao M , Lin Q , Shu N , Xia M , Bi Y , “Identifying and mapping connectivity patterns of brain network hubs in Alzheimer’s disease,” Cerebral Cortex, vol. 25 , no. 10 , pp. 3723–3742, 2014.25331602
[26] de Haan W , Mott K , van Straaten EC , Scheltens P , and Stam CJ , “Activity dependent degeneration explains hub vulnerability in Alzheimer’s disease,” PLoS Computational Biology, vol. 8 , no. 8 , p. e1002582, 2012.22915996
[27] Van Den Heuvel MP and Pol HEH , “Exploring the brain network: A review on resting-state fMRI functional connectivity,” European Neuropsychopharmacology, vol. 20 , no. 8 , pp. 519–534, 2010.20471808
[28] Jie B , Zhang D , Wee C-Y , and Shen D , “Topological graph kernel on multiple thresholded functional connectivity networks for mild cognitive impairment classification,” Human Brain Mapping, vol. 35 , no. 7 , pp. 2876–2897, 2014.24038749
[29] Bi X , Shu Q , Sun Q , and Xu Q , “Random support vector machine cluster analysis of resting-state fMRI in Alzheimer’s disease,” PloS One, vol. 13 , no. 3 , p. e0194479, 2018.29570705
[30] Bai F , Watson DR , Yu H , Shi Y , Yuan Y , and Zhang Z , “Abnormal resting-state functional connectivity of posterior cingulate cortex in amnestic type mild cognitive impairment,” Brain Research, vol. 1302 , pp. 167–174, 2009.19765560
[31] Campbell NL , Unverzagt F , LaMantia MA , Khan BA , and Boustani MA , “Risk factors for the progression of mild cognitive impairment to dementia,” Clinics in Geriatric Medicine, vol. 29 , no. 4 , pp. 873–893, 2013.24094301
[32] Wee C-Y , Yang S , Yap P-T , and Shen D , “Sparse temporally dynamic resting-state functional connectivity networks for early MCI identification,” Brain Imaging and Behavior, vol. 10 , no. 2 , pp. 342–356, 2016.26123390
[33] Jie B , Liu M , and Shen D , “Integration of temporal and spatial properties of dynamic connectivity networks for automatic diagnosis of brain disease,” Medical Image Analysis, vol. 47 , pp. 81–94, 2018.29702414
[34] Ma G , Lu C , He L , Yu PS , and Ragin AB , “Multi-view graph embedding with hub detection for brain network analysis,” in IEEE International Conference on Data Mining (ICDM), 2017, pp. 967–972.
[35] Wang M , Huang J , Liu M , and Zhang D , “Functional connectivity network analysis with discriminative hub detection for brain disease identification,” in Association for the Advancement of Artificial Intelligence (AAAI), 2019.
[36] Sporns O , Honey CJ , and Kotter R , “Identification and classification¨ of hubs in brain networks,” PloS one, vol. 2 , no. 10 , p. e1049, 2007.17940613
[37] Hochreiter S and Schmidhuber J , “Long short-term memory,” Neural Computation, vol. 9 , no. 8 , pp. 1735–1780, 1997.9377276
[38] Hochreiter S , “The vanishing gradient problem during learning recurrent neural nets and problem solutions,” International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, vol. 6 , no. 02 , pp. 107–116, 1998.
[39] Wee CY , Yap PT , Zhang D , Denny K , Browndyke JN , Potter GG , Welshbohmer KA , Wang L , and Shen D , “Identification of MCI individuals using structural and functional connectivity networks,” NeuroImage, vol. 59 , no. 3 , pp. 2045–2056, 2012.22019883
[40] Hastie T , Tibshirani R , and Friedman J , The Elements of Statistical Learning Springer New York Inc, 2001.
[41] LeCun Y , Boser B , Denker JS , Henderson D , Howard RE , Hubbard W , and Jackel LD , “Backpropagation applied to handwritten zip code recognition,” Neural computation, vol. 1 , no. 4 , pp. 541–551, 1989.
[42] Pereira F , Mitchell T , and Botvinick M , “Machine learning classifiers and fMRI: A tutorial overview,” NeuroImage, vol. 45 , no. 1 , pp. S199–S209, 2009.19070668
[43] Fletcher RH , Fletcher SW , and Fletcher GS , Clinical epidemiology: The essentials. Lippincott Williams and Wilkins, 2012.
[44] Son S-J , Kim J , and Park H , “Structural and functional connectional fingerprints in mild cognitive impairment and Alzheimer’s disease patients,” PloS One, vol. 12 , no. 3 , p. e0173426, 2017.28333946
[45] Xiang J , Guo H , Cao R , Liang H , and Chen J , “An abnormal resting-state functional brain network indicates progression towards Alzheimer’s disease,” Neural Regeneration Research, vol. 8 , no. 30 , pp. 2789–2799, 2013.25206600
[46] Cai S , Huang L , Zou J , Jing L , Zhai B , Ji G , von Deneen KM , Ren J , and Ren A , “Changes in thalamic connectivity in the early and late stages of amnestic mild cognitive impairment: A resting-state functional magnetic resonance study from ADNI,” PloS One, vol. 10 , no. 2 , p. e0115573, 2015.25679386
[47] Aksenov MY and Markesbery WR , “Changes in thiol content and expression of glutathione redox system genes in the hippocampus and cerebellum in Alzheimer’s disease,” Neuroscience Letters, vol. 302 , no. 2–3 , pp. 141–145, 2001.11290407
[48] Wang Z , Yan C , Zhao C , Qi Z , Zhou W , Lu J , He Y , and Li K , “Spatial patterns of intrinsic brain activity in mild cognitive impairment and Alzheimer’s disease: A resting-state functional MRI study,” Human Brain Mapping, vol. 32 , no. 10 , pp. 1720–1740, 2011.21077137
[49] Ortiz A , Munilla J , Gorriz JM , and Ramirez J , “Ensembles of deep learning architectures for the early diagnosis of the Alzheimer’s disease,” International Journal of Neural Systems, vol. 26 , no. 07 , pp. 1650025:1–23, 2016.27478060
[50] Korolev S , Safiullin A , Belyaev M , and Dodonova Y , “Residual and plain convolutional neural networks for 3D brain MRI classification,” in International Symposium on Biomedical Imaging (ISBI). IEEE, 2017, pp. 835–838.
[51] Shakeri M , Lombaert H , Tripathi S , and Kadoury S , “Deep spectral-based shape features for Alzheimer’s disease classification,” in International Workshop on Spectral and Shape Analysis in Medical Imaging. Springer, 2016, pp. 15–24.
[52] Liu S , Liu S , Cai W , Pujol S , Kikinis R , and Feng D , “Early diagnosis of Alzheimer’s disease with deep learning,” in International Symposium on Biomedical Imaging (ISBI). IEEE, 2014, pp. 1015–1018.
[53] Goryawala M , Zhou Q , Barker W , Loewenstein DA , Duara R , and Adjouadi M , “Inclusion of neuropsychological scores in atrophy models improves diagnostic classification of Alzheimer’s disease and mild cognitive impairment,” Computational Intelligence and Neuroscience, vol. 2015 , pp. 1–14, 2015.
[54] Wang M , Zhang D , Shen D , and Liu M , “Multi-task exclusive relationship learning for Alzheimer’s disease progression prediction with longitudinal data,” Medical Image Analysis, vol. 53 , pp. 111–122, 2019.30763830
[55] Sun Y , Bi Q , Wang X , Hu X , Li H , Li X , Ma T , Lu J , Chan P , Shu N , and Han Y , “Prediction of conversion from amnestic mild cognitive impairment to Alzheimer’s disease based on the brain structural connectome,” Alzheimer’s and Dementia: The Journal of the Alzheimer’s Association, vol. 9 , no. 1178 , pp. 1–15, 2019.
[56] Duchesne S , Caroli A , Geroldi C , Collins DL , and Frisoni GB , “Relating one-year cognitive change in mild cognitive impairment to baseline MRI features,” NeuroImage, vol. 47 , no. 4 , pp. 1363–1370, 2009.19371783
[57] Convit A , De AJ , de Leon MJ , Tarshish CY , De SS , and Rusinek H , “Atrophy of the medial occipitotemporal, inferior, and middle temporal gyri in non-demented elderly predict decline to Alzheimer’s disease,” Neurobiology of Aging, vol. 21 , no. 1 , pp. 19–26, 2000.10794844
[58] Lian C , Liu M , Zhang J , and Shen D , “Hierarchical fully convolutional network for joint atrophy localization and Alzheimer’s disease diagnosis using structural MRI,” IEEE Transactions on Pattern Analysis and Machine Intelligence, 2019.
[59] Wang J , Zuo X , Dai Z , Xia M , Zhao Z , Zhao X , Jia J , Han Y , and He Y , “Disrupted functional brain connectome in individuals at risk for Alzheimer’s disease,” Biological Psychiatry, vol. 73 , no. 5 , pp. 472–481, 2013.22537793
[60] Zhang D and Shen D , “Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheimer’s disease,” NeuroImage, vol. 59 , no. 2 , pp. 895–907, 2012.21992749
