LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


9814863
21942
J Alzheimers Dis
J. Alzheimers Dis.
Journal of Alzheimer's disease : JAD
1387-2877
1875-8908

32390615
7427104
10.3233/JAD-190973
NIHMS1609091
Article
Integrating Convolutional Neural Networks and Multi-task Dictionary Learning for Cognitive Decline Prediction with Longitudinal Images
Dong Qunxi PhD 1ǂ
Zhang Jie BS 1ǂ
Li Qingyang PhD 1
Wang Junwen PhD 2
Leporé Natasha PhD 3
Thompson Paul M. PhD 4
Caselli Richard J. MD 5
Ye Jieping PhD 6
Wang Yalin PhD 1
Alzheimer’s Disease Neuroimaging Initiative
1. School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ, USA
2. Department of Health Sciences Research, Center for Individualized Medicine, Mayo Clinic, Scottsdale, AZ, 85259, USA
3. Department of Radiology, Children’s Hospital Los Angeles, Los Angeles, CA, USA
4. Imaging Genetics Center, Institute for Neuroimaging and Informatics, University of Southern California, Los Angeles, CA, USA
5. Department of Neurology, Mayo Clinic Arizona, Scottsdale, AZ, USA
6. Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI, USA
Correspondence author: Dr. Yalin Wang, School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, P.O. Box 878809, Tempe, AZ 85287 USA, Phone: (480) 965-6871, Fax: (480) 965-2751, ylwang@asu.edu.
ǂ Authors contributed equally

5 7 2020
2020
14 8 2020
75 3 971992
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Background:

Disease progression prediction based on neuroimaging biomarkers is vital in Alzheimer’s disease (AD) research. Convolutional neural networks (CNN) have been proved to be powerful for various computer vision research by refining reliable and high-level feature maps from image patches. However, a key challenge in applying CNN to neuroimaging research is the limited labeled samples with high dimensional features. Another challenge regards how to improve the prediction accuracy by joint analysis of multiple data sources (i.e., multiple time points or multiple biomarkers).

Objective:

To address these two challenges, we propose a novel multi-task learning framework based on CNN.

Methods:

First, we pre-trained CNN on the ImageNet dataset and transferred the knowledge from the pre-trained model to neuroimaging representation. We used this deep model as feature extractor to generate high-level feature maps of different tasks. Then a novel unsupervised learning method, termed Multi-task Stochastic Coordinate Coding (MSCC), was proposed for learning sparse features of multi-task feature maps by using shared and individual dictionaries. Finally, Lasso regression was performed on these multi-task sparse features to predict AD progression measured by the Mini Mental State Examination (MMSE) and the Alzheimer's Disease Assessment Scale cognitive subscale (ADAS-Cog).

Results:

We applied this novel CNN-MSCC system on the Alzheimer’s disease Neuroimaging Initiative (ADNI) dataset to predict future MMSE/ADAS-Cog scales. We found our method achieved superior performances compared with seven other methods.

Conclusion:

Our work may add new insights into data augmentation and multi-task deep model research and facilitate the adoption of deep models in neuroimaging research.

Alzheimer’s disease
Dictionary learning
Convolutional neural networks (CNN)
Transfer learning
Multi-task learning

INTRODUCTION

Alzheimer’s disease (AD) is the most prevalent neurodegenerative brain disease worldwide [1,2]. Clinical trial failures in symptomatic patients have led to the belief that capturing brain changes and therapeutically intervening at earlier disease stages would be more likely to achieve disease modification [3]. Various modalities of biomarkers have been used for early identification of brain changes related to AD and its earlier symptomatic stage, mild cognitive impairment (MCI), including the brain structural atrophy measured by magnetic resonance imaging (MRI) [4-6], metabolic alterations in the brain measured by fluorodeoxyglucose positron emission tomography (FDG-PET) [7,8] and pathological amyloid depositions measured through cerebrospinal fluid (CSF) and amyloid-PET [3,9]. Of these, abnormal structural MRI is considered as a typical marker of neurodegeneration and retains a close relationship with cognitive performance through the clinical phases of MCI and dementia [3]. MRI is more widely available, less invasive and more affordable for clinical applications than other imaging biomarker modalities. To date, the inevitable deformations of hippocampus, ventricle and cortical thickness are well captured by structural MRI (Fig. 1) [10-13]. Prior work [3,9,12,14-16], including our own study in a cognitively unimpaired brain imaging cohort (Arizona APOE cohort) [10], indicated that MRI hippocampal atrophy accelerates 20+ years prior to incident to MCI. Thus, structural MRI is promising as a potential preclinical AD biomarker. However, MRI biometrics do not yet reliably predict diagnosis and prognosis in early AD stages especially in individual patients [2,17-20].

Convolutional neural networks (CNN) are capable of learning comprehensive feature maps from images [21]. CNN has been successfully applied to a variety of computer vision and medical imaging applications including image classification [22], segmentation [23] and disease diagnosis [24]. It has the potential to improve the predictability of AD progression [21]. Li et al. [25] proposed a CNN framework for early prognosis of AD dementia based on the baseline hippocampal MRI data, and demonstrated improved performance for predicting progression to AD dementia. However, there are still few CNN studies on modeling AD progression. One issue has been the limited training data in the AD research domain while transfer learning has been proven to be a highly effective technique for limited medical image analysis. Kermany et al. [26] successfully applied CNN with transfer learning to classify images for macular degeneration and diabetic retinopathy and distinguish bacterial and viral pneumonia on chest X-rays. Xu et al. [27] designed a deep model of CNN with transfer learning and achieved a good performance in distinguishing histopathology images of low and high tumor mutational burden patients. CNN with transfer learning, therefore, has potential for AD dementia diagnostic modeling based on MR images.

After using CNNs with transfer learning, we confront an additional challenge that is high dimensional feature maps derived from small number of individual biomarkers based on MR images. To address this so called “large p, small n” problem, sparse coding has been applied. Sparse coding is an effective way of learning a small number of basis vectors termed dictionary to represent high dimensional features effectively and concisely [28-30]. However traditional dictionary learning algorithms confront challenges of handling very large training sets or dynamic training data changing over time, such as MR image sequences accompanying AD progression [30]. Studies of [17,31-33] demonstrated that joint analysis of multi-tasks (i.e., multiple time points or biomarkers) improved the prediction performance and may be used for tracking AD progression.

To track AD progression measured by cognitive scores, Zhang and Shen [18] proposed Multi-Modal Multi-Task (M3T) learning to jointly predict multiple variables from multi-modal data. However, they excluded conditions of missing values in both modalities and tasks. The study of [17] proposed Multi-Task Learning (MTL) formulations by considering the prediction at each time point as a task. It demonstrated that MTL outperformed single-task learning algorithms including ridge regression and Lasso for AD progression. However, their approaches treated dictionary learning for all tasks in the same manner, which was suboptimal for modeling AD progression. To address the above two issues, our previous study [32] proposed a two-stage Multi-task Stochastic Coordinate Coding (MSCC), stage 1 involved multi-source dictionary learning to utilize the common and individual sparse features in multi-tasks. In stage 2, an MTL method was developed to solve the missing values issue. Experimental results demonstrated that MSCC had an improved prediction accuracy and speed efficiency for future AD clinical score predictions compared to other similar algorithms.

To explore the statistical power of the combination of CNN with transfer learning and multi-task sparse coding, we developed an advanced deep model CNN-MSCC to predict AD progression measured by the Mini Mental State Examination (MMSE) [34] and the Alzheimer’s disease Assessment Scale cognitive subscale (ADAS-Cog) [35] scores using multi-task imaging biomarkers. We hypothesized that our system may produce accurate AD progression modeling results while offering the flexibility to work with structural imaging features from both longitudinal data and multiple regions-of-interest (ROIs). To validate our hypothesis, we designed two sets of experiments where we applied our framework to study the structural MRI data from Alzheimer Disease Neuroimaging Initiative (ADNI) [36,37] and compared our approach with seven other similar methods. In Experimental I, we aimed to use longitudinal (baseline, 6-months, 12-months) hippocampal structural measures to predict MMSE/ADAS-Cog scales of 24-months subjects. In Experiment II, we applied the proposed framework on three kinds of baseline structural features (hippocampal morphometry, lateral ventricular morphometry, and cortical thickness) to predict MMSE/ADAS-Cog scales of varied time points (6-months, 12-months and 24-months).

Materials and Methods

Subjects

Data for testing the performances of our proposed framework and comparison methods were obtained from the ADNI database (adni.loni.usc.edu). The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI is to test whether biological markers such as serial MRI and positron emission tomography (PET), combined with clinical and neuropsychological assessment can measure the progression of MCI and early AD. The structural MR images were acquired from 1.5T scanners. The raw MR images and MMSE/ADAS-Cog scales were downloaded from the public ADNI website (www.loni.ucla.edu/ADNI).

In this work, all of these performance comparison analysis have been conducted on ADNI-I dataset which including 837 subjects, the selection criteria can refer our previous study [38], the identification numbers of subjects were included in section A of Supplementary Information. There were 837 baseline subjects between 68-82 years of age, 733 subjects in the 6th months, and 676 subjects in the 12th months and 544 subjects in the 24th months. There were 814 baseline subjects having MMSE/ADAS-Cog scores, including (1) 186 AD subjects: baseline MMSE scores between 20-26, (2) 399 MCI subjects: baseline MMSE scores between 24-30, and (3) 229 cognitive unimpaired (CU) subjects: baseline MMSE scores between 24-30. The demographics of subjects used in our experiments are shown in Table 1.

Proposed Pipeline

In this section, we introduce the CNN-MSCC framework which predicts future MMSE/ADAS-Cog based on previous image patches from multiple time points or multiple ROIs. We pre-trained the CNN model on the ImageNet dataset [22,39]. Surface measures of hippocampi, lateral ventricle and cortical thickness were estimated from individual structural MR images [6,40]. Surface maps were first constructed for these ROIs, and image patches were further extracted from these surface maps [29,41,42]. With the transfer learning strategy, the pre-trained CNN network was adopted as a feature extractor for the following multi-task learning process (i.e. different time points or ROIs) [31]. We further employed MSCC to conduct the multi-task learning to simultaneously refine sparse features and dictionaries [32]. Finally, we employed the sparse codes generated from MSCC to perform the Lasso and predict the future MMSE/ADAS-Cog scores [43]. The entire pipeline of our proposed framework is illustrated in Fig. 2.

MR Image Preprocessing

Hippocampal surfaces were firstly segmented and reconstructed from individual MR images using FIRST software [44] and marching cube method [45]. Then, we computed hippocampal conformal grids on the Euclidean domain with holomorphic 1-form functions [46]. With these conformal grids, we transferred the original 3D hippocampal structure into 2D vertex-based features. The benefit of the conformal parameterization is that it helped compute both surface intrinsic and extrinsic geometry features, and dramatically simplified the implementation of surface fluid registration algorithm [47]. We further applied the inverse consistent surface fluid registration method to register hippocampal surfaces across subjects. After the surface registration, we introduced consistent image-grid like mesh structures on all hippocampal surfaces, for each subject, a 90,000-dimensional mesh structure represented mTBM of the hippocampal (HP) surfaces. To reduce the high mesh dimension, we can treat the surface-based feature structure as the pixel-grid and build patch structures. Quadrilateral patches were adopted here to improve the computational efficiency. Specifically, with the rectangular surface parameterization obtained in our surface fluid registration [47], taking advantage of the regular grid-like mesh structure, we randomly generated a number of square windows (50 x 50 vertices) on each registered registered surface to obtain a collection of small surface patches with different amounts of overlaps. We choose 132 patches on each hippocampus because it will cover all the vertices on each side of hippocampus. The procedure is in fact equivalent to applying a low-pass filter on the original meshes. As a result, the geometrical structures are still present while surface feature variances are reduced. We performed the same procedure to compute patches on both lateral ventricular and cortical surfaces. Finally, we represent the original bilateral hippocampal surface features with 264 overlapping patches [29]. It is worth noting that even we randomly select patches on all subjects, because of the registered surfaces, the patches we select in each task are in fixed locations on each hippocampus. Fig. 3 shows an example of patch selection on a pair of the hippocampal surfaces. As these patches are allowed to overlap, a vertex may be contained in several patches. The zoom-in windows in Fig. 3 show overlapping areas of selected patches. In this way, we can still keep the surface spatial structure and learn the mesh structures.

Further, we created surface mesh models of the lateral ventricles using our multi-atlas fluid image alignment (MAFIA) method that combines multiple fluid registrations to boost accuracy [48]. To model the lateral ventricular surfaces, we automatically located and introduced three cuts, based on the topology of the lateral ventricles, in which several horns are joined together at the ventricular “atrium” or “trigone” [6]. With the holomorphic flow segmentation method, each lateral ventricular surface was automatically partitioned into 3 pieces [46]. These three pieces are roughly three horns of the lateral ventricle: anterior horn, posterior horn and inferior horn. The surface segmentation was done by tracing curves that went through the zero point and had equal parameter coordinates. Then we registered each segmented surface of the lateral ventricular surfaces across subjects using constrained harmonic maps and computed mTBM features. For each subject, a 308,247-dimensional mTBM statistics were computed from registered ventricular surfaces. We randomly generated a number of square windows (50 x 50) on each registered surface to obtain a collection of small surface patches with different amounts of overlaps, 1713 image patches on each ventricular surface were chosen.

We adopted FreeSurfer [40] to compute cortical thickness on each point of cortical surfaces. For calculating cortical thickness, MR images were segmented into white matter (WM) and pial cortical surfaces using FreeSurfer. Then the cortical thickness was computed by deforming the WM surface to the pial surface. The deformation distance was taken as the cortical thickness. A spherical parameterization for each pial surface was also produced with FreeSurfer. The spherical parameter surface and weighted spherical harmonics [49] were further used to register pial surfaces across subjects and each subject had the same dimension (161,800) cortical thickness. Finally, the spherical parameter surface was the canonical space from which patches were selected. Similar to our prior work [41], we computed circular patches on the cortical surface. Specifically, 1798 patches of individual cortical thickness were chosen.

Among the three processing pipeline, FreeSurfer is publicly available and we have published our pipelines to compute both hippocampal and ventricular surface features on our web site (http://gsl.lab.asu.edu/software/). In next section, we will take image patches extracted from the above three kind of biomarkers as the input of the proposed CNN-MSCC method.

CNN with Transfer Learning

The architecture of a general CNN consists of the input layer, the output layer, and hidden layers between input and output layers. The input to the CNN is an image, and the outputs are class categories such as dementia or non-dementia. The hidden layers of a CNN consist of convolutional layers, pooling layers, fully connected layers, normalized layers and activation function [50]. Convolutional layers are the necessary part of CNN and make a convolution operation on the input image, emulating an individual neuron perception of visual stimuli. Each unit (neuron) in a subsequent convolutional layer has local shift-invariant inter-connections with its receptive units in the preceding layer. These connections are trained by the back-propagating (BP) algorithm [51]. Pooling layers was introduced into the CNN for down-sampling outputs of the prior layer with max-pooling or average-pooling strategy [52]. Fully connected layers are usually added at the end of CNN where every neuron in fully connected neurons connects every neuron in the previous layer for generating a distribution over classes [53]. The sample size of neuroimaging data is typically small compared to those in computer vision, so transfer learning is proposed to overcome this problem. One strategy of transfer learning [26] is as follows: 1). using a feed-forward approach to fix the optimized weights in the lower levels (convolutional and pooling layers) trained from general images with large size; 2). retraining the upper levels (fully connected layers) with the BP algorithm; 3). using the fine-tuned CNN to perform medical image analysis.

Our first goal here is to explore whether the transfer learning framework of CNN can be generalized to biological image studies. In this study, we took AlexNet structure [22] as the initial CNN model, which contains 7 layers, including convolutional layers with fixed filter sizes (see Table 2). We employed rectified non-linearity, max-pooling on each layer in this model. We pre-trained the CNN model on the ImageNet dataset [54], containing millions of labeled natural images with thousands of categories, and removed the last fully-connected layer (this layer's outputs are the 1000 class scores for a different task like ImageNet). The transferred CNN was used to extract high-level features from rescaled and resized brain surface patches of the training data. Finally the fine-tuned CNN were used to refine feature maps of surface-based biomarkers of the test set [55]. We implemented the CNN model using the Caffe toolbox [56]. The network was trained on an Intel (R) Xeon (R) 48-core machine, with 2.50 GHZ processors, 256 GB of globally addressable memory and a single Nvidia Tesla K40 GPU.

Multi-task Stochastic Coordinate Coding

Feature maps from CNN are fed to our proposed MSCC algorithm. Given feature maps from T different tasks: {X1, X2, … , XT}, our objective is to learn a set of sparse codes {Z1, Z2, … , ZT} for each task where Xt∈Rp×nt, Zt∈Rlt×nt and t ∈ {1, … , T}. p is the feature dimension of each subject, nt is the number of subjects for Xt and lt is the dimension of each sparse code in Zt. Online dictionary learning methods (ODL) [30] is one possible solution to learn the sparse codes Zt by Xt individually, the detail of ODL is summarized into Algorithm 1. The learning process runs κ (a fixed constant) iterations until there are no more changes on dictionary (D) and Z. Xt = (x1, x2, … , xn) is a finite training patch set of one subject, where Xt∈Rp×n, each xi∈Rp is an image patch with p dimension. By using ODL, we obtain a set of dictionaries {D1, … , DT} but there is no correlation between learnt dictionaries.

Algorithm 1 Online Dictionary Learning and Sparse Coding	
Input: Sample dataset: Xt=(x1,x2,…,xn)∈Rp×n.	
Output: Dictionary D∈Rp×l and sparse codes Z=(z1,z2,…,zn)∈Rl×n	
1: for k = 1 to κ do	
2:   Get an image patch xi from Xt.	
3:   Update sparse code zi by: minzi12∣∣xi−Dzi∣∣22+λ∣∣zi∣∣1.	
4:   Update the dictionary D by: minD12∣∣xi−Dzi∣∣22+λ∣∣zi∣∣1.	
5:   Normalize the dictionary by each column of D.	
6: end for	

Another solution is to construct the subjects {X1, … , XT} into one matrix X to obtain the dictionary D. However, if there is no latent common information shared by the same subject during different tasks, only one dictionary D is not enough to show the variation among features from different tasks. To address this challenge, we integrate the idea of multi-task learning into the online dictionary learning method [17,18,57,58] and propose a novel dictionary learning algorithm – MSCC – to learn the sparse codes of subjects from different tasks. The MSCC framework is non-convex. However, it becomes a convex problem when we fix D to update Z or fix Z to update D. Our latest study provides a sufficient argumentation about the convergence of MSCC during the sparse codes and dictionary learning process [59]. It is time-consuming in the optimization process of dictionary learning initialized by random patches. Empirically, the iteration may take thousands of steps to converge. However, we observe that after a few steps, the support of the coordinates, i.e., the locations of the non-zero entries becomes very stable, usually after less than ten steps. We tested the convergence time by running MSCC on a single-GPU, four-core 3.10 Ghz computer. The computation time is 0.188 hours.

For the subject feature matrix Xt of a particular task, MSCC learns a dictionary Dt and sparse codes Zt. Dt is composed of two parts: Dt=[D^t,D¯t] where D^t∈Rp×l^, D¯t∈Rp×l¯t and l^+l¯t=lt. D^t is the same among all the learnt dictionaries {D1, … , DT} while D¯t is different from each other and only learnt from the corresponding subjects' feature matrix Xt. Objective function of MSCC can be reformulated as follows: (1) minD1,…,DT∈ΨtZ1,…,ZT∑t=1T12‖Xt−[D^t,D¯t]Zt‖F2+λ∑t=1T‖Zt‖1,subject toD^1=⋯=D^T

where Ψt={Dt∈Rp×lt:∀j∈1,…,lt,‖[Dt]j‖2≤1} (t = 1, 2, … , T) and [Dt]j is the jth column of Dt. There is no limitation of the task numbers (less or more than three). In this paper, we only take three time points and three well-known biomarkers as examples. Fig. 4 illustrates the framework of MSCC with feature maps of structural measures from three different tasks, which are represented as X1, X2 and X3, respectively. For longitudinal MMSE/ADAS-Cog scales predictions, the input order of multi-task biomarkers is the actual time order of disease progress. Each time point is a specific task in our formulation. Through the multi-task learning process of MSCC, we obtain the dictionary and sparse codes for features from each time point t: Dt and Zt. In MSCC, a dictionary Dt is composed by a shared common part D^t and an individual part D¯t. In this example D^1, D^2 and D^3 are the same. For the individual part of dictionaries, MSCC learns a different D¯t only from the corresponding feature matrix Xt. We vary the number of columns l¯t in D¯t to introduce the variant in the learnt sparse codes Zt. As a result, the dimensions of learnt sparse codes matrix Zt are different from each other.

The initialization of dictionaries in MSCC is critical to the entire learning process. We propose a random patch method to initialize the dictionaries from different tasks. The main idea is to randomly select l image patches from n subjects {x1, x2, … , xn} to construct D∈RP×l. In MSCC, the way we initialize D^t is to randomly select l^ subjects' features from feature matrices across different tasks {X1, … , XT}. Similarly, for the individual part of each dictionary, we randomly select l¯ subjects' features from the corresponding matrix Xt to construct D¯t.

Algorithm 2 Multi-task Sparse Coordinate Coding	
Require: Samples from different tasks: {X1, X2, … , XT}, XT∈Rp×nt	
Ensure: Dictionaries and sparse codes for each tasks: {D1, … , DT} and {Z1, … , ZT}	
1: for k = 1 to κ do	
2:  for each image patch xt (i) ∈ Xt, i ∈ {1, … , nt} and t ∈ {1, … , T}.	
3:    Update D^tk: D^tk=Φ.	
4:    Update Ztk+1(i) and index set Itk+1(i) by a few steps of CCD:	
5:    [Ztk+1(i),Itk+1(i)]=CCD(D^tk,D¯tk,xt(i),Itk(i),Ztk(i)).	
6:    Update the D^t and D¯t by one step SGD:	
7:    [D^tk+1,D¯tk+1]=SGD(D^tk,D¯tk,xt(i),Itk+1(i),Ztk+1(i)).	
8:    Normalize D^tk+1 and D¯tk+1 based on the index set Itk+1(i).	
9:    Update the shared dictionary Φ:Φ=D^tk+1.	
10:   end for	
11:  end for	
12: end for	

After initializing dictionary Dt for each time point, we set all the sparse codes Zt to be zero in the beginning. The key steps of MSCC are summarized in Algorithm 2, k denotes the epoch number where k ∈ {1, … , κ}, Φ represents the shared part of each dictionary Dt which is initialized by the random patch method. For each subject’s patch xt(i) extracted from Xt, we learn the ith sparse code Zik+1(i) from Zt by several steps of Cyclic Coordinate Descent (CCD) [60]. Then we use learnt sparse codes Ztk+1(i) to update the dictionaries D^tk+1 and D¯tk+1 by one step Stochastic Gradient Descent (SGD) [61]. Since Zik+1(i) is very sparse, we use the index set Iik+1(i) to record the location of non-zero entries in Zik+1(i) to accelerate the update of sparse codes and dictionaries, Φ is updated in the end of kth interaction to ensure D^tk+1 is the same among all the dictionaries.

After we pick an image patch xt(i) from the sample xt at the time point t, we fix the dictionary and update the sparse codes by following the ODL method [30]. Then the optimization problem we need to solve becomes the following equation: (2) minzt(i)F(zt(i))=12‖xt(i)−[D^t,D¯t]zt(i)‖22+λ‖zt(i)‖1

It is known as the Lasso problem [43]. Coordinate descent [60] is known as one of the state-of-the-art methods for solving this problem. In this study, we perform the CCD to optimize Eq. (2). Empirically, the iteration may take thousands of steps to converge. It is time-consuming in the optimization process of dictionary learning. However, we observe that after a few steps, the support of the coordinates, i.e., the locations of the non-zero entries in zt(i), becomes very stable, usually after less than ten steps. In this study, we perform P steps CCD to generate the non-zero index set Itk+1, recording the non-zero entry of Ztk+1(i). Then we perform S steps CCD to update the sparse codes only on the non-zero entries of Ztk+1(i), accelerating the learning process significantly. SCC [62,63] employs a similar strategy to update the sparse codes in a single task. For the multi-task learning, we summarize the updating rules as follows:

Perform P steps CCD to update the locations of the non-zero entries Itk+1(i) and the model Ztk+1(i).

Perform S steps CCD to update the Ztk+1(i) in the index of Itk+1(i).

The detailed optimization procedure [62-64] is reported in section B of Supplementary Information.

Performance Evaluation Protocol

To evaluate the proposed framework, we randomly split the data into training and testing sets using an 8:2 ratio, i.e., models were constructed on 80% of the data and evaluated on the remaining 20% of the data. We also used 10-fold cross validation to select key parameters and avoid data bias during the training. Lastly, we evaluated the overall prediction performance using normalized mean square error (nMSE), weighted correlation coefficient (wR) and root mean square error (rMSE) for task-specific regression performance measures [17]. The three performance measures are defined as follows: (3) nMSE(Y,Y^)=∑i=1t‖Yi−Y^i‖22∕σ(Yi)∑i=1tni,wR(Y,Y^)=∑i=1tCorr(Yi,Y^i)ni∑i=1tni,rMSE(y,y^)=‖y−y^‖22n.

For nMSE and wR, Yi is the ground truth of target task i and Y^i is the corresponding predicted value, σ(Yi) is the standard deviation of Yi, Corr is the Pearson correlation coefficient between two vectors and ni is the number of subjects of task i. For rMSE, y is the ground truth of the target at a single task and y^i is the corresponding prediction by a prediction model. The smaller nMSE and rMSE, as well as the bigger wR mean the better prediction performances, nMSE and wR are used to evaluate the overall performances of the proposed system across multiple times points, rMSE is used to evaluate CNN-MSCC performance of each time point. We reported the mean and standard deviation based on 40 iterations of experiments on different splits of data. We compared the proposed model with seven other methods, which are as follows:

CNN-R: CNN learned surface feature without transfer learning, followed by Lasso regression.

MSCC-R: The proposed multi-task dictionary learning algorithm followed by Lasso regression.

OLSC-R: The single-task dictionary learning [30] followed by Lasso regression.

cFSGL: A multi-task algorithm called convex fused sparse group Lasso [17].

L21: A multi-task algorithm called L2,1, norm regularization with least square loss [65].

Lasso: A single task method called Lasso regression [43].

Ridge: A single task method called Ridge regression [66].

Paired sample t-test was applied to compare performances (rMSE/nMSE and wR) between CNN-MSCC and seven other similar methods [67] and the statistical p values were corrected for false discovery rate (FDR) [68].

Results

This section explains how to configure key parameters of the proposed system CNN-MSCC and provides performance comparisons between CNN-MSCC and other state-of-the-art methods.

We designed two different experiments to validate our proposed CNN-MSCC framework. In the first experiment (Experiment I), we applied CNN-MSCC to predict MMSE/ADAS-Cog scores of 24-months using hippocampal (HP) image patches of baseline, 6-months and 12-months. In the second experiment (Experiment II), we applied the CNN-MSCC to predict MMSE/ADAS-Cog scales of multi-time slots (6, 12 and 24-months) using image patches of baseline multi-ROIs (hippocampal/ventricle mTBM and cortical thickness). Comparison analyses were performed between CNN-MSCC and seven other similar methods in each experiment. To fit the pre-trained CNN model, patches of size 50 × 50 are extracted and resized to size of 227*227 input sample. There are either HP patches from multi-time slots (Experiment I) or three kinds of baseline structural patches (Experiment II). The image patch amount of each time point and structural measure are shown in Table 3.

Key Parameter Estimation

In this work, we estimate two key parameters of CNN-MSCC on longitudinal HP image patches and then use the optimized parameters throughout the paper. The first key parameter is the amount pre-trained CNN layers for transferring learning. In this work, we aimed to get feature maps related with AD from image patch-based features using the well pre-trained CNN. With the transfer learning technique, the AlexNet architecture pre-trained on the ImageNet dataset [69] was tested on longitudinal HP image patches. CNN consists of multiple layers of feature maps, and each layer is a different representation of the input data. We used the HP image patches of three time points (baseline, 6-months and 12-months) as inputs to predict MMSE/ADAS-Cog scales of 24-months. We studied their performances when working with different network layers (detailed in Table 2) of CNN-MSCC.

To verify the role of MSCC part, we also compared the performance of CNN-MSCC with the performance without MSCC part (CNN-R). The results are provided in Fig. 5. We observed that both CNN-MSCC and CNN-R with 6 network layers outperformed the others measured by rMSE. The discriminative power increases from the 4 to 6 layers, and then drops afterwards as the depth of network increases. One reasonable explanation about this observation is the lower layers do not fully capture the surface features and the higher layers captured features that overfit to the training image patches. So in this paper, we used the 6th layer's features (4096) as the number of rows for all the dictionaries. Additionally, we also noted that CNN-MSCC outperformed CNN-R with different layer settings. It indicates that MSCC part helps to improve the prediction performance.

The second key parameter is the proportions of common and individual parts in the dictionary of MSCC algorithm. The dictionary of MSCC algorithm includes common and individual parts for considering the constant and varied features of multi-task learning. It is necessary to evaluate the optimal proportions of the two parts in the dictionary. We still used the longitudinal HP image patches of three time points (baseline, 6-months and 12-months) as inputs to predict MMSE/ADAS-Cog scales of 24-months and adopted 6-layers of CNN in the proposed algorithm. We set the dictionary size to be 2000 and partitioned the dictionary by different proportions: 250:1750, 500:1500, 1000:1000, 1500:500 and 1750:250, where the left number is the size of common part while the right number is the size of individual part for each dictionary. To verify the role of CNN part of the proposed method, we also calculated the performance of an algorithm MSCC-R without the CNN part. Fig. 6 shows the rMSEs as the performance measures of two methods MSCC-R and CNN-MSCC on the longitudinal HP data. The rMSEs of MMSE/ADAS-Cog scales are lowest when we divide the dictionary in half. So in all experiments, we use the ratio of 1000:1000 as the proportion of common and individual parts for all the dictionaries. Additionally, we observed that CNN-MSCC outperformed MSCC-R with different dictionary proportion settings. This indicates that CNN part also helps to improve the prediction performance. So, the combination of optimized CNN and MSCC is expected to have a promising performance on AD progression prediction. In the follow-up experiments, we will further validate this expectation.

Experiment I: CNN-MSCC on Longitudinal HP Surface Patch Features

Studies demonstrate that the hippocampal structure is a primary biomarker in the longitudinal structural MRI analysis of AD progression [11,70-73] and significant hippocampal deformations related with AD pathology can be detected even before observing obviously lower MMSE/ADAS-Cog scores [10,11,74,75]. In Experiment I, we used previous longitudinal HP patches (baseline, 6-months and 12 months) to predict future MMSE/ADAS-Cog scales at the 24-months point. Image patches with size 50 × 50 were extracted from individual hippocampal mTBM feature maps of three tasks (baseline, 6-months and 12-months), and we had 220968, 193512, 178464 individual HP image patches for three tasks respectively. Using these image patches as the input of CNN-MSCC, we got three sets of feature sparse codes of baseline, 6-months and 12-months. We used individual 12-months sparse codes learned by CNN-MSCC as Lasso design matrices to train and test the 24-months MMSE/ADAS-Cog scales with 8:2 subjects ratio, because the 12-months sparse codes contain both common features along with time points (baseline, 6 and 12-months) and task-specific features of 12-months. Fig. 7 shows scatter plots of CNN-MSCC for the predicted values versus the actual values for MMSE/ADAS-Cog on the testing data.

To estimate the performance of CNN-MSCC on this application, we randomly split the training data and testing data as the 8:2 ratio and ran 40 iterations of each method, then we could apply paired sample t-test with lower-tailed hypothesis to compare the rMSEs performances of CNN-MSCC with seven other similar methods on the longitudinal HP dataset. All the p values were corrected by FDR. The rMSEs of 24-months MMSE/ADAS-Cog scale predictions are shown in Fig. 8. Statistical results indicate that, for MMSE scale predictions, CNN-MSCC has significantly smaller rMSEs (p &lt; 0.05) compared to CNN-R, OLSC-R, cFSGL, L21, Lasso and Ridge, while there is no significant rMSEs difference (p = 0.3459) for CNN-MSCC vs. MSCC-R. For ADAS-Cog scale predictions, CNN-MSCC has significantly smaller rMSEs (p &lt; 0.05) compared to all the other methods. All the eight methods demonstrate that the rMSEs of MMSE predictions are better than ADAS-Cog prediction.

Experiment II: CNN-MSCC on Multiple Baseline Cortical Structural Surface Patch Features

Ventricular mTBM and cortical thickness are another two important biomarkers for tracking the AD progression [6,11,73,76]. In Experiment II, we used the baseline structural image patches, including hippocampal mTBM features, ventricular mTBM features and cortical thickness of 837 subjects to predict the MMSE/ADAS-Cog variations of future time points (6-months, 12-months and 24-months). After preprocessing these MRI data, we have 220968, 2867562, 1504926 individual image patches corresponding to three kinds of baseline structural measures respectively. Using the CNN-MSCC framework, we got three sets of feature sparse codes. Since each subject has three sparse codes, we combined these three sparse codes as Lasso design matrix to train and test the 6, 12 and 24-months MMSE/ADAS-Cog scales with 8:2 subjects’ ratio. This process was repeated 40 times. Fig. 9 shows the boxplots of wRs between the predicted and the actual MMSE/ADAS-Cog scales of 6, 12 and 24-months. Using paired t-test with higher-tailed hypothesis between wRs of different time points, we found wRs on MMSE/ADAS-cog score predictions of 24-months are significantly higher (p &lt; 0.05) than wRs of 6 and 12-months. These improved wRs on 24-months benefited from MSCC method to iteratively learn features from previous time points.

Then we further compared our results with those of seven other state-of-the-art methods on the baseline multi-cortical dataset. Similarly as previous experiments, we randomly split the baseline training data and testing data as the 8:2 ratio and ran 40 iterations of each method, then we could apply paired sample t-test with lower-tailed hypothesis to compare the rMSE/nMSE performances and with higher-tailed hypothesis to compare wR performances of CNN-MSCC with seven other similar methods. Fig. 10 shows the comparison results of our proposed method and seven other similar methods on longitudinal MMSE/ADAS-Cog prediction performances using baseline image patches of multiple ROIs in terms of normalized mean square error (nMSE, see Fig. 10 (a)), weighted correlation coefficient (wR, see Fig. 10 (b)) and root mean square error (rMSE, see Fig. 10 (c)) at 6, 12 and 24-months (M06, M12 and M24). With paired sample t-test and FDR correction, we observed CNN-MSCC significantly outperform other similar methods with smaller (p &lt; 0.05, corrected) rMSEs/nMSEs and higher (p &lt; 0.05, corrected) wRs on future MMSE/ADAS-Cog scale predictions. Additionally, all the methods show apparently lower nMSE/rMSE when predict MMSE scales compared to predict ADAS-Cog scales. That is, neuroimaging features have closer relationship with MMSE scales compared to ADAS-Cog scales. These results support our hypothesis that a combination of features from multiple ROIs may enhance the statistical power in future cognitive measure regression.

Sex/gender is one of the strongest predictors of AD and women have twofold increased risk of AD than men after 65 years old [77,78]. We applied CNN-MSCC to predict future MMSE/ADAS-Cog scales of males and females using baseline multi-task biomarkers. Paired sample t-test was applied to estimate performance differences between male and female groups. We observe that the female group has significantly smaller rMSEs (p &lt; 0.05) on MMSE/ADAS-Cog scale predictions at 6-months compared to the male group while no statistical difference is observed on rMSEs with 12-months and 24-months prediction and the overall nMSE and wR values (see Fig. 11). It may demonstrate that CNN-MSCC has a slightly higher effect size to predict female MMSE/ADAS-Cog scales than the male group. Our research show that female may have stronger connections between structural changes and future cognitive decline. It may provide some evidence supporting the existing research [77-79] that reported the female is more vulnerable to AD than the male.

Discussion

This work has two main findings. First, we have demonstrated a novel system that integrates deep transfer learning and multi-task sparse coding research for enhanced AD progression modeling. CNN [24,25] is good at extracting accurate neuroimaging characteristics of special neurodegenerative disease and the extracted neuroimaging features are in a high dimension as opposed to small sample size as known as “large p, small n” problem. While our proposed multi-task learning method MSCC can represent these high dimensional features and jointly analyze multi-task sparse features. One of the major discoveries of the current work is that the integration of both methods achieves improved statistical power. To the best of our knowledge, CNN-MSCC is the first deep model transfer learning from the large scale annotated natural images to brain surface statistics. Second, the surface mTBM, which is computed from the conformal grid and carries rich information on local surface geometry, is applicable to deep models for AD progressive prediction. Although surface-based morphometry achieved great success in population-based analyses to discover the general trend of disease burden and progression [6,80-82], few studies have investigated the use of surface-based morphometry features for brain disease diagnosis on an individual basis [83-85]. This work validated the feasibility of surface mTBM [86], as imaging biomarkers for prediction of future MMSE/ADAS-Cog scales decline. This discovery is in line with several of our prior studies [6,83]. The newly combined surface statistics practically encode a great deal of neighboring intrinsic geometry information that would otherwise be inaccessible or overlooked. The surface-based computer-aided diagnosis research may become more powerful by adopting these patch analysis-based multivariate statistics.

CNNs are considered as one of the most successful deep models for identifying, classifying and quantifying patterns in medical images [53,87]. There are still relatively few CNN studies on AD diagnosis due to limited training data. Transfer learning technique has proven to be a highly effective technique for addressing a lack of data in AD research domain and it leverages data from another domain. ImageNet includes millions of labeled natural images [54]. However, because of the substantial differences between natural and medical images, transfer learning is unsuitable to be applied directly [69]. Studies of [26,69] demonstrated that fine-tuning the transferred CNNs on medical images could decrease overfitting of the pre-trained CNNs and was a practical way to reach the best performance for the medical image application at hand. So in this study, we pre-trained CNN structures on ImageNet database. After we pre-trained the CNN model on the ImageNet dataset, we removed the last fully connected layer (this layer’s outputs are the 1000 class scores for ImageNet). The dimension of ImageNet image is 227*227*3, while the dimension of our mTBM patch features is 50*50*3. We rescaled the surface mesh features to 227*227*3. Then the CNN on the surface mesh features was fine-tuned. Our results demonstrate that the transferred CNNs with optimal layers are capable to extract higher level features from image-patches of biomarkers and gain performance improvement for AD progressing modeling.

After using CNN with transfer learning technique, image patches of biomarkers were transformed to high dimensional feature maps. On one hand, to address the problem of high dimensional feature maps derived from small number of image patches, it is necessary to apply the sparse coding method to generate a small number of basis vectors termed dictionary to represent high dimensional features effectively and concisely [30,62,88]. On the other hand, multi-task sparse features contain complementary information for tracking AD progression measured by MMSE/ADAS-Cog scales [17,18], so we need to effectively integrate these features together. Previous studies concatenated different kinds of features into a longer feature vector or applied multi-task learning method to fuse them together [18]. The study of [89,90] reported that multi-task learning method performed better than feature concatenation method. However, if there is no latent common information shared by the same subject during different time points [17], only one dictionary from multiple-kernel method is not enough to show the variation among features from different time points. To address this challenge, we integrate the idea of multi-task learning into the online dictionary learning method [17,58,91] and propose the novel dictionary learning algorithm MSCC to learn multi-task sparse codes of subjects.

In our proposed model, we innovatively introduce the common part of dictionaries to capture the interrelationships between multi-task learning. As expected, CNN-MSCC outperformed several similar methods. To verify the common part role of multi-task dictionary, we tested the performances of CNN-MSCC vs. CNN-separate task stochastic coordinate coding (CNN-STSC) that is without the common dictionary part. As shown in Fig. 12, CNN-MSCC with common dictionary part outperforms CNN-STSC without common dictionary part with significantly smaller rMSEs (p &lt; 0.05) on MMSE scale predictions at three time points, with significantly smaller rMSEs (p &lt; 0.05) on ADAS-Cog scale predictions at 6 and 12-months, and with significantly larger wRs (p &lt; 0.05) on ADAS-Cog scale predictions. The experimental results validated the gained statistical power by adding the common part of dictionaries. However, we did not observe significant rMSE differences on ADAS-Cog scale predictions at 24-months. Neither did we have significant nMSE differences on MMSE/ADAS-Cog scale predictions, nor significant wRs differences on MMSE scale predictions. MMSE/ADAS-Cog scale predictions of 6-months are based on the common and individual sparse features at baseline, while MMSE/ADAS-Cog scales of 12-months are based on the updated common sparse features along with time points (baseline and 6-months) and task-specific features of 6-months. Similarly, MMSE/ADAS-Cog scales of 24-months are based on the updated common sparse features along with time points (baseline, 6-months and 12-months) and task-specific features of 12-months. This accumulate learning capability makes the prediction performances at 6-, 12- and 24-months stable.

Despite the promising experimental results, four caveats remain. First, this work aims to propose one comprehensive framework which includes CNN structure for image feature extractions, multi-task sparse coding algorithm for feature fusions and Lasso regression model for future cognitive scale predictions. We select AlexNet as the CNN part, the proposed automatic system outperformed 7 similar methods. In future work we would like to make comparison analysis of our proposed CNN-MSCC system based on kinds of well-known CNN structures, e.g., [92,93] and expect the performance will be further improved. Second, transfer learning is still empirical and it lacks theoretical interpretations about what to transfer, how to transfer and when to transfer [94]. It is still a mystery that machine learning systems can work on brain images while they were trained in other image domains. Even so, our work still demonstrated that the optimized CNN-MSCC model may extract reliable features for AD progression prediction and validated the feasibility to apply deep models on surface-based neuroimaging features. Third, as one of the useful data augmentation methods, transfer learning is not the only one to apply deep models in a small size dataset. Other ongoing methods, such as one-short / few shot learning, horizontal flips, random crops, and principal component analysis (PCA) are also promising ways to go [95-99]. These strategies have been shown to capture important characteristics of natural and medical images. In our future work, we will keep exploring other data augmentation techniques to build deep neural networks with our surface features and compare their performances with the current transfer learning strategy. Fourth, our current model does not consider the temporal information, another work from our group [100] enforces the sparsity of the sparse codebook representation by representing neighboring feature resemblance to improve the smoothness of prediction over the longitudinal neighboring time points. In future work, we will try to study the integration of the resemblant model with CNN and compare its performance with our current results.

Conclusions

This study proposed a novel deep learning system, CNN-MSCC, for AD clinical score predictions using multi-task image patches. By leveraging the transfer learning, we were able to apply a pre-trained CNN models to study brain images. We also innovatively proposed a multi-task stochastic coordinate coding (MSCC) algorithm for the multi-task learning which may integrate patched-based brain surface features from longitudinal or multiple ROIs. Our preliminary experimental results and performance analyses showed that our proposed system may outperform other similar methods and showed a promising accuracy for future MMSE/ADAS-Cog scale predictions. The proposed system may aid in expediting the diagnosis of AD progression, facilitating earlier clinical intervention and resulting in improved clinical outcomes.

In future, we will continue our deep model-based brain imaging research [101], optimize our methods and investigate their capability on longitudinal brain multimodality imaging datasets. There are various opportunities to generalize and enhance our current study for AD research. For example, there are many other neuroimaging biomarkers from modalities such as PET, functional MRI (fMRI), Magnetoencephalography (MEG) and electroencephalogram (EEG), which have been widely studied for AD diagnosis [102-104]. Since our proposed system is capable to refine and fuse features from multi-task biomarkers so we may also fuse these data in our system. The current work applied the proposed CNN-MSCC model to predict AD progression measured by MMSE/ADAS-Cog scales successfully. We may investigate more AD clinical assessments, such as Functional Assessment Questionnaire (FAQ), the Clock Test and the Rey Auditory Verbal Learning Test (AVLT) [105]. The gained experience may shed new lights the correlation between brain images and various AD clinical assessments and eventually help set up standards for subject recruitments in AD clinical trials [106].

Supplementary Material

Supplementary Information

Acknowledgement

Algorithm development and image analysis for this study was funded, in part, by the National Institute on Aging (RF1AG051710 to QD, JZ and YW, R01EB025032 to NL and YW, R01AG031581 and P30AG19610 to RJC), the National Science Foundation (IIS-1421165 to JZ and YW), and Arizona Alzheimer’s Consortium. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40 GPU used for this research.

Data collection and sharing for this project was funded by the ADNI (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie, Alzheimer’s Association; Alzheimer’s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research &amp; Development, LLC.; Johnson &amp; Johnson Pharmaceutical Research &amp; Development LLC.; Lumosity; Lundbeck; Merck &amp; Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer’s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.

Data used in preparation of this article were obtained from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf.

Fig. 1. Three promising brain structure measures of the structural MR images used for clinical diagnosis of Alzheimer's Disease: (a) Hippocampal contractions; (b) Ventricle expansions; (c) Cortical thickness reductions.

Fig. 2. An illustration of the proposed CNN-MSCC framework. The CNN model was pre-trained on the ImageNet dataset (a). The pre-trained model was modified as a feature extractor for brain structural MR image patches based on transfer learning strategy (b) and deep feature maps were extracted from varied structural measures or time slots (c). MSCC was adopted to generate the sparse features from deep feature maps (d). Finally, Lasso regression was applied on the sparse features to predict future MMSE and ADAS-Cog scores (e).

Fig. 3. Visualization of selected surface patches on a pair of the hippocampal surfaces. In this figure, we show some randomly selected surface patches with different amounts of overlapping. The zoom-in pictures show some overlapping areas between surface patches. We generate a series of square windows on each side of hippocampus.

Fig. 4. Illustration of the learning process of MSCC on ADNI datasets from multiple tasks.

Fig. 5. Comparison of 24-months’ MMSE/ADAS-Cog prediction models with different CNN layers (both with and without MSCC part – CNN-MSCC vs. CNN-R), in terms of root mean square error (rMSE) on HP patches of baseline, 6 and 12-months. MMSE denotes Mini-Mental State Examination, ADAS-Cog denotes Alzheimer’s disease Assessment Scale-Cognitive Subscale, CNN denotes Convolutional Neural Network, MSCC denotes Multi-task Stochastic Coordinate Coding. CNN-R denotes CNN-Regression.

Fig. 6. Comparison of 24-months’ MMSE/ADAS-Cog prediction performances with different dictionary settings of MSCC, in terms of root mean square error (rMSE) on hippocampal patches of baseline, 6 and 12-months. MMSE denotes Mini-Mental State Examination, ADAS-Cog denotes Alzheimer’s disease Assessment Scale-Cognitive Subscale, CNN denotes Convolutional Neural Network, MSCC-R denotes Multi-task Stochastic Coordinate Coding Regression.

Fig. 7. Scatter plots of actual versus predicted MMSE/ADAS-cog values of 24-months using CNN-MSCC based on hippocampal patches of baseline, 6 and 12-months. MMSE denotes Mini-Mental State Examination, ADAS-Cog denotes Alzheimer’s disease Assessment Scale-Cognitive Subscale, CNN denotes Convolutional Neural Network, MSCC denotes Multi-task Stochastic Coordinate Coding, rMSE denotes root mean square error, CORR denotes Correlation coefficients.

Fig. 8. Comparison analysis of our proposed method and seven other similar methods on 24-months MMSE/ADAS-Cog scale prediction performances using hippocampal image patches of baseline, 6 and 12-months in terms of root mean square error (rMSE). Paired sample t-test was applied to estimate the significant outperformances of the proposed method CNN-MSCC. The asterisk above green boxplot shows that, for MMSE scale predictions, CNN-MSCC has significantly smaller (p &lt; 0.05, corrected) rMSEs compared to CNN-R, OLSC-R, cFSGL, L21, Lasso and Ridge, while there is no significant rMSEs difference for the contrast of CNN-MSCC vs. MSCC-R. The asterisk above blue boxplot shows that, for ADAS-Cog scale predictions, CNN-MSCC has significantly smaller rMSEs (p &lt; 0.05, corrected) compared to all other methods.

Fig. 9. Weighted correlation coefficient (wR) between predicted and actual MMSE/ADAS-Cog scales of 6, 12 and 24-months (M06, M12 and M24) on testing data using CNN-MSCC based on baseline multi-cortical image batches. Paired sample t-test was applied to estimate the significant outperformances on MMSE/ADAS-Cog scale predictions of 24-months. The asterisks above blue boxplots show that wRs on MMSE/ADAS-cog score predictions of 24-months are significantly higher (p &lt; 0.05) than wRs of 6 and 12-months.

Fig. 10. Comparison analysis of CNN-MSCC and seven other similar methods on longitudinal MMSE/ADAS-Cog prediction performances using baseline image patches of multiple ROIs in terms of normalized mean square error (nMSE) (a), weighted correlation coefficient (wR) (b) and root mean square error (rMSE) at 6, 12 and 24-months (M06, M12 and M24) (c). The asterisks above green boxplots and blue boxplots show that, for MMSE/ADAS-Cog scale predictions, CNN-MSCC has significantly smaller nMSEs/rMSEs (p &lt; 0.05, corrected), and larger wRs (p &lt; 0.05, corrected) compared to all other seven similar methods.

Fig. 11. MMSE/ADAS-Cog prediction performances of male and female groups using the proposed CNN-MSCC method and baseline patches of multiple ROIs in terms of root mean square error (rMSE) at 6, 12 and 24-months (a) and (b), normalized mean square error (nMSE) (c), and weighted correlation coefficient (wR) (d). The asterisks above green boxplots in (a) and (b) show that female group have significantly smaller rMSEs (p &lt; 0.05) on MMSE/ADAS-Cog scale predictions at 6-months compared to the male group.

Fig. 12. MMSE/ADAS-Cog prediction performances of CNN-MSCC and CNN-STSC on baseline patches of multiple ROIs in terms of root mean square error (rMSE) at 6, 12 and 24-months (a) and (b), normalized mean square error (nMSE) (c), and weighted correlation coefficient (wR) (d). The asterisks above green boxplots in (a) show that CNN-MSCC has significantly smaller rMSEs (p &lt; 0.05) on MMSE scale predictions at three time points compared to CNN-STSC. The asterisks above green boxplots in (b) show that CNN-MSCC has significantly smaller rMSEs (p &lt; 0.05) on MMSE scale predictions at 6-months and 12-months compared to CNN-STSC. The asterisks above green boxplots in (d) show that CNN-MSCC has significantly larger wRs (p &lt; 0.05) on ADAS-Cog scale predictions compared to CNN-STSC.

Table 1. Demographic characteristics and longitudinal neuropsychological scores of the subjects.

Baseline sample size of each group	AD (n=186)	CU (n=229)	MCI (n=399)	
Male/Female	98/88	119/110	255/144	
Age	75.36±7.57	75.97±5.04	74.85±7.37	
Education	14.69±3.12	15.96±3.05	15.54±3.24	
MMSE (Baseline)	23.28±2.05	29.09±1.05	27.01±1.79	
MMSE (6 months)	20.88±6.50	27.96±5.47	25.06±6.40	
MMSE (12 months)	17.69±8.78	26.72±8.13	23.69±8.40	
MMSE (24 months)	13.36±9.87	25.67±9.46	19.16±11.40	
ADAS-Cog (Baseline)	29.03±7.66	9.55±4.34	18.71±6.28	
ADAS-Cog (6 months)	28.05±12.70	9.21±5.04	18.63±8.89	
ADAS-Cog (12 months)	27.34±16.46	7.83±5.13	18.15±10.08	
ADAS-Cog (24 months)	24.79±21.15	8.20±5.63	16.75±13.09	
AD denotes Alzheimer’s disease, CU denotes cognitive unimpaired, MCI denotes Mild Cognitive Impairment, MMSE denotes Mini-Mental State Examination, ADAS-Cog denotes Alzheimer’s disease Assessment Scale-Cognitive Subscale.

Table 2. The architecture of pre-trained CNN used in this study.

Deep Layer	Function	Neurons	
1	Convolutional Layer	290400	
2	Pooling Layer	186624	
3	Convolutional Layer	64896	
4	Convolutional Layer	64896	
5	Convolutional Layer	43264	
	Pooling Layer	9216	
6	Fully Connected layer	4096	
7	Fully Connected layer	4096	

Table 3. The image patch amounts of two experimental datasets.

	Baseline	6-months	12-months	
Longitudinal Hippocampal patches (individual patch number * subjects)	220968 (264 * 837)	193512 (264 * 733)	178464 (264 * 676)	
	Hippocampal surfaces	Ventricular surfaces	Cortical thickness	
Three baseline structural patches (individual patch number * subjects)	220968 (264 * 837)	2867562 (3426 * 837)	1504926 (1798 * 837)	

Conflict of Interest/Disclosure Statement

The authors have no conflict of interest to report


References

[1] Brookmeyer R , Johnson E , Ziegler-Graham K , Arrighi HM (2007) Forecasting the global burden of Alzheimer’s disease. Alzheimer’s Dement. 3 , 186–191.19595937
[2] Rathore S , Habes M , Iftikhar MA , Shacklett A , Davatzikos C (2017) A review on neuroimaging-based classification studies and associated feature extraction methods for Alzheimer’s disease and its prodromal stages. Neuroimage 155 , 530–548.28414186
[3] Sperling RA , Aisen PS , Beckett LA , Bennett DA , Craft S , Fagan AM , Iwatsubo T , Jack CR Jr. , Kaye J , Montine TJ , Park DC , Reiman EM , Rowe CC , Siemers E , Stern Y , Yaffe K , Carrillo MC , Thies B , Morrison-Bogorad M , Wagster MV , Phelps CH (2011) Toward defining the preclinical stages of Alzheimer’s disease: recommendations from the National Institute on Aging-Alzheimer’s Association workgroups on diagnostic guidelines for Alzheimer’s disease. Alzheimers Dement 7 , 280–292.21514248
[4] Saykin AJ , Shen L , Foroud TM , Potkin SG , Swaminathan S , Kim S , Risacher SL , Nho K , Huentelman MJ , Craig DW , Thompson PM , Stein JL , Moore JH , Farrer LA , Green RC , Bertram L , Jack CR , Weiner MW (2010) Alzheimer’s Disease Neuroimaging Initiative biomarkers as quantitative phenotypes: Genetics core aims, progress, and plans. Alzheimer’s Dement. 6 , 265–273.20451875
[5] van de Pol LA , van der Flier WM , Korf ES , Fox NC , Barkhof F , Scheltens P (2007) Baseline predictors of rates of hippocampal atrophy in mild cognitive impairment. Neurology 69 , 1491–1497.17923611
[6] Wang Y , Song Y , Rajagopalan P , An T , Liu K , Chou Y-Y , Gutman B , Toga AW , Thompson PM (2011) Surface-based TBM boosts power to detect disease effects on the brain: An N=804 ADNI study. Neuroimage 56 , 1993–2010.21440071
[7] Mosconi L , Nacmias B , Sorbi S , De Cristofaro MT , Fayazz M , Tedde A , Bracco L , Herholz K , Pupi A (2004) Brain metabolic decreases related to the dose of the ApoE e4 allele in Alzheimer’s disease. J Neurol Neurosurg Psychiatry 75 , 370–376.14966149
[8] Mosconi L , Berti V , Glodzik L , Pupi A , De Santi S , de Leon MJ (2010) Pre-Clinical Detection of Alzheimer’s Disease Using FDG-PET, with or without Amyloid Imaging. J. Alzheimer’s Dis. 20 , 843–854.20182025
[9] Jack CR , Bennett DA , Blennow K , Carrillo MC , Dunn B , Haeberlein SB , Holtzman DM , Jagust W , Jessen F , Karlawish J , Liu E , Molinuevo JL , Montine T , Phelps C , Rankin KP , Rowe CC , Scheltens P , Siemers E , Snyder HM , Sperling R , Elliott C , Masliah E , Ryan L , Silverberg N (2018) NIA-AA Research Framework: Toward a biological definition of Alzheimer’s disease. Alzheimer’s Dement. 14 , 535–562.29653606
[10] Dong Q , Zhang W , Wu J , Li B , Schron EH , McMahon T , Shi J , Gutman BA , Chen K , Baxter LC , Thompson PM , Reiman EM , Caselli RJ , Wang Y (2019) Applying surface-based hippocampal morphometry to study APOE-E4 allele dose effects in cognitively unimpaired subjects. NeuroImage Clin. 22 , 101744.30852398
[11] Frisoni GB , Fox NC , Jack CR , Scheltens P , Thompson PM (2010) The clinical use of structural MRI in Alzheimer disease. Nat. Rev. Neurol 6 , 67–77.20139996
[12] Reiter K , Nielson KA , Durgerian S , Woodard JL , Smith JC , Seidenberg M , Kelly DA , Rao SM (2017) Five-Year Longitudinal Brain Volume Change in Healthy Elders at Genetic Risk for Alzheimer’s Disease. J. Alzheimer’s Dis. 55 , 1363–1377.27834774
[13] Sørensen L , Igel C , Pai A , Balas I , Anker C , Lillholm M , Nielsen M (2017) Differential diagnosis of mild cognitive impairment and Alzheimer’s disease using structural MRI cortical thickness, hippocampal shape, hippocampal texture, and volumetry. NeuroImage Clin. 13 , 470–482.28119818
[14] Weston PS , Nicholas JM , Lehmann M , Ryan NS , Liang Y , Macpherson K , Modat M , Rossor MN , Schott JM , Ourselin S , Fox NC (2016) Presymptomatic cortical thinning in familial Alzheimer disease: A longitudinal MRI study. Neurology 87 , 2050–2057.27733562
[15] Pettigrew C , Soldan A , Zhu Y , Wang MC , Moghekar A , Brown T , Miller M , Albert M (2016) Cortical thickness in relation to clinical symptom onset in preclinical AD. NeuroImage Clin. 12 , 116–122.27408796
[16] Zhao Y , Raichle ME , Wen J , Benzinger TL , Fagan AM , Hassenstab J , Vlassenko AG , Luo J , Cairns NJ , Christensen JJ , Morris JC , Yablonskiy DA (2017) In vivo detection of microstructural correlates of brain pathology in preclinical and early Alzheimer Disease with magnetic resonance imaging. Neuroimage 148 , 296–304.27989773
[17] Zhou J , Liu J , Narayan VA , Ye J (2013) Modeling disease progression via multi-task learning. Neuroimage 78 , 233–248.23583359
[18] Zhang D , Shen D (2012) Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheimer’s disease. Neuroimage 59 , 895–907.21992749
[19] Vemuri P , Gunter JL , Senjem ML , Whitwell JL , Kantarci K , Knopman DS , Boeve BF , Petersen RC , Jack CR (2008) Alzheimer’s disease diagnosis in individual subjects using structural MR images: Validation studies. Neuroimage.
[20] Fan Y , Resnick SM , Wu X , Davatzikos C (2008) Structural and functional biomarkers of prodromal Alzheimer’s disease: A high-dimensional pattern classification study. Neuroimage 41 , 277–285.18400519
[21] Greenspan H , van Ginneken B , Summers RM (2016) Guest Editorial Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique. IEEE Trans. Med. Imaging 35 , 1153–1159.
[22] Krizhevsky A , Sutskever I , Hinton GE (2017) ImageNet classification with deep convolutional neural networks. Commun. ACM 60 , 84–90.
[23] Turaga SC , Murray JF , Jain V , Roth F , Helmstaedter M , Briggman K , Denk W , Seung HS (2010) Convolutional networks can learn to generate affinity graphs for image segmentation. Neural Comput. 22 , 511–538.19922289
[24] Hazlett HC , Gu H , Munsell BC , Kim SH , Styner M , Wolff JJ , Elison JT , Swanson MR , Zhu H , Botteron KN , Collins DL , Constantino JN , Dager SR , Estes AM , Evans AC , Fonov VS , Gerig G , Kostopoulos P , McKinstry RC , Pandey J , Paterson S , Pruett JR , Schultz RT , Shaw DW , Zwaigenbaum L , Piven J , Network TI (2017) Early brain development in infants at high risk for autism spectrum disorder. Nature 542 , 348–351.28202961
[25] Li H , Habes M , Wolk DA , Fan Y (2019) A deep learning model for early prediction of Alzheimer’s disease dementia based on hippocampal magnetic resonance imaging data. Alzheimer’s Dement. 1–12.30195482
[26] Kermany DS , Goldbaum M , Cai W , Valentim CCS , Liang H , Baxter SL , McKeown A , Yang G , Wu X , Yan F , Dong J , Prasadha MK , Pei J , Ting M , Zhu J , Li C , Hewett S , Dong J , Ziyar I , Shi A , Zhang R , Zheng L , Hou R , Shi W , Fu X , Duan Y , Huu VAN , Wen C , Zhang ED , Zhang CL , Li O , Wang X , Singer MA , Sun X , Xu J , Tafreshi A , Lewis MA , Xia H , Zhang K (2018) Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning. Cell 172 , 1122–1131.e9.29474911
[27] Xu X HH , Park P SS , Lee L HS , Hwang H HT (2019) Using transfer learning on whole slide images to predict tumor mutational burden in bladder cancer patients. bioRxiv Bioinforma.
[28] Lee H , Battle A , Raina R , Ng AY (2006) Efficient sparse coding algorithms. In Advances in neural information processing systems, pp. 801–808.
[29] Zhang J , Stonnington C , Li Q , Shi J , Bauer RJ , Gutman BA , Chen K , Reiman EM , Thompson PM , Ye J , Wang Y (2016) Applying sparse coding to surface multivariate tensor-based morphometry to predict future cognitive decline. In 2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI) IEEE, pp. 646–650.
[30] Mairal J , Bach F , Ponce J , Sapiro G (2009) Online dictionary learning for sparse coding. In Proceedings of the 26th Annual International Conference on Machine Learning, pp. 689–696.
[31] Giger ML (2018) Machine Learning in Medical Imaging. J. Am. Coll. Radiol 15 , 512–520.29398494
[32] Zhang J , Li Q , Caselli RJ , Thompson PM , Ye J , Wang Y (2017) Multi-Source Multi-Target Dictionary Learning for Prediction of Cognitive Decline. Inf Process Med Imaging 10265 , 184–197.28943731
[33] Liu M , Zhang J , Adeli E , Shen D (2019) Joint Classification and Regression via Deep Multi-Task Multi-Channel Learning for Alzheimer’s Disease Diagnosis. IEEE Trans. Biomed. Eng 66 , 1195–1206.30222548
[34] Ferrarini L , Palm WM , Olofsen H , van der Landen R , Jan Blauw G , Westendorp RGJ , Bollen ELEM , Middelkoop HAM , Reiber JHC , van Buchem MA , Admiraal-Behloul F (2008) MMSE scores correlate with local ventricular enlargement in the spectrum from cognitively normal to Alzheimer disease. Neuroimage 39 , 1832–1838.18160312
[35] Cano SJ , Posner HB , Moline ML , Hurt SW , Swartz J , Hsu T , Hobart JC (2010) The ADAS-cog in Alzheimer’s disease clinical trials: psychometric evaluation of the sum and its parts. J. Neurol. Neurosurg. Psychiatry 81 , 1363–1368.20881017
[36] Weiner MW , Veitch DP , Aisen PS , Beckett LA , Cairns NJ , Green RC , Harvey D , Jack CR , Jagust W , Liu E , others (2013) The Alzheimer’s Disease Neuroimaging Initiative: a review of papers published since its inception. Alzheimer’s Dement. 9 , e111–e194.23932184
[37] Jack CR Jr. , Bernstein MA , Fox NC , Thompson P , Alexander G , Harvey D , Borowski B , Britson PJ , Whitwell JL , Ward C , Dale AM , Felmlee JP , Gunter JL , Hill DLG , Killiany R , Schuff N , Fox-Bosetti S , Lin C , Studholme C , DeCarli CS , Krueger G , Ward HA , Metzger GJ , Scott KT , Mallozzi R , Blezek D , Levy J , Debbins JP , Fleisher AS , Albert M , Green R , Bartzokis G , Glover G , Mugler J , Weiner MW , Study A (2008) The Alzheimer’s disease neuroimaging initiative (ADNI): MRI methods. J. Magn. Reson. Imaging 27 , 685–691.18302232
[38] Shi J , Thompson PM , Wang Y (2011) Human Brain Mapping with Conformal Geometry and Multivariate Tensor-Based Morphometry. In Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), pp. 126–134.
[39] Lawrence S , Giles CL , Ah Chung Tsoi , Back AD (1997) Face recognition: a convolutional neural-network approach. IEEE Trans. Neural Networks 8 , 98–113.18255614
[40] Fischl B (2012) FreeSurfer. Neuroimage 62 , 774–781.22248573
[41] Zhang J , Fan Y , Li Q , Thompson PM , Ye J , Wang Y (2017) Empowering cortical thickness measures in clinical diagnosis of Alzheimer’s disease with spherical sparse coding. In 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017) IEEE, pp. 446–450.
[42] Zhang J , Shi J , Stonnington C , Li Q , Gutman BA , Chen K , Reiman EM , Caselli R , Thompson PM , Ye J , Wang Y (2016) Hyperbolic Space Sparse Coding with Its Application on Prediction of Alzheimer’s Disease in Mild Cognitive Impairment. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 326–334.
[43] Tibshirani R (2018) Regression Shrinkage and Selection Via the Lasso. J. R. Stat. Soc. Ser. B 58 , 267–288.
[44] Patenaude B , Smith SM , Kennedy DN , Jenkinson M (2011) A Bayesian model of shape and appearance for subcortical brain segmentation. Neuroimage 56 , 907–922.21352927
[45] Lorensen WE , Cline HE (1987) Marching cubes: A high resolution 3D surface construction algorithm. In ACM siggraph computer graphics, pp. 163–169.
[46] Wang Y , Lui LM , Gu X , Hayashi KM , Chan TF , Toga AW , Thompson PM , Yau S-T (2007) Brain Surface Conformal Parameterization using Riemann Surface Structure. IEEE Trans. Med. Imag 26 , 853–865.
[47] Shi J , Thompson PM , Gutman B , Wang Y , Alzheimer’s Disease Neuroimaging I (2013) Surface fluid registration of conformal representation: application to detect disease burden and genetic influence on hippocampus. Neuroimage 78 , 111–134.23587689
[48] Chou Y-Y , Leporé N , Saharan P , Madsen SK , Hua X , Jack CR , Shaw LM , Trojanowski JQ , Weiner MW , Toga AW , Thompson PM (2010) Ventricular maps in 804 ADNI subjects: correlations with CSF biomarkers and clinical decline. Neurobiol. Aging 31 , 1386–1400.20620663
[49] Chung MK , Dalton KM , Shen L , Evans AC , Davidson RJ (2007) Weighted Fourier Series Representation and Its Application to Quantifying the Amount of Gray Matter. IEEE Trans. Med. Imaging 26 , 566–581.17427743
[50] Suzuki K (2017) Overview of deep learning in medical imaging. Radiol. Phys. Technol 10 , 257–273.28689314
[51] Rumelhart DE , Hinton GE , Williams RJ (1986) Learning representations by back-propagating errors. Nature 323 , 533–536.
[52] Mittal S (2020) A survey of FPGA-based accelerators for convolutional neural networks. Neural Comput. Appl 32 , 1109–1139.
[53] Litjens G , Kooi T , Bejnordi BE , Setio AAA , Ciompi F , Ghafoorian M , van der Laak JAWM , van Ginneken B , Sánchez CI (2017) A survey on deep learning in medical image analysis. Med. Image Anal 42 , 60–88.28778026
[54] Deng J , Dong W , Socher R , Li L-J , Li K , Fei-Fei L (2009) Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 248–255.
[55] Jack CR , Bernstein MA , Fox NC , Thompson P , Alexander G , Harvey D , Borowski B , Britson PJ , L. Whitwell J , Ward C , Dale AM , Felmlee JP , Gunter JL , Hill DLG , Killiany R , Schuff N , Fox-Bosetti S , Lin C , Studholme C , DeCarli CS , Gunnar Krueger G , Ward HA , Metzger GJ , Scott KT , Mallozzi R , Blezek D , Levy J , Debbins JP , Fleisher AS , Albert M , Green R , Bartzokis G , Glover G , Mugler J , Weiner MW (2008) The Alzheimer’s disease neuroimaging initiative (ADNI): MRI methods. J. Magn. Reson. Imaging 27 , 685–691.18302232
[56] Jia Y , Shelhamer E , Donahue J , Karayev S , Long J , Girshick R , Guadarrama S , Darrell T (2014) Caffe. In Proceedings of the ACM International Conference on Multimedia - MM ‘14 ACM Press, New York, New York, USA, pp. 675–678.
[57] Lao Y , Wang Y , Shi J , Ceschin R , Nelson MD , Panigrahy A , Leporé N (2016) Thalamic alterations in preterm neonates and their relation to ventral striatum disturbances revealed by a combined shape and pose analysis. Brain Struct. Funct 221 , 487–506.25366970
[58] Wang X , Zhang T , Chaim TM , Zanetti M V , Davatzikos C (2015) Classification of MRI under the Presence of Disease Heterogeneity using Multi-Task Learning: Application to Bipolar Disorder. In Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015 Springer, pp. 125–132.
[59] Zhang J , Dong Q , Shi J , Li Q , Stonnington CM , Gutman BA , Chen K , Reiman EM , Caselli RJ , Thompson PM , Ye J , Wang Y (2019) Predicting Future Cognitive Decline with Hyperbolic Stochastic Coding and Ring-Shaped Patch Selection. In Medical Image Analysis (Under Revision).
[60] Canutescu AA , Dunbrack RL (2003) Cyclic coordinate descent: A robotics algorithm for protein loop closure. Protein Sci. 12 , 963–972.12717019
[61] Zhang T (2004) Solving large scale linear prediction problems using stochastic gradient descent algorithms. In Twenty-first international conference on Machine learning - ICML ‘04 ACM Press, New York, New York, USA, p. 116.
[62] Lin B , Li Q , Sun Q , Lai M-J , Davidson I , Fan W , Ye J (2014) Stochastic coordinate coding and its application for drosophila gene expression pattern annotation. arXiv Prepr. arXiv1407.8147.
[63] Lv J , Lin B , Li Q , Zhang W , Zhao Y , Jiang X , Guo L , Han J , Hu X , Guo C , Ye J , Liu T (2017) Task fMRI data analysis based on supervised stochastic coordinate coding. Med. Image Anal. 38 , 1–16.28242473
[64] Zhang J , Li Q , Caselli RJ , Thompson PM , Ye J , Wang Y (2017) Multi-source Multi-target Dictionary Learning for Prediction of Cognitive Decline. In Springer, Cham, pp. 184–197.
[65] Argyriou A , Evgeniou T , Pontil M (2008) Convex multi-task feature learning. Mach. Learn. 73 , 243–272.
[66] Hoerl AE , Kennard RW (1970) Ridge regression: Biased estimation for nonorthogonal problems. Technometrics 12 , 55–67.
[67] Ho R (2006) Paired-Samples T-Test In Handbook of Univariate and Multivariate Data Analysis and Interpretation with SPSS Chapman and Hall/CRC, pp. 47–50.
[68] Benjamini Y , Hochberg Y (1995) Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing. J. R. Stat. Soc. Ser. B 57 , 289–300.
[69] Tajbakhsh N , Shin JY , Gurudu SR , Hurst RT , Kendall CB , Gotway MB , Liang J (2016) Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning? IEEE Trans. Med. Imaging 35 , 1299–1312.26978662
[70] Worker A , Dima D , Combes A , Crum WR , Streffer J , Einstein S , Mehta MA , Barker GJ , C. R. Williams S , O’daly O (2018) Test–retest reliability and longitudinal analysis of automated hippocampal subregion volumes in healthy ageing and Alzheimer’s disease populations. Hum. Brain Mapp. 39 , 1743–1754.29341323
[71] Li B , Shi J , Gutman BA , Baxter LC , Thompson PM , Caselli RJ , Wang Y (2016) Influence of APOE Genotype on Hippocampal Atrophy over Time - An N=1925 Surface-Based ADNI Study. PLoS One 11 , e0152901.27065111
[72] Jack CR Jr. , Slomkowski M , Gracon S , Hoover TM , Felmlee JP , Stewart K , Xu Y , Shiung M , O’Brien PC , Cha R , Knopman D , Petersen RC (2003) MRI as a biomarker of disease progression in a therapeutic trial of milameline for AD. Neurology 60 , 253–260.12552040
[73] Thompson PM , Hayashi KM , Sowell ER , Gogtay N , Giedd JN , Rapoport JL , de Zubicaray GI , Janke AL , Rose SE , Semple J , Doddrell DM , Wang Y , van Erp TGM , Cannon TD , Toga AW (2004) Mapping cortical change in Alzheimer’s disease, brain development, and schizophrenia. Neuroimage 23 , S2–S18.15501091
[74] Cacciaglia R , Molinuevo JL , Falcón C , Brugulat-Serrat A , Sánchez-Benavides G , Gramunt N , Esteller M , Morán S , Minguillón C , Fauria K , Gispert JD (2018) Effects of APOE-ε4 allele load on brain morphology in a cohort of middle-aged healthy individuals with enriched genetic risk for Alzheimer’s disease. Alzheimer’s Dement. 14 , 902–912.29605385
[75] Operto G , Cacciaglia R , Grau-Rivera O , Falcon C , Brugulat-Serrat A , Ródenas P , Ramos R , Morán S , Esteller M , Bargalló N , Molinuevo JL , Gispert JD (2018) White matter microstructure is altered in cognitively normal middle-aged APOE-ε4 homozygotes. Alzheimers. Res. Ther 10 , 48.29793545
[76] Chung MK , Robbins SM , Dalton KM , Davidson RJ , Alexander AL , Evans AC (2005) Cortical thickness analysis in autism with heat kernel smoothing. Neuroimage 25 , 1256–1265.15850743
[77] Vest RS , Pike CJ (2013) Gender, sex steroid hormones, and Alzheimer’s disease. Horm. Behav 63 , 301–307.22554955
[78] Podcasy JL , Epperson CN (2016) Considering sex and gender in Alzheimer disease and other dementias. Dialogues Clin. Neurosci 18 , 437–446.28179815
[79] Nebel RA , Aggarwal NT , Barnes LL , Gallagher A , Goldstein JM , Kantarci K , Mallampalli MP , Mormino EC , Scott L , Yu WH , Maki PM , Mielke MM (2018) Understanding the impact of sex and gender in Alzheimer’s disease: A call to action. Alzheimer’s Dement. 14 , 1171–1183.29907423
[80] Thompson P (1998) Cortical variability and asymmetry in normal aging and Alzheimer’s disease. Cereb. Cortex 8 , 492–509.9758213
[81] Dale AM , Fischl B , Sereno MI (1999) Cortical Surface-Based Analysis. Neuroimage 9 , 179–194.9931268
[82] Chung MK , Robbins S , Evans AC (2005) Unified statistical approach to cortical thickness analysis. In Biennial International Conference on Information Processing in Medical Imaging, pp. 627–638.
[83] Wang Y , Yuan L , Shi J , Greve A , Ye J , Toga AW , Reiss AL , Thompson PM (2013) Applying tensor-based morphometry to parametric surfaces can improve MRI-based disease diagnosis. Neuroimage 74 , 209–230.23435208
[84] Sun D , van Erp TGM , Thompson PM , Bearden CE , Daley M , Kushan L , Hardt ME , Nuechterlein KH , Toga AW , Cannon TD (2009) Elucidating a Magnetic Resonance Imaging-Based Neuroanatomic Biomarker for Psychosis: Classification Analysis Using Probabilistic Brain Atlas and Machine Learning Algorithms. Biol. Psychiatry 66 , 1055–1060.19729150
[85] Gutman B , Wang Y , Morra J , Toga AW , Thompson PM (2009) Disease classification with hippocampal shape invariants. Hippocampus 19 , 572–578.19437498
[86] Wang Y , Zhang J , Gutman B , Chan TF , Becker JT , Aizenstein HJ , Lopez OL , Tamburo RJ , Toga AW , Thompson PM (2010) Multivariate tensor-based morphometry on surfaces: Application to mapping ventricular abnormalities in HIV/AIDS. Neuroimage 49 , 2141–2157.19900560
[87] Shen D , Wu G , Suk H-I (2017) Deep Learning in Medical Image Analysis. Annu. Rev. Biomed. Eng 19 , 221–248.28301734
[88] Donoho DL , Elad M (2003) Optimally sparse representation in general (nonorthogonal) dictionaries via l1 minimization. Proc. Natl. Acad. Sci 100 , 2197–2202.16576749
[89] Hinrichs C , Singh V , Xu G , Johnson SC (2011) Predictive markers for AD in a multi-modality framework: An analysis of MCI progression in the ADNI population. Neuroimage 55 , 574–589.21146621
[90] Zhang D , Wang Y , Zhou L , Yuan H , Shen D (2011) Multimodal classification of Alzheimer’s disease and mild cognitive impairment. Neuroimage 55 , 856–867.21236349
[91] Zhang D , Shen D (2012) Predicting Future Clinical Changes of MCI Patients Using Longitudinal and Multimodal Biomarkers. PLoS One 7 , e33182.22457741
[92] Farooq A , Anwar S , Awais M , Rehman S (2017) A deep CNN based multi-class classification of Alzheimer’s disease using MRI. In 2017 IEEE International Conference on Imaging Systems and Techniques (IST) IEEE, pp. 1–6.
[93] Song Y , Zhang Y-D , Yan X , Liu H , Zhou M , Hu B , Yang G (2018) Computer-aided diagnosis of prostate cancer using a deep convolutional neural network from multiparametric MRI. J. Magn. Reson. Imaging 48 , 1570–1577.29659067
[94] Pan SJ , Yang Q (2010) A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng. 22 , 1345–1359.
[95] Sharif Razavian A , Azizpour H , Sullivan J , Carlsson S (2014) CNN features off-the-shelf: an astounding baseline for recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 806–813.
[96] Ronneberger O , Fischer P , Brox T (2015) U-Net: Convolutional Networks for Biomedical Image Segmentation. In Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015, Navab N , Hornegger J , Wells WM , Frangi AF , eds. Springer International Publishing, Cham, pp. 234–241.
[97] Zhao A , Balakrishnan G , Durand F , Guttag JV , Dalca AV (2019) Data augmentation using learned transformations for one-shot medical image segmentation.
[98] Li Fei-Fei , Fergus R , Perona P (2006) One-shot learning of object categories. IEEE Trans. Pattern Anal. Mach. Intell 28 , 594–611.16566508
[99] Fink M (2005) Object classification from a single example utilizing class relevance metrics. In Advances in Neural Information Processing Systems.
[100] Zhang J , Li Q , Caselli RJ , Thompson PM , Ye J , Wang Y (2020) Multi-Resemblance Multi-Target Low-Rank Coding for Prediction of Cognitive Decline with Longitudinal Brain Images. In IEEE Transactions on Medical Imaging (Under Review).
[101] Zhang J , Wang Y (2019) Continually Modeling Alzheimer’s Disease Progression via Deep Multi-order Preserving Weight Consolidation. In 22nd International Conference on Medical Image Computing and Computer Assisted Intervention - MICCAI , Shenzhen, China, pp. 850–859.
[102] Hulbert S , Adeli H (2013) EEG/MEG- and imaging-based diagnosis of Alzheimer’s disease. Rev. Neurosci 24 ,.
[103] Dauwels J , Vialatte F , Cichocki A (2010) Diagnosis of Alzheimer’s Disease from EEG Signals: Where Are We Standing? Curr. Alzheimer Res 999 , 1–19.
[104] Zwan MD , Bouwman FH , Konijnenberg E , van der Flier WM , Lammertsma AA , Verhey FRJ , Aalten P , van Berckel BNM , Scheltens P (2017) Diagnostic impact of [18F]flutemetamol PET in early-onset dementia. Alzheimers. Res. Ther 9 , 2.28093088
[105] Salvatore C , Cerasa A , Castiglioni I (2018) MRI Characterizes the Progressive Course of AD and Predicts Conversion to Alzheimer’s Dementia 24 Months Before Probable Diagnosis. Front. Aging Neurosci 10 , 135.29881340
[106] Langbaum JB , Fleisher AS , Chen K , Ayutyanont N , Lopera F , Quiroz YT , Caselli RJ , Tariot PN , Reiman EM (2013) Ushering in the study and treatment of preclinical Alzheimer disease. Nat. Rev. Neurol 9 , 371–81.23752908
[107] Combettes PL , Wajs VR (2005) Signal recovery by proximal forward-backward splitting. Multiscale Model. Simul 4 , 1168–1200.
