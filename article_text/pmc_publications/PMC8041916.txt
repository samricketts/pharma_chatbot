LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


9503760
20530
J Int Neuropsychol Soc
J Int Neuropsychol Soc
Journal of the International Neuropsychological Society : JINS
1355-6177
1469-7661

33046162
8041916
10.1017/S1355617720000934
NIHMS1621987
Article
Identifying sensitive measures of cognitive decline at different clinical stages of Alzheimer’s disease
Jutten Roos J. 1
Sikkes Sietske A.M. 12
Amariglio Rebecca E. 23
Buckley Rachel F. 2345
Properzi Michael J. 2
Marshall Gad A. 23
Rentz Dorene M. 23
Johnson Keith A. 26
Teunissen Charlotte E. 7
Van Berckel Bart N.M. 8
Van der Flier Wiesje M. 1
Scheltens Philip 1
Sperling Reisa A. 23
Papp Kathryn V. 23
Alzheimer Disease Neuroimaging Initiative National Alzheimer’s Coordinating Center, the Harvard Aging Brain Study, and the Alzheimer Dementia Cohort*
1 Alzheimer Center Amsterdam, Department of Neurology, Amsterdam Neuroscience, Amsterdam UMC, Vrije Universiteit Amsterdam, Amsterdam, the Netherlands
2 Department of Neurology, Massachusetts General Hospital, Harvard Medical School, Boston MA, USA
3 Department of Neurology, Brigham and Women’s Hospital, Harvard Medical School, Boston MA, USA
4 Florey Institute of Neuroscience and Mental Health, Melbourne, VIC, Australia
5 Melbourne School of Psychological Sciences, University of Melbourne, Melbourne, VIC, Australia
6 Department of Radiology, Massachusetts General Hospital, Harvard Medical School, Boston MA, USA
7 Neurochemistry Laboratory, Department of Clinical Chemistry, Amsterdam UMC, Vrije Universiteit Amsterdam, Amsterdam Neuroscience, The Netherlands
8 Department of Radiology and Nuclear Medicine, Amsterdam UMC, Vrije Universiteit Amsterdam, Amsterdam, The Netherlands
Corresponding author: Roos J. Jutten, PhD, Alzheimer Center Amsterdam, Amsterdam UMC, location VUmc, P.O. Box 7057, 1007 MB Amsterdam, The Netherlands, E| r.jutten@amsterdamumc.nl, P| +31 20 4440823
4 12 2020
13 10 2020
5 2021
21 5 2021
27 5 426438
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Objective:

Alzheimer’s disease (AD) studies are increasingly targeting earlier (pre)clinical populations, in which the expected degree of observable cognitive decline over a certain time-interval is reduced as compared to the dementia stage. Consequently, endpoints to capture early cognitive changes require refinement. We aimed to determine the sensitivity to decline of widely-applied neuropsychological tests at different clinical stages of AD as outlined in the National Institute on Aging – Alzheimer’s Association (NIA-AA) research framework.

Method:

Amyloid-positive individuals (as determined by PET or CSF) with longitudinal neuropsychological assessments available were included from four well-defined study cohorts, and subsequently classified among the NIA-AA stages. For each stage, we investigated the sensitivity to decline of seventeen individual neuropsychological tests using linear mixed models.

Results:

1103 participants (age=70.54±8.7, 47% female) were included: n=120 Stage 1, n=206 Stage 2, n=467 Stage 3 and n=309 Stage 4. Neuropsychological tests were differentially sensitive to decline across stages. E.g. Category Fluency captured significant 1-year decline as early as Stage 1 (β=−.58, p&lt;.001). Word List Delayed Recall (β=−.22, p&lt;.05) and Trail Making Test (β=6.2, p&lt;.05) became sensitive to 1-year decline in Stage 2, whereas the Mini-Mental State Examination did not capture 1-year decline until Stage 3 (β=−1.13, p&lt;.001) and 4 (β=−2.23, p&lt;.001).

Conclusions:

We demonstrated that commonly-used neuropsychological tests differ in their ability to capture decline depending on clinical stage within the AD continuum (preclinical to dementia). This implies that stage-specific cognitive endpoints are needed to accurately assess disease progression and increase the chance of successful treatment evaluation in AD.

Alzheimer’s disease
cognitive decline
outcome measures
disease progression

Introduction

Accurately capturing cognitive changes along the Alzheimer’s disease (AD) continuum is essential for monitoring clinical progression and evaluating the efficacy of treatments to slow or halt cognitive decline (Evans et al., 2018; Food and Drug Administration, 2018). Future AD research and clinical trials will likely target a more narrow spectrum of participants at earlier disease stages, in which AD pathology is present but clinical symptoms remain subtle or absent (Bateman et al., 2012; Dubois et al., 2016). In these (pre)clinical stages, the expected degree of observable cognitive decline over a certain time interval is likely reduced as compared to later clinical stages in which cognitive impairment is (more) evident and decline more rapid (Sperling et al., 2011). As most existing cognitive tests were primarily designed to track decline in the mild cognitive impairment (MCI) and dementia stages, they are probably suboptimal to track subtle cognitive decline observed in preclinical stages of AD (Evans et al., 2018; Mortamais et al., 2017; Rentz et al., 2013). In addition, several studies have shown that tests addressing specific cognitive domains such as episodic memory and semantic memory are more prone to capture decline in early clinical stages of AD, as compared to, for example, tests addressing global cognition (Lim et al., 2016; Mortamais et al., 2017; Papp, Rentz, Orlovsky, Sperling, &amp; Mormino, 2017). Consequently, optimal cognitive endpoints to assess cognitive changes over time are likely to differ across clinical stages on the AD continuum.

In the recently updated National Institute of Aging – Alzheimer’s Association (NIA-AA) research framework, Jack et al. proposed a novel clinical staging scheme to classify individuals along the continuum of AD, based on the presence of AD pathophysiology and severity of clinical symptoms (C R Jack et al., 2018). In this 4+ clinical staging scheme, Stage 1 is described as a preclinical stage in which overt clinical symptoms are absent. Stage 2 is defined by subjective concerns regarding previous level of functioning and/or subtle abnormalities detectable on (longitudinal) sensitive cognitive testing, without the presence of any functional impairment. In Stage 3, abnormalities on cognitive tests are more apparent and mild functional impairment may be detectable. Finally, Stage 4, 5 and 6 are described as overt dementia, corresponding to mild, moderate and severe dementia respectively. Grouping individuals into these refined clinical stages may be beneficial in optimizing the selection and assessment of participants for a given treatment target and may be similarly beneficial in refining the cognitive assessment procedures optimal for a given stage (Jack et al., 2019). However, specific procedures to operationalize these stages have yet to be delineated. Moreover, it is yet unknown to what extent currently used cognitive outcomes vary in their ability to capture decline at the different clinical stages defined in the NIA-AA research framework.

A more refined understanding of the differential sensitivity of existing neuropsychological tests at the different NIA-AA defined clinical stages is needed to provide guidance on the selection of outcome measures when this framework is applied to define the treatment population. Therefore, the current study aimed to identify sensitive measures to detect cognitive change for each of the four NIA-AA defined clinical stages (C R Jack et al., 2018). To achieve this, we operationalized the NIA-AA clinical staging schema into measurable criteria and applied these criteria across AD biomarker-positive individuals obtained from four large cohorts. Subsequently, we investigated the sensitivity to decline of commonly-used neuropsychological tests by clinical stage, with a focus on the pre-dementia stages 1 to 3. We hypothesized that with increasing clinical stage, more tests would show greater sensitivity to decline.

Methods

Study participants

Data were obtained from the Harvard Aging Brain Study (HABS), the Alzheimer’s Disease Neuroimaging Initiative (ADNI) and National Alzheimer’s Coordinating Center (NACC) databases, and the Amsterdam Dementia Cohort (ADC). For each cohort, specific recruitment criteria and data collection have been described in detail elsewhere (Aisen et al., 2010; Beekly et al., 2007; Dagley et al., 2017; van der Flier, 2018). Briefly, the HABS cohort is a community-based sample of individuals aged ≥ 63 years, who are considered clinically normal at baseline by 1) a global Clinical Dementia Rating score of 0; 2) and performance above education-adjusted cut-offs on Logical Memory Story A Delayed Recall and the Mini-Mental State Examination (MMSE) (Dagley et al., 2017). ADNI is a multicenter longitudinal cohort study with the primary goal of testing whether serial neuroimaging and other biological, clinical and neuropsychological markers can be combined to measure clinical progression on the AD spectrum (http://adni.loni.usc.edu/wp-content/uploads/2008/07/adni2-procedures-manual.pdf). The NACC has developed and maintains a large database of standardized clinical and neuropathological research data, obtained from NIA-funded Alzheimer’s Disease Centers across the United States (Beekly et al., 2007; Morris et al., 2006). The NACC database contains mostly memory-clinic referred participants with some additional community-based recruitment. The ADC is a Dutch memory-clinic based cohort of individuals visiting the Alzheimer Center Amsterdam (van der Flier, 2018). All participants in the ADC had undergone a standard diagnostic work-up, including medical history, neurological examination, laboratory screening tests and neuropsychological evaluation. All studies were approved by an ethical review board, and all participants provided written informed consent to use their clinical data for research purposes. All data included in this manuscript was obtained in compliance with the Helsinki Declaration. All data were collected between June 2002 and April 2018.

Selection criteria for the current study included 1) amyloid positivity as determined by at least one abnormal marker of amyloid accumulation in positron emission tomography (PET) imaging or amyloid-β levels in cerebrospinal fluid (CSF) using previously published cohort-specific summary measures and cut-offs [19–21] (detailed amyloid assessment methods for each cohort are specified in Supplementary file 1); 2) at least one follow-up visit with neuropsychological testing available; and 3) MMSE &gt; 10 or Montreal Cognitive Assessment &gt; 2 at baseline (Folstein, Folstein, &amp; McHugh, 1975; Nasreddine et al., 2005). Neuropsychological baseline performance was anchored to time of first amyloid assessment.

AD biomarker classification

The HABS and ADNI cohorts used PET imaging data only, while both PET and CSF measures were used in NACC and ADC. Amyloid binding in HABS was measured using Pittsburgh compound B PET scanning, and in ADNI using Florbetapir AV-45 PET scanning (summary data were obtained from the ADNI Laboratory of Neuroimaging database: http://www.loni.ucla.edu/ADNI/). In HABS, amyloid positivity was based on GMM of the distribution volume ratio (DVR) of mean uptake in frontal, lateral parietal and temporal, and retrosplenial regions (cut off value ≥ 1.20 (Mormino et al., 2014)). In ADNI, amyloid positivity was based on standard uptake value ratios of mean uptake in four cortical regions (frontal, cingulate, parietal and temporal cortices) normalized to the whole cerebellum uptake (cut-off value ≥ 1.11 (Clark et al., 2011)). In the NACC cohort, amyloid positivity in PET or CSF was based on each center’s local standard for positivity (Besser et al., 2018). In the ADC, amyloid positivity on Florbetaben, Flutametamol, PIB-PET or Florbetapir AV-45 PET scans was based on whole-brain visual assessment performed by an experienced nuclear medicine physician (B.N.M.B) who was blinded to clinical information. Amyloid positivity in CSF in the ADC was based on drift corrected amyloid-β 1–42 values, with a cut-off of 813 pg/ml (Tijms et al., 2018).

Clinical stages

To operationalize the NIA-AA clinical staging scheme, we used baseline measures of subjective cognitive decline (SCD), cognitive impairment and functional impairment available across cohorts (Table 1).

Subjective cognitive decline.

SCD (yes/no) was quantified as either a memory-clinic visit or by an SCD screening score for the community-based cohorts. That is, by definition, all individuals from the ADC memory-clinic cohort were classified as having SCD. For the NACC cohort, all individuals that were referred by an ADRC (n=154, 75%) were classified as having SCD as well. For the remaining NACC individuals, as well as the for all individuals from the ADNI and HABS cohorts, an SCD screening score was calculated. This SCD screening score was extracted from single-items from available self-report questionnaires (i.e. the Everyday Cognition scale (ECog) (Farias et al., 2008), the Geriatric Depression Scale – 12 item version (GDS-12)(Yesavage et al., 1983), and Memory Questionnaire (MemQ), addressing 1) recent change in memory functioning (MemQ item 1); 2) consistent change over the last few months (GDS-12 item 6); and 3) concern associated with this change (ECog item 1). Answers were scored as yes = 1 and no = 0, leading to a total score range from 0–3 with higher scores reflecting higher level of SCD. A score of 2 or higher was labelled as having SCD.

Cognitive impairment.

Level of cognitive impairment was quantified using 1) the MMSE (or a MOCA transformed score if MMSE was unavailable) (Folstein et al., 1975; Nasreddine et al., 2005; Trzepacz, Hochstetler, Wang, Walker, &amp; Saykin, 2015); and 2) a memory retention score reflecting the proportion of items recalled from either story or word list on immediate and delayed recall (Schmidt, 1996; Wechsler, 1987).

Functional impairment.

Severity of functional impairment was determined using the CDR® Dementia Staging Instrument global score or the CDR sum of boxes (CDR-SB) (Hughes, Berg, Danziger, Coben, &amp; Martin, 1982; M. M. Williams, Storandt, Roe, &amp; Morris, 2013). For all measures, we created stage-specific cut-off scores based on previously published data or the highest or lowest quintiles in our sample (Table 1).

Classification criteria.

To summarize, Stage 1 was quantified as 1) no visit to a memory-clinic or a SCD screening score &lt; 2; 2) an MMSE score of ≥ 26 (Chapman et al., 2016), a proportion of ≥ 52% items learned on a story or word list (highest quintile in our sample) and a delayed recall of &gt; 11 items on the logical memory tests (Aisen et al., 2010) and 3) a CDR-SB score ≤.05 and global CDR of 0 (M. M. Williams et al., 2013). Stage 2 was quantified as 1) an MMSE score of ≥ 26 (Chapman et al., 2016), a proportion of ≥ 52% items learned on a story or word list and a delayed recall; and 2) a CDR-SB score ≤1 and global CDR of &lt;.5 [31] only if caused by endorsement of memory box of the CDR-SB of 0.5. Stage 3 was quantified as 1) a MMSE score ≥ 24 (Chapman et al., 2016) and a proportion items learned ≥ %20 (lowest quintile in our sample); 2) a CDR-SB score between 1.5 and 4 and global CDR of .5 (M. M. Williams et al., 2013). Stage 4 was quantified as 1) a MMSE score &lt;26 [31] and a proportion items learned &lt; 20% (lowest quantile in our sample); 2) a CDR-SB score ≥ 4.5 and global CDR of ≥ 1 (M. M. Williams et al., 2013).

We initially applied a strict approach in that at least one variable from all clinical features (SCD, cognition and function) was required for categorization, in order to create distinct categories in line with clinical trial screening procedures. Participants who remained unclassified due to incongruencies among clinical features were classified in the stage in which the majority of their classification measures fit best. For example, an individual with an MMSE of 23, a proportion items learned of .45, a CDR-SB of 2 and a global CDR score of 0.5 was classified as Stage 3.

Neuropsychological tests

We selected all neuropsychological tests available in at least two cohorts. This resulted in a total of 12 different tests providing 17 individual measures. Supplementary Table 1 provides an overview of which tests were available by cohort. Global cognition measures included the MMSE and MOCA (Folstein et al., 1975; Nasreddine et al., 2005). Episodic memory measures included the Wechsler memory subscale Logical Memory (LM) immediate recall and delayed recall (Wechsler, 1987), and the Rey Auditory Verbal Learning Test (RAVLT) (Schmidt, 1996) with version 1 used in ADC, and version 1 and 2 alternated in ADNI. Additionally, we standardized immediate recall, delayed recall and recognition measures obtained from list learning tests that were available across cohorts (Selective Reminding Test in HABS, the ADAS-Cog Word Lists in ADNI and RAVLT in ADC), by calculating z-scores by cohort with total baseline mean and standard deviation as reference values. Subsequently, these z-scores were combined into an overall immediate recall score, an overall delayed recall score and overall recognition score. Semantic memory measures included the Category Fluency Test (CFT) Animals and Vegetables (Lezak, 2004) and the Boston Naming Test (BNT) (B. W. Williams, Mack, &amp; Henderson, 1989). EF measures included the controlled oral word association test (COWAT) (Ruff, Light, Parker, &amp; Levin, 1996) and Trail Making Test (TMT) part B (Tombaugh, 2004). Attention and working memory measures included the Wechsler Adult Intelligence Scale (WAIS-IV) subscales Digit Span Forward and Backward (Wechsler, 2008). Measures of processing speed included the TMT part A (Tombaugh, 2004), and WAIS-IV Symbol Substitution (Wechsler, 2008).

Statistical analyses

Statistical analyses were performed using R version 3.5.3 (R Core Team, 2018). Statistical significance was set at p&lt;.05. Demographic and clinical differences between stages were investigated using Chi-square tests and one-way analyses of variance followed by Tukey’s HSD test for post-hoc comparisons.

To investigate the sensitivity to change over time of each neuropsychological test, a series of linear mixed models (LMM) were performed with a random intercept and slope for each subject. Separate models were run for each test score (dependent), with time (measured on a continuous level), age (centered at overall mean), sex, education (centered at overall mean), stage (as categorial variable), and the interaction between time and stage as independent variables. To examine whether tests were differentially sensitive to change over time across stages, we focused on the time and time*stage estimates. Subsequently, LMM were repeated for each cognitive test separately for each stage, to identify which tests were sensitive within 12 months of follow-up within each stage. For tests that were identified as sensitive to 12-months decline, mean to standard deviation ratios (MSDR) of change over baseline to 12, 24 and 36 months follow-up were calculated as a measure of effect-size.

Results

A total of 1103 participants were included (HABS n=74, ADNI n=506, NACC = 204, ADC n=319). The majority of the US individuals were Caucasian (93% in ADNI, 92% in NACC, and 78% in HABS). Overall, years of follow-up ranged from 1 to 12.9, with a mean of 2.3 ± 1.6 years, and number of follow-up visits ranged from 1 to 8, with a mean of 2.3 ± 1.4 visits. After applying our defined staging criteria, n=1005 (91%) participants were initially classified in one of the four stages while n=99 (9%) remained unclassified due to incongruencies among classification measures, and were then classified in the closest stages. Ultimately, n=120 were classified as Stage 1, n=206 as Stage 2, n=467 as Stage 3, and n=309 as Stage 4+.

Table 2 presents the demographic and clinical characteristics for the different stages. Groups differed regarding age, sex and education, with post-hoc comparisons revealing that Stage 1 participants were older than all other participants, and Stage 2 participants were older than Stage 4 participants. Post-hoc comparisons also showed that Stage 1 participants had higher education levels compared with all other participants and Stage 2 had higher education than Stage 4 participants. By definition, we found worse MMSE and CDR-SB scores with increasing clinical stage. All HABS participants fell into Stage 1 and 2, all ADC participants were classified in Stage 2 to 4 and ADNI and NACC participants were distributed among all stages. Overall, the four stages were in correspondence with clinical diagnoses as established in the original cohorts, given that Stage 1 only included cognitively normal participants, and that most SCD, MCI and dementia participants fell into Stage 2, 3 and 4 respectively (Table 2).

Sensitivity to decline over time by cognitive test

Overall LMM results revealed that neuropsychological tests were differentially sensitive to change over time at different clinical stages, as indicated by the Time and Time*Stage estimates in Table 3 (and Supplementary Table 2). For example, CFT Animals detected annual decline at all stages, showing a significant decline of .58 points (i.e. animals named in 60 seconds) in Stage 1 and Stage 2 (p&lt;.001), and marginally significant steeper decline in Stage 3 (−.28 points, p=.06), and significantly steeper decline in Stage 4 (−1.27 points, p&lt;.001). In contrast, the MMSE did not capture decline in Stage 1 and 2, but showed steeper decline in Stage 3 (−1.13 points, p&lt;.001) and Stage 4 (−2.23 points, p&lt;.001). Figure 1 illustrates the difference in sensitivity to decline over time for these two measures.

Second, LMM results indicated that Time*Stage estimates escalated by increasing clinical stage (Table 3), with most tests exhibiting a steeper decline in Stage 3 and 4 as compared to Stage 1.

Sensitivity to decline of cognitive tests by follow-up duration

Annual decline on the individual neuropsychological tests summarized by cognitive domain is shown in Figure 2, with corresponding regression coefficients presented in Supplementary Table 3. Only 3 measures captured significant decline after 12 months in Stage 1 (CFT Animals, CFT Vegetables, LM Immediate Recall) and only 4 measures captured decline after 12 months in Stage 2 (CFT Animals, CFT Vegetables, Word List Delayed Recall and TMT-B). Six additional measures detected decline in Stage 3, (Digit Span Backward, Digit Span Forward, Word List Recognition, MMSE, MOCA and TMT-A). In Stage 4, all measures detected decline after 12 months, except for Word Recognition. Table 4 presents the tests that detected decline after 12 months separately for Stage 1, 2 and 3, including their MSDRs at 12, 24 and 36 months follow-up, showing that, overall, MSDR’s tended to increase over time.

Discussion

We operationalized the NIA-AA clinical scheme into measurable criteria, which enabled classification of individuals with biomarker evidence of AD into the four different stages of clinical severity. Subsequently, we demonstrated that neuropsychological tests differed in their sensitivity to decline at these different clinical stages. We found that more tests were sensitive to decline by increasing clinical stage. Moreover, in general longer time intervals were needed to capture greater magnitude of change. Sensitive tests for Stage 1 focused primarily on semantic memory, whereas sensitive tests in succeeding stages also covered episodic memory, executive functioning (Stage 2), working memory, processing speed and global cognition (Stage 3 and 4).

We found that most tests were sensitive to change over time in Stage 3 and 4, and that the majority of those were capable of detecting decline after one year. This is unsurprising, as most of those measures were originally designed to detect frank cognitive decline which is assumed to become apparent from Stage 3 on (C R Jack et al., 2018). However, we also identified a few measures that were sensitive to decline at Stage 1 and 2. Sensitive tests for Stage 1 included the CFT Animals and Vegetables (semantic memory) and LM immediate recall (episodic memory), whereas sensitive tests in Stage 2 included both CFT measures as well, plus Delayed Recall (episodic memory) and TMT-B (executive functioning). These results are largely in line with other studies showing that tests addressing the cognitive domains semantic memory, episodic memory and executive functioning are among the first to decline in early AD (Mortamais et al., 2017; Papp et al., 2017; Ritchie et al., 2017).

Notably, not all measures addressing a particular cognitive domain were similarly sensitive to change across stages. For instance, a discrepancy between two semantic memory measures was observed, as the CFT detected decline in Stage 1 and 2, whereas the BNT did not. Possible explanations for this include differences regarding the difficulty level of both tests, as well as differences in measurement characteristics; for example, the BNT is untimed and has a fixed maximum score. As such, the BNT might be more susceptible to ceiling-effects as compared to the CFT, thereby limiting its ability to detect decline in individuals with only subtle cognitive impairment. However, this is not to suggest that measurement properties alone influence the sensitivity of tests, as illustrated by the differences in sensitivity to change between the CFT and COWAT measures, which have similar measurement properties but rely on different cognitive strategies (Henry, Crawford, &amp; Phillips, 2004).

Multi-domain cognitive composite measures have been designed in attempt to improve the measurement of cognitive change in early stages of AD. Examples include the Preclinical Alzheimer’s Cognitive Composite (PACC) (Donohue et al., 2014) and the Alzheimer’s Prevention Initiative (API) composite for preclinical AD (Langbaum et al., 2014), and the Alzheimer’s disease Composite Score (ADCOMS) (Wang et al., 2016) and the Cognitive-Functional Composite for prodromal stages of AD.(Jutten et al., 2017) While composite scores resulting from these measures seem capable of tracking decline in preclinical and prodromal stages of AD (Donohue et al., 2017; Lim et al., 2016), few studies have focused on the individual components that contribute to these composites. In the current study, we identified sensitive measures that largely correspond with tests that have been included in the aforementioned composite measures (Donohue et al., 2014; Jutten et al., 2017; Langbaum et al., 2014). However, our results also indicated that some of the measures included in composites for preclinical AD may actually be less useful for detecting decline in this stage. For instance, the PACC includes the MMSE and the API includes both the MMSE and BNT, whereas in our dataset these measures were not found to be sensitive to decline before Stage 3. This suggests that existing composites could potentially be further optimized to track short-term disease progression in Stage 1 and 2. Our findings could be used to select most sensitive measures in order to optimize composites or create novel composites, which could then be validated in an independent sample.

There are some limitations that should be taken into account. First, our combination of community-based and memory-clinic based cohorts may have led to some heterogeneity in our sample, especially in Stages 1 and 2. With regard to the memory-clinic based cohorts, a potential limitation includes the fact that individuals who were labeled as having SCD may include individuals who actually did not have a memory concern themselves, but went to the memory-clinic because a family member or other person expressed such a concern. Additionally, our results might have been biased by other differences between study cohorts, for example regarding amyloid assessment methods, follow-up timeframes, and cross-cultural differences. However, we explored cohort-effects on the selected cognitive tests in an initial stage of our analyses, which we found did not affect our results. Another potential limitation includes the fact that we only looked at measures that were available across cohorts, thereby excluding potentially sensitive measures, such as the Free and Cued Selective Reminding Test (Grober, Veroff, &amp; Lipton, 2018) which was only available in the HABS cohort. However, we chose this approach to avoid that results on a specific tests would be driven by a single cohort. Lastly, it should be noted that the majority of our sample is Caucasian, which limits the generalizability of our findings across populations. On the other hand, our study represents a more global sample than other studies that rely on single cohorts, by combining four datasets originating from Europe and the US, and also regional diversity within the US. Another major strength of this study is our large sample of AD biomarker positive individuals covering the entire AD continuum. Furthermore, our classification of clinical severity as defined by the NIA-AA framework might have provided a more objective method to classify individuals instead of relying on clinical syndrome diagnoses that could have been biased by cohort (Clifford R Jack et al., 2019).

To conclude, we demonstrated that commonly-used cognitive tests differ in their ability to capture short-term cognitive decline and therefore disease progression depending on clinical stage (preclinical to symptomatic) within the AD continuum. This implies that stage-specific cognitive endpoints are needed to accurately assess change over time at different clinical stages of AD. The current study results can provide guidance on the selection of cognitive endpoints when the NIA-AA 2018 framework is applied to define the treatment population. Since only few existing cognitive tests were identified as sensitive in Stage 1 and 2, future directions include the development and validation of optimized composite measures, to capture the subtle cognitive decline observed in those preclinical stages. Furthermore, novel test paradigms that rely on digital assessment and scoring software are being developed, which could potentially aid in detecting and tracking of a greater magnitude of decline in preclinical stages of AD. This will ultimately lead to more accurate and fine-grained measurement, and thereby increase the chance of successful evaluation of potentially preventive treatments for AD.

Supplementary Material

1

2

3

Acknowledgements

The authors are very thankful to all patients and participants in the studies included in the paper, as well as to everyone involved in the data collection and data sharing.

a. Conflicts of interest disclosure

RJJ, REA, RFB, MJP, DMR, KAJ, BNMB, PS and RS report no disclosures relevant to this manuscript. SAMS is supported by grants from JPND and Zon-MW, and has provided consultancy services in the past 2 years for Nutricia and Takeda. All funds were paid to her institution. GAM has received research salary support from Eisai Inc., Eli Lilly and Company, Janssen Alzheimer Immunotherapy, Novartis, and Genentech. Additionally, GAM has served as a consultant for Grifols Shared Services North America, Inc., Eisai Inc., and Pfizer. WMF holds the Pasman chair. CET received grants from the European Commission, the Dutch Research Council (ZonMW), Association of Frontotemporal Dementia/Alzheimer’s Drug Discovery Foundation, The Weston Brain Institute, Alzheimer Nederland. CET has functioned in advisory boards of Roche, received non-financial support in the form of research consumables from ADxNeurosciences and Euroimmun, performed contract research or received grants from Probiodrug, Biogen, Esai, Toyama, Janssen prevention center, Boehringer, AxonNeurosciences, EIP farma, PeopleBio, Roche. KVP has served as a paid consultant for Biogen.

b. Funding sources of financial support

HABS. The Harvard Aging Brain Study is funded by the National Institute on Aging (P01AG036694; Principal Investigators Reisa Sperling, Keith Johnson) with additional support from several philanthropic organizations. KVP (1K23AG053422-01) is supported by a K23 award from NIA and an award from the Alzheimer’s Association.

ADC. The Alzheimer Center Amsterdam is supported by Alzheimer Nederland and Stichting VUMC funds. Research of the Alzheimer Center Amsterdam is part of the neurodegeneration research program of Amsterdam Neuroscience. The clinical database structure was developed with funding from Stichting Dioraphte. The SCIENCe project is supported by a research grant from Gieskes-Strijbis fonds. The present study is supported by a grant from Memorabel (grant no. 733050205), which is the research program of the Dutch Deltaplan for Dementia.

ADNI. Data collection and sharing for this project was funded by the Alzheimer’s Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie, Alzheimer’s Association; Alzheimer’s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol,Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann,La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research &amp; Development, LLC.; Johnson &amp; Johnson Pharmaceutical Research &amp; Development LLC.; Lumosity; Lundbeck; Merck &amp; Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer’s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.

NACC. The NACC database is funded by NIA/NIH Grant U01 AG016976. NACC data are contributed by the NIA-funded ADCs: P30 AG019610 (PI Eric Reiman, MD), P30 AG013846 (PI Neil Kowall, MD), P30 AG062428-01 (PI James Leverenz, MD) P50 AG008702 (PI Scott Small, MD), P50 AG025688 (PI Allan Levey, MD, PhD), P50 AG047266 (PI Todd Golde, MD, PhD), P30 AG010133 (PI Andrew Saykin, PsyD), P50 AG005146 (PI Marilyn Albert, PhD), P30 AG062421-01 (PI Bradley Hyman, MD, PhD), P30 AG062422-01 (PI Ronald Petersen, MD, PhD), P50 AG005138 (PI Mary Sano, PhD), P30 AG008051 (PI Thomas Wisniewski, MD), P30 AG013854 (PI Robert Vassar, PhD), P30 AG008017 (PI Jeffrey Kaye, MD), P30 AG010161 (PI David Bennett, MD), P50 AG047366 (PI Victor Henderson, MD, MS), P30 AG010129 (PI Charles DeCarli, MD), P50 AG016573 (PI Frank LaFerla, PhD), P30 AG062429-01(PI James Brewer, MD, PhD), P50 AG023501 (PI Bruce Miller, MD), P30 AG035982 (PI Russell Swerdlow, MD), P30 AG028383 (PI Linda Van Eldik, PhD), P30 AG053760 (PI Henry Paulson, MD, PhD), P30 AG010124 (PI John Trojanowski, MD, PhD), P50 AG005133 (PI Oscar Lopez, MD), P50 AG005142 (PI Helena Chui, MD), P30 AG012300 (PI Roger Rosenberg, MD), P30 AG049638 (PI Suzanne Craft, PhD), P50 AG005136 (PI Thomas Grabowski, MD), P30 AG062715-01 (PI Sanjay Asthana, MD, FRCP), P50 AG005681 (PI John Morris, MD), P50 AG047270 (PI Stephen Strittmatter, MD, PhD).

Figure 1. Comparison between Category Fluency Test (CFT), Word List Delayed Recall, and Mini-Mental State Examination (MMSE), based on LMM adjusting for age, sex and education. Scores were z-transformed using overall group mean and SD, to facilitate comparisons between tests.

Figure 2. Annual change for individual tests based on LMM correcting for, age, sex and education, stratified per stage. For each test, scores were z-transformed using baseline overall group mean and SD, to facilitate comparisons between tests.

Table 1. Operationalization of the NIA-AA clinical staging scheme

		Stage 1	Stage 2	Stage 3	Stage 4–6	
		No evidence of clinical impact	Subjective report of decline or subtle cognitive abnormalities	Apparent cognitive abnormalities with mild functional impairment	Overt dementia	
Pathophysiologic changes	Amyloid pathology	Abnormal	Abnormal	Abnormal	Abnormal	
Subjective complaints	Visit memory clinic	No	Not required	Not required	Not required	
	OR					
	SCD screening score*	&lt;2	Not required	Not required	Not required	
Cognitive abnormalities	MMSE	26–30	26–30	24–30	&lt; 26	
	AND					
	Story or list learning	Proportion items learned ≥.52* AND Delayed word recall &gt; 11 items	Proportion items learned ≥.52	Proportion items learned ≥ .20*	Proportion items learned &lt;.20	
Functional impact	CDR-SB	≤ .5	≤ 1.0**	1.5 – 4.5	≥ 4.5	
	Global CDR	0	0 – 0.5**	0.5 – 1	≥ 1	
* Based on the highest and lowest quintile in our study sample

** Only if caused by endorsement of memory box of the CDR-SB with 0.5.

Table 2. Demographic and clinical characteristics for each clinical stage

	Stage 1	Stage 2	Stage 3	Stage 4	P-Value	Post-hoc comparisons	
		
N	120	206	467	309	N.a.	N.a.	
Years of FU (M ± SD)	2.6 ± 1.6	2.8 ± 1.8	2.3 ±1.6	1.6 ± 1.1	N.a.	N.a.	
Age (M ± SD)	74.5 ± 6.4	70.9 ± 9	70.8 ± 8.2	68.4 ± 9.2	&lt;.001	Stage 1 &gt; Stage 3 &gt; Stage 4,Stage 1 &gt; Stage 2 &gt; Stage 4	
Female, n (%)	68 (57%)	107 (52%)	204 (44%)	135 (44%)	.02	N.a.	
Education (M ± SD)	16.2 ± 2.9	15.1 ± 3.3	15.1 ± 3.3	13.6 ± 3.6	&lt;.001	Stage 1 &gt; Stage 3 &gt; Stage 4, Stage 1 &gt; Stage 2 &gt; Stage 4	
MMSE (M ± SD)	29.1 ± 1	28.4 ±1.2	26.9 ±2	21.6 ±3.1	&lt;.001	Stage 1 &gt; Stage 3 &gt; Stage 4, Stage 2 &gt; Stage 3	
CDR-SB (M ± SD)	0.04 ±0.13	0.29 ±0.38	2.05 ±1.3	5.5 ±2.1	&lt;.001	Stage 1 &gt; Stage 3 &gt; Stage 4, Stage 2 &gt; Stage 3	
HABS, n (%)	42 (35%)	32 (16%)	0 (0%)	0 (0%)	N.a.	N.a.	
ADC, n (%)	0 (0%)	79 (38%)	94 (20%)	145 (47%)	N.a.	N.a.	
ADNI, n (%)	49 (41%)	72 (35%)	288 (62%)	97 (31%)	N.a.	N.a.	
NACC, n (%)	29 (24%)	23 (11%)	85 (18%)	67 (22%)	N.a.	N.a.	
CN	120 (100%)	91 (44%)	11 (2%)	0	N.a.	N.a.	
SCD	0	44 (22%)	11 (2%)	2 (1%)	N.a.	N.a.	
MCI	0	71 (34%)	317 (68%)	4 (2%)	N.a.	N.a.	
Dementia	0	0	128 (28%)	300 (97%)	N.a.	N.a.	
** HABS = Harvard Aging Brain Study; ADC = Amsterdam Dementia Cohort; ADNI = Alzheimer’s Disease Neuroimaging Initiative; NACC = National Alzheimer’s Coordinating Center.

Table 3. Regression coefficients from linear mixed models investigating change over time in cognitive test scores

	Global cognition	Semantic memory	
		
	MMSE	MOCA	CFT Animals	CFT Vegetables	BNT Total 30	
	Beta	95% CI	p-value	Beta	95% CI	p-value	Beta	95% CI	p-value	Beta	95% CI	p-value	Beta	95% CI	p-value	
		
Intercept	28.97	28.50 – 29.44	&lt;0.001	25.66	24.29 – 27.03	&lt;0.001	20.37	19.47 – 21.28	&lt;0.001	12.84	11.89 – 13.79	&lt;0.001	28.97	28.03 – 29.91	&lt;0.001	
Time (Stage 1)	−0.13	−0.43 – 0.17	0.409	−0.52	−1.33 – 0.29	0.215	−0.58	−0.84 – −0.32	&lt;0.001	−0.63	−0.85 – −0.41	&lt;0.001	−0.16	−0.41 – 0.09	0.198	
Stage 2	−0.45	−0.99 – 0.09	0.101	−1.90	−3.75 – −0.05	0.048	−0.97	−2.01 – 0.07	0.068	−0.62	−1.80 – 0.57	0.312	−1.22	−2.18 – −0.25	0.014	
Stage 3	−1.86	−2.34 – −1.38	&lt;0.001	−4.71	−6.20 – −3.22	&lt;0.001	−4.00	−4.92 – −3.07	&lt;0.001	−3.87	−5.00 – −2.74	&lt;0.001	−2.29	−3.16 – −1.42	&lt;0.001	
Stage 4	−6.68	−7.22 – −6.15	&lt;0.001	−11.67	−13.26 – −10.09	&lt;0.001	−7.76	−8.77 – −6.75	&lt;0.001	−7.30	−8.52 – −6.08	&lt;0.001	−6.18	−7.22 – −5.13	&lt;0.001	
Time*Stage2	−0.35	−0.74 – 0.04	0.076	0.68	−0.52 – 1.88	0.274	−0.00	−0.35 – 0.34	0.988	−0.02	−0.34 – 0.31	0.927	−0.11	−0.47 – 0.26	0.565	
Time*Stage3	−1.13	−1.47 – −0.80	&lt;0.001	−0.48	−1.43 – 0.46	0.318	−0.28	−0.58 – 0.02	0.064	−0.38	−0.92 – 0.17	0.175	−0.50	−0.78 – −0.21	0.001	
Time*Stage4	−2.23	−2.64 – −1.82	&lt;0.001	−1.63	−2.66 – −0.60	0.002	−1.27	−1.67 – −0.87	&lt;0.001	−0.53	−1.16 – 0.10	0.102	−2.02	−2.47 – −1.57	&lt;0.001	
		
Observations	3551			387			3890			837			2420			
		
	Episodic memory (Immediate Recall)	Episodic memory (Delayed Recall and Recognition)	
		
	Logical Memory Immediate Recall	Word List Immediate Recall	Logical Memory Delayed Recall	Word List Delayed Recall	Word List Recognition	
	Beta	95% CI	p-value	Beta	95% CI	p-value	Beta	95% CI	p-value	Beta	95% CI	p-value	Beta	95% CI	p-value	
		
Intercept	16.37	15.70 – 17.04	&lt;0.001	0.52	0.34 – 0.71	&lt;0.001	12.45	9.97 – 14.92	&lt;0.001	0.78	0.59 – 0.98	&lt;0.001	0.65	0.45 – 0.84	&lt;0.001	
Time (Stage 1)	0.04	−0.17 – 0.25	0.734	−0.03	−0.07 – 0.02	0.212	2.80	0.48 – 5.13	0.018	−0.12	−0.16 – −0.08	&lt;0.001	−0.05	−0.10 – −0.00	0.040	
Stage 2	−3.71	−4.49 – −2.92	&lt;0.001	−0.08	−0.29 – 0.12	0.420	−3.38	−6.25 – −0.51	0.021	−0.22	−0.44 – −0.00	0.046	−0.24	−0.46 – −0.02	0.036	
Stage 3	−7.34	−8.00 – −6.68	&lt;0.001	−0.58	−0.77 – −0.39	&lt;0.001	−5.52	−8.24 – −2.80	&lt;0.001	−0.85	−1.05 – −0.66	&lt;0.001	−0.57	−0.77 – −0.37	&lt;0.001	
Stage 4	−12.41	−13.20 – −11.63	&lt;0.001	−1.23	−1.43 – −1.02	&lt;0.001	−10.53	−13.64 – −7.41	&lt;0.001	−1.36	−1.58 – −1.15	&lt;0.001	−1.20	−1.42 – −0.99	&lt;0.001	
Time*Stage2	−0.04	−0.34 – 0.27	0.816	−0.12	−0.18 – −0.06	&lt;0.001	0.77	−2.03 – 3.57	0.591	0.01	−0.05 – 0.07	0.716	−0.04	−0.10 – 0.03	0.294	
Time*Stage3	−0.45	−0.69 – −0.20	&lt;0.001	−0.14	−0.19 – −0.09	&lt;0.001	−3.80	−6.40 – −1.21	0.004	0.03	−0.01 – 0.08	0.161	−0.09	−0.15 – −0.03	0.003	
Time*Stage4	−0.71	−1.15 – −0.28	0.001	−0.28	−0.35 – −0.20	&lt;0.001	−3.76	−6.76 – −0.76	0.014	−0.02	−0.09 – 0.05	0.652	−0.05	−0.14 – 0.03	0.219	
		
Observations	2688			3524			2675			3424			3419			
		
	Attention and working memory	Executive functioning	
		
	Digit Span Forward	Digit Span Backward	TMT B	COWAT Total	COWAT 1	
	Beta	95% CI	p-value	Beta	95% CI	p-value	Beta	95% CI	p-value	Beta	95% CI	p-value	Beta	95% CI	p-value	
		
Intercept	6.68	6.41 – 6.95	&lt;0.001	4.86	4.62 – 5.11	&lt;0.001	86.61	73.16 – 100.05	&lt;0.001	42.30	38.61 – 45.99	&lt;0.001	14.41	13.56 – 15.25	&lt;0.001	
Time (Stage 1)	−0.05	−0.10 – 0.01	0.080	−0.01	−0.07 – 0.05	0.745	4.02	0.34 – 7.70	0.033	−0.59	−1.27 – 0.10	0.095	−0.07	−0.29 – 0.15	0.514	
Stage 2	−0.28	−0.60 – 0.03	0.079	0.11	−0.18 – 0.40	0.477	20.40	5.25 – 35.55	0.008	−2.38	−6.58 – 1.81	0.267	−1.05	−2.01 – −0.08	0.034	
Stage 3	−0.67	−0.97 – −0.36	&lt;0.001	−0.56	−0.84 – −0.28	&lt;0.001	48.56	34.90 – 62.22	&lt;0.001	−7.20	−11.71 – −2.68	0.002	−1.84	−2.70 – −0.97	&lt;0.001	
Stage 4	−1.10	−1.41 – −0.80	&lt;0.001	−1.13	−1.41 – −0.84	&lt;0.001	108.29	92.84 – 123.73	&lt;0.001	−10.63	−15.11 – −6.15	&lt;0.001	−3.84	−4.79 – −2.89	&lt;0.001	
Time*Stage2	−0.02	−0.09 – 0.05	0.551	−0.07	−0.14 – 0.01	0.076	2.17	−2.73 – 7.07	0.385	0.22	−0.64 – 1.09	0.611	−0.07	−0.36 – 0.22	0.630	
Time*Stage3	−0.09	−0.16 – −0.02	0.015	−0.15	−0.23 – −0.07	&lt;0.001	9.32	5.07 – 13.56	&lt;0.001	−0.80	−1.74 – 0.13	0.095	−0.29	−0.55 – −0.04	0.023	
Time*Stage4	−0.15	−0.24 – −0.06	0.001	−0.15	−0.25 – −0.05	0.003	27.46	20.18 – 34.73	&lt;0.001	−1.98	−3.10 – −0.87	0.001	−1.02	−1.39 – −0.65	&lt;0.001	
		
Observations	1726			1722			3415			1232			3744			
		
	Processing speed	
		
	TMT A	Symbol Substitution	
	Beta	95% CI	p-value	Beta	95% CI	p-value	
		
Intercept	36.48	29.57 – 43.39	&lt;0.001	45.77	42.21 – 49.34	&lt;0.001	
Time (Stage 1)	0.44	−2.74 – 3.61	0.788	−1.15	−1.78 – −0.52	&lt;0.001	
Stage 2	4.58	−3.24 – 12.41	0.251	−2.12	−6.15 – 1.91	0.304	
Stage 3	10.02	2.96 – 17.07	0.005	−11.08	−15.52 – −6.63	&lt;0.001	
Stage 4	33.86	26.16 – 41.55	&lt;0.001	−17.71	−22.11 – −13.31	&lt;0.001	
Time*Stage2	2.27	−1.90 – 6.43	0.287	−0.21	−1.06 – 0.64	0.634	
Time*Stage3	6.64	3.08 – 10.20	&lt;0.001	−0.94	−2.02 – 0.15	0.092	
Time*Stage4	25.49	21.04 – 29.94	&lt;0.001	−0.90	−2.37 – 0.56	0.227	
		
Observations	3817			867			

Table 4. Cognitive tests identified as sensitive to decline after 12 months, including mean to standard deviation ratios (MSDR) of change from baseline over succeeding follow-up time points.

		Baseline – 12 months	Baseline – 24 months	Baseline – 36 months	
			
Stage 1	CFT (Animals)	0.30 (n= 107)	0.29 (n= 90)	0.43 (n= 44)	
	CFT (Vegetables)	0.38 (n= 68)	0.41 (n= 44 )	0.38 (n= 39)	
	LM Immediate Recall	0.19 (n= 104)	0.13 (n= 89)	0.14 (n= 43)	
Stage 2	CFT (Animals)	0.12 (n= 172)	0.26 (n= 133)	0.57 (n= 82)	
	CFT (Vegetables)	0.39 (n= 54)	0.59 (n= 39)	0.74 (n= 24)	
	Word List Delayed Recall	0.22 (n= 121)	0.19 (n= 93)	0.42 (n= 57)	
	TMT Part B	0.15 (n= 171)	0.24 (n= 130)	0.47 (n= 79)	
Stage 3	CFT (Animals)	0.22 (n= 434)	0.34 (n= 274)	0.45 (n= 191)	
	CFT (Vegetables)	0.49 (n= 78)	0.55 (n= 18)		
	Digit Span Backward	0.12 (n= 141)	0.35 (n= 63)	0.41 (n= 29)	
	Digit Span Forward	0.20 (n= 141)	0.34 (n= 63)	0.39 (n= 29)	
	Word List Delayed Recall	0.43 (n=348)	0.46 (n= 255)	0.52 (n= 185)	
	Word List Recognition	0.21 (n= 346)	0.24 (n= 252)	0.34 (n= 184)	
	MMSE	0.24 (n= 363)	0.53 (n= 261)	0.54 (n= 195)	
	MOCA	0.37 (n= 69)	0.57 (n= 17)	N.a.	
	TMT Part A	0.16 (n= 428)	0.24 (n= 275)	0.30 (n= 188)	
	TMT Part B	0.17 (n= 397)	0.31 (n= 248)	0.39 (n= 172)	
Abbreviations: CFT = Category Fluency Test; LM = Logical Memory; TMT = Trail Making Test; MMSE = Mini-Mental State Examination; MOCA = Montréal Cognitive Assessment. N.a. = Data not available for this time point.

* Data used in preparation of this article were obtained from the Alzheimer Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp,content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf


References

Aisen PS , Petersen RC , Donohue MC , Gamst A , Raman R , Thomas RG , … Initiative ADN (2010). Clinical Core of the Alzheimer’s Disease Neuroimaging Initiative: progress and plans. Alzheimer’s &amp; Dementia : The Journal of the Alzheimer’s Association, 6 (3 ), 239–246. 10.1016/j.jalz.2010.03.006
Bateman RJ , Xiong C , Benzinger TLS , Fagan AM , Goate A , Fox NC , … for the Dominantly Inherited Alzheimer N (2012). Clinical and Biomarker Changes in Dominantly Inherited Alzheimer’s Disease. The New England Journal of Medicine, 367 (9 ), 795–804. 10.1056/NEJMoa1202753 22784036
Beekly DL , Ramos EM , Lee WW , Deitrich WD , Jacka ME , Wu J , … Raskind M (2007). The National Alzheimer’s Coordinating Center (NACC) database: The uniform data set. Alzheimer Disease and Associated Disorders, 21 (3 ), 249–258. 10.1080/00380768.1987.10557563 17804958
Besser L , Kukull W , Knopman DS , Chui H , Galasko D , Weintraub S , … Morris JC (2018). Version 3 of the National Alzheimer’s Coordinating Center’s Uniform Data Set. Alzheimer Disease and Associated Disorders, 32 (4 ), 351–358. 10.1097/WAD.0000000000000279 30376508
Chapman KR , Bing-Canar H , Alosco ML , Steinberg EG , Martin B , Chaisson C , … Stern RA (2016). Mini Mental State Examination and Logical Memory scores for entry into Alzheimer’s disease trials. Alzheimers Res Ther, 8 , 9. 10.1186/s13195-016-0176-z 26899835
Clark CM , Schneider JA , Bedell BJ , Beach TG , Bilker WB , Mintun MA , … AV45-A07 Study Group, for the. (2011). Use of Florbetapir-PET for Imaging β-Amyloid Pathology. JAMA, 305 (3 ), 275–283. 10.1001/jama.2010.2008 21245183
Dagley A , LaPoint M , Huijbers W , Hedden T , McLaren DG , Chatwal JP , … Schultz AP (2017). Harvard Aging Brain Study: Dataset and accessibility. NeuroImage, 144 (Pt B ), 255–258. 10.1016/j.neuroimage.2015.03.069 25843019
Donohue MC , Sperling RA , Salmon DP , Rentz DM , Raman R , Thomas RG , … Alzheimer’s Disease Cooperative S (2014). The preclinical Alzheimer cognitive composite: measuring amyloid-related decline. JAMA Neurol, 71 (8 ), 961–970. 10.1001/jamaneurol.2014.803 24886908
Donohue MC , Sun CK , Raman R , Insel PS , Aisen PS , An A , … J A . (2017). Cross-validation of optimized composites for preclinical Alzheimer’s disease. Alzheimers Dement (N Y), 3 (1 ), 123–129. 10.1016/j.trci.2016.12.001 28758145
Dubois B , Hampel H , Feldman HH , Scheltens P , Aisen P , Andrieu S , … Jack CR (2016). Preclinical Alzheimer’s disease: Definition, natural history, and diagnostic criteria. Alzheimer’s &amp; Dementia, 12 (3 ), 292–323. 10.1016/J.JALZ.2016.02.002
Evans S , McRae-McKee K , Wong MM , Hadjichrysanthou C , De Wolf F , &amp; Anderson R (2018). The importance of endpoint selection: How effective does a drug need to be for success in a clinical trial of a possible Alzheimer’s disease treatment? European Journal of Epidemiology, 33 (7 ), 635–644. 10.1007/s10654-018-0381-0 29572656
Farias ST , Mungas D , Reed BR , Cahn-Weiner D , Jagust W , Baynes K , &amp; DeCarli C (2008). The measurement of everyday cognition (ECog): scale development and psychometric properties. Neuropsychology, 22 (4 ), 531.18590364
Folstein MF , Folstein SE , &amp; McHugh PR (1975). “Mini-mental state”. A practical method for grading the cognitive state of patients for the clinician. J.Psychiatr.Res, 12 (3 ), 189–198.1202204
Food and Drug Administration. (2018). Early Alzheimer’s Disease: Developing Drugs for Treatment. Guidance for Industry.
Grober E , Veroff AE , &amp; Lipton RB (2018). Temporal unfolding of declining episodic memory on the Free and Cued Selective Reminding Test in the predementia phase of Alzheimer’s disease: Implications for clinical trials. Alzheimer’s &amp; Dementia: Diagnosis, Assessment &amp; Disease Monitoring, 10 , 161–171.
Henry JD , Crawford JR , &amp; Phillips LH (2004). Verbal fluency performance in dementia of the Alzheimer’s type: A meta-analysis. Neuropsychologia, 42 (9 ), 1212–1222. 10.1016/j.neuropsychologia.2004.02.001 15178173
Hughes CP , Berg L , Danziger WL , Coben LA , &amp; Martin RL (1982). A new clinical scale for the staging of dementia. Br.J.Psychiatry, 140 , 566–572. Retrieved from http://bjp.rcpsych.org/content/bjprcpsych/140/6/566.full.pdf 7104545
Jack CR , Bennett DA , Blennow K , Carrillo MC , Dunn B , Haeberlein SB , … Contributors. (2018). NIA-AA Research Framework: Toward a biological definition of Alzheimer’s disease. Alzheimers Dement, 14 (4 ), 535–562. 10.1016/j.jalz.2018.02.018 29653606
Jack Clifford R , Therneau TM , Weigand SD , Wiste HJ , Knopman DS , Vemuri P , … Petersen RC (2019). Prevalence of Biologically vs Clinically Defined Alzheimer Spectrum Entities Using the National Institute on Aging–Alzheimer’s Association Research Framework. JAMA Neurology, 76 (10 ), 1174–1183. 10.1001/jamaneurol.2019.1971
Jutten RJ , Harrison J , de Jong FJ , Aleman A , Ritchie CW , Scheltens P , &amp; Sikkes SAM (2017). A composite measure of cognitive and functional progression in Alzheimer’s disease: Design of the Capturing Changes in Cognition study. Alzheimer’s &amp; Dementia: Translational Research &amp; Clinical Interventions, 3 (1 ), 130–138. Retrieved from http://ac.els-cdn.com/S2352873717300045/1-s2.0-S2352873717300045-main.pdf?_tid=f0bd2a46-2bf4-11e7-9482-00000aab0f6b&amp;acdnat=1493371846_0ae2f35af7861b14f06d41065aae2cb2 29067324
Langbaum JB , Hendrix SB , Ayutyanont N , Chen K , Fleisher AS , Shah RC , … Reiman EM (2014). An empirically derived composite cognitive test score with improved power to track and evaluate treatments for preclinical Alzheimer’s disease. Alzheimers Dement, 10 (6 ), 666–674. 10.1016/j.jalz.2014.02.002 24751827
Lezak MD (2004). Neuropsychological assessment. Oxford University Press, USA.
Lim YY , Snyder PJ , Pietrzak RH , Ukiqi A , Villemagne VL , Ames D , … Maruff P (2016). Sensitivity of composite scores to amyloid burden in preclinical Alzheimer’s disease: Introducing the Z-scores of Attention, Verbal fluency, and Episodic memory for Nondemented older adults composite score. Alzheimers Dement (Amst), 2 , 19–26. 10.1016/j.dadm.2015.11.003 27239532
Mormino EC , Betensky RA , Hedden T , Schultz AP , Ward A , Huijbers W , … Sperling RA (2014). Amyloid and &amp;lt;em&amp;gt;APOE ε4&amp;lt;/em&amp;gt; interact to influence short-term decline in preclinical Alzheimer disease. Neurology, 82 (20 ), 1760 LP – 1767. 10.1212/WNL.0000000000000431 24748674
Morris JC , Weintraub S , Chui HC , Cummings J , DeCarli C , Ferris S , … Ramos EM (2006). The Uniform Data Set (UDS): Clinical and cognitive variables and descriptive data from Alzheimer disease centers. Alzheimer Disease and Associated Disorders, 20 (4 ), 210–216. 10.1097/01.wad.0000213865.09806.92 17132964
Mortamais M , Ash JA , Harrison J , Kaye J , Kramer J , Randolph C , … Ritchie K (2017). Detecting cognitive changes in preclinical Alzheimer’s disease: A review of its feasibility. Alzheimer’s &amp; Dementia, 13 (4 ), 468–492. 10.1016/J.JALZ.2016.06.2365
Nasreddine ZS , Phillips NA , Bédirian V , Charbonneau S , Whitehead V , Collin I , … Chertkow H (2005). The Montreal Cognitive Assessment, MoCA: a brief screening tool for mild cognitive impairment. Journal of the American Geriatrics Society, 53 (4 ), 695–699.15817019
Papp KV , Rentz DM , Orlovsky I , Sperling RA , &amp; Mormino EC (2017). Optimizing the preclinical Alzheimer’s cognitive composite with semantic processing: The PACC5. Alzheimer’s &amp; Dementia: Translational Research &amp; Clinical Interventions, 3 (4 ), 668–677. 10.1016/J.TRCI.2017.10.004
Rentz DM , Parra Rodriguez MA , Amariglio R , Stern Y , Sperling R , &amp; Ferris S (2013). Promising developments in neuropsychological approaches for the detection of preclinical Alzheimer’s disease: a selective review. Alzheimers.Res.Ther., 5 (6 ), 58. Retrieved from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3978443/pdf/alzrt222.pdf 24257331
Ritchie K , Ropacki M , Albala B , Harrison J , Kaye J , Kramer J , … Ritchie CW (2017). Recommended cognitive outcomes in preclinical Alzheimer’s disease: consensus statement from the European prevention of Alzheimer’s dementia project. Alzheimers Dement, 13 . 10.1016/j.jalz.2016.07.154
Ruff RM , Light RH , Parker SB , &amp; Levin HS (1996). Benton controlled oral word association test: Reliability and updated norms. Archives of Clinical Neuropsychology, 11 (4 ), 329–338.14588937
Schmidt M (1996). Rey auditory verbal learning test: A handbook. Western Psychological Services Los Angeles, CA.
Sperling RA , Aisen PS , Beckett LA , Bennett DA , Craft S , Fagan AM , … Phelps CH (2011). Toward defining the preclinical stages of Alzheimer’s disease: Recommendations from the National Institute on Aging-Alzheimer’s Association workgroups on diagnostic guidelines for Alzheimer’s disease. Alzheimer’s &amp; Dementia, 7 (3 ), 280–292. 10.1016/j.jalz.2011.03.003
Tijms BM , Willemse EAJ , Zwan MD , Mulder SD , Visser PJ , van Berckel BNM , … Teunissen CE (2018). Unbiased Approach to Counteract Upward Drift in Cerebrospinal Fluid Amyloid-beta 1–42 Analysis Results. Clin Chem, 64 (3 ), 576–585. 10.1373/clinchem.2017.281055 29208658
Tombaugh TN (2004). Trail Making Test A and B: Normative data stratified by age and education. Archives of Clinical Neuropsychology, 19 (2 ), 203–214. 10.1016/S0887-6177(03)00039-8 15010086
Trzepacz PT , Hochstetler H , Wang S , Walker B , &amp; Saykin AJ (2015). Relationship between the Montreal Cognitive Assessment and Mini-mental State Examination for assessment of mild cognitive impairment in older adults. BMC Geriatrics, 15 (1 ), 1–9. 10.1186/s12877-015-0103-3 25559550
van der Flier WM (2018). Amsterdam Dementia Cohort: Performing Research to Optimize Care. Journal of Alzheimer’s Disease : JAD, 62 (3 ), 1091–1111.29562540
Wang J , Logovinsky V , Hendrix SB , Stanworth SH , Perdomo C , Xu L , … Satlin A (2016). ADCOMS: a composite clinical outcome for prodromal Alzheimer’s disease trials. J Neurol Neurosurg Psychiatry, 87 (9 ), 993–999. 10.1136/jnnp-2015-312383 27010616
Wechsler D (1987). WMS-R: Wechsler memory scale-revised. Psychological Corporation.
Wechsler D (2008). Wechsler adult intelligence scale–Fourth Edition (WAIS–IV). San Antonio, TX: NCS Pearson, 22 , 498.
Williams BW , Mack W , &amp; Henderson VW (1989). Boston naming test in Alzheimer’s disease. Neuropsychologia, 27 (8 ), 1073–1079. 10.1016/0028-3932(89)90186-3 2797414
Williams MM , Storandt M , Roe CM , &amp; Morris JC (2013). Progression of Alzheimer’s disease as measured by Clinical Dementia Rating Sum of Boxes scores. Alzheimers Dement, 9 (1 Suppl), S39–44. 10.1016/j.jalz.2012.01.005 22858530
Yesavage JA , Brink TL , Rose TL , Lum O , Huang V , Adey M , &amp; Leirer VO (1983). Development and validation of a geriatric depression screening scale: a preliminary report. Journal of Psychiatric Research, 17 (1 ), 37–49.
