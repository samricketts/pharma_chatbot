LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


8904467
21230
Neuropsychology
Neuropsychology
Neuropsychology
0894-4105
1931-1559

36037486
9971333
10.1037/neu0000847
NIHMS1845121
Article
Neural network process simulations support a distributed memory system and aid design of a novel computer adaptive digital memory test for preclinical and prodromal Alzheimer’s disease
Stricker John L. 12
Corriveau-Lecavalier Nick http://orcid.org/0000-0002-6561-9870
3
Wiepert Daniela A. http://orcid.org/0000-0002-6076-1712
3
Botha Hugo http://orcid.org/0000-0003-4390-685X
3
Jones David T. http://orcid.org/0000-0002-4807-9833
34
Stricker Nikki H. http://orcid.org/0000-0001-9034-1252
1
1 Department of Psychiatry and Psychology, Mayo Clinic, Rochester, Minnesota, USA
2 Department of Information Technology, Mayo Clinic, Rochester, Minnesota, USA
3 Department of Neurology, Mayo Clinic, Rochester, Minnesota, USA
4 Department of Radiology, Mayo Clinic, Rochester, Minnesota, USA
Correspondence concerning this article should be addressed to Nikki H. Stricker, Ph.D., Mayo Clinic, 200 First Street SW, Rochester, MN 55905. Phone: 507-284-2649, Fax: 507-284-4158, Stricker.Nikki@mayo.edu
4 11 2022
9 2023
29 8 2022
01 9 2024
37 6 698715
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Objective

Growing evidence supports the importance of learning as a central deficit in preclinical/prodromal Alzheimer’s disease. The aims of this study were to conduct a series of neural network simulations to develop a functional understanding of a distributed, non-modular memory system that can learn efficiently without interference. This understanding is applied to the development of a novel digital memory test.

Method

Simulations using traditional feed forward neural network architectures to learn simple logic problems are presented. The simulations demonstrate three limitations: (1) inefficiency, (2) an inability to learn problems consistently, and (3) catastrophic interference when given multiple problems. A new mirrored cascaded architecture is introduced to address these limitations, with support provided by a series of simulations.

Results

The mirrored cascaded architecture demonstrates efficient and consistent learning relative to feed forward networks but also suffers from catastrophic interference. Addition of context values to add the capability of distinguishing features as part of learning eliminates the problem of interference in the mirrored cascaded, but not the feed forward, architectures.

Conclusions

A mirrored cascaded architecture addresses the limitations of traditional feed forward neural networks, provides support for a distributed memory system, and emphasizes the importance of context to avoid interference. These process models contributed to the design of a digital computer adaptive word list learning test that places maximum stress on the capability to distinguish specific episodes of learning. Process simulations provide a useful method of testing models of brain function and contribute to new approaches to neuropsychological assessment.

Learning
Stricker Learning Span
Neuropsychology
Cognitive Science
Neural Networks
Computer
Catastrophic Interference

pmcIntroduction

Methods to assess episodic memory in clinical neuropsychology rely heavily on an outdated modular conceptualization of memory and emphasize two relatively independent components: 1) short-term or working memory and 2) long-term memory (Atkinson &amp; Shiffrin, 1968; Malmberg et al., 2019; Norris, 2017). Within this modular view, episodic memory has historically been characterized by three processes: 1) encoding or learning, where new information enters the short-term memory store and begins the process of transfer to the long-term memory store, 2) storage/consolidation, where information continues the transfer and strengthening process from the short-term to the long-term memory store, and 3) retrieval from the long-term memory store. Current clinically used memory tests continue to emphasize this framework (Lezak et al., 2012; Strauss et al., 2006). This manuscript aims to illustrate the importance of identifying alternative ways of developing and testing our understanding of how the brain learns new information to help develop novel approaches to neuropsychological assessment. We conducted a series of neural network simulations to develop a functional understanding of a distributed, non-modular memory system that can learn multiple problems efficiently without catastrophic interference (i.e., new learning interfering with older learning in a connectionist model: French, 1999; McCloskey &amp; Cohen, 1989). We then explain how process simulations using neural network models guided the development of a novel computer adaptive word list memory test specifically designed as a self-administered measure for preclinical and prodromal Alzheimer’s disease (PAD).

While memory models have advanced beyond a simple short-term and long-term memory dichotomy in the fields of cognitive psychology and cognitive neuroscience (Allen &amp; Fortin, 2012; Diana et al., 2007; Rajah &amp; McIntosh, 2020; Winocur &amp; Moscovitch, 2011), a modular view of memory continues to influence memory tests in active use by clinical neuropsychologists (Lezak et al., 2012; Rabin et al., 2016; Strauss et al., 2006). This relative inertia in clinical neuropsychology is well recognized. For example, a recent special issue of the The Clinical Neuropsychologist was devoted to the significant need for the development and adoption of new tests (Marcopulos &amp; Łojek, 2019) given that most currently used clinical neuropsychology measures were developed 50-150 years ago (Bilder &amp; Reise, 2019). The past emphasis on a modular memory system in neuropsychology has led to a prototypical clinical memory test format that includes immediate recall, delayed recall, and delayed recognition as key components, particularly for word list memory measures (Loewenstein, 2018). For instance, one of the most popular stand-alone memory measures following this standard is the California Verbal Learning Test (CVLT, versions I-III), which consists of the repeated encoding of a word list over a series of immediate recall trials, a distractor list presented once, short and long delay recall trials with both free and cued-recall formats, and recognition trials (Delis et al. 2000; Rabin et al., 2016). This and other memory tests help neuropsychologists determine whether the observed pattern of memory impairment is characterized by a primary encoding/storage profile, as seen in individuals with medial temporal lobe damage, or by a primary retrieval memory profile, as seen in individuals with disorders impacting fronto-subcortical circuits (Delis et al., 1991).

However, the two classical memory profiles of encoding/storage and retrieval often do not capture the full spectrum of memory performance. Growing evidence suggests that even among individuals with conditions expected to produce a prototypical retrieval memory profile (multiple sclerosis, Huntington’s disease, Parkinson’s disease), both encoding and retrieval are impacted (Basso et al., 2021; Thornton et al., 2002; Zizak et al., 2005). Further, when a learning to criterion approach is used to ensure adequate encoding, verbal memory impairment in multiple sclerosis has been attributed to inadequate initial encoding as opposed to impaired retrieval (DeLuca et al., 1994). Similar differences in conclusions about memory profiles can be seen in the Alzheimer’s disease (AD) literature. While individuals with AD dementia appear to be “forgetting” or having difficulty with consolidation/storage from immediate to delayed memory trials, at least part of this may be due to the specific characteristics of the memory tests used. For example, serial position effects play an important role in the pattern of performance on word list memory tests (Atkinson &amp; Shiffrin, 1968). Recency effects may drive forgetting across delays by making it appear that individuals have “learned” words during learning trials, but for some items these correct recalls largely represent attentional span (Gavett &amp; Horwitz, 2012). When these words are not recalled at delay, they are considered “forgotten”, but an alternate view is that the words were never fully encoded during the repeated learning trials (Greene et al. 1996). When learning to criterion is used to equate initial learning, the primary memory impairment in AD dementia is described as one of learning/encoding and not one of forgetting (Greene et al., 1996; Grober &amp; Kawas, 1997; Stamate et al., 2020).

Learning deficits are also predominant before conversion to AD dementia. Verbal learning was a more consistent indicator of preclinical AD than verbal delayed recall in a systematic review (Twamley et al., 2006). Measures of learning derived from serial position effects, rate of learning over learning trials, and the item-specific deficit approach are sensitive to prevalent amnestic MCI (Andrés et al., 2019) and incident MCI (Talamonti et al., 2020), and improve prediction of conversion from MCI to dementia (Chang et al., 2010; Turchetta et al., 2020). Studies comparing cognitively unimpaired individuals with and without elevated brain amyloid show absent or attenuated practice effects on longitudinal assessment, and this has been proposed as a potential marker of preclinical AD (Duff et al., 2017; Hassenstab, 2015; Machulda et al., 2017). These observations have contributed to the hypothesis that the central deficit in PAD is one of learning (Baker et al., 2019; Lim et al., 2020), conceptualized as a failure to benefit from repeated exposure to material or a lack of benefit from practice.

In summary, there is increasing support for the view that individuals with AD in the pre-dementia phase (including non-demented individuals who later convert to dementia or non-demented individuals with biological AD; Jack et al., 2018) show predominant learning/encoding deficits as opposed to predominant storage/consolidation impairment. Just as the neuropsychology of AD is evolving, accumulating neuroimaging evidence questions the exclusive role of the medial temporal lobe in the formation of episodic memories and the idea of distinct modular memory systems in general (Dudai et al., 2015; Gaffan, 2002; Price, 2018; Ranganath &amp; Blumenfeld, 2005; Squire, 2004; Sutterer &amp; Tranel, 2017). For instance, lesion case studies revealed that selective hippocampal damage can lead to very dissimilar patterns of memory deficits (Holdstock et al., 2008; Price, 2018) and that focal neocortical lesion with preserved hippocampal integrity can result in anterograde memory impairment (Davidson et al., 2008; Ferguson et al., 2019). Taken together, these findings make a compelling case for a dynamic, distributed memory system. However, conceptualizing how such a system would function, and how behaviors such as “learning” and “forgetting” might manifest in such a system—or any distributed biological system—is challenging (Koch, 1985; Luria, 1966, pp. 23-30; Newell, 1973; Parsons &amp; Duffield, 2020).

Process simulations, defined here as the use of mathematical or neural network models to help understand a process, can help reduce barriers to conceptualizing complex models and guide the development of measures to assess cognitive functions. In prior work, mathematical process simulations demonstrated that the semantic and serial organization indices used in the original CVLT were in fact not accurately measuring organization (Stricker et al., 2002). It was only through these simulations that this problem was discovered, and these process simulations paved the way for selecting updated clustering indices for the second edition of the CVLT. A notable example of how neural network process simulations can help evolve fundamental tenets of cognitive concepts pertains to the field of linguistics, in which it used to be commonly assumed that humans must have innate rules of grammar. One of the primary reasons for this assumption is that it was unclear how humans could receive enough environmental input and feedback to learn the sophisticated rules of grammar that children demonstrate as they start to speak (Chomsky 1965, pp. 47-59, Elman et al., 1998 pp. 367-371). However, neural network simulations demonstrated a capability of learning grammatical structure without the need for innate rules, and with a realistic level of training and feedback. While these network models were not fitting real human data and did not have near the complexity of the human brain, by demonstrating how language can be learned without predefined rules they changed many of the assumptions that were commonly made about language acquisition in humans (see Elman, 2001 for a review).

In neuropsychology, a “process” approach has historically been used to help understand the core deficit(s) underlying an impaired score on testing, which can have numerous different causes (Kaplan, 1991). Similarly, the current manuscript uses neural network process simulations or “process models” to explore a distributed conceptualization of memory. The aims of this study were to (1) conduct a series of neural network simulations to develop a functional understanding of a distributed, non-modular memory system that can learn efficiently without interference and (2) apply this functional understanding to the development of a novel digital memory test. As we set out to develop a new memory test that would be sensitive to PAD, we began with the following question: Is it possible to conceptualize the memory system as non-modular where learning is the principal process and everything else is a side effect? In the following studies, we built a simple functional system that can learn to solve multiple problems by a single learning process, without introducing the need for separate short-term and long-term memory stores. This approach was heavily influenced by David Marr’s approach to vision (Marr, 1982), where developing a functional understanding of the problem being solved is just as essential as understanding biological processes.

Studies

The following studies demonstrate the development of a process model that works efficiently and consistently learns how to solve multiple problems, without catastrophic interference causing forgetting. This work does not include human subjects and is exempt from IRB review.

The constraints on the development of this model are (1) there is no separation between learning and recall and (2) everything functions within a single learning system (e.g., there is no short-term or long-term store). The development of the model started with using a neural network model to solve simple logic problems. The two logic problems used were OR and Exclusive-OR (XOR). These problems can be illustrated as a response to the relationship between two values (inputs), as shown in Table 1. For OR, if one or both inputs is true, then the output is true. For XOR, if one and only one input is true, then the output is true.

Learning in neural networks occurs through experience, just as humans learn through experience. Neural networks “learn” by training with data until they can reliably identify patterns, make predictions, or solve problems. Learning to solve problems and being able to remember how to differentiate them is one of the simplest ways to represent new learning within neural networks. The critical question at hand in the present manuscript is: How can a distributed, non-modular memory system learn new information without catastrophic interference (without new learning disrupting old learning due to interference). While learning more than one problem may not appear to be “episodic” in nature, we contend that any new learning is episodic, as all learning occurs within a given time and context. This differs from one traditional definition of episodic memory as requiring autonoetic awareness and “mental time travel” (Tulving, 2002). From this traditional standpoint of mental time travel, learning and remembering two distinct problems is not considered an episodic memory task. In the context of this study, we adopt a broader definition of episodic memory as providing “memory-based predictions to support adaptive behavior in the present or immediate future” (Allen &amp; Fortin, 2012), which encompasses the learning of problems as presented here.

Transparency and Openness

The source code for these neural network simulation studies is available publicly at GitHub and can be accessed at https://github.com/MayoNeurologyAI/NeuralNetworksNeuropsychology. In addition, a website which lets users recreate each study in this paper is available at https://Mayoneurologyai.github.io/NeuralNetworksNeuropsychology (note that because of the randomization of initialization values and input/output pair presentations, there will be small differences in the results each time the study is run). The website also allows some of the general parameters to be changed for each study. This study was not preregistered.

Neural network methods

Neural Network Fundamentals

Neural networks have a long and contentious history (see for example Anderson &amp; Rosenfeld, 1988; Arbib, 2002). Most of the neural networks used by researchers today stem from the Parallel Distributed Processing models described by Rumelhart &amp; McClelland (1986). A simple introduction to the networks used in this paper will be provided in this section. For a more in-depth description and walkthrough see Antiga et al. (2020).

A simple two-layer network consists of three layers of units, or nodes: an input layer (i.e., which receives information), a hidden layer (i.e., which performs the computation), and an output layer (i.e., which provides the outcome of the computation) (see Figure 1). Each node in a network’s layers has an activation function which adds all that node’s inputs together and transforms that summative input into its output. Common activation functions include linear (no transformation), sigmoid (producing an output between 0 and 1) or hyperbolic tangent (tanh: producing an output between −1 and 1). In addition to receiving input from connections, nodes can also receive input from an external source (e.g., the input layer is given an input pair for a specific problem).

The nodes of a given layer then transmit their outputs to other layers via connections (represented as lines in Figure 1). Each connection has a value, known as a weight, that represents the strength of the connection. That weight modifies the output of the connection’s sending node to that connection’s receiving node. In practice, a node’s output to another node is multiplied by this weight.

Nodes also can have a resting state, known as a bias. Computationally, the bias value is treated as another input to the node (i.e., the bias value is added to the node’s input when that node’s output is calculated with an activation function). Input layers do not typically have bias values, while hidden and output layers will commonly have bias values. The bias activation is frequently represented as a separate “bias node” with a constant output of 1 (as shown in Figure 1). The connection weights from this bias node represent the bias value for the receiving node.

Activation in neural networks typically occurs in a feed-forward fashion: External Source → Input → Hidden Layer → Output. For example, in the network in Figure 1, the input nodes receive input from an outside source; the resulting output will be transferred to the hidden nodes via the connections from the input nodes to the hidden nodes. In turn, the two hidden nodes will then transfer their outputs to the output node.

Training

The process of training in neural networks consists of providing the network with a set of inputs and expected outputs, allowing the network to feed the activation forward to the output units, and then adjusting the weights of the network connections and each node’s bias value based upon the amount of error that the network produces. Error in the network is then determined by the amount to which the output activation of the network differs from the output expected in the training set. For all networks in these studies, each training step consists of presenting an input to the network, calculating the error based upon the weights of the connections in the network and expected output, and then adjusting those weights using gradient descent (Rumelhart &amp; McClelland, 1986; Weidman, 2019).

For each problem, the network is trained stochastically without replacement (Lecun et al., 1998). That is, after a network is trained on a randomly selected input/output pair, that pair is not made available again for training until training steps have occurred for the remaining input/output pairs.

Each of the following studies consist of 10,000 simulations. For each simulation, networks were trained until either (1) 1,000 training steps occurred or (2) all the network’s outputs were correct, and the square-root of the mean squared error (RMS) was less than 0.5.

Input and Output Coding

Neural network inputs for simplified problems like the logic problems used in the present work are often coded with values of 1 and 0 (Rumelhart &amp; McClelland, 1986). However, the use of zero values reduces the ability of a network to utilize the absence of information during training. When an input value is zero, all signals form that input node will be zero. The use of −1 instead of zero allows the networks to computationally take advantage of both inputs. For all networks in the present work, inputs are coded as 1 and −1 (for ‘true’ and ‘false’ values as shown in Table 1). For expected output values, it is common practice to place the output values at points before the asymptotes of the transformation function (Lecun et al., 1998; Rumelhart &amp; McClelland, 1986, pp. 329). Since hyperbolic tangent (tanh) transformation functions are used for the output nodes, the expected values were set at −0.9 (‘false’ output values in Table 1) and 0.9 (‘true’ output values in Table 1).

Initialization, Parameters, and Activation Functions

Neural networks must have some initial weight values (other than zero) assigned prior to training. For each simulation in each study, network weights were initialized from a uniform random distribution with values between −1 and 1 for feed forward networks, and −0.1 and 0.1 for cascaded networks. A smaller range was used for cascaded networks because they were much less sensitive to their initial starting values and solved problems faster starting with a smaller distribution, whereas feedforward networks benefitted from a larger range of initial values. Learning parameters were constant across all networks: 0.6 for the learning rate (the amount by which the computed weight change is applied to the weight) and 0.9 for momentum (the amount by which the previous weight change influences the current weight change). All neural networks in these studies used hyperbolic tangent (tanh) transformation functions for all nodes except input and bias nodes. The use of tanh functions allows nodes to produce a greater variety of responses by allowing both positive and negative outputs (−1 to 1), as opposed to a logsig, which only allows a range of 0 to 1. Input and bias nodes both use linear (additive) transformation functions as they are expected to simply transmit the values they have been provided (i.e., the input values for the input nodes, and a constant activation value of 1 for the bias nodes). For each of the studies, the parameters used are also listed in separate tables on the supporting website for this manuscript: https://Mayoneurologyai.github.io/NeuralNetworksNeuropsychology.

Study 1: Introducing feed-forward networks, illustrating inefficiency and inconsistency.

Methods

We started with examining a traditional feed forward network that can solve the classic problem of XOR. Study 1 presents a traditional feed forward neural network that uses hidden units and backpropagation to solve XOR (see Figure 1). This network was originally introduced by Rumelhart and McClelland (1986) as a demonstration that neural networks could solve more complex logical problems such as XOR in response to criticisms of multilayer perceptron networks (Minsky &amp; Papert, 1969).

Results

The results of this study are shown in the first row of Table 2. On average the network needed to be exposed to the entire XOR problem about 29 times (115/4, as there are 4 input/output pairs in the problem) before it could solve the problem. In addition, the networks were unable to solve XOR 28% of the time within 1,000 training steps.

Discussion

Since we are trying to work towards an efficient learning system, we want to reduce the number of training steps it takes the network to solve the problem. Furthermore, we want the network to be consistent as well, meaning that it should be able to easily solve the problem regardless of its starting state (the initial random weight values). We developed alternative neural network models to address these requirements in the subsequent studies.

Study 2: Addressing inefficiency and inconsistency with cascaded networks.

Methods

Building upon Pollack’s (1987) work describing a network with context setting weights that Pollack referred to as “cascaded networks,” we developed an architecture that can solve XOR both efficiently and consistently (Stricker, 2004). This architecture makes use of two networks: 1) a weight setting network (also known as the context network in Pollack’s work), and 2) an output network (also known as the function network in Pollack’s work). Inputs to the two networks are mirrored, with activation starting at the weight setting network, which sets the weights for the output network. Figure 2 illustrates this architecture, which we refer to as a Mirrored Cascaded Network (MCN). The term ‘Mirrored’ is used to indicate that inputs are duplicated (mirrored) across both the weight setting network and the output network; this mirrored element of the architecture is a novel addition to the cascaded architectures described by Pollack (1987). “Cascaded” is used to describe how activation first starts with the weight setting network producing weights that are then applied (or cascaded down to) the output network. In Pollack’s original cascaded networks, the inputs were only provided to the output or “function” network.

Calculating the output for an MCN involves three steps. First, the input is provided to the weight setting network and the output of the weight setting nodes are calculated. Next, each weight setting node’s output is used to set a single weight in the output network. Finally, the same input is provided to the output network and the final output is calculated. In the present work, the weight setting nodes used a tanh transformation function that restricts any weight’s value to a minimum of −1 and a maximum of 1. This is an update to our prior approach that used a linear activation function for the weight setting nodes (Stricker, 2004). This adjustment improved the overall efficiency of the MCNs.

In the MCN, training occurs by taking the errors from the output network’s output and adjusting the weights of the weight setting network. Using Rumelhart and McClelland’s (1986) notation for describing backpropagation, the value of each weight k in the output networks is calculated as: (1) wk=f(netpj)

Where for each input/output pair p with output j and input i in the weight setting network, the node output is first calculated as the sum of inputs to that node: (2) f(netpj)=∑iwjiopi

And then transformed by the hyperbolic tangent (tanh) function: (3) f(x)=(ex−e−x)/(ex+e−x)

Changes in weights in the weight setting network are calculated using the error of the output node in the output network. The error for node k in the weight setting network is determined by the difference between the expected output value t and actual output value o of output node j for each problem set p multiplied by the derivative f’ of the tanh function of the summed input of that output node: (4) δpk=δpj=(tpj−opj)fj′(netpj)

Where for the tanh function: (5) f′(x)=1−f(x)2

Given this error, the change (Δ) for each weight j in the weight setting network for training step n+1 is calculated by multiplying the error of the output node in the output network with the output of the weight setting node and a learning rate (h). This value is then added to the last change in the network weight multiplied by a momentum constant (α).

(6) Δpwji(n+1)=η(δpjopi)+Δpwji(n)

Results

When training the MCN in Figure 2 on XOR it was extremely efficient, often not needing to see the whole problem to solve it (on average 2.31 training steps). The MCN was also able to solve the problem regardless of its starting point across 10,000 simulations (see Table 2).

Discussion

These results demonstrate that the basic architecture specified for a learning system can have a substantial impact on how the system performs. Many connectionist approaches assume a hierarchical structure, but this cascaded approach demonstrates superior efficiency and consistency with less than half of the trainable parameters of the feed forward network (4 vs. 9). In fact, if XOR was the only problem to learn, the system could easily learn to solve the problem with only 2 learning parameters, as illustrated in Figure 3.

In this case, the selected architecture plus the structure of the problem (XOR) leads to an extremely efficient solution. One possible reason for this is that the cascaded approach allows for the manipulation of the inputs to be separate from the inputs themselves. In a feed forward network, the inputs are transformed by layers of weights between the input and output layers and the hidden and output layers as the output is being produced. However, in the cascaded network, the inputs are transformed by the weight setting network, but those weights are allowed to be directly applied to the inputs in the output network. Another way to think about this is separating experience (input) from processing about that experience and then applying that processing to the experience.

Study 3: Catastrophic interference with multiple problem solving prevents retention of previously learned problems.

While Study 2 demonstrated how a network’s architecture can eliminate inconsistency and inefficiency, a learning system must also be able to remember how to solve more than one problem. The system must be able to learn new problems while retaining its ability to solve previously learned problems. However, this is an area where connectionist approaches like neural networks can easily fail: previously learned information can be easily overwritten by newly learned information (otherwise known as catastrophic interference: McCloskey &amp; Cohen, 1989).

Methods

To demonstrate the problem of catastrophic interference, a cascaded network was trained to solve both OR and XOR (see Table 1). The simple MCN described in Study 2 was unable to solve OR without the addition of a bias node added to the weight setting network. The MCN architecture with the addition of the bias node is shown in Figure 4.

In order to demonstrate interference, the model was first trained to learn OR, then trained to learn XOR. After learning XOR, a check is made to see if the model can still solve OR (e.g., did the model retain this initial learning after learning a new problem that introduced interference). This was done for both the traditional Feed Forward networks (Study 3a) and MCNs (Study 3b).

Results

Both the traditional and cascaded networks were unable to retain OR information after being trained on XOR (see Table 3). Though the cascaded networks were able to learn OR and XOR more consistently (100% successful initial learning for the MCNs, vs. 70% for FFs) and efficiently (20.55 total training steps for the MCNs vs. 149.14 for FFs), they still were unable to retain the capability of solving OR.

Discussion

If we were to stop here, we could conclude a single distributed memory system, even one that is efficient and consistent, is incapable of solving multiple problems due to catastrophic interference. Additionally, previous learning reduces the capability of a learning system to learn the next problem. When a cascaded network learned XOR without having learned OR in Study 2 it was much faster to learn, taking an average of 2.31 training steps as opposed to 20.55. Given these presumed limitations of a single distributed learning system, at least two separate systems would be needed to solve multiple problems: one for learning, and one for retention. In other words, consolidation, or transfer from short-term to long-term memory would be required for information to not be overwritten if this work stopped after these results showing catastrophic interference prevents retention in these neural networks.

Study 4: Introducing context to prevent catastrophic interference and thereby allow retention of learned information.

The catastrophic interference demonstrated in Study 3 is a no-win situation for a distributed system. There is no way to distinguish between the problems, so new learning will overwrite old learning. However, if the learning system has a simple way of distinguishing between the two problems as it learns, it may be able to retain previously learned information.

Methods

To test if distinguishing the problems while learning would eliminate interference, we added an additional “context” input node to the networks that describes the problem: a −1 for OR, and a 1 for XOR. This context value provides a way to separate different sets of information being learned to avoid catastrophic interference. In a more realistic system, this “context” could be anything that separates one episode of learning from another including time or any other experiences that are occurring as the information is being learned that help define it as a specific and separate learning episode. In Study 4, both traditional and cascaded networks with context are tested on learning OR and then XOR as described in Study 3 but with context added. The Feed Forward network in Figure 5 illustrates how an additional context input was added to the input layer (Study 4a). The Mirrored Cascaded network in Figure 6 illustrates how context was added to the Mirrored Cascaded Networks by adding a context input node to the input layer of the weight setting network (Study 4b).

In addition to being trained to learn OR then XOR, retraining cycles were allowed. Figure 7 presents a flowchart describing how retraining was implemented as part of Study 4’s simulations. If a network failed to retain OR after learning XOR, then the network was retrained on OR. If it lost XOR information after retraining on OR, then the network was retrained on XOR, and so on until either both problems were learned, or a maximum of 100 training retries occurred.

Results

The results of Study 4 are provided in Table 4. All MCN networks were able to learn both OR and XOR initially, though 13% of those networks were unable to retain the OR information. However, of those networks which failed to retain the OR information after learning XOR, 100% of those networks only required a single retraining on OR, needing on average 3.73 additional training steps. After that single retraining, those networks were able to retain XOR. In contrast, the Feed Forward networks were far less capable of retaining OR information: Of the 68% that could learn both problems, 64% of them failed to retain OR after training on XOR. Of those 64%, 98% were able to learn and retain both problems with retraining but they required 13 additional problem presentations on average.

Discussion

Study 4 illustrates that if the system is efficient and has “context” to provide a way of separating the information to be learned, catastrophic interference is minimized. Importantly, if we had only used traditional feed forward networks, we would have concluded that contextual information while learning is still not enough to avoid catastrophic interference. In other words, conclusions drawn from traditional feed forward networks would have led us to believe that separate memory systems are necessary. Results using the MCN architecture with the addition of context support the possibility of an alternative view and offer a conceptualization of how memory could function as a distributed, non-modular system.

General Discussion

Through this series of studies, we highlighted the importance of contextual input for a neural network to learn how to efficiently solve multiple logical problems while preventing catastrophic interference to allow for successful retention of learned information. We first began with a traditional feed forward neural network which could solve a single problem (XOR) and proceeded to modify the network’s architecture through a series of studies to increase its efficiency and accuracy and to allow it to learn to solve multiple problems. This optimally resulted in a cascaded network with context inputs, which showed that adding context to the neural networks prevents interference when learning multiple problems at once (OR and XOR). Overall, this demonstrates that a single distributed learning system can retain information if the system is also efficient.

If we assume that memory is stored in a distributed fashion, then the results of these studies suggest that using context to differentiate new material being learned allows the distributed memory system to manage different sets of information without the need for separate long-term and short-term storage. Recent research in PAD has suggested that the underlying deficit may not be one of forgetting, but one of learning (Baker et al., 2019; Lim et al., 2020). The models presented in this paper suggest a deficit that is more specific: a decreasing ability to incorporate context while learning new information.

Consider what would happen if a person’s ability to separate episodes of learning degrades: they would still be able to learn new information in the moment, but they would “rapidly forget” that information because new learning is overwriting recently learned information. In terms of neural network models, if there is a decreasing ability to incorporate context during learning, then the contextual system stops putting in distinguishing values to separate problems (or episodes) as part of learning. Information learned previously, when the contextual system was functioning properly, would still be remembered because it was previously encoded with distinguishing contextual information. However, new information that is learned would constantly be overwritten. Therefore, the central deficit here could be described as a failure in the contextual system that leads to interference.

These process models are artificial by nature and hence preclude causal inference about organic learning systems. However, functional parallels can be made with the current literature about neurobiology underpinning learning abilities. Specifically, medial temporal structures play an important role in how information is categorized and separated as it is learned. The hippocampus, entorhinal cortex, perirhinal cortex and their connectivity to neocortical areas have been associated with pattern-separation and distinguishing the spatial source of items to be memorized (Stevenson et al., 2020). The hippocampus has also been hypothesized to assume the role of a “sequence generator” to organize cortical input related to sensory experiences, regardless of modality, which also includes the temporal sequence between stimuli (Buzsáki &amp; Tingley, 2018). Within this framework, medial temporal areas are thought to provide contextual input in the early phase of learning to make episodes distinct from already learned information rather than being the exclusive anatomical underpinning of episodic memory. This is further supported by “network lesion studies,” which elegantly demonstrate that specific cognitive impairment such as episodic memory deficits could emerge from lesions in distributed, functionally interconnected, large-scale networks rather than localized brain areas (Bauer &amp; Asken, 2018; Darby et al., 2019; Ferguson et al., 2019; Fox, 2018). Studies in PAD also suggest that loss of contextual input would imperil learning abilities. For instance, well-established cognitive models suggest that the capacity of “binding” separate elements into a compound episode (Li et al., 2005), which can also be understood through the lens of context, would be selectively degraded in PAD (Della Sala et al., 2012; Parra et al., 2010). Studies leveraging experimental tasks assessing associative memory learning, which requires associating target items to contextual features, found lower performance in individuals with PAD compared to healthy controls (Berron et al., 2020; Clément &amp; Belleville, 2012; Corriveau-Lecavalier et al., 2021a, 2021b; Polcher et al., 2017). Interestingly, some of these studies used fMRI and observed that low associative memory performance was accompanied by hyperactivation of hippocampal and temporal areas, a well-documented early biomarker of AD (Corriveau-Lecavalier et al., 2021a, 2021b; Selkoe, 2019; Zott et al., 2018, 2019). Thus, although the network architecture presented in this study was not explicitly designed to reproduce biological learning systems, it is nonetheless consistent with knowledge highlighting the importance of context for efficient learning. It also underlines the importance of contextual input for designing memory tests aiming to detect individuals in the early phase of AD. While our focus is on implications for understanding memory changes in PAD, there are also some parallels in cognitive psychology studies focused on interference as the primary cause of forgetting in “immediate memory” (Oberauer &amp; Lewandowsky, 2008) and “working memory” (Farrell et. Al, 2016) in healthy individuals. These studies demonstrated that a mathematical model of forgetting based upon interference was better able to fit data from several experiments in young adults as opposed to alternative theories that included decay components (Oberauer &amp; Lewandowsky, 2008; Farrell et. al, 2016).

Creating an adaptive digital verbal learning test that targets the contextual system: the Stricker Learning Span.

The process models presented here directly influenced the development of a novel computer adaptive word list memory test designed as a digital, self-administered measure for PAD, the Stricker Learning Span (SLS). Three primary factors influenced test development: 1) test design that emphasizes learning and taxes the contextual system, in line with the process model-based conceptualization and expected sensitivity to PAD described in the previous section, 2) consideration of the literature demonstrating the utility of word list memory tests in AD, and 3) a test format that allows for digital self-administration. The general test format is a 5-trial adaptive list learning task. The length of the word list presented ranges from 2 to 23 words and starts with visual presentation of 8 items. Single words are presented sequentially during learning trials (1 second on, 1 second off). After each list presentation, memory for the word list is tested with 4-choice recognition. In subsequent trials, the number of words either stays the same, increases or decreases according to pre-specified rules based on percentage of correct responses, following a computer adaptive testing (CAT) approach (Gonthier et al., 2018). Additional testing of all items presented on any learning trial occurs after a short delay. We describe the rationale for this structure in the sections below.

Targeting context in learning

We used the functional concepts described in this paper to assist with paradigm design. Stimuli selection was directly shaped by the insights learned from the process simulation models. If we assume that the contextual system is the vulnerable system that is impacted early in the AD process (in the pre-dementia phase), then we should target that system as much as possible when developing a new test. To do this we need stimuli that are relatively context-free, such as over-learned stimuli that do not lend themselves to easy generation of contextual cues (visualizations or personal associations). We therefore use common, high frequency words for the SLS. Common words are easier to recall, but harder to recognize (Lohnas &amp; Kahana, 2013). In this way, we are capitalizing on the need to utilize a recognition testing format to optimize self-administered assessment as an asset instead of a potential hindrance.

We created an item bank of 92 high frequency English words and assigned 4 words to pre-specified item bins (1-23). These words are so widely used that remembering exactly when the words were encountered in time is more difficult (words such as “the” and “of,” for example). For word selection, we first extracted the 250 highest word frequency per million words from the SUBTLEXUS corpus (Brysbaert et al., 2009). Next, this item pool was merged with word imagery data (Clark &amp; Piavio, 2004), yielding 130 available words with this data. Items were then selected to generate bins with similar imagery ratings (Clark &amp; Piavio, 2004) and with consideration of other word characteristics (length, semantic category, syllables), yielding the final 92 item bank. Item bins 1-3 represent words with higher imagery ratings (&gt; 4.0), which we expect to lower the floor for patients with MCI/dementia. Having some words presented that are more imageable also allows for more capacity to generate context from the stimuli to be learned themselves, rather than the indirect context of the test experience. Difficulty is increased across item bins through use of words with successively declining imagery ratings, which is expected to increase the stress on the contextual system as the participant is exposed to more common words and equally common foils. Each test session randomly selects 1 word from each item bin as the “target” and the 3 others serve as the foils and a 23-item target word list is generated, even if not all items are presented due to the adaptive procedure. The order of item presentation is randomized for each trial. To reduce recency effects, the last item presented is never the first tested.

In addition to the use of stimuli encountered at a high frequency in daily life (common words), our use of 4-choice recognition to assess memory for the target word list places further stress on the contextual system by embedding interference into each recognition trial. The presentation of the target item with 3 similar foils that are consistently presented across each trial within a given session will likely increase the likelihood of false-positive errors. It may also be that once a false-positive error is made, there will be an increased tendency to repeat this error on subsequent trials due to an impaired recall-to-reject process related to impaired recollection in AD (Gallo et al., 2004). In this way, the SLS imbeds interference in the study design without having to have a “distractor” or specific interference list. Previous studies suggest that individuals with amnestic MCI are particularly prone to interference effects (Loewenstein et al., 2021), which aligns with a potential breakdown in the context system and the overwriting of learned information that follows due to catastrophic interference.

Building upon the existing foundation of word list memory tests

In line with the known utility of word list memory paradigms across the AD spectrum, we identified word list memory as our target for a new digital memory test. Word list memory tests consistently demonstrate high diagnostic accuracy for distinguishing persons who are cognitively unimpaired (CU) from those with clinically diagnosed MCI or AD dementia, often outperforming other memory measures (Weissberger et al., 2017). Word list memory performance declines very early in the preclinical phase of AD, with an inflection point up to 20 years prior to onset of mild cognitive impairment (MCI) (Caselli et al., 2020). However, an ideal memory test should not only detect early preclinical impairment, but also provide sufficient range of performance to monitor disease progression. Floor effects prevent such ongoing monitoring for most delayed recall memory measures (Greene et al., 1996), which is why we took active steps to lower the floor as described above.

Word list memory tests typically present the same fixed number of words to learn across 3 to 5 learning trials, with the length of the word list often ranging from 9 to 16 words. Longer word lists are chosen to maximize sensitivity to subtle impairments and increase reliability, whereas shorter word lists can be better tolerated by individuals with cognitive impairment. Shorter word lists restrict both the sensitivity of the test and the ability to capture change over time by restricting the range, particularly for delayed recall trials that are already prone to floor effects and restricted range in individuals with memory impairment (Baker et al., 2018; Steinerman et al., 2010). For instance, ceiling effects or lack of variability in performance can be observed with word lists of 12 or fewer items, thus precluding detection of preclinical AD at a single assessment and contributing to low test-retest reliability (Baker et al., 2018; Jessen et al., 2014; Rabin et al., 2017; Woods et al., 2005). If we shift the focus of memory testing in PAD away from “forgetting” and towards “learning,” the range of performance can be expanded by applying CAT approaches that dynamically change the amount of material to be learned based on participant performance, shortening test duration while maximizing psychometric properties and providing a “customized” test for each participant (Gershon, 2005).

The importance of a recognition format for a digitized, self-administered memory paradigm

Computerized measures that provide the option for unsupervised self-administration at home are better suited for large-scale cognitive screening and monitoring than traditional neuropsychological measures or other computerized measures that require interactive administration with an examiner (Sabbagh et al., 2020). We therefore aimed to develop a brief and sensitive digital memory test optimized for remote self-administration. To meet this goal, we built a flexible web-based Mayo Clinic cognitive testing platform called Mayo Test Drive (MTD): Test Development through Rapid Iteration, Validation and Expansion (DRIVE). The MTD platform is optimized for smartphone use but is also compatible with alternative web-based devices (e.g., tablet, PC).

A digital verbal memory test requires use of either speech detection software to allow for recall or a recognition format. Although some self-administered verbal memory measures use automated speech detection software with an option to double check scoring with recordings, this may be more challenging to implement when high accuracy is required for the test to be adaptive (i.e., change stimuli based upon a test tasker’s response in real time). While under ideal circumstances where a specific hardware is used consistently across all study participants, a reasonable accuracy rate of 91.9% has been reported for a word list memory test utilizing automated speech detection in the home environment (Mackin et al., 2021), such consistency of device type would require providing all study participants with devices. We chose to use a recognition format for our verbal learning test. A review of the AD literature shows that recognition paradigms may have better utility than often assumed. In addition, the type of recognition paradigm used impacts any comparisons of recall and recognition. Most research on verbal memory recognition is based on yes/no recognition formats where participants identify whether an item presented was (yes) or was not (no) on the target list; yes/no recognition is often less sensitive to MCI and AD dementia than spontaneous verbal free recall (Weissberger et al., 2017). However, Bäckman et al. (2001) showed that recall and yes/no recognition were equally impacted in preclinical AD 6 and 3 years prior to an AD dementia diagnosis. Further, recall and recognition are impacted by AD dementia to a similar degree when recognition is tested with a 4-choice format (Greene et al., 1996; Lowndes &amp; Savage, 2007).

Preliminary data

Recently published preliminary data provide initial support for the feasibility and validity of the SLS (Stricker et al., 2022). In 96 older women, MTD showed high usability; 98% of participants completed a test session when a session was initiated in this all-remote study. Median completion time for a complete MTD session was 15 minutes; within the session, the SLS learning trials were completed in 8 minutes. Test-retest reliability across 2 sessions 1-2 weeks apart was adequate for the SLS despite use of randomized alternate forms (ICC = .77 for trials 1-5 total); this is similar to ranges reported for other in-person tests of memory (Calamia et al. 2013; Stricker et al., 2021) and competitive with session 1 to 2 ICCs for other self-administered memory tests (Stricker et al., 2019; Mackin et al., 2021). Distributional properties of SLS measures (e.g., max span, 1-5 total, delay) were similar to the distributional properties of AVLT recall variables and did not show the prominent ceiling effects that AVLT recognition variables displayed, demonstrating that different recognition formats can produce a different pattern of results. The 4-choice SLS recognition format simulated recall performances. Our use of randomized alternate forms successfully minimized practice effects (none were significant). Validity of the SLS was shown through significant correlations with an in-person memory measure (AVLT) and cortical thickness (entorhinal cortex and temporal meta-ROI).

Limitations and Future Directions

Interpretation of process simulation results led us to propose a new hypothesis that the central deficit in PAD could be described as a failure in the contextual system that leads to interference rather than one of forgetting. A key limitation of this work is that this hypothesis is largely based on the current process model simulation results, with some additional preliminary human data support as summarized above (Stricker et al., 2022). Additional human studies work is needed, and indeed work is underway to test our primary a priori hypothesis that the SLS will show sensitivity to PAD; we predict that cognitively unimpaired amyloid positive individuals will show lower performance than cognitively unimpaired amyloid negative individuals with at least a medium (d &gt; 0.5) cross-sectional effect size. Similar to prior work examining the Cogstate Brief Battery in the Mayo Clinic Study of Aging, future work will also examine sensitivity of the SLS to preclinical AD using a multiple biomarker framework (e.g., both amyloid and tau), MCI, and associations with continuous AD biomarkers (Alden et al., 2021; Pudumjee et al., 2021; Stricker et al., 2019, 2020a, 2020b). The contextual system failure hypothesis can also help make predictions about the relative sensitivity of different memory measures to PAD based on the degree of semantic support provided by the testing paradigm and stimuli used. Specifically, as the contextual system slowly degrades, testing paradigms that tax the contextual system the most will be affected earliest in the disease process. For example, paired associate learning of weakly related word pairs will be more sensitive than word pairs with strong semantic relationships, word lists comprised of semantically unrelated words will be more sensitive than word lists that provide semantic structure through use of semantic categories, word lists that include an interference trial will be more sensitive than those that do not, word list recall will be more sensitive than story memory recall, and recognition memory for words will be more sensitive than recognition memory for pictures (Ally, 2012; Grande et al., 2021). Interestingly, although very few studies directly compare the sensitivity of different neuropsychological tests in PAD, there are some data that follow this pattern. Caselli et al. (2020) examined what neuropsychological measures showed the earliest cognitive inflection point in individuals who later converted to MCI versus non-converters; among verbal memory tests, the AVLT, which only minimally relies on contextual information, showed the earliest inflection point, which just preceded the Selective Reminding Test; the inflection point for Logical Memory, which provides substantial contextual input during the learning phase, was 3 to 5 years later.

The simulations used are not meant to be biologically accurate or to cover the full spectrum of network possibilities when it comes to distributed models. However, they are meant to serve as a tool to allow us to simplify how a distributed model of memory might work so that we can use it to generate new ways of thinking about and measuring learning and memory. Other approaches to learning multiple problems with neural networks have introduced processes that reduce the mutability of previously learned weights or add new learning resources as new problems are being learned (Benna &amp; Fusi, 2016; Kirkpatrick et al., 2017; Wiskott et al., 2006; Yang, 2019). It is not clear that different systems of weight differentiation and/or learning resource allocation must be included. Within the simple networks that we have constructed we observed some weights moving quickly as a new problem is learned while others remain static. For our MCNs, such behavior is a side effect of the architecture, as opposed to additional systems that are in play during learning.

Several constraints on generality are acknowledged for the neural networks presented. Even if we constrain ourselves to the basic feed forward and cascaded architectures described in this paper, the networks that have been explored here are by no means exhaustive nor are the training criteria: both the feed forward and cascaded networks could behave differently with the addition of more layers and hidden units, such as those often included in available AI software packages. Results could be altered or improved for either architecture with tuned parameters, different input/output coding, different training regimens (e.g. batch training, or stochastic training with replacement) or different learning criteria (e.g., a higher maximum number of training steps allowed). The cascaded networks could be further explored by examining the role of a bias node in the output network, as well as having multiple layers in the output network with weights set by a single or multiple weight setting networks. On one hand, the conceptual point of how these networks help us think about distributed systems is important, regardless of if we have explored all architectures and training permutations. On the other hand, continued exploration of new architectures is important. To our knowledge, the use of cascaded architectures as described by Pollack (1987) is not common in modern AI approaches and mirroring the inputs (duplicating the inputs to both the output networks and context networks), as done in our MCN models, is a novel approach. The MCN architecture, when combined with the addition of context inputs, provides a new alternative for solving the common problem of catastrophic interference in neural networks (Beer &amp; Barak, 2019; Ellefsen et al., 2015; Lee, 2019). Future work is needed to explore how mirrored cascaded architectures can be applied to increase efficiency and consistency of modern AI data fitting. Future work is also needed to further explore and elaborate on how the contextual system operates through investigating how context is generated, simulating the breakdown of context and applying it to simulated and observed performance on the SLS.

While the current work provides further evidence that it may be helpful to shift the focus away from rapid forgetting to more emphasis on learning in neuropsychology and PAD in particular, this study did not aim to prove that the brain does not have non-modular memory or that memory decay does not exist. Instead, these models provide insights into how a distributed, non-modular memory process could work. The current work also does not aim to address whether a distributed memory system would circumvent a possible process of memory transformation, which has been proposed as necessary for memories to transform from being context-dependent to more schematic (or semantic) in nature (Winocur &amp; Moscovitch, 2011). Future work is needed to help integrate hypotheses raised by these process simulation results with predominant memory models in the field.

With the clear need to develop measures that can be used globally, our use of an English word list is a potential limitation of the SLS as this requires both the ability to read and it is currently available only to English speakers. However, our test design that uses word frequency data to guide stimuli selection will facilitate future translation to other languages. Instead of requiring a direct translation, translation can consider word frequency rates in the target language. This aligns with previous results demonstrating that developing culturally specific stimuli yields better equivalence across different versions of a verbal memory test targeting different languages and cultures compared to a direct translation approach (Lim et al., 2009). A non-verbal equivalent of the SLS is a future direction, but even non-verbal measures perform differently across cultures, and literacy impacts performance on non-verbal memory measures as well (Byrd et al., 2005; Rosselli &amp; Ardila, 2003).

Summary

In summary, we presented a series of neural network process simulations to show that the addition of context to a system with an efficient architecture allows for a functional understanding of a distributed, non-modular memory system that can learn efficiently without interference. These neural network model results align with evidence in the literature pointing towards the importance of learning, as opposed to forgetting, as a central deficit in PAD. Process model results suggest a further refinement of this emphasis on learning may be that individuals with PAD experience a decreasing ability to incorporate context while learning information. We then applied insights obtained from these neural network results to the development of a novel digital computer adaptive word list memory test. Process simulations provide a useful method of testing models of brain function and can play a significant role in the development of novel approaches to neuropsychological assessment.

Research reported in this publication was supported by the National Institute on Aging of the National Institutes of Health under Award Number R21AG073967. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. This work was also supported by the Mayo Clinic Neurology Artificial Intelligence Program and the Kevin Merszei Career Development Award in Neurodegenerative Diseases Research IHO Janet Vittone, MD. NHS serves as a consultant to Biogen, outside the scope of the current work. A Mayo Clinic invention disclosure has been submitted for the Stricker Learning Span and the Mayo Test Drive platform (NHS, JLS) and the Mirrored Cascaded Network architecture (JLS). We have no other conflicts of interest to disclose. The source code for these neural network simulation studies are available publicly at GitHub and can be accessed at https://github.com/MayoNeurologyAI/NeuralNetworksNeuropsychology. In addition, a website which lets users recreate each study in this paper is available at https://Mayoneurologyai.github.io/NeuralNetworksNeuropsychology/. We thank Gregory G. Brown, Jeffery L. Elman, Sandra P. Marshall and Aimee J. Karstens for their contributions to this work.

Figure 1 Simple Feed Forward Network

Note. Diagram of a simple feed forward network with three layers: an input layer, a hidden layer, and an output layer. Each circle represents a node in the network, with lines showing connections between nodes where weights are shared. The dashed lines show where bias is added to the network. Each node also has a transformation function that maps the node’s input weights to the output. Input and bias nodes have linear transformation functions, hidden and output nodes have hyperbolic tangent (tanh) transformation functions. Used with permission of Mayo Foundation for Medical Education and Research; all rights reserved.

Figure 2 Mirrored Cascaded Network

Note. Diagram of a mirrored cascaded network (MCN). The MCN consists of two networks: a weight setting network (colored red) and an output network (colored blue). During activation, the output of each weight setting node is used to set each individual weight in the output network. The same inputs are provided to both the weight setting network and the output network during activation. For each training step, the error of the output network’s output node is used to assign errors to each of the weight setting nodes. Used with permission of Mayo Foundation for Medical Education and Research; all rights reserved.

Figure 3 Common Mirrored Cascaded Network Solution to XOR

Note. Example of how a mirrored cascaded network can solve XOR. Only two connections with negative values are needed in the weight setting network (as opposed to the four connections shown in Figure 2). Used with permission of Mayo Foundation for Medical Education and Research; all rights reserved.

Figure 4 Mirrored Cascaded Network Architecture with Bias Connections

Note. Diagram of a mirrored cascaded network with a bias connection in the weight setting network (the bias node is highlighted in green). Used with permission of Mayo Foundation for Medical Education and Research; all rights reserved.

Figure 5 Feed Forward Network with an Additional Context Input

Note. Diagram of a feed forward network with additional context input node used to indicate if the problem is OR or XOR. Used with permission of Mayo Foundation for Medical Education and Research; all rights reserved.

Figure 6 Mirrored Cascaded Network with an Additional Context Input

Note. Diagram of a Mirrored Cascaded Network with an additional context input node for the weight setting and output networks. The context input is used to indicate if the problem is OR or XOR. Used with permission of Mayo Foundation for Medical Education and Research; all rights reserved.

Figure 7 Flowchart of Learning and Retraining for Each Simulation in Study 4

Note. Diagram describing the process of learning and retraining for networks in Study 4. If a network was able to learn both OR and then XOR, then the network was checked to see if it had retained its OR knowledge after learning XOR. If not, then a process of retraining was allowed with a maximum number of 100 retraining attempts.

Table 1 Truth Tables for Logical Expressions OR and XOR

Inputs	Outputs	
	
Value 1	Value 2	OR	XOR	
False (−1)	False (−1)	False (−0.9)	False (−0.9)	
False (−1)	True (1)	True (0.9)	True (0.9)	
True (1)	False (−1)	True (0.9)	True (0.9)	
True (1)	True (1)	True (0.9)	False (−0.9)	
Note. Presents a truth table showing how various True/False combinations of two inputs are evaluated for logical OR and XOR. The values in parenthesis are the numerical values provided to the models.

Table 2 Results of Studies 1 and 2 for XOR

Study	Training Steps	Incorrect	Trainable Weights	
		
	M	SD	n	%	n	
1: Feed Forward Network	114.89	109.52	2812	28	9	
2: Simple Cascaded Network	2.31	0.5	0	0	4	
Note. Simulations were run 10,000 times per study. A diagram of the network architecture for a simple feed forward network appears in Figure 1. A diagram of a simple cascaded network appears in Figure 2. We present the results for both networks learning to solve XOR, including the number of training steps needed, the number of simulations that incorrectly learned XOR, and the number of trainable weights needed. Overall, the simple cascaded network learns XOR more successfully and more efficiently, with no incorrect solutions and fewer training steps and trainable weights.

Table 3 Study 3: Demonstrating How Catastrophic Interference Prevents Retention

	Successful learning OR &amp; XOR	Training Steps to learn OR	Training Steps to learn XOR	Retention of OR	
		
	%	M	SD	M	SD	M	SD	
Feed Forward Network	70.01	15.50	10.76	149.14	144.64	0	0	
Cascaded Network with bias	100	6.60	4.05	20.55	12.14	0	0	
Note. 10,000 simulations were run for both networks. A diagram for the simple feed forward network appears in Figure 1. A diagram for a cascaded network with bias appears in Figure 4. We demonstrate interference by showing the success rate of learning both OR and XOR problems, comparing how many training steps it took to learn each problem individually (OR, XOR), and showing the low retention rate of OR after the networks successfully learn XOR. While both networks successfully learn, with the cascaded network learning more successfully and efficiently than the feed forward network, neither retain OR after learning XOR.

Table 4 Study 4: Minimizing Interference with Mirrored Cascaded Networks (MCNs) Aids Retention

	Successful initial learning	Training Steps to learn initially	Failed to retain OR after learning XOR	Retain failures able to relearn with retraining	Additional problem presentations needed	Additional Training Steps needed	
		
	%	M	SD	%	%	M	SD	M	SD	
Feed Forward Network	67.45	156.51	147.36	64.95	97.41	12.77	13.72	87.54	156.11	
Mirrored Cascaded Network	100	8.79	6.80	12.96	100	1.03	0.17	3.73	2.56	
Note. 10,000 Simulations were run for both networks. Both networks included additional context inputs as shown in Figures 5 and 6. We present results showing how well each network initially learns both OR and XOR, including the percent of models that succeed (Successful initial learning) and the number of training steps it takes to complete initial learning (Training Steps to learn initially). We also show the number of times models fail on OR after the initial learning of XOR (Failed to retain OR after learning XOR). For the models that fail, they are presented with OR again and retrained until they successfully retain both OR and XOR (see Figure 7). We include the percent of these models that can successfully relearn using this method (Retain failures able to relearn with retraining), as well as the average additional number of problem presentations needed, and number of additional training steps needed.

Key Points

Question: Can a neural network process model help conceptualize a principal deficit in preclinical and prodromal Alzheimer’s disease as one of learning instead of forgetting?

Findings: Models support a conceptualization of a distributed memory system with learning as the principal deficit; context is required to organize information as it is learned, or it will be forgotten because of interference.

Importance: The insights provided by process models contributed to the development of a digital memory test that stresses the contextual system by minimizing contextual features available during learning through use of high frequency stimuli.

Next Steps: Process simulations provide a useful method of testing models of brain function and can play a key role in the development of novel approaches to neuropsychological assessment.

Open practices disclosure: Applying for Open Materials Badge

CRediT

John L. Stricker: Conceptualization, Supervision, Methodology, Data curation, Software, Formal analysis, Visualization, Writing – original draft, Writing – review and editing

Nick Corriveau-Lecavalier: Conceptualization, Writing – original draft, Writing – review and editing

Daniela A. Wiepert: Conceptualization, Visualization, Writing – review and editing

Hugo Botha: Conceptualization, Resources, Writing – review and editing

David T. Jones: Resources, Writing – review and editing

Nikki H. Stricker: Conceptualization, Funding acquisition, Project administration, Supervision, Writing – original draft, Writing – review and editing


References

Alden EC , Pudumjee SB , Lundt ES , Albertson SM , Machulda MM , Kremers WK , Jack CR Jr , Knopman DS , Petersen RC , Mielke MM , &amp; Stricker NH (2021). Diagnostic accuracy of the Cogstate Brief Battery for prevalent MCI and prodromal AD (MCI A+ T+ ) in a population-based sample. Alzheimer’s &amp; dementia, 17 (4 ), 584–594. 10.1002/alz.12219
Allen TA , &amp; Fortin NJ (2013). The evolution of episodic memory. Proceedings of the National Academy of Sciences of the United States of America, 110 (Suppl 2 ), 10379–10386. 10.1073/pnas.1301199110 23754432
Ally BA (2012). Using pictures and words to understand recognition memory deterioration in amnestic mild cognitive impairment and Alzheimer’s disease: a review. Current neurology and neuroscience reports, 12 (6 ), 687–694. 10.1007/s11910-012-0310-7 22927024
Anderson JA , &amp; Rosenfeld E (Eds.). (1988). Neurocomputing: Foundations of research. MIT Press.
Andrés P , Vico H , Yáñez A , Siquier A &amp; Ferrer GA (2019). Quantifying memory defecits in amnestic mild cognitive impairment. Alzheimer’s &amp; Dementia: Diagnosis, Assessment &amp; Disease Monitoring, 11 (1 ), 108–114. 10.1016/j.dadm.2018.12.002
Antiga LPG , Viehmann T , &amp; Stevens E (2020). Deep learning with PyTorch. Manning Publications.
Arbib MA (2002). The handbook of brain theory and neural networks (2nd ed.). MIT Press.
Atkinson RC , &amp; Shiffrin RM (1968). Human memory: A proposed system and its control processes. In Spence KW &amp; Spence JT , The psychology of learning and motivation: II. Academic Press. 10.1016/S0079-7421(08)60422-3
Bäckman L , Small BJ , &amp; Fratiglioni L (2001). Stability of the preclinical episodic memory deficit in Alzheimer’s disease. Brain, 124 (Pt 1 ), 96–102. 10.1093/brain/124.E96 11133790
Baker JE , Lim YY , Jaeger J , Ames D , Lautenschlager NT , Robertson J , Pietrzak RH , Snyder PJ , Villemagne VL , Rowe CC , Master CL , &amp; Maruff P (2018). Episodic memory and learning dysfunction over an 18-month period in preclinical and prodromal Alzheimer’s disease. Journal of Alzheimer’s Disease, 65 (3 ) ,977–988. 10.3233/JAD-180344
Baker JE , Pietrzak RH , Laws SM , Ames D , Villemagne VL , Rowe CC , Masters CL , Maruff P , &amp; Lim YY (2019). Visual paired associate learning deficits associated with elevated beta-amyloid in cognitively normal older adults. Neuropsychology, 33 (7 ), 964–974. 10.1037/neu0000561 31368758
Basso MR , Whiteside D , Combs D , Woods SP , Hoffmeister J , Mulligan R , Arnett P , Alden E , &amp; Tobin O (2021). Memory in multiple sclerosis: A reappraisal using the item specific deficit approach. Neuropsychology, 35 (2 ), 207–219. 10.1037/neu0000712 33764111
Bauer RM , &amp; Asken B (2018). The three amnesias. In Morgan JE &amp; Ricker JH (Eds.) Textbook of Clinical Neuropsychology (2nd ed.). Taylor &amp; Francis. 10.4324/9781315271743-28
Beer C , &amp; Barak O (10 2019). One Step Back, Two Steps Forward: Interference and Learning in Recurrent Neural Networks. Neural Computation, 31 (10 ), 1985–2003. 10.1162/neco_a_01222 31393826
Benna MK , &amp; Fusi S (2016). Computational principles of synaptic memory consolidation. Nature Neuroscience, 19 (12 ), 1697–1706. 10.1038/nn.4401 27694992
Berron D , van Western D , Ossenkoppele R , Strandberg O , &amp; Hansson O (2020). Medial temporal lobe connectivity and its associations with cognition in early Alzheimer’s disease. Brain, 143 (4 ), 1233–1248. 10.1093/brain/awaa068 32252068
Bilder RM , &amp; Reise SP (2019). Neuropsychological tests of the future: How do we get there from here? The Clinical Neuropsychologist, 33 (2 ), 220–245. 10.1080/13854046.2018.1521993 30422045
Brysbaert M , &amp; New B (2009). Moving beyond Kucera and Francis: A critical evaluation of current word frequency norms and the introduction of new and improved word frequency measure for American English. Behavior Research Methods, 41 (4 ), 977–990. 10.3758/BRM.4L4.977 19897807
Buzsáki G , &amp; Tingley D (2018). Space and time: The hippocampus as a sequence generator. Trends in Cognitive Sciences, 22 (10 ), 853–869. 10.1016/j.tics.2018.07.006 30266146
Byrd DA , Jacobs DM , Hilton HJ , Stern Y , &amp; Manly JJ (2005). Sources of error on visuoperceptual tasks: Role of education, literacy, and search strategy. Brain and Cognition, 55 (3 ), 251–257. 10.1016/j.bandc.2004.12.003
Calamia M , Markon K , &amp; Tranel D (2013). The robust reliability of neuropsychological measures: Meta-analyses of test-retest correlations. The Clinical Neuropsychologist, 27 (1 ), 1077–1105. 10.1080/13854046.2013.809795 24016131
Caselli RJ , Langlais BT , Dueck AC , Chen Y , Su Y , Locke DEC , Woodruff BK , &amp; Reiman EM (2019). Neuropsychological decline up to 20 years before incident mild cognitive impairment. Alzheimer’s &amp; Dementia, 16 (3 ), 512–523. 10.1016/jjalz.2019.09.085
Chang Y-L , Bondi MW , Fennema-Notestine C , McEvoy LK , Hagler DJ , Jacobson MW , Dale AM , &amp; the Alzheimer’s Disease Neuroimaging Initiative. (2010). Brain substrates of learning and retention in mild cognitive impairment diagnosis and progression to Alzheimer’s disease. Neuropsychologia, 48 (5 ), 1237–1247. 10.1016/j.neuropsychologia.2009.12.024 20034503
Chomsky N (1965). Aspects of the Theory of Syntax. MIT Press.
Clark JM , &amp; Paivio A (2004). Extensions of the Paivio, Yuille, and Madigan (1968) norms. Behavior Research Methods, Instruments, &amp; Computers, 36 (3 ), 371–383. 10.3758/BF03195584
Clément F , &amp; Belleville S (2012). Effect of disease severity on neural compensation of item and associative recognition in mild cognitive impairment. Journal of Alzheimer’s Disease, 29 (1 ), 109–123. 10.3233/JAD-2012-110426
Corriveau-Lecavalier N , Duchesne S , Gauthier S , &amp; Hudon C (2021a). A quadtratic function of activation in individuals at risk of Alzheimer’s disease. Alzhiemer’s &amp; Dementia: Diagnosis, Assessment &amp; Disease Monitoring, 12 (1 ), 1–10. 10.1002/dad2.12139
Corriveau-Lecavalier N , Rajah MN , Mellah S , &amp; Belleville S (2021b). Latent patterns of task-related functional connectivity in relation to regions of hyperactivation in individuals at risk of Alzheimer’s disease. Neuroimage: Clinical, 30 , 102643. 10.1016/j.nicl.2021.102643 33813263
Darby RR , Joutsa J , &amp; Fox DM (2019). Network localization of heterogeneous neuroimaging findings. Brain, 142 (1 ), 70–79. 10.1093/brain/awy292 30551186
Davidson PSR , Anaki D , Ciaramelli E , Cohn M , Kim ASN , Murphy KJ , Troyer AK , Moscovitch M , &amp; Levine B (2008). Does lateral parietal cortex support episodic memory? Evidence from focal lesion patients. Neuropsychologia, 46 (7 ), 1743–1755. 10.1016/j.neuropsychologia.2008.01.011 18313699
Della Sala S , Parra MA , Fabi K , Luzzi S , &amp; Abrahams S (2012). Short-term memory binding is impaired in AD but not in non-AD dementias. Neuropsychologia, 50 (5 ), 833–840. 10.1016/j.neuropsychologia.2012.01.018 22289292
Delis DC , Massman PJ , Butters N , Salmon DP , Cermak LS , &amp; Kramer JH (1991). Profiles of demented and amnesic patients on the California Verbal Learning Test: Implications for the assessment of memory disorders. Psychological Assessment: A Journal of Consulting and Clinical Psychology, 3 (1 ), 19–26. 10.1037/1040-3590.3.l.19
Delis DC , Kramer JH , Kaplan E , &amp; Ober B (2000). The California Verbal Learning Test-Second Edition. San Antonio TX: The Psychological Corporation.
Deluca J , Barbieri-berger S , &amp; Johnson SK (1994). The nature of memory impairments in multiple sclerosis: Acquisition versus retrieval. Journal of Clincal and Experimental Neuropsychology, 16 (2 ), 183–189. 10.1080/01688639408402629
Diana RA , Yonelinas AP , &amp; Ranganath C (2007). Imaging recollection and familiarity in the medial temporal lobe: a three-component model. Trends in cognitive sciences, 11 (9 ), 379–386. 10.1016/j.tics.2007.08.001 17707683
Dudai Y , Kami A , &amp; Born J (2015). The consolidation and transformation of memory. Neuron, 88 (1 ), 20–32. 10.1016/j.neuron.2015.09.004 26447570
Duff K , Atkinson TJ , Suhrie KR , Allred Dalley BC , Schaefer SY , &amp; Hammers DB (2017). Short-term practice effects in mild cognitive impairment: Evaluating different methods of change. Journal of Clinical and Experimental Neuropsychology, 39 (4 ), 396–407. 10.1080/13803395.2016.1230596 27646966
Ellefsen KO , Mouret JB , &amp; Clune J (2015). Neural modularity helps organisms evolve to learn new skills without forgetting old skills. PLoS computational biology, 11 (4 ), e1004128. 10.1371/journal.pcbi.1004128 25837826
Elman JL , Bates EA , Johnson MH , Karmiloff-Smith A , Parisi D &amp; Plunkett K (1998). Rethinking Innateness: A connectionist perspective on development. MIT Press.
Elman JL (2001). Connectionism and language acquisition. In Tomasello M &amp; Bates E (Eds.), Language development: The essential readings (pp. 295–306). Blackwell Publishing.
Farrell S , Oberauer K , Greaves M , Pasiecznik K , Lewandowsky S , &amp; Jarrold C (2016). A test of interference versus decay in working memory: Varying distraction within lists in a complex span task. Journal of Memory and Language, 90 , 66–87. 10.1016/jjml.2016.03.010
Ferguson MA , Lim C , Cooke D , Darby RR , Wu O , Rost NS , Corbetta M , Grafman J , &amp; Fox MD (2019). A human memory circuit derived from brain lesions causing amnesia. Nature Communications, 10 (1 ), 3497. 10.1038/s41467-019-11353-z
Fox MD (2018). Mapping symptoms to brain networks with the human connectome. New England Journal of Medicine, 379 , 2237–2245. 10.1056/NEJMra1706158 30575457
French R (1999). Catastrophic forgetting in connectionist networks. Trends in Cognitive Sciences, 3 (4 ), 128–135. 10.1016/S1364-6613(99)01294-2 10322466
Gaffan D (2002) Against memory systems. Philosophical Transactions of the Royal Society Biological Sciences, 357 (1424 ), 1111–1121. 10.1098/rstb.2002.1110 12217178
Gallo DA , Sullivan AL , Daffner KR , Schacter DL , &amp; Budson AE (2004). Associative Recognition in Alzheimer’s Disease: Evidence for Impaired Recall-to-Reject. Neuropsychology, 18 (3 ), 556–563. 10.1037/0894-4105.18.3.556 15291733
Gavett BE , &amp; Horwitz JE (2012). Immediate list recall as a measure of short-term episodic memory: Insights from the serial position effect and item response theory. Archives of Clinical Neuropsychology, 27 (2 ), 125–35. 10.1093/arclin/acr104 22138320
Gershon RC (2005). Computer adaptive testing. Journal of Applied Measurement, 6 (1 ), 109–127.15701948
Gonthier C , Aubry A , &amp; Bourdin B (2018). Measuring working memory capacity in children using adaptive tasks: Example validation of an adaptive complex span. Behavior Research Methods, 50 (3 ), 910–921. 10.3758/s13428-017-0916-4 28643158
Grande X , Berron D , Maass A , Bainbridge WA , &amp; Düzel E (2021). Content-specific vulnerability of recent episodic memories in Alzheimer’s disease. Neuropsychologia, 160 , 107976. 10.1016/j.neuropsychologia.2021.107976 34314781
Greene JDW , Baddeley AD , &amp; Hodges JR (1996). Analysis of the episodic memory deficit in early Alzheimer’s disease: Evidence from the doors and people test. Neuropsychologia, 34 (6 ), 537–551. 10.1016/0028-3932(95)00151-4 8736567
Grober E , &amp; Kawas C (1997). Learning and retention in preclinical and early alzheimer’s disease. Psychology and Aging, 12 (1 ), 183–188. 10.1037//0882-7974.12.1.183 9100279
Hassenstab J , Ruvolo D , Jasielec M , Xiong C , Grant E , &amp; Morris JC (2015). Absence of practice effects in preclinical Alzheimer’s disease. Neuropsychology, 29 (6 ), 940–948. 10.1037/neu0000208 26011114
Holdstock JS , Parslow DM , Morris RG , Fleminger S , Abrahams S , Denby C , Montaldi D , &amp; Mayes AR (2008). Two case studies illustrating how relatively selective hippocampal lesions in humans can have quite different effects on memory. Hippocampus, 18 (7 ), 679–691. 10.1002/hipo.20427 18398850
Jack CR Jr , Bennett DA , Blennow K , Carrillo MC , Dunn B , Haeberlein SB , Holtzman DM , Jagust W , Jessen F , Karlawish J , Liu E , Molinuevo JL , Montine T , Phelps C , Rankin KP , Rowe CC , Scheltens P , Siemers E , Snyder HM , Sperling R , … Contributors (2018). NIA-AA Research Framework: Toward a biological definition of Alzheimer’s disease. Alzheimer’s &amp; dementia, 14 (4 ), 535–562. 10.1016/j.jalz.2018.02.018
Jessen F , Amariglio RE , van Boxtel M , Breteler M , Ceccaldi M , Chételat G , Dubois B , Dufouil C , Ellis KA , van der Flier WM , Glodzik L , van Harten AC , de Leon MJ , McHugh P , Mielke MM , Molinuevo JL , Mosconi L , Osorio RS , Perrotin A , Petersen RC , … Subjective Cognitive Decline Initiative (SCD-I) Working Group (2014). A conceptual framework for research on subjective cognitive decline in preclinical Alzheimer’s disease. Alzheimer’s &amp; dementia: the journal of the Alzheimer’s Association, 10 (6 ), 844–852. 10.1016/j.jalz.2014.01.001
Kaplan E , Fein D , Morris R , &amp; Delis DC (1991). WAIS-NI:manual: WAIS-R as a neuropsychological instrument. San Antonio: Psychological Corp.
Kirkpatrick J , Pascanu R , Rabinowitz N , Veness J , Desjardins G , Rusu AA , Milan K , Quan J , Ramalho T , Grabska-Barwinska A , Hassabis D , Clopath C , Kumaran D , &amp; Hadsell R (2017). Proceedings of the National Academy of Science of the United States of America, 114 (13 ), 3521–3526. 10.1073/pnas.1611835114
Koch S (1985). The nature and limits of psychological knowledge: Lessons of a century qua “science” In Koch S &amp; Leary DE (Eds.), A century of psychology as science (pp. 75–97). American Psychological Association, 10.1037/10117-024
Lecun Y , Bottou L , Orr GB , Müller K-R (1998). Efficient BackProp. In Orr GB , Müller K-R (eds) Neural Networks: Tricks of the Trade (pp. 546). Springer, Berlin, Heidelberg. ISBN: 978-3-540-65311-0. 10.1007/3-540-49430-8_2
Lee J (2019). DynMat, a network that can learn after learning. Neural Networks, 116 . 10.1016/j.neunet.2019.04.005
Lezak MD , Howieson DB , Bigler ED , &amp; Tranel D (2012). Neuropsychological assessment (5th ed.). Oxford University Press.
Li SC , Naveh-Benjamin M , &amp; Lindenberger U (2005). Aging Neuromodulation Impairs Associative Binding: Neurocomputational Account. Psychological Science, 16 (6 ), 445–450. 10.llll/j.0956-7976.2005.01555.x 15943670
Lim YY , Prang KH , Cysique L , Pietrzak RH , Snyder PJ , &amp; Maruff P (2009). A method for cross-cultural adaptation of a verbal memory assessment. Behavior Research Methods, 41 (4 ), 1190–1200. 10.3758/BRM.4T4.1190 19897828
Lim YY , Baker JE , Bruns L , Mills A , Fowler C , Fripp J , Rainey-Smith SR , Ames D , Masters CL , &amp; Maruff P (2020). Association of deficits in short-term learning and Aβ and hippocampal volume in cognitively normal adults. Neurology, 95 (18 ), 2577–2585. 10.1212/WNL.0000000000010728
Loewenstein DA , Curiel RE , Duara R , &amp; Buschke H (2018). Novel cognitive paradigms for the detection of memory impairment in preclinical alzheimer’s disease. Assessment, 25 (3 ), 348–359. 10.1177/1073191117691608 29214859
Loewenstein DA , Curiel Cid RE , Kitaigorodsky M , Crocco EA , Zheng DD , &amp; Gorman KL (2021). Amnestic mild cognitive impairment is characterized by the inability to recover from proactive semantic interference across multiple learning trials. The Journal of Prevention of Alzheimer’s Disease, 8 (2 ), 181–187. 10.14283/jpad.2021.3
Lohnas LJ , &amp; Kahana MJ (2013). Parametric effects of word frequency in memory for mixed frequency lists. Journal of Experimental Psychology: Learning, Memory, and Cognition, 39 (6 ), 1943–1946. 10.1037/a0033669 23834055
Lowndes G , &amp; Savage G (2007). Early detection of memory impairment in Alzheimer’s disease: A neurocognitive perspective on assessment. Neuropsychology Review, 17 (3 ), 193–202. 10.1007/sll065-007-9032-z 17805975
Luria AR (1966). Higher cortical functions in man. Basic Books.
Machulda MM , Hagen CE , Wiste HJ , Mielke MM , Knopman DS , Roberts RO , Vemuri P , Lowe VJ , Jack CR Jr , &amp; Petersen RC (2017). Practice effects and longitudinal cognitive change in clinically normal older adults differ by Alzheimer imaging biomarker status. The Clinical neuropsychologist, 37 (1 ), 99–117. 10.1080/13854046.2016.1241303
Mackin RS , Rhodes E , Insel PS , Nosheny R , Finley S , Ashford M , Camacho MR , Truran D , Seabrook K , Morrison G , Narayan R , Weiner V , &amp; Michael . (2021). Home-based self-administration of a computerized cognitive tests of list learning and memory using speech recognition. Neuropsychology, development, and cognition. Section B, Aging, neuropsychology and cognition, 1–15. Advance online publication, 10.1080/13825585.2021.1927961
Malmberg KJ , Raaijmakers JGW , &amp; Shiffrin RM (2019). 50 years of research sparked by Atkinson and Shiffrin (1968). Memory &amp; Cognition, 47 (4 ), 561–574. 10.3758/sl3421-019-00896-7 30689198
Marcopulos B , &amp; Łojek E (2019). Introduction to the special issue: Are modern neuropsychological assessment methods really “modern”? Reflections on the current neuropsychological test armamentarium. The Clinical Neuropsychologist, 33 (2 ), 187–199. 10.1080/13854046.2018.1560502 30760098
Marr D (1982). Vision: A computational investigation into the human representation and processing of visual information. San Francisco: W.H. Freeman.
McCloskey M , &amp; Cohen NJ (1989). Catastrophic interference in connectionist networks: The sequential learning problem. Psychology of Learning and Motivation, 24 , 109–165. 10.1016/S0079-7421(08)60536-8
Minsky ML , &amp; Papert SA (1969). Perceptrons. M.I.T. Press.
Newell A (1973). Production systems: Models of control structures. In Chase WG , Visual information processing. Academic.
Norris D (2017). Short-term memory and long-term memory are still different. Psychological Bulletin, 143 (9 ), 992–1009. 10.1037/bul0000108 28530428
Oberauer K , &amp; Lewandowsky S (2008). Forgetting in immediate serial recall: decay, temporal distinctiveness, or interference?. Psychological review, 115 (3 ), 544–576. 10.1037/0033-295X.115.3.544 18729591
Parra MA , Abrahams S , Logie RH , &amp; Della Sala S (2010). Visual short-term memory binding in Alzheimer’s disease and depression. Journal of Neurology, 257 (7 ), 1160–1169. 10.1007/s00415-010-5484-9 20162428
Parsons T , &amp; Duffield T (2020). Paradigm shift toward digital neuropsychology and high-dimensional neuropsychological assessments: Review. Journal of Medical Internet Research, 22 (12 ), 23777. 10.2196/23777
Polcher A , Frommann I , Koppara A , Wolfsgruber S , Jessen F , &amp; Wagner M (2017). Face-name associative recognition deficits in subjective cognitive decline and mild cognitive impairment. Journal of Alzheimer’s Disease, 56 (3 ),1185–1196. 10.3233/JAD-160637
Pollack JB (1987). Cascaded back-propagation on dynamic connectionist networks. Program of the Ninth Annual Conference of the Cognitive Science Society. Hillsdale, New Jersey, Lawarence Erlbaum Associates: 391–404.
Price CJ (2018). The evolution of cognitive models: From neuropsychology to neuroimaging and back. Cortex, 107 , 37–49. 10.1016/j.cortex.2017.12.020 29373117
Pudumjee SB , Lundt ES , Albertson SM , Machulda MM , Kremers WK , Jack CR , Knopman DS , Petersen RC , Mielke MM , &amp; Stricker NH (2021). A Comparison of Cross-Sectional and Longitudinal Methods of Defining Objective Subtle Cognitive Decline in Preclinical Alzheimer’s Disease Based on Cogstate One Card Learning Accuracy Performance. Journal of Alzheimer’s disease, 83 (2 ), 861–877. 10.3233/JAD-210251
Rabin LA , Paolillo E , &amp; Barr WB (2016). Stability in test-usage practices of clinical neuropsychologists in the United States and Canada over a 10-year period: A follow-up survey of INS and NAN members. Archives of Clinical Neuropsychology, 31 (3 ), 206–230. 10.1093/arclin/acw007 26984127
Rabin LA , Smart CM , &amp; Amariglio RE (2017). Subjective cognitive decline in preclinical Alzheimer’s disease. Annual review of clinical psychology, 13 , 369–397. 10.1146/annurev-clinpsy-032816-045136
Rajah MN , &amp; McIntosh AR (2005). Overlap in the Functional Neural Systems Involved in Semantic and Episodic Memory Retrieval. Journal of Cognitive Neuroscience, 17 (3 ), 470–482. 10.1162/0898929053279478 15814006
Ranganath C , &amp; Blumenfeld RS (2005) Doubts about double dissociations between short- and long-term memory. Trends in Cognitive Sciences, 9 (8 ), 374–380. 10.1016/j.tics.2005.06.009 16002324
Rosseli M , &amp; Ardila A (2003). The impact of culture and education on non-verbal neuropsychological measurements: A critical review. Brain and Cognition, 52 (3 ), 326–333. 10.1016/S0278-2626(03)00170-2 12907177
Rumelhart DE , &amp; McClelland JL , (1986). Parallel distributed processing: Explorations in the microstructure of cognition, Vol. 1 : Foundations. MIT Press.
Sabbagh MN , Boada M , Borson S , Chilukuri M , Dubois B , Ingram J , Iwata A , Porsteinsson AP , Possin KL , Rabinovici GD , Vellas B , Chao S , Vergallo A , &amp; Hampel H (2020). Early detection of mild cognitive impairment (MCI) in primary care. The Journal of Prevention of Alzheimer’s Disease, 7 (3 ), 165–170. 10.14238/jpad.2020.21
Selkoe DJ (2019). Early network dysfunction in Alzheimer’s disease. Science, 365 (6453 ), 540–541. 10.1126/science.aay5188 31395769
Squire LR (2004). Memory systems of the brain: A brief history and current perspective. Neurobiology of Learning and Memory, 82 (3 ), 171–177. 10.1016/j.nlm.2004.06.005 15464402
Stamate A , Logie RH , Baddeley AD , &amp; Della Sala S (2020). Forgetting in Alzheimer’s disease: Is it fast? Is it affected by repeated retrieval? Neuropsychologia, 138 (17 ), 107351. 10.1016/j.neuropsychologia.2020.107351 31978403
Steinerman JR , Hall CB , Sliwinski MJ , &amp; Lipton RB (2010). Modeling cognitive trajectories within longitudinal studies: A focus on older adults. Journal of the American Geriatrics Society, 58 (SUPPL. 2 ), S313–S318. 10.1111/j.1532-5415.2010.02982.x 21029060
Stevenson RF , Reagh ZM , Chun AP , Murray EA , &amp; Yassa MA (2020). Pattern separation and source memory engage distinct hippocampal and neocortical regions during retrieval. Journal of Neuroscience, 40 (4 ), 843–851. 10.1523/JNEUROSCI.0564-19.2019 31748377
Strauss E , Sherman EMS , &amp; Spreen O (2006). A compendium of neuropsychological tests: Administration, norms, and commentary (3rd ed.). Oxford University Press.
Stricker JL , Brown GG , Wixted J , Baldo JV , &amp; Delis DC (2002). New semantic and serial clustering indices for the California Verbal Learning Test-Second Edition: Background, rationale, and formulae. Journal of the International Neuropsychological Society, 8 (3 ), 425–435. 10.1017/S1355617702813224 11939700
Stricker JL (2004). Executive Functions and Constructive Neural Networks [Doctoral dissertation, University of California, San Diego]. ISBN: UCSD:31822009435504.
Stricker NH , Lundt ES , Edwards KK , Machulda MM , Kremers WK , Roberts RO , Knopman DS , Petersen RC , &amp; Mielke MM (2019). Comparison of PC and iPad administrations of the Cogstate Brief Battery in the Mayo Clinic Study of Aging: Assessing cross-modality equivalence of computerized neuropsychological tests. The Clinical neuropsychologist, 33 (6 ), 1102–1126. 10.1080/13854046.2018.1519085 30417735
Stricker NH , Lundt ES , Alden EC , Albertson SM , Machulda MM , Kremers WK , Knopman DS , Petersen RC , &amp; Mielke MM (2020a). Longitudinal Comparison of in Clinic and at Home Administration of the Cogstate Brief Battery and Demonstrated Practice Effects in the Mayo Clinic Study of Aging. The journal of prevention of Alzheimer’s disease, 7 (1 ), 21–28. 10.14283/jpad.2019.35
Stricker NH , Lundt ES , Albertson SM , Machulda MM , Pudumjee SB , Kremers WK , Jack CR , Knopman DS , Petersen RC , &amp; Mielke MM (2020b). Diagnostic and Prognostic Accuracy of the Cogstate Brief Battery and Auditory Verbal Learning Test in Preclinical Alzheimer’s Disease and Incident Mild Cognitive Impairment: Implications for Defining Subtle Objective Cognitive Impairment. Journal of Alzheimer’s disease, 76 (1 ), 261–274. 10.3233/JAD-200087
Stricker NH , Christianson TJ , Lundt ES , Alden EC , Machulda MM , Fields JA , Kremers WK , Jack CR , Knopman DS , Mielke MM , &amp; Petersen RC (2021). Mayo Normative Studies: Regression-Based Normative Data for the Auditory Verbal Learning Test for Ages 30-91 Years and the Importance of Adjusting for Sex. Journal of the International Neuropsychological Society : JINS, 27 (3 ), 211–226. 10.1017/S1355617720000752 32815494
Stricker NH , Stricker JL , Karstens AJ , Geske J , Fields J , Hassenstab J , Schwarz CG , Tosakulwong N , Wiste HJ , Jack CR , Kantarci K , &amp; Mielke MM (2022). A Novel Computer Adaptive Word List Memory Test Optimized for Remote Assessment: Psychometric properties and Associations with Neurodegenerative Biomarkers in Older Women Without Dementia. Alzheimer’s &amp; Dementia. 10.1002/dad2.12299
Sutterer MJ , &amp; Tranel D (2017). Neuropsychology and cognitive neuroscience in the fMRI era: A recapitulation of localizationist and connectionist views. Neuropsychology, 31 (8 ), 972–980. 10.1037/neu0000408 28933871
Talamonti D , Koscik R , Johnson S , &amp; Bruno D (2020). Predicted early mild cognitive impairement with free recall: The primacy of primacy. Archives of Clinical Neuropsychology, 35 (2 ), 133–142. 10.1093/arclin/acz013 30994919
Thornton AE , Raz N , &amp; Tucke KA (2002). Memory in multiple sclerosis: contextual encoding deficits. Journal of the International Neuropsychological Society : JINS, 8 (3 ), 395–409. 10.1017/s1355617702813200 11939698
Tulving E (2002). Episodic Memory: From Mind to Brain. Annual Review of Psychology, 53 (1 ), 1–25. 10.1146/annurev.psych.53.100901.135114
Turchetta CS , De Simone MS , Perri R , Fadda L , Caruso G , De Tollis M , Caltagirone C , &amp; Carlesimo GA (2020). Forgetting rates on the recency portion of a word list predict conversion from mild cognitive impairment to Alzheimer’s disease. Jounral of Alzheimer’s Disease, 73 (4 ), 1295–1304. 10.3233/JAD-190509
Twamley EW , Legendre Ropacki SA , &amp; Bondi MW (2006). Neuropsychological and neuroimaging changes in preclinical Alzheimer’s disease. Journal of the International Neuropsychological Society, 12 (5 ), 707–735. 10.1017/S1355617706060863 16961952
Weidman S (2019). Deep Learning from Scratch: Building with Python from First Principles. O’Reilly Media, Inc.
Weissberger GH , Strong JV , Stefanidis KB , Summers MJ , Bondi MW , &amp; Stricker NH (2017). Diagnostic accuracy of memory measures in Alzheimer’s dementia and mild cognitive impairment: A systematic review and meta-analysis. Neuropsychology Review, 27 (4 ), 354–388. 10.1007/sll065-017-9360-6 28940127
Winocur G , &amp; Moscovitch M (2011). Memory transformation and systems consolidation. Journal of the International Neuropsychological Society : JINS, 17 (5 ), 766–780. 10.1017/S1355617711000683 21729403
Wiskott L , Rasch M , &amp; Kempermann G (2006). A functional hypothesis for adult hippocampal neurogenesis: Avoidance of catastrophic interference in the dentate gyrus. Hippocampus, 16 (f ), 329–343. 10.1002/hipo.20167 16435309
Woods SP , Scott JC , Conover E , Marcotte TD , Heaton RK , Grant I , &amp; HIV Neurobehavioral Research Center (HNRC) Group. (2005). Test-retest reliability of component process variables within the Hopkins verbal learning test-revised. Assessment, 12 (1 ), 96–100. 10.1177/1073191104270342 15695747
Yang GR , Joglekar MR , Song HF , Newsome WT , &amp; Wang X-J (2019). Task representations in neural networks trained to perform many cognitive tasks. Nature Neuroscience, 22 (2 ), 297–306. 10.1038/s41593-018-0310-2 30643294
Zizak VS , Filoteo JV , Possin KL , Lucas JA , Rilling LM , Davis JD , Peavy G , Wong A , &amp; Salmon DP (2005). The ubiquity of memory retrieval deficits in patients with frontal-striatal dysfunction. Cognitive Behavioral Neurology, 18 (4 ), 198–205. 10.1097/01.wnn.0000192134.53616.39 16340392
Zott B , Busche MA , Sperling RA , &amp; Konnerth A (2018). What happens with the circuit in Alzheimer’s disease in mice and humans?. Annual review of neuroscience, 41 , 277–297. 10.1146/annurev-neuro-080317-061725
Zott B (2019). A Cellular Mechanism of Amyloid β-Induced Neuronal Hyperactivity (Doctoral dissertation, Technische Universität München).
