LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


101097023
22433
IEEE Trans Neural Syst Rehabil Eng
IEEE Trans Neural Syst Rehabil Eng
IEEE transactions on neural systems and rehabilitation engineering : a publication of the IEEE Engineering in Medicine and Biology Society
1534-4320
1558-0210

30998476
6554026
10.1109/TNSRE.2019.2911970
NIHMS1029220
Article
A Single-Channel EEG-Based Approach to Detect Mild Cognitive Impairment via Speech-Evoked Brain Responses
Khatun Saleha Student Member, IEEE https://orcid.org/0000-0003-4604-4992
Department of Electrical and Computer Engineering (EECE), The University of Memphis, Memphis, TN 38152 USA

Morshed Bashir I. Member, IEEE https://orcid.org/0000-0002-2178-433
Department of Electrical and Computer Engineering (EECE), The University of Memphis, Memphis, TN 38152 USA

Bidelman Gavin M. https://orcid.org/0000-0002-1821-3261
School of Communication Sciences and Disorders (CSD), The University of Memphis, Memphis, TN 38152 USA, and also with the Institute of Intelligent Systems (IIS), The University of Memphis,Memphis, TN38152 USA

Corresponding author: Saleha Khatun. misti.buet@gmail.com.
14 5 2019
18 4 2019
5 2019
01 5 2020
27 5 10631070
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Mild cognitive impairment (MCI) is the preliminary stage of dementia, which may lead to Alzheimer’s disease (AD) in the elderly people. Therefore, early detection of MCI has the potential to minimize the risk of AD by ensuring the proper mental health care before it is too late. In this paper, we demonstrate a single-channel EEG-based MCI detection method, which is cost-effective and portable, and thus suitable for regular home-based patient monitoring. We collected the scalp EEG data from 23 subjects, while they were stimulated with five auditory speech signals. The cognitive state of the subjects was evaluated by the Montreal cognitive assessment test (MoCA). We extracted 590 features from the event-related potential (ERP) of the collected EEG signals, which included time and spectral domain characteristics of the response. The top 25 features, ranked by the random forest method, were used for classification models to identify subjects with MCI. Robustness of our model was tested using leave-one-out cross-validation while training the classifiers. Best results (leave-one-out cross-validation accuracy 87.9%, sensitivity 84.8%, specificity 95%, and F score 85%) were obtained using support vector machine (SVM) method with radial basis kernel (RBF) (sigma = 10/cost = 102). Similar performances were also observed with logistic regression (LR), further validating the results. Our results suggest that single-channel EEG could provide a robust biomarker for early detection of MCI.

Electroencephalography
event-related potential
mild cognitive impairment
speech-evoked brain responses

I. Introduction

MEMORY impairment due to aging is common. However, if the level of impairment progresses beyond what is expected in normal aging, mild cognitive impairment (MCI) can ensue [1]. MCI is a prodromal state of cognitive aging between changes deriving from natural/normal aging and dementia [2], [3]. Alzheimer’s disease (AD) is the most prevalent dementia [4]–[7] among elderly population [1], [3] in many countries, and it is accompanied by progressively worsening memory, reasoning, and other aspects of cognition [7], [8]. As the MCI is a preliminary stage of cognitive impairment, most often it is not treated properly despite the fact that there is up to 54% chance that MCI may lead to AD or related dementias [8]. The cost of providing care for the AD patients in the US was $200 billion in 2012 and it is estimated to grow to $1.1 trillion per year by 2050 [9]. Therefore, preventing this disease is of great importance for better healthcare as well as for the national financial interest. Early MCI detection may play a critical role to enhance the management of the AD and dementia care as the root cause of this neurodegenerative disease is still unclear.

Detection and characterization of MCI is an active field of research. Various physiological data such as resting-state functional magnetic resonance imaging (rs-fMRI) [4], structural magnetic resonance imaging (sMRI), diffusion tensor imaging (DTI) [5], positron emission tomography (PET) [10], fluorodeoxyglucose positron emission tomography (FDG-PET) [11], cerebrospinal fluid (CSF) [11], [12], and magnetoencephalography (MEG) [13] are being investigated to study the effect of MCI and its underlying biomarkers. Although these physiological data provide multi-dimensional information about the brain, these methods are costly and also impractical in terms of portability. Low cost spontaneous speech data had been used by researchers to detect MCI or AD [14]–[17]. Relatively low-cost electroencephalography (EEG) is also being investigated to detect [2], [7], [18]–[23] and classify [21] MCI from other diseases that affect the cognitive state. Multi-channel EEG data have been used to characterize MCI or AD using EEG signals in various literature such as: (i) mismatch negativity (MMN) and auditory P300 component from 256-channel EEG [2], (ii) features extracted by recurrence quantification analysis (RQA) and cross recurrence quantification analysis (CRQA) from 14-channel EEG [21], (iii) spectral features extracted from 19-channel EEG [7], (iv) auditory P2 component computed from 64-channel EEG [22], (v) the auditory mismatch negativity (MMN) from 19-channel EEG [23], (vi) event-related potential (ERP) amplitude and latency from 256-channel EEG [24], (vii) accuracy and response time during low and high working memory conditions of memory task using 32-channel EEG [19] etc. Non-ERP based multi-channel EEG approach has also been investigated to detect MCI, e.g. using data from a 19-channel EEG system [20]. Although multiple studies based on multi-channel EEG data are available in the literature, to the best of our knowledge, none of the studies attempted to use single-channel EEG data for the MCI detection and classification.

In this study, we have used single-channel EEG data from Fpz (near forehead) as this location is considered optimal for analyzing auditory evoked potential [25]–[27] to classify between MCI and normal functioning individuals using five sound stimuli for better sensitivity in MCI detection [24], [28]. This kind of system can be integrated into the wearable headband (i.e. MUSE™ headband with a mobile application), which will allow the assessment of cognitive strength. It is important to mention that EEG data may be affected by different types of artifacts such as ocular, muscle, electrode artifacts, which can be removed using either multi-channel [29] or single-channel [30], [31] EEG data. Therefore, studying EEG data obtained from a single-channel is not hindered by the artifacts that might degrade the quality of the EEG signal. Initial findings of this study were reported elsewhere [32]. In this paper, we provide our complete and comprehensive study results.

II. Method

We designed our experiments with five contrastive speech sounds along a vowel continuum (/a/ vs. /u/) [33]. This vowel continuum were played sequentially, and the subjects were requested to identify the sounds while their EEG data was collected. We obtained 590 features from the ERP extracted from the EEG signal, which included time domain and spectral domain characteristics from the windowed ERP data. The top 25 features ranked by the random forest algorithm were used in several classification models that are widely used in the literature e.g. Support Vector Machine (SVM), Logistic Regression (LR). We described the methodology of this study below, which is consisted of six steps: Subjects, Experimental Design, Data Collection, ERP Processing, Features Extraction and Ranking, and Classification.

A. Subjects

The physiological data used in this study was collected from an experiment, where twenty-three older adults (age ranges from 52-86 years; mean ± standard deviation: 70.2 ± 7.2 yrs) participated. All the subjects were strongly right-handed [28] with no known history of psychiatric or neurological illness. The cognitive state of the participants was evaluated by the well-established Montreal Cognitive Assessment (MoCA) test [34]. In this assessment, among all the participants, fifteen older adults (8 male, 7 female) were normal (MoCA score: 26-30), and eight participants’ (4 male, 4 female) were found to have MCI (MoCA score: 22-25). It is worth mentioning that patients having Alzheimer’s disease or severe dementia generate MoCA score within 11.4 to 21 [35]. The age of the MCI group and the control group was 74.6 ± 3.3 years, and 67.5 ± 8.2 years, respectively (t21 = 2.34, p = 0.03). The chi-square test for the gender of the two groups gave a p-value of 0.81. The total years of formal education of the MCI, and normal group was 14.6 ± 3.2 years, and 17.4 ± 3.75 years, respectively (t21 = −1.68, p = 0.11). Participants in the study were compensated for their time and they gave their written consent under the protocol approved by the Baycrest Centre Ethics Committee (REB #06-31). The study was designed to observe the aging effect on the auditory system and to evaluate the cognitive state of the subjects. While recruiting the participants, exclusion criteria were based on age, musical training, handedness, and hearing loss [33].

B. Experiment Design

The phonetic continuum was generated by varying the first formant (F1) frequency within 430 Hz and 730 Hz over five equal steps. Fundamental (F0), second (F2), and third formant (F3) frequencies were kept the same for all five sound tokens. The values of F0, F2, and F3 were 100 Hz, 1090 Hz, and 350 Hz, respectively. The five-stepped vowel continuum (vw1-vw5) was constructed in a way so that each sound token of 100 ms would differ minimally acoustically, still be perceived categorically [36], [37]. We were aware that hearing loss due to aging may alter cortical auditory evoked potentials [25], and may influence the response; however, audiometric testing showed that hearing thresholds did not differ between groups at octave frequencies between 250 and 4000 Hz [33], which is well beyond the bandwidth of the stimuli.

C. Data Collection

Data collection technique and response evaluation were homogeneous to the studies reported in [25], [26], [32], [33], [36]. During EEG recording, participants went through 200 trials for each sound token. Each participant took part in the data collection twice. The experiment was conducted in an electroacoustically shielded chamber (Industrial Acoustics, Inc.). Subjects experienced the stimuli through earphones (ER-3A, Etymotic Research) in both ears at an intensity of 83 dB SPL. To eliminate electromagnetic stimulus artifact from corrupting neurophysiological responses, extended acoustic tubing (50 cm) was used [27], [33], [36]. Sound token came to subjects randomly, and they were requested to rapidly categorize them with a binary response (“u” or “a”) by pressing specific buttons on the keyboard. In this study, their response does not matter as we were only interested to see how the ERP changes with different stimulus. However, we wanted them to focus while the stimulus was applied. This was done to make sure that the resulting ERP is produced only due to the applied stimulus. Each sound token was 100 ms duration with 10 ms of rise and fall time to reduce the spectral splatter [25]. After the participants’ response, an inter-stimulus interval (ISI) followed randomly between 400 and 600 ms (20-ms steps, rectangular distribution) to avoid subjects anticipating subsequent stimuli [38]. SynAmps RT EEG amplifiers (Compumedics Neuroscan, Charlotte, NC, USA) were used to capture EEG data. EEGs was recorded differentially between an electrode placed on the high forehead at the hairline referenced to linked mastoids. To record auditory evoked potentials from the cortical origin, this montage (~Fpz-A1/A2) is considered optimal [36], [39], [40]. Throughout the duration of the experiment, contact impedances were maintained below 3 kΩ, and the EEG signal was captured at 20 kHz sampling rate and then filtered by a band pass filter having passband within 0.05 Hz – 3500 Hz.

D. Event-Related Potential Processing

EEG data were processed using ERPLAB, an open source toolbox, which runs in the MATLAB environment [41]. An interval of 700 ms (100 ms pre-stimulus and 600 ms poststimulus) constituted an EEG epoch as shown in Fig. 1 [32]. The left part of Fig. 1 represents five grand average ERP from a normal subject due to five auditory stimuli. The right part of Fig. 1 contains the comparison between the ERPs of Normal and MCI group. The pre-stimulus region was used for baseline correction, where the subtraction method [42] was used. Trials exceeded ±50 μV were excluded from the analysis as they were probably contaminated by different artifacts such as eye-blinks, eye-movements etc as mentioned in [30], [31]. For each auditory stimulus, artifact-free epochs were used to calculate the grand average ERP. Finally, the grand average ERP is bandpass filtered from within (0-30) Hz because of a priori knowledge of the ERP bandwidths and the stimuli [26], [32], [33], [36], [40], [43]. It is to be noted that data from the different subjects do not go into the ERP calculation, rather each subject has its own ERP, which is calculated from the 200 trials of two sessions.

E. Features Extraction and Ranking

We extracted total 590 candidate features from the ERP prominent points and the time and spectral domain characteristics, and used top 25 features in the classification models, which were ranked by the random forest algorithm. In the cortical auditory evoked responses, prominent ERP points seem to have discriminatory power between normal and MCI stage [22] in the older adults. For that reason, we included the ERP prominent points in the candidate feature vector (CFV). The ERP prominent points such as Pa, P1, N1, and P2 were defined as the peak points between the intervals [25 ms - 35 ms], [60 ms – 80 ms], [90 ms – 110 ms], and [150 ms - 250 ms] respectively [32] as shown in Fig. 2. The peak amplitudes and their respective latencies of these prominent points, and the mean amplitudes of the intervals containing the prominent points were also included in the CFV because of their known importance in separating groups in the experiments involving evoked responses [44]. Relative powers in the EEG bands [i.e. delta (0-4)Hz / theta (4-7)Hz / alpha (8-12)Hz / beta (12-30)Hz] were also useful in classifying normal, mild cognitive impaired, and Alzheimer’s’ disease group [45]; thereby, included in the CFV. We used band-power.m function of MATLAB to compute the relative power. Total 16 features were calculated from the ERP prominent points from each stimulus, which resulted in total 80 feature points in the CFV. As the ERP changes rapidly with time within the window over which the stimulus is applied, it was important to track the variation of the time-domain characteristics in high-resolution. In order to accomplish that, we applied a 25ms window, with a 50% overlap through the entire ERP signal (i.e. 700ms EEG epoch) as depicted in Fig. 2.

The sliding window allowed us to observe the variation of the time domain properties, which has shown significance in classifying MCI and normal subject in earlier studies [33]. Total 107 time-domain characteristics such as signal statistics, correlation properties, entropies, etc. from each window were calculated using the opensource software package “HCTSAtool” [46], [47] written in Matlab. For the details of the extracted time domain characteristics, please see [46], [47]. The authors of [46], [47] also provided the documentation of the HCTSA tool [50] for the detail explanation of the time-domain characteristics. Among available properties in the HCTSA tool, we have considered four categories such as: (i) Distribution, (ii) Correlation, (iii) Entropy and information theory, and (iv) Basics statistics and trend [other groups are not applicable for the EEG signal].

To calculate the variation of the time-domain characteristics over time, we computed the slope and the coefficient of variation (CV), which constituted two feature points at each time-stamp for each stimulus. The feature points that had intra-class similarity and inter-class variability (judged by visual inspection) were included in the CFV. For example, Fig. 2(a &amp;b) show the slope and CV of one of the time domain characteristics (computed by the HCTSAtool known as “proportion of data within two-standard deviation of mean [46]–[48]”) for the normal and the MCI group, respectively. Here we observed that this feature point was different for two classes and the shaded regions depict that there was an intra-class similarity, but this feature was different between the classes (i.e. interclass variability), thereby selected as a feature point in the CFV. Similarly, the slope and CV shown in Fig. 2 (c&amp;d) at a different timestamp also have intra-class similarity and inter-class variability, which fulfill their requirement to be in the CFV. Among all the time-domain feature points, 510 such feature points met the condition as mentioned above and were included in the CFV.

All 590 features of the CFV (i.e. 80 from the prominent points and 510 from the time-domain characteristics) were ranked by the random forest algorithm [49], and top 25 features were used in the classification models. The reason for taking top 25 features can be explained by Fig. 3. We obtained the highest cross-validation accuracy while using top 25 features and then it decreased at a higher number of features. The random forest algorithm was implemented using the “randomForest” package of R. In the random forest algorithm, total 590 trees were constructed and at each split, 50 randomly sampled features were considered. To demonstrate the efficacy of the feature ranking process by random forest, we also demonstrated the results obtained by SVM at different number of features in Fig. 3. The SVM algorithm was implemented using “fitcsvm” module of MATLAB and radial basis kernel was used (C = 102, sigma = 103). We observed that the SVM also gave the highest cross-validation accuracy while using top 25 features. Among 25 features, there are four features related with the prominent points of the ERP and rest of them are related with the statistical properties of the ERP extracted with the opensource software package “HCTSAtool” (Fulcher, Little, &amp; Jones, 2013) written in Matlab. In the statistical properties related features, seven are related with entropy, twelve are related with the mean, and one is related with mean absolute deviation. Feature ranking helped us to reduce the number of features in final implementation and it helped to keep the computation cheap and also to reduce the probability of overfitting the data.

F. Classification

In this study, we used support vector machine (SVM), and logistic regression (LR) as they have already been used in the study related with EEG/ERP [49] data, and at the same time inference from these algorithms were computationally efficient. We used “fitcsvm” module of MATLAB to implement the support vector machine (SVM), and “liblinear” package of Weka 3.7 to implement the logistic regression (LR). In the SVM grid search, we implemented polynomial and radial basis kernel, and varied the cost, C = {10−2, 10−1, 1, 101, 102}.

The degree and sigma used in the case of polynomial and RBF kernel, respectively are reported in TABLE I. Similar approach was followed while LR grid search was implemented. For the detail grid search parameters, please see TABLE I.

It was necessary to find a model that balances between bias and variance to prevent overfitting and ensure generalization. Preventing overfitting is especially challenging if the sample size is small. To overcome this challenge, we followed the approach of [26] that means we used leave-one-out cross-validation set fixed for all classifiers (SVM, LR). In leave-one-out cross validation, the model is trained with N-1 samples and tested by the Nth sample. This process is repeated for all N samples. The experimental setup, EEG preprocessing, feature extraction, and classification method are summarized through a flowchart in Fig. 4.

III. Results

To evaluate the classification models, we observed the key performance attributes such as leave-one-out cross-validation accuracy, sensitivity of the positive class (i.e. MCI group), and support vector ratio (SVR) (when applicable) in our SVM/LR grid search. In Fig. 5, we demonstrate the variation of the performance metrics in the case of the SVM for both the polynomial (d = 2, 3, and 4), and the RBF (σ = 10) kernels.

The top row of Fig. 5 shows the variation of the leave-one-out cross-validation accuracy with respect to the cost parameters, C = {10−2, 10−1, 1, 101, 102. The results show that with the increase ofC, both the leave-one-out cross-validation accuracy initially increases and reaches at the maximum for the optimal values of C. In Fig. 5(a), Fig. 5(b) and Fig. 5(c), the cross-validation accuracy reaches the maximum point and did not change later with the increment in C. The optimal C also provides the highest sensitivity and the lowest SVR as shown in the bottom row of Fig. 5 (exception for Fig. 5(e), the sensitivity increased after the optimal C). Lower support vector ratio ensures the model’s stability with respect to the overfitting. The variation of the sensitivity, and, leave-one-out cross-validation accuracy with respect to the cost parameter, C = {10−2, 10−1, 1, 101, 102 in the case of LR for both the L1 and L2 regularization is shown in Fig. 6. Likewise, SVM, the variation of the leave-one-out cross-validation accuracy, and sensitivity follow similar trend with C, and becomes maximum for the optimal value of C.

We observed that SVMSigma10C100 works best among all the models considered here. The performance attributes for the best classification models for different cases are summarized in TABLE II. These observations suggest that the selected feature vector is robust to multiple classification models in classifying between the normal and the MCI group.

In order to investigate the impact of different sounds used in the experiment, we used features collected from each sound in our classification models. The results obtained with the best models are summarized in Fig. 7. The sounds were ranked according to the leave-one-out cross-validation accuracy, sensitivity for MCI, and F score in TABLE III. We observed that the clear sounds (vw1: /μ/, vw4, and vw5: /a/) are perceived differently by the normal and impaired individuals and thereby are a better candidate to be used for future study related to MCI detection.

IV. Discussion

Multi-channel EEG data with auditory stimulus is proven to work to classify between MCI and HC [20], [23]. From this study, we observed that even single-channel EEG data with auditory stimulus has the potential to classify between the MCI and HC. It was reported in previous studies that there are differential properties in the ERP responses between the MCI and HCs due to auditory stimulus. For example, Pekkonen et al., (1994) [50] reported that dementia patients have faster decay in auditory sensory memory than the agematched controls, which gets reflected in the mismatch negativity (MMN) (a component measured from ERP). In our previous study (Bidelman et al., (2017) [33]), we observed that prefrontal dysfunction via efferent connections or abnormalities within the ascending auditory pathways may be related to MCI. Due to these reasons. We believe that the EEG signal collected from the frontal lobe (Fpz channel) has proven to be useful in the MCI detection. Additionally, we observed that the choice of auditory signal is also important. We found that ambiguous stimulus has less performance than non-ambiguous stimulus in the classification.

We tabularized our result with the existing work in the literature in TABLE IV. Expensive sMRI, FDG-PET, CSF, fMRI, DTI, PET data achieved more than 90% accuracy in discriminating MCI vs HC in multiple studies [5], [10]–[12].Low-cost speech data also showed promising performance in this area [15]. Relatively low-cost multi-channel EEG data also demonstrated comparable accuracy ([20], [23] obtained around 88.9% accuracy in differentiating MCI and HC). Our single-channel EEG-based MCI classifier, which obtained 87.9% accuracy, further demonstrates the significance of the EEG data in MCI study.

Our results are comparable to those observed with multi-channel EEG, and fMRI-based techniques in terms of classification accuracy, sensitivity, and specificity. This suggests that our single- channel based method may provide an alternative way of MCI detection, which is easy-to-use, and cost-effective.

The primary goal of this work is to investigate the use of the single-channel EEG data in detecting the early cognitive impairment to support the wearable technology. As we mentioned earlier in the discussion section, multi-channel EEG and other physiological data have proven to be a reliable source for the MCI detection; however, the idea of using the single-channel EEG data in determining complex neurological phenomena is relatively new. We believe that our work will motivate further study in this area.

In MRI technique, a patient needs to lie in the MRI scanner (a very large, strong magnet) and a radio wave is used to send signals to the part of the body of interest and receive them back. A computer attached to the scanner converts the returning signal into images. In PET technique, a patient swallows, inhales, or gets injected by radioactive tracer and then lies under a big PET scanner for generating PET image for diagnosis. fMRI uses the same basic principles as MRI. However, MRI scans anatomical structure whereas fMRI scans metabolic function. DTI, and sMRI also have similarities with MRI technique. High-density multichannel EEG setup requires a patient to sit in a quiet environment for a certain time determined by the study for data collection. All the techniques discussed so far here can only be employed in a hospital environment but not in wearable or portable devices. Conversely, the technique discussed in this paper can be implemented in a home environment.

V. Conclusion

In this study, we targeted to find a solution in the MCI detection using minimalistic, non-invasive, and low-cost approach–via ERP responses from the scalp EEG data. We selected existing algorithms such as SVM, LR and extracted features from time and frequency domain responses during speech processing responses reflected in the single-channel EEG data obtained from Fpz location. We observed that the top 25 ranked features ranked by the random forest method performed well with most of the classification models. Based on the best performances from the SVM model, we can predict MCI with 87.9% leave-one-out cross-validation accuracy, 84.8% sensitivity, and 95% specificity. In the future, this study can be expanded to real-time implementation of the system with the hardware-software implementation.

The work of S. Khatun was supported by the Herff College of Engineering, University of Memphis, through the Herff Graduate Fellowship. This work was supported by grant NIH/NIDCD R01DC016267 awarded to G.M.B.

Fig. 1. Visualization of the ERP at different auditory stimuli. Left: individual response for the auditory stimulus vw1, vw2, vw3, vw4, and, vw5 of a normal subject; right: comparison between the ERPs of two subjects that belong to the Normal and the MCI group. ERP responses in the case of four auditory stimulus vw1, vw2, vw3, vw4 are visualized.

Fig. 2. Schematic of the feature extraction process: (a) and (c) are slopes and (b) and (d) are covariances for two different time windows from timestamp t1 to t2.

Fig. 3. Feature ranking and feature subset selection.

Fig. 4. Flow diagram of the algorithm.

Fig. 5. Performance evaluation of SVM models: Leave-One-Out Cross Validation accuracy of Polynomial kernel (a) d = 2, (b) d = 3, (c) d = 4, Leave-One-Out Cross Validation accuracy of RBF kernel (d) σ = 10, Support vector ratio and Sensitivity of Polynomial kernel (e) d = 2, (f) d = 3, (g) d = 4, Support vector ratio and Sensitivity of RBF kernel (h) σ = 10.

Fig. 6. Performance evaluation of LR models: (a) Sensitivity of L1 and L2 regularization, Leave-One-Out Cross-Validation accuracy of (b) L1 regularization, (c) L2 regularization.

Fig. 7. Comparison of performances among auditory stimulus.

TABLE I Models Selected for Observing Aggregated Sound Features’ Performance

Model Name	Combination	Type		
SVMDnCm	SVM (degree = n, cost = m)	Polynomial kernel	degree = {2, 3, 4}
cost = {10−2, 10−1, 1, 101, 102}	
SVMSigmanCm	SVM (sigma = n, cost = m)	Radial basis kernel	sigma = {10−5, 10−4, 10−3, 10−2, 10−1, 1, 10}
cost = (10−2, 10−1, 1, 101, 102}	
LRL1Cm	LR (regularization = 1, cost = m)	L1 regularization	cost = (10−2, 10−1, 1, 101, 102}	
LRL2Cm	LR (regularization = 2, cost = m)	L2 regularization	cost = (10−2, 10−1, 1, 101, 102}	

TABLE II Performance of SVMSigma10C100 Model Selected for Observing Aggregated Sound Features’ Performance

Sen.	Spec.	Prec.	F	ROC	
0.85	0.95	0.92	0.88	0.91	

TABLE III Stimulus Rank

Stimulus	Rank	
vw1	1	
vw2	4	
vw3	5	
vw4	2	
vw5	3	

TABLE IV Literature Summary

Paper	Source of
Data	Focus	Classification
Method	Accuracies
(%)	Sensitivity (%)	Specificity (%)	Stimuli	
Zhang et al [11].	sMRI, FDG-PET, CSF	Classification AD vs HC, MCI vs HC	Linear SVM	93.2, 76.4	93.0, 81.8	93.3, 66.0	N/A	
Sui et al.[12]	fMRI, DTI	Classification MCI vs. HC	Multi kernel SVM	96.3	100	94.1	N/A	
Suk et al.[10]	MRI, PET	Classification AD vs. HC, MCI vs. HC, AD vs. MCI	Deep learning	98.8, 90.7, 83.7	N/A	N/A	N/A	
Ruzzoli et al [23]	Multi-ch. EEG	Classification MCI vs. HC	LR	N/A	76.9	73.3	Auditory	
Kashefpoor et al [20]	Multi-ch. EEG	Classification HC vs MCI	Neurofuzzy system and KNN	88.9	100	83.3	N/A	
Ahmed et al.[5]	sMRI, DTI	Classification AD vs. HC, MCI vs. HC, AD vs. MCI	Multiple kernel learning	90.2, 79.4, 76.6	82.9, 71.6, 65.5	94.6, 84.7, 81.3	N/A	
Toth et al. [15]	Speech	Classification HC vs. MCI	Naïve Bayes, Linear SVM, Random Forest	71.4	79.2	61.1	Visual	
This Study	Single ch. EEG	Classification HC vs MCI	SVM, LR	87.9	84.8	95.0	Auditory	


References

[1] Petersen RC , Smith GE , Waring SC , Ivnik RJ , Tangalos EG , and Kokmen E , “Mild cognitive impairment: Clinical characterization and outcome,” Arch. Neurol, vol. 56 , no. 3 , pp. 303–308, 1999.10190820
[2] Tsolaki A , “Brain source localization of MMN and P300 ERPs in mild cognitive impairment and Alzheimer’s disease: A high-density EEG approach,” Neurobiol. Aging, vol. 55 , pp. 190–201, 7 2017.28461101
[3] Vinters HV , “Emerging concepts in Alzheimer’s disease,” Annu. Rev. Pathol., Mech. Disease, vol. 10 , pp. 291–319, 1 2015.
[4] Ni H , “Network analysis in detection of early-stage mild cognitive impairment,” Phys. A, Stat. Mech. Its Appl, vol. 478 , pp. 113–119, 7 2017.
[5] Ahmed OB , Benois-Pineau J , Allard M , Catheline G , and Amar CB , “Recognition of Alzheimer’s disease and mild cognitive impairment with multimodal image-derived biomarkers and multiple kernel learning,” Neurocomputing, vol. 220 , pp. 98–110, 1 2017.
[6] Knowles RB , “Plaque-induced neurite abnormalities: Implications for disruption of neural networks in Alzheimer’s disease,” Proc. Nat. Acad. Sci, vol 96 , no. 9 , pp. 5274–5279, 1999.10220456
[7] Trambaiolli LR , Spolaôr N , Lorena AC , Anghinah R , and Sato JR , “Feature selection before EEG classification supports the diagnosis of AlzheimerâŁ™s disease,” Clin. Neurophysiol, vol. 128 , pp. 2058–2067, 10 2017.28866471
[8] Tsai C-L , Pai M-C , Ukropec J , and Ukropcova B , “The role of physical fitness in the neurocognitive performance of task switching in older persons with mild cognitive impairment,” J. Alzheimer’s Disease, vol. 53 , no. 1 , pp. 143–159, 2016.27128369
[9] De Venuto D , Annese VF , and Mezzina G , “Remote neuro-cognitive impairment sensing based on P300 spatio-temporal monitoring,” IEEE Sensors J, vol. 16 , no. 23 , pp. 8348–8356, 12 2016.
[10] Suk H. Il , Lee SW , and Shen D , “Latent feature representation with stacked auto-encoder for AD/MCI diagnosis,” Brain Struct. Function, vol. 220 , no. 2 , pp. 841–859, 2015.
[11] Zhang D , Wang Y , Zhou L , Yuan H , Shen D , and Alzheimer’s I , “Multimodal classification of Alzheimer’s disease and mild cognitive impairment,” NeuroImage, vol. 55 , no. 3 , pp. 856–867, 2011.21236349
[12] Sui J , Huster R , Yu Q , Segall JM , and Calhoun VD , “Function—Structure associations of the brain: Evidence from multimodal connectivity and covariance studies,” NeuroImage, vol. 102 , no. 15 , pp. 11–23, 2014.24084066
[13] López ME , “MEG beamformer-based reconstructions of functional networks in mild cognitive impairment,” Frontiers Aging Neurosci, vol. 25 , no. 9 , p. 107, 2017.
[14] Konig A , “Use of speech analyses within a mobile application for the assessment of cognitive impairment in elderly people,” Current Alzheimer Res, vol. 15 , no. 2 , pp. 120–129, 2018.
[15] Toth L , “A speech recognition-based solution for the automatic detection of mild cognitive impairment from spontaneous speech,” Current Alzheimer Res, vol. 15 , no. 2 , pp. 130–138, 2018.
[16] Gosztolya G , “Detecting mild cognitive impairment from spontaneous speech by correlation-based phonetic feature selection,” in Proc. Annu. Conf. Int. Speech Commun. Assoc,, 4 2016, pp. 107–111
[17] Weiner J , Herff C , and Schultz T , “Speech-based detection of Alzheimer’s disease in conversational German,” in Proc. Annu. Conf. Int. Speech Commun. Assoc, 5 2016, pp. 1938–1942.
[18] Kaiser AK , Doppelmayr M , and Iglseder B , “EEG beta 2 power as surrogate marker for memory impairment: A pilot study,” Int. Psychogeriatrics, vol. 29 , no. 9 , pp. 1515–1523, 2017.
[19] López Zunini RA , “Event-related potentials elicited during working memory are altered in mild cognitive impairment,” Int. J. Psychophysiol, vol. 109 , pp. 1–8, 11 2016.27677232
[20] Kashefpoor M , Rabbani H , and Barekatain M , “Automatic diagnosis of mild cognitive impairment using electroencephalogram spectral features,” J. Med. Signals Sensors, vol. 6 , no. 1 , p. 25, 1 2016.
[21] Timothy LT , Krishna BM , and Nair U , “Classification of mild cognitive impairment EEG using combined recurrence and cross recurrence quantification analysis,” Int. J. Psychophysiol, vol. 120 , pp. 86–95, 10 2017.28711698
[22] Lister JJ , Bush ALH , Andel R , Matthews C , Morgan D , and Edwards JD , “Cortical auditory evoked responses of older adults with and without probable mild cognitive impairment,” Clin. Neurophysiol, vol. 127 , no. 2 , pp. 1279–1287, 2 2016.26643153
[23] Ruzzoli M , Pirulli C , Mazza V , Miniussi C , and Brignani D , “The mismatch negativity as an index of cognitive decline for the early detection of Alzheimer’s disease,” Sci. Rep, vol. 6 , 9 2016, Art. no. .33167.
[24] Papadaniil CD , Kosmidou VE , Tsolaki A , Tsolaki M , Kompatsiaris IY , and Hadjileontiadis LJ , “Cognitive MMN and P300 in mild cognitive impairment and Alzheimer’s disease: A high density EEG-3D vector field tomography approach,” Brain Res, vol. 1648 , pp. 425–433, 10 2016.27485659
[25] Bidelman GM , Villafuerte JW , Moreno S , and Alain C , “Age-related changes in the subcortical—Cortical encoding and categorical perception of speech,” Neurobiol. Aging, vol. 35 , no. 11 , pp. 2526–2540, 2014.24908166
[26] Bidelman GM and Alain C , “Musical training orchestrates coordinated neuroplasticity in auditory brainstem and cortex to counteract age-related declines in categorical vowel perception,” J. Neurosci, vol. 35 , no. 3 , pp. 1240–1249, 1 2015.25609638
[27] Aiken SJ and Picton TW , “Envelope and spectral frequency-following responses to vowel sounds,” Hearing Res, vol. 245 , nos. 1–2 , pp. 35–47, 11 2008.
[28] Oldfield RC , “The assessment and analysis of handedness: The Edinburgh inventory,” Neuropsychologia, vol. 9 , no. 1 , pp. 97–113, 1971.5146491
[29] Mahajan R and Morshed B , “Unsupervised eye blink artifact denoising of EEG data with modified multiscale sample entropy, kurtosis, and wavelet-ICA,” IEEE J. Biomed. Health Inform, vol. 19 , no. 1 , pp. 158–165, 1 2015.24968340
[30] Khatun S , Mahajan R , and Morshed BI , “Comparative study of wavelet-based unsupervised ocular artifact removal techniques for single-channel EEG data,” IEEE J. Transl. Eng. Health Med, vol. 4 , no. 9 , 3 2016, Art. no. 2000108.
[31] Khatun S , Mahajan R , and Morshed BI , “Comparative analysis of wavelet based approaches for reliable removal of ocular artifacts from single channel EEG,” in Proc. IEEE Int. Conf. Electro/Inf. Technol. (EIT), 5 2015, pp. 335–340.
[32] Khatun S , Morshed BI , and Bidelman GM , “Single channel EEG time-frequency features to detect mild cognitive impairment,” in Proc. IEEE Int. Symp. Med. Meas. Appl. (MeMeA), 5 2017, pp. 437–442.
[33] Bidelman GM , Lowther JE , Tak SH , and Alain C , “Mild cognitive impairment is characterized by deficient brainstem and cortical representations of speech,” J. Neurosci, vol. 37 , no. 13 , pp. 3610–3620, 3 2017.28270574
[34] Nasreddine ZS , “The montreal cognitive assessment, MoCA: A brief screening tool for mild cognitive impairment,” J. Amer. Geriatrics Soc, vol. 53 , no. 4 , pp. 695–699, 2005.
[35] Doerflinger DMC , “Mental status assessment in older adults: Montreal cognitive assessment: MoCA Version 7.1 (original version),” Clinical Neuropsychol., vol. 25 , no. 1 , pp. 119–126, 2012.
[36] Bidelman GM , Moreno S , and Alain C , “Tracing the emergence of categorical speech perception in the human auditory system,” Neuroimage, vol. 79 , no. 1 , pp. 201–212, 2013.23648960
[37] Pisoni DB , “Auditory and phonetic memory codes in the discrimination of consonants and vowels,” Perception Psychophys, vol. 13 , no. 2 , pp. 253–260, 6 1973.
[38] Luck SJ , An Introduction to the Event-related Potential Technique. Cambridge, MA, USA: MIT Press, 2005.
[39] Krishnan A , Gandour JT , and Bidelman GM , “The effects of tone language experience on pitch processing in the brainstem,” J. Neurolinguistics, vol. 23 , no. 1 , pp. 81–95, 1 2010.20161561
[40] Musacchia G , Strait D , and Kraus N , “Relationships between behavior, brainstem and cortical encoding of seen and heard speech in musicians and non-musicians,” Hearing Res, vol. 241 , nos. 1–2 , pp. 34–42, 2008.
[41] Lopez-Calderon J and Luck SJ , “ERPLAB: An open-source toolbox for the analysis of event-related potentials,” Frontiers Hum. Neurosci, vol. 8 , p. 213, 4 2014.
[42] Hu L , Xiao P , Zhang ZG , Mouraux A , and Iannetti GD , “Single-trial time—Frequency analysis of electrocortical signals: Baseline correction and beyond,” Neuroimage, vol. 84 , pp. 876–887, 1 2014.24084069
[43] Bidelman GM , “Towards an optimal paradigm for simultaneously recording cortical and brainstem auditory evoked potentials,” J. Neurosci. Methods, vol. 241 , no. 15 , pp. 94–100, 2 2015.25561397
[44] Blankertz B , Lemm S , Treder M , Haufe S , and Müller K-R , “Single-trial analysis and classification of ERP components—A tutorial,” Neuroimage, vol. 56 , no. 2 , pp. 814–825, 2011.20600976
[45] van der Hiele K , “EEG and MRI correlates of mild cognitive impairment and Alzheimer’s disease,” Neurobiol. Aging, vol. 28 , no. 9 , pp. 1322–1329, 9 2007.16854500
[46] Fulcher BD and Jones NS . (2016). “Automatic time-series phenotyping using massive feature extraction.” [Online]. Available: https://arxiv.org/abs/1612.05296
[47] Fulcher BD , Little MA , and Jones NS , “Highly comparative time-series analysis: The empirical structure of time series and their methods,” J. Roy. Soc. Interface, vol. 83 , no. 10 , 2013, Art. no. 20130048.
[48] Accessed: Apr. 23, 2019 [Online]. Available: https://hctsa-users.gitbook.io/hctsa-manual/list-of-included-code-files.
[49] Bashivan P , Yeasin M , and Bidelman GM , “Single trial prediction of normal and excessive cognitive load through EEG feature fusion,” in Proc. IEEE Signal Process. Med. Biol. Symp. (SPMB), 12 2016, pp. 1–5.
[50] Pekkonen E , Jousmäki V , Könönen M , Reinikainen K , and Partanen J , “Auditory sensory memory impairment in Alzheimer’s disease: An event-related potential study.,” Neuroreport, vol. 5 , no. 18 , pp. 2537–2540, 1994.7696598
