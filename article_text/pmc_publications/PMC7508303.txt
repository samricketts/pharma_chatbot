LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


01510020R
28065
J Am Stat Assoc
J Am Stat Assoc
Journal of the American Statistical Association
0162-1459
1537-274X

32973370
7508303
10.1080/01621459.2019.1623042
NIHMS1534766
Article
Likelihood ratio tests for a large directed acyclic graph
Li Chunlin 1
Shen Xiaotong 1
Pan Wei 2
1 School of Statistics, University of Minnesota, Minneapolis, MN 55455.
2 Division of Biostatistics, University of Minnesota, Minneapolis, MN 55455.
24 7 2019
25 6 2019
2020
01 1 2021
115 531 13041319
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.

Inference of directional pairwise relations between interacting units in a directed acyclic graph (DAG), such as a regulatory gene network, is common in practice, imposing challenges because of lack of inferential tools. For example, inferring a specific gene pathway of a regulatory gene network is biologically important. Yet, frequentist inference of directionality of connections remains largely unexplored for regulatory models. In this article, we propose constrained likelihood ratio tests for inference of the connectivity as well as directionality subject to nonconvex acyclicity constraints in a Gaussian directed graphical model. Particularly, we derive the asymptotic distributions of the constrained likelihood ratios in a high-dimensional situation. For testing of connectivity, the asymptotic distribution is either chi-squared or normal depending on if the number of testable links in a DAG model is small. For testing of directionality, the asymptotic distribution is the minimum of d independent chi-squared variables with one-degree of freedom or a generalized Gamma distribution depending on if d is small, where d is number of breakpoints in a hypothesized pathway. Moreover, we develop a computational method to perform the proposed tests, which integrates an alternating direction method of multipliers and difference convex programming. Finally, the power analysis and simulations suggest that the tests achieve the desired objectives of inference. An analysis of an Alzheimer’s disease gene expression dataset illustrates the utility of the proposed method to infer a directed pathway in a gene network.

Directed acyclic graph
high-dimensional inference
gene network
L0-regularization
nonconvex minimization

1 Introduction

Directional pairwise relations have been essential to represent local Markov property [6] between interacting units in a directed acyclic graph (DAG), as in regulatory gene network analysis [25] and in human brain network analysis [17]. In brain network analysis, effective connectivity or directional function connectivity becomes informative to infer the interactions among brain regions of interest from a neuroscience perspective. In this article, we develop constrained likelihood ratio tests to make a formal inference of directional pairwise relations with respect to the strength of connectivity as well as directionality.

In the statistics literature, in spite of its critical importance, significance testing concerning directional pairwise relations in DAG models has received much less attention than discovery or point estimation of the DAG structures [3, 8, 11], including Bayesian network inference [4, 16, 18]. To our knowledge, frequentist inference of directional pairwise relations remains largely unexplored for DAG models, especially so with an unknown DAG partial ordering and a growing dimension of model parameters, although a confidence set for relations to a single target node has recently become available in a different context for causal discovery with interventions [22, 24]. In our situation, several challenges emerge. First, any local approach based on multiple tests of the node connectivity of a graph, followed by enumeration over all candidate nodes, is likely to lose power when a multiplicity adjustment is made for a large number of individual tests to be performed. Second, a series of directional pairwise relations defined by a pathway requires certain acyclicity constraints of directional connections to ensure validity of the local Markov property [31]. Consequently, the corresponding inference is constrained, making it difficult to derive the distribution of a test statistic, especially with a growing dimension of constraints. Note that even the asymptotic distribution of a likelihood ratio test subject to low-dimensional constraints can be non-standard [10]. In other words, new treatments are necessary.

In this article, we propose constrained likelihood ratio tests for the strength of directed connectivity and for a given directed pathway, of a large directed graph. In particular, a constrained likelihood ratio test is subject to nonconvex constraints regularizing nuisance parameters that are not being tested, in addition to an acyclicity constraint to ensure a directed acyclic graph. The parameters of interest are not regularized to alleviate the impact of regularization on inference. For testing the strength of directed connectivity, the asymptotic distribution of the constrained likelihood ratio is a chi-squared or a normal distribution, depending on if the number of testable links in a DAG model is fixed or increases with the sample size, particularly when ∣D0∣1∕2∣E0∪D0∣logpn→0 (Assumption 4), where D0 is the largest testable subindex set (Definition 1) defined by the null hypothesis and D0 ∪ E0 is the DAG index set under its alternative, and p is the number of nodes and ∣ · ∣ denotes a set’s size. For testing a given directed pathway, the asymptotic distribution of the constrained likelihood ratio is the minimum of d independent chi-squared random variables with one-degree of freedom when d is small, but is a generalized Gamma distribution when d is large, where d is the number of breakpoints in a hypothesized pathway when ∣E0∣logpn→0 (Assumption 5), where ∣E0∣ is the number of nonzero links of the truth DAG. In either situation, p may exceed the sample size n. Moreover, our power analysis suggests that the proposed tests achieve the desired objective of inference. To our knowledge, our result is the first of the kind, providing constrained likelihood ratio tests to infer multiple directional pairwise relations in a high-dimensional situation. Finally, we design an algorithm based on difference convex programming and alternating direction method of multipliers [9] to compute constrained likelihood ratios, guaranteeing a resulting graph to be DAG under the null and alternative hypotheses.

The rest of the article is organized as follows. Section 2 briefly introduces the DAG model and its associated acyclicity constraint. Section 3 proposes two constrained likelihood ratio tests for inference of graph linkages and a directed pathway, and provides specific conditions under which asymptotic approximations of the sampling distributions of the test statistics are valid. Section 4 develops computational methods to solve constrained optimization. Section 5 performs simulation studies, followed by an application of the tests to infer some gene pathways possibly related to Alzheimer’s disease with a late-onset Alzheimer’s disease (LOAD) dataset [29].

2 DAG models and acyclicity

To infer pairwise relations imposed by the local Markov dependence [6] for a vector of Gaussian random variables (Y1,…, Yp)T, consider a DAG model induced by structure equations: (1) Yj=∑k:k≠jUkjYk+ej,ej∼N(0,σ2),

where U = (Ukj)p×p is an adjacency matrix, T denotes the transpose, and e1,…,ep are independently identically distributed random errors. Note that (1) is identifiable with respect to model parameters U and σ2 [21].

Model (1), when satisfying acyclicity constraint (3), induces a directed acyclic graph model [31], factorizing the joint probability distribution of (Y1,…,Yp)T, P(y1,…,yp)=∏j=1pP(yj∣paj), into a product of conditional distributions of each variable given its parent, where paj denotes the parent set of Yj and is allowed to be empty when Yj has no parent. This factorization is known as the local Markov property [6], and is related to generalized Markov dependence [19]. Importantly, Ujk ≠ 0 encodes a directed edge from Yj to Yk under (3), whereas Ujk = 0 implies conditional independence of Yj and Yk given the parent of Yi, occurring when Yk is not a parent of Yj.

In (1), given a random sample {(Yi1,⋯,Yip)T}i=1n of size n, the log-likelihood is proportional to (2) l(U,σ2)=−∑j=1p(12σ2∑i=1n(yij−∑k≠jUjkyik)2+n2logσ2),

where U and σ2 are estimated from (2) subject to the requirement that U defines a DAG, or a directed graph without directed cycles. This enables us to identify all directional pairwise relations simultaneously by identifying nonzero off-diagonals of U.

According to [31], U renders a DAG if the following acyclicity constraints are satisfied: (3) ∑j1=jL+1:1≤k≤LI(Ujk−1jk≠0)≤L−1;any(j1,…,jL),L=2,…,p,

which ensures the local Markov property defining directional pairwise relations [6]. It follows from Lemma B1 of [31] that (3) is recast into a constraint on the maximum of p linear programs; k = 1,…,p, (4) (p−1)≥maxqij∑1≤i,j≤pcijkqij,subj to(qij)p×pis a doubly stochastic matrix,

where cijk=I(Uij≠0) if i ≠ j, cijk=0 if i = j = k, and ciik=1 otherwise. After introducing nonnegative dual variables Λ = (λik)p×p for (4), we obtain an equivalent form of (3), (5) λik+I(j≠k)−λjk≥I(Uij≠0);i,j,k=1,…,p,i≠j.

See [31] for technical details.

To treat nonconvex constraints in (5), we replace the corresponding indicator functions in (5) by its computational surrogate Jτ(z)=min(∣z∣τ,1) [26] to circumvent the discontinuity in optimization so that difference convex programming [12] is applicable, where τ is a small tuning parameter controlling the degree of approximation in that Jτ(z) approximates the indicator function as τ → 0+. This yields that (6) λik+I(j≠k)−λjk≥Jτ(Uij);i,j,k=1,…,p,i≠j.

3 Constrained likelihood ratio tests

In the framework of (1), we develop two types of tests concerning directional pairwise relations, encoded by adjacent matrix U = (Uij)p×p in Sections 3.1 and 3.2.

3.1 Test of graph linkages

Before specifying hypotheses, we define an index set F ⊆ {1,…,p}2, where an index (j, k) represents a directed connection from variables j and k, or the corresponding node j is a parent node of k for a DAG under (1). Given the index set F, the null H0 and alternative Ha hypotheses for testing linkages are H0:Uij=0;all(i,j)∈FversusHa:notH0,

with unspecified nuisance parameters Uij; (i, j) ∈ Fc and σ2 &gt; 0, where c denotes complement. Rejection of H0 indicates the strength of directed connectivity specified by F.

The constrained likelihood ratio for H0 versus Ha is Lr=l(U^Ha,σ^Ha2)−l(U^H0,σ^H02), where (7) (U^H0,σ^H02)=arg max(U,σ2,Λ)l(U,σ2),subj to(6),UF=0,∑(i,j)∈FcJτ(∣Uij∣)≤κ;(U^Ha,σ^Ha2)=arg max(U,σ2,Λ)l(U,σ2),subj to(6),∑(i,j)∈FcJτ(∣Uij∣)≤κ,

where κ ≥ 0 is an integer-valued tuning parameter and Λ = (λij)p×p is defined after (6).

To derive the asymptotic distribution of Lr under H0, we make some technical assumptions. Denote by Ω = (I – U)T(I – U)/σ2, and ΩS = (I – US)T(I – US)/σ2, where US is an adjacency matrix with its support index set S, that is, USc = 0. In what follows, let Ω0, U0 be the truth parameters, and E0 represents the true support index of U0.

Assumption 1 (Boundedness of the parameter space) For some constants c1 &gt; 0 and c2 &gt; 0, c1 ≤ λmin(Ω) ≤ λmax(Ω) ≤ c2, where λmin(Ω) and λmax(Ω) denote the smallest and largest eigenvalues of Ω, respectively.

Assumption 2 (Degree of separation). For some positive constant c3, Cmin≡inf{ΩS1∪S2:S1∪S2⊉E0,∣S1∣≤∣E0∖F∣,S2⊆F,S1∪S2forms DAG}−log(1−h2(ΩS1∪S2,Ω0))∣E0∖(S1∪S2)∣≥4c3n−1max(∣E0∣+∣F∣,logp),

where h2(Ω,Ω0)≡1−([det(Ω)det(Ω0)]1∕2det(Ω+Ω02))1∕2.

Assumption 3 (Approximation) For some positive constants c4-c6, h2(Ω,Ω0)≥c4h2(Ωτ,Ω0)−c6pτc5,

where Ωτ = (I – Uτ)T (I – UT)/σ2 and Uτ is the truncated version of U on Fc, defined by (Uτ)ij=UijI(∣Uij∣&gt;τ) for (i, j) ∈ Fc, and (Uτ)ij = Uij for (i, j) ∈ F.

Assumptions 1-3 are regularity conditions to quantify the parameter space and the degree of separation of candidate models.

Before proceeding, we note that not every link in F may contribute one degree of freedom to Lr due to the acyclicity constraint. For example, in a two-node graph, if E0 = {(1, 2)} and F = {(2, 1)}, then E0 ∪ F does not render a DAG, and Lr = 0 is degenerate asymptotically. This motivates us to introduce the notion of “testability” and “nonsingularity”.

Definition 1 (Testability and nonsingularity) A link (j, k) ∈ F is called testable if {(j, k)} ∪ E0 does not contain a directed cycle. An index set F is called nonsingular if D0 ∪ E0 forms a DAG, where D0 consists of all testable links. Note that D0 can be empty when F is trivially nonsingular.

Interestingly, only the links in D0 contribute degrees of freedom to Lr. Next we impose a condition that restricts the size of the index set F under H0.

Assumption 4 (Restriction of the index set F) Assume that F is nonsingular under H0 and ∣D0∣1∕2∣E0∪D0∣logpn→0,asn→∞,

where ∣ · ∣ denotes the size of the set.

Assumption 4 restricts ∣D0∣, ∣E0∣, p, and n in that ∣D0∣1∕2∣E0∪D0∣logpn→0, permitting p exceeding n provided that the number of testable links in D0 and non-zero nuisance links under H0 are not too large.

Theorem 1 (Sampling distribution of Lr for testing linkage under H0) Assume that Assumptions 1-4 are met. Then there exist tuning parameters κ = ∣E0 \ F∣ and τ ≤ Cminc1/4p such that under H0, as n → ∞, (i)P(Lr=0)→1,if∣D0∣=0,

(ii)2Lr→dχ∣D0∣2,if∣D0∣&gt;0isfixed,

(iii)(2∣D0∣)−1∕2(2Lr−∣D0∣)→dN(0,1),if∣D0∣→∞.

The degrees of freedom ∣D0∣, as specified in Assumption 4, is usually unknown, and hence that we propose an estimate D^0 of D0, defined as the largest subset of F such that F∪E^0 forms a DAG. Here D^0 is estimated based on an estimate U^H00 under H0 from (7).

The next corollary says that ∣D^0∣ consistently estimates ∣D0∣.

Corollary 1 (Substitution of D0 by D^0) Under the assumptions of Theorem 1, P(∣D^0∣=∣D0∣)→1, as n – ∞. Then the result of Theorem 1 continues to hold with D0 replaced by D^0.

On the ground of Theorem 1, we proceed our constrained likelihood ratio test with following empirical rule: (1) Fail to reject H0 if ∣D^0∣=0, (2) Use χ∣D0∣2 for Lr if 1≤∣D^0∣&lt;25, (3) Use normal distribution for Lr if ∣D^0∣≥25, as a chi-squared distribution can be well approximated by a normal distribution when its degrees of freedom is sufficiently large.

3.2 Test of a directed pathway

A direct pathway is specified by an index set F in a consecutive manner, where a common segment is shared by two consecutive indices of F = {(i1, i2), (i2, i3),…, (i∣F∣, i∣F∣+1)}, for instance, (i1, i2) and (i2, i3) are shared by i2. Now consider H0:Uij=0;for some(i,j)∈FversusHa:Uij≠0;for all(i,j)∈F

with unspecified nuisance parameters Uij; (i, j) ∈ Fc and σ2 &gt; 0. Rejection of H0 suggests the presence of a directed pathway specified by F.

In this situation, H0 in (8) dramatically differs from that in (7). Now the constrained likelihood ratio statistic for H0 versus Ha is modified to account for a directed pathway at some indices: Lr=l(U^Ha,σ^Ha2)−maxk=1∣F∣l(U^H0(k), σ^H0(k)), where (8) (U^H0(k),σ^H02(k))=arg max(U,σ2,Λ)l(U,σ2),subj to(6),Uik,ik+1=0;(ik,ik+1)∈F,∑(i,j)∈FcJτ(∣Uij∣)≤κ,(U^Ha,σ^Ha2)=arg max(U,σ2,Λ)l(U,σ2),subj to(6),∑(i,j)∈FcJτ(∣Uij∣)≤κ.

Next, Assumptions 5 is a modified version of Assumptions 4.

Assumption 5 (Restriction of the index set E0) ∣E0∣logpn→0,asn→∞.

Theorem 2 (Sampling distribution of Lr for testing a directed pathway under H0) Under Assumptions 1,2,3, and 5, there exist tuning parameters κ = ∣E0 \ F∣ and τ ≥ Cminc1/4p such that under H0, as n → ∞, (i)P(Lr=0)→1ifE0∪FdoesnotfromaDAG;

(ii)2Lr→dmin{X1,…,Xd}ifE0∪FformsaDAGanddisfixed;

(iii)2d2Lr→dΓifE0∪FformsaDAGbutd→∞,

where d=∣{(i,j)∈F:Uij0=0}∣ is the number of breakpoints in the hypothesized pathway, X1,…,Xd are independently identically distributed χ12 variables, and Γ is the generalized Gamma distribution with density 12πxexp(−2x∕π) for x &gt; 0.

The degrees of freedom d is estimated by d^=max(∣{(i,j)∈F:U^ij=0}∣,1), where U^ is the constrained maximum likelihood estimate under Ha in (8) but with F = ∅. The next corollary says that d^ consistently estimates d.

Corollary 2 (Substitution of d by d^) Under the assumptions of Theorem 2, P(d^=d)→1, as n → ∞. Then the result of Theorem 2 continues to hold with d replaced by d^.

In practice, we proceed with our test as follows: (1) Fail to reject H0 if E^0∪D does not form a DAG, (2) Use the distribution of min{X1,…,Xd} for Lr if E^0∪D forms a DAG but d^&lt;25, (3) Use the generalized Gamma distribution for Lr if d^≥25.

3.3 Power analysis

This section analyzes the local power of the CLR tests for (7) and (8) separately.

In (7), consider a local alternative Ha:Uij=Uij0+δijn for (i, j) ∈ F, with Uij0=0 for (i, j) ∈ F, where δn=(δijn)p×p satisfies: δFcn=0, and ∥δn∣F = n−1/2h if ∣D0∣ is fixed and ∥δn∣F = ∣D0∣1/4n−1/2h if ∣D0∣ → ∞, where δn=(δijn)p×p and ∥ · ∥F is the Frobenius norm of a matrix. Now define the power function πn(h) as 1 with Un = U0 and h = 0 if ∣D0∣ = 0, PUn(2Lr≥χ∣D0∣,1−α2) if ∣D0∣ &gt; 0 is fixed, and PUn(2∣D0∣)−1/2(2Lr – ∣D0∣) ≥ z1–α) if ∣D0∣ → ∞, where Un = U0 + δη, with U0 being an adjacency matrix such that Uij0=0 for any (i, j) ∈ D, and χ∣D0∣,1−α2 and z1–α are the (1 – α)th quantiles of the distributions of χ∣D0∣2 and N(0, 1), respectively.

The next theorem confirms that the CLR test for (7) has the power function tending to 1 when the sample size tends to infinity.

Theorem 3 (Local limiting power for graph linkages) For any U0 satisfying Assumptions 1-4 such that Un induces a DAG, we have that limh→∞ lim infn→∞ πn(h) = 1.

In (8), consider a local alternative Ha:Uij=Uij0+δijn for (i, j) ∈ A, where ∣δijn∣=hn for (i, j) ∈ A and A={(i,j)∈F:Uij0=0}. Let the power function π~n(h) be 1 with Un = U0 and h = 0 if E0 ∪ F is cyclic, PUn (2Lr ≥ Γd,1–α) = 1 if E0 ∪ F is acyclic and d is fixed, and PUn (2d2Lr ≥ Γ1–α) = 1 if E0 ∪ F is acyclic and d → ∞, where Γd,1–α and Γ1–α are the (1 – α)th quantiles of the minimal of the chi-squares and Γ distributions in Theorem 2.

Theorem 4 gives a parallel result for (8).

Theorem 4 (Local limiting power for a directed pathway) For any U0 satisfying Assumptions 1,2,3,5, such that Un induces a DAG, we have that limh→∞ lim infn→∞π~n(h)=1.

4 Optimization and computation

This section develops a strategy to compute the CLR tests for (7) and (8). To treat the nonconvex minimization in (7) or (8), we develop a difference convex programming approach to iteratively relax the nonconvex constraints through a sequence of convex set approximations. Then each convex subproblem is solved by an alternating direction method of multipliers [1]. The process iterates until a termination criterion is met.

Specifically, we decompose Jτ into a difference of two convex functions Jτ(z) = ∣z∣/τ – max(∣z∣/τ – 1, 0) ≡ f1(z) – f2(z). On this ground, a convex approximation at (m + 1)-th iteration is constructed by replacing f2(z) with its affine majorization f2(z[m]) + ∇f2(z[m])T(z – z[m]) at the solution z[m] at m-th iteration, where ∇f2(z[m])=Sign(z[m])τI(∣z[m]∣&gt;τ) is a subgradient of f2 at z[m]. This leads to a convex subproblem at the (m + 1)-th iteration, (9) max(U,σ2,Λ)l(U,σ2)=−∑j=1p(12σ2∑i=1n(yij−∑k≠jUjkyik)2+n2logσ2)subj to∑(i,j)∉E1∣Uij∣I(∣U^ij[m]∣≤τ)≤τ(κ−∑(i,j)∉E1I(∣U^ij[m]∣&gt;τ)),UE2=0,τλjk+τI(i≠k)−τλik≥∣Uij∣I(U^ij[m]∣≤τ)+τI(∣U^ij[m]∣&gt;τ),i,j,k=1,…,p,i≠j,

where E1 = E2 = F for H0 in (7), E1 = F and E2 = ∅ for Ha in (7), E1 = F and E2 = {(ik, ik+1)} for H0 in (8), and E1 = F, E2 = ∅ for Ha in (8), and U^[m] is the solution of (9) at its previous m-th iteration.

To solve (9), we employ an alternating direction method of multipliers [1]. Note that (9) can proceed through profiling by maximizing with respect to σ2 and (U, Λ) separately. Plugging an expression σ^2=(np)−1∑j=1p∑i=1n(yij−∑k≠jyikUjk)2 into (9), it reduces to minimization of RSS(U)≡12∑j=1p∑i=1n(yij−∑k≠jyikUjk)2 in (U, Λ) subject to the constraints in (9). Now consider an equivalent form of (9) by introducing a nonnegative multiplier μ: (10) min(U,Λ)RSS(U)+μ∑(i,j)∉E1∣Uij∣I(∣U^ij[m]∣≤τ),subj toUE2=0,UijI(∣U^ij[m]∣≤τ)≤τλjk+τI(i≠k)−τλik−τI(∣U^ij[m]∣&gt;τ),UijI(∣U^ij[m]∣≤τ)≥−τλjk−τI(i≠k)+τλik+τI(∣U^ij[m]∣&gt;τ),i,j,k=1,…,p,i≠j.

To solve (10), we separate its differentiable from non-differentiable parts by introducing a decoupling matrix V for U, in addition to slack variables ξ={ξijk1,ξijk2}p×p×p to convert inequality to equality constraints. This yields min(U,V,Λ,ξ)RSS(U)+μ∑(i,j)∉E1∣Vij∣I(∣U^ij[m]∣≤τ),subj toUE2=0,U−V=0,VijI(∣U^ij[m]∣≤τ)+τI(∣U^ij[m]∣&gt;τ)+ξijk1−τλjk−τI(i≠k)+τλik=0,VijI(∣U^ij[m]∣≤τ)−τI(∣U^ij[m]∣&gt;τ)−ξijk2+τλjl+τI(i≠k)−τλik=0,ξijk1,ξijk2≥0,i,j,k=1,…,p,i≠j.

Following [1], an introduction of scaled dual variables α={αijk1,αijk2}p×p×p and W = {wij}p×p leads to an augmented Lagrangian, Lρ(V,U,Λ,ξ,α,W)=RSS(U)+μ∑(i,j)∉E1∣Vij∣I(∣U^ij[m]∣≤τ)+ρ2‖U−V+W‖F2+ρ2∑k∑i≠j(VijI(∣U^ij[m]∣≤τ)+τI(∣U^ij[m]∣&gt;τ)+ξijk1−τλjk−τI(i≠k)+τλik+αijk1)2+ρ2∑k∑i≠j(VijI(∣U^ij[m]∣≤τ)−τI(∣U^ij[m]∣&gt;τ)−ξijk2+τλjk+τI(i≠k)−τλik+αijk2)2,

where the minimization is solved iteratively. At (s + 1)-th iteration of ADMM, we update following steps: (11) V[s+1]=arg minVLρ(V,U[s],Λ[s],ξ[s],α[s],W[s]),U[s+1]=arg minULρ(V[s+1],U,Λ[s],ξ[s],α[s],W[s]),(Λ[s+1],ξ[s+1])=arg minΛLρ(V[s+1],U[s+1],Λ,ξ,α[s],W[s]),W[s+1]=W[s]+U[s]−V[s],

where αijk1[s+1]=Vij[s]I(∣Uij[m]∣≤τ)+τI(∣Uij[m]∣&gt;τ)+ξijk1[s]−τλjk[s]−τI(i≠k)+τλik[s]+αijk1[s], αijk2[s+1]=Vij[s]I(∣Uij[m]∣≤τ)−τI(∣Uij[m]∣&gt;τ)−ξijk2[s]+τλjk[s]+τI(i≠k)−τλik[s]+αijk2[s], and an updating formula is given in the Appendix to facilitate computation.

The strategy for computing U^H0 and U^Ha is summarized in Algorithm 1.

Algorithm 1.

Step 1: (Initialization) Fix E1 and E2 in (9). Initiate an estimate (U[0], Λ[0]) satisfying (6). Set E[0]={(i,j):∣Uij[0]∣&gt;τ}.

Step 2: (ADMM) At m-th iteration, compute (U[m], Λ[m]) by ADMM through (11).

Step 3: (Check for acyclicity) Let E[m]={(i,j):∣Uij[m]∣&gt;τ}. If E[m] constitutes a cycle in the graph, sort ∣Uij[m]∣ decreasingly; (i, j) ∈ E[m]. For each (i, j) ∈ E[m] in order, if E[m] \ {(i, j)} induces a DAG, update E[m] by E[m] \ {(i, j)}. Otherwise, keep E[m] intact. Here a cycle detection algorithm such as depth-first search is applied [5].

Step 4: (Termination) Repeat Steps 2-3 until a termination criterion is met, that is, RSS(U[m−1]) – RSS(U[m]) ≤ ε. The final solution U[m*] is the corresponding estimate under H0 or Ha, where m* is the smallest index at termination.

Importantly, Step 3 in Algorithm 1 ensures that U[m*] satisfies the acyclicity condition by removing the weakest link in an existing cycle, hence that it yields a DAG.

Concerning Algorithm 1, we note that its complexity over five blocks in one iteration is roughly of order p3 + np2. In terms of convergence speed, based on our limited numerical experience, the ADMM component converges with a modest accuracy within a few thousand iterations, while the difference convex programming component usually terminates within ten steps.

Theorem 5 (Convergence of Algorithm 1) For ρ &gt; 0 and sufficiently small τ &gt; 0, Algorithm 1 yields a local minimizer U^, which satisfies the optimality condition for some multipliers μ ≥ 0 and {νijk ≥ 0}i,j,k=1,…p;i≠j, ∂ijl(U)+μτ∂ijJτ(∣Uij∣)+∑1≤k≤pνijkτ∂ijJτ(∣Uij∣)=0;i,j=1,…,p,i≠j

where ∂ij denotes the subgradient [23].

As indicated by Theorem 5, Algorithm 1 yields a local minimizer. However, as showed in Table 3, it can yield a global minimizer or a good local minimizer. In fact, the probability that the solution of Algorithm 1 agrees with the the oracle estimator is high, which is a global minimizer asymptotically, c.f. Lemmas 1-2 in the Appendix. This aspect has been recognized [27] for a difference convex algorithm. Note, however, that a global minimizer can be attained if Breiman and Culter’s outer approximation method (a version of difference convex algorithm) can attain a global minimizer at the expense of slow convergence [2].

5 Numerical examples

This section examines operating characteristics of the proposed tests and compares against oracle tests in regard to the size and power in simulated and real data examples. Here the oracle tests for (7) and (8) are LrOR=l(U^E0∪F,σ^E0∪F)−l(U^E0∖F,σ^E0∖F) and LrOR=l(U^E0∪F,σ^E0∪F)−maxk=1∣F∣l(U^E0∪F∖{(ik,ipathwayk+1)}, σ^E0∪F∖{(ik,ik+1)}, based on the constrained maximum likelihood estimates (U^E0∖F,σ^E0∖F) and (U^E0∪F∖{(ik,ik+1)}, σ^E0∪F∖{(ik,ik+1)}) assuming that the true graph structure would be known in advance.

In simulations, we consider three different types of DAGs, known as random, hub, and chain graphs, as displayed in Figure 1, and report the empirical size and power of a test. For the size of a test, we compute the percentage of times rejecting H0 out of 1000 simulations when H0 is true. For the power of a test, we examine four alternatives Ha hypotheses. The empirical power of a test is the percentage of times rejecting H0 out of 100 simulations when Ha is true.

For the proposed method, tuning parameters (μ, τ) are estimated by maximizing the five-fold predictive likelihood l^(μ,τ), defined as 15∑l=15∑j=1p(12σ^−l2(μ,τ)∑yi∈Dl(yij−∑k≠jU^jk−l(μ,τ)yik)2+∣Dl∣2logσ^−l2(μ,τ)),

where U^−l(μ,τ) and σ^−l2(μ,τ) are the estimates under Ha based on a random partition of the original data with roughly equal parts, Dl; l = 1,…,5. Then the optimal tuning parameters (μ^,τ^)=arg minl^(μ,τ) are used to compute the final estimator based on original data D. In our simulations, μ is selected from 100.5l and τ is selected from 0.05 + 0.1l; l = 0,…,4.

Numerical results are produced using an R package “clrdag”, implementing the proposed constrained likelihood ratio tests based on Algorithm 1.

5.1 Simulated examples

Example 1. (Test for linkage) In (1), consider a random DAG of p nodes in the absence of no graph structures, defined by adjacency matrix U, with σ = 1. The graph is displayed in Figure 1. For the value of U, upper off-diagonals are set as a random sample from {0, 1} using the Bernoulli distribution with success probability 2/p, and the rest of entries of U are set to be zero. For the linkage test in (7), with (i0, j0) = (2, p), we examine two different H0 hypotheses: (i) H0 : Ui0j0 = 0; (ii) H0 : Uij = 0; i = 2,…,16, j = p – 1, p. Whereas the first concerns one single entry of U, the second focuses on the last two columns. Here ∣D0∣ = ∣F∣. Moreover, for the power analysis, we look at four alternatives Ha : Ui0j0 = 0.1l; l = 1, 2, 3; Uij = 0 otherwise.

Example 2. (Test for linkage) This example considers consider a hub graph DAG of p nodes in a set-up as in Example 1, see Figure 1 for a display of a network. To define adjacency matrix U, we set U1j = 1; j = 2,…,p, and set remaining entries to be zero. The other set-up remains the same as in Example 1.

As a result, the neighborhood of the first node is dense, while the overall graph remains sparse.

Example 3. (Test for a pathway) This examples focuses on testing a pathway in a chain DAG of p nodes in (1) with σ = 1, see Figure 1 for a display of a graph. First, we construct a directed pathway from nodes 1 to 50 with other node variables being independent. Towards this end, let Ui(i+1) = 1; i = 1,…,49, and Uij = 0 otherwise. Second, randomly sample ν0 = 5 edges from {(i, i + 1) : i = 1,…,49} without replacement. Now UA = 0, where A is the set of sampled edges.

For the pathway test in (8), let F = {(i, i + 1) : i = 1,…,49} and consider: H0 : Ui(i+1) = 0 for some (i, i + 1) ∈ F versus Ha : Ui(i+1) ≠ 0 for all (i, i + 1) ∈ F. For the power calculations, we examine four alternatives Ha : Ui(i+1) = 1 for (i, i + 1) ∈ F \ S and Ui(i+1) = 0.1l; (i, i + 1) ∈ S; l = 1, 2, 3, and Uij = 0 otherwise.

Example 4. (Oracle rate of CLR) This example illustrates that Algorithm 1 can yield a global or a good local optimum for (7) with a reasonably good chance. In particular, we compare the constrained likelihood ratio Lr in (7) against the corresponding oracle constrained likelihood ratio LrOR to see if our test can reconstruct the oracle test. Note that LrOR=l(U^E0∪F,σ^E0∪F)−l(U^E0∖F,σ^E0∖F), where (U^E0∪F,σ^E0∪F) and (U^E0∖F,σ^E0∖F) are maximizers of the constrained likelihood in (7) asymptotically. In the setting of Examples 1-2, we generate random and hub graphs with p nodes and consider the chi-squared linkage test over the hypothesized index set F = {(2, p)}, where H0 : U2p = 0. Now we define the oracle rate of CLR as the chance that Lr and LrOR are sufficiently close (tol ≤ 10–4).

Power and empirical size of the CLR tests.

As indicated in Tables 1 and 2, the tests perform well for testing linkages of a DAG in Examples 1-2 as well as a directed pathway of a DAG in Example 3. Specifically, the empirical sizes are close to the nominal level 0.05 in all scenarios. Moreover, the power functions of the tests exhibit desirable properties in that it increases as the sample size n increases when p is held fixed, and/or increases to 1 as the level of difficulty of a test decreases, determined by the alternative hypothesis Ha. This is consistent with the result of Theorems 1-4. Overall, the proposed tests perform well when comparing against the corresponding oracle tests.

Asymptotic approximations for testing linkages (7) and a directed pathway (8).

For (7), as suggested by Figures 2-3, the chi-squared and normal approximations appear adequate for ∣D0∣ = 1 and ∣D0∣ = 30 in Examples 1-2, respectively. For (8), the approximation by minimum of d chi-squared variables seems adequate for d = 5 in Example 3, as suggested by Figure 4.

Globality of Lr in (7).

As suggested by Table 3 in Example 4, the proposed CLR test has good agreement rates with the oracle test, exceeding 95%. Roughly, the constrained likelihood estimator based on Algorithm 1 are likely to attain an approximate global optimum of nonconvex minimization in (7). This aspect of a difference convex algorithm agrees with findings of [27] for different nonconvex problems.

5.2 Gene networks for Alzheimer’s disease

This section applies the proposed tests to analyze the late-onset Alzheimer’s disease (AD) dataset [29], containing expression levels of 8560 genes in the brain tissue for 176 AD patients and 187 healthy controls (HCs). Our primary goal is to infer gene pathways related to AD, then contrast the corresponding pathways between the AD and HC groups to highlight some gene-gene interactions possibly differentiating these two groups.

From the KEGG database [13], we extract the AD reference pathway (map05010), including 99 genes in the AD data. Then we conduct a differential gene expression analysis on these genes with a two-sample t-test, detecting p = 21 genes differentially expressed (at the significance level 0.01) between the AD and HC groups. After some data preprocessing, the gene expression levels of the 21 genes for 154 AD and 182 HC individuals are approximately normally distributed.

The existing literature suggests that the Bcl-2-associated death promoter (BAD) gene is involved in neurodegeneration [7]. Thus, for this dataset we focus attention on a regulatory subnetwork associated with gene BAD in the AD reference pathway map, particularly three genetic pathways/subnetworks, (P1) CALM3 → PPP3CA → BAD, (P2) CALM3 → PPP3CB → BAD, and (P3) CALM3 → PPP3R1 → BAD. We consider testing of three hypotheses for simultaneous presence of the three pathways specified by Pl; l = 1, 2, 3: H0 : Uij = 0 for some (i, j) ∈ Pl versus Ha : Uij ≠ 0 for all (i, j) ∈ Pl.

The p-values and significant pathways under the significance level α = 0.01 after the Holm-Bonferroni adjustment are displayed in Figure 5. As a comparison, the reconstructed networks, using constrained maximum likelihood in (7) with F = ∅, are displayed in Figure 6. Interestingly, both pathways CALM3 → PPP3CA → BAD and CALM3 → PPP3CB → BAD are present in the reconstructed network for the AD group, but the proposed test suggests that only one pathway CALM3 → PPP3CA → BAD is significant (p-value = 0.001735). Besides this difference, the results of the testing and reconstruction mostly agree: the pathway CALM3 → PPP3CB → BAD is identified for the HC group (p-value = 2.001 × 10−8), whereas the last pathway CALM3 → PPP3R1 → BAD is not present for both groups. Our result suggests that the regulatory subnetwork associated with BAD for AD patients differs from that for healthy individuals. In summary, our analysis suggest that the two pathways/subnetworks CALM3 → PPP3CA → BAD and CALM3 → PPP3CB → BAD may differentiate these two groups, though more follow-up studies are needed.

For model checking, the residual plots and Q-Q plots in Figure 7 suggest no strong evidence against the normality assumption and the equal-variance assumption for the error terms in the structure equations model (1).

Research supported in part by NSF grants DMS-1712564, DMS-1721216, NIH grants 1R01GM081535-01, 1R01GM126002, HL65462 and R01HL105397. The authors would like to thank the editor, the associate editor and two anonymous referees for helpful comments and suggestions.

A Appendix

A.1 Analytical updating formulas for (11)

V direction: Elementwise minimization yields that Vij[s+1]={Softμ∕ρ(2p+1)(γij[s])if(i,j)∉E1,∣Uij[m]∣≤τ,γij[s]if(i,j)∈E1,∣Uij[m]∣≤τ,Uij[s]+Wij[s]if∣Uij[m]∣&gt;τ,}

where Softr(·) denotes r-soft-thresholding and γij[s]=(2p+1)−1[Uij[s]+Wij[s]−∑k(ξijk1[s]−ξijk2[s]+αijk1[s]+αijk2[s])].

U direction: The minimizer satisfies U⋅j[s+1]=(USj,0)T; j = 1,…,p with (YSjTYSj+ρI∣Sj∣×∣Sj∣)USj=YSjTYj+ρ(VSj[s+1]−WSj[s]),

where Sj = {(i, j) : i ≠ j and (i, j) ∉ E2}.

(Λ, ξ) direction: The updating formula of Λ is Λ[s+1]=Mp×pLp×p[s+1],

where Mp×p=1τ(100⋯012p1p⋯1p11p2p⋯1p⋮⋮⋱⋮11p⋯1p2p),

L1j[s+1]=1,Lik[s+1]=12[τ+12∑j(2τI(∣U^ij[m]∣&gt;τ)+ξijk1[s+1]+ξijk2[s+1]+αijk1[s]−αijk2[s])]−12∑j[(2τI(∣U^ji[m]∣&gt;τ)+ξjik1[s+1]+ξjik2[s+1]+αjik1[s]−αjik2[s])];i≠k,Lkk[s+1]=12[−(p−1)τ+12∑j(2τI(∣U^kj[m]∣&gt;τ)+ξkjk1[s+1]+ξijk2[s+1]+αkjk1[s]−αkjk2[s])]−12∑j[(2τI(∣U^jk[m]∣&gt;τ)+ξjkk1[s+1]+ξjkk2[s+1]+αjkk1[s]−αjkk2[s])].

The updating formula of ξ is ξijk[s+1]=max(0,τλjk[s]+τI(i≠k)−τλik[s]−Vij[s+1]I(∣U^ij[m]∣≤τ)−τI(∣U^ij[m]∣&gt;τ)−αijk1[s]),ξijk2[s+1]=max(0,τλjk[s]+τI(i≠k)−τλik[s]+Vij[s+1]I(∣U^ij[m]∣≤τ)−τI(∣U^ij[m]∣&gt;τ)+αijk2[s]);i,j,k=1,…,p.

A.2 Technical proofs

For simplicity, we write l(Ω) as l(U, σ) in what follows.

Lemma 1 (Test for linkages) Assume Assumptions 1-3 are met. If κ = ∣E0 \ D∣ and τ &lt; Cminc1/4p, then under H0, as n → ∞, max(P(Ω^H0≠Ω^E0),P(Ω^Ha≠Ω^E0∪D0))≤exp(−c2c4nCmin∕2+2log((p2−p+1)+∣D∣log2+3)→0.

Proof of Lemma 1: Without of loss of generality, we only prove the bound for P(Ω^Ha≠Ω^E0∪D0) as the proof for other cases is similar.

Let S1τ={(i,j)∈Fc:∣Uij∣≥τ}. When κ=∣E0∖F∣=∣E0∣, ∑(i,j)∈FcJτ(∣Uij∣)≤∣E0∣, so ∣F1τ∣≤∣E0∣. If E^Haτ∖F=E0, then ∑(i,j)∈Fc∣U^ijHa∣I(∣U^ijHa∣&lt;τ)=0, which implies U^Ha=U^E0∪D0. It therefore suffices to prove the case when E^Haτ∖F≠E0.

Recall that Ω = ΩS = (I – US)T(I – US)/σ2 for any S = S1 ∪ S2, where S1 ⊂ Fc and S2 ⊂ F. Partition S1 into two parts, S1 = (S1 ∩ E0) ∪ (S1 \ E0). Let k = (k1, k2, k3) and Bk = (Ωτ : S1 ≠ E0, ∣S1 ∩ E0∣ = k1, ∣S1 \ E0∣ = k2, S2 ⊂ D, ∣F2∣ = k3, c4(∣E0∣ – k1)Cmin – c6pτc5 ≤ h2(Ωτ, Ω0)}; k1 = 0,…, ∣E0∣ – 1, k2 = 1,…, ∣E0∣ – k1, k3 = 0,…, ∣F∣. Thus, Bk consists of elements with (∣E0∣k1)(p(p−1)−∣E0∣k2)(∣F∣k3) different supports. Note that {Ωτ : S1 ≠ E0, ∣S1∣ ≤ ∣E0∣, c4(∣E0∣−k1)Cmin−c6pτc5≤h2(Ωτ,Ω0)}⊂⋃k1=0∣E0∣⋃k2=1∣E0∣−k1⋃k3=0∣F∣Bk. Then P(Ω^Ha≠Ω^E0),≤P∗(supΩS1∪S2:S1≠E0,∣S1∣≤∣E0∣l(ΩS1∪S2)−l(Ω^E0)≥0)≤P∗(supΩS1∪S2:S1≠E0,∣S1∣≤∣E0∣l(ΩS1∪S2)−l(Ω0)≥0)≤∑k1=0∣E0∣−1∑k2=1∣E0∣−k1∑k3=0∣F∣P∗(supΩS1∪S2∈Bkl(ΩS1∪S2)−l(Ω0)≥0)≡I,

where P* denotes the outer probability.

We apply Theorem 1 of [30] to bound I. Towards this end, we verify Condition (3.1) there for the bracketing entropy over Bk. Let Fk={p1∕2(Ω,⋅):Ω∈Bk}, where p(Ω, ·) is the normal density function with mean zero and precision matrix Ω. Note that ∫supΩ¯:‖Ω¯−Ω‖&lt;δ∣p1∕2(Ω¯,x)−p1∕2(Ω,x)∣2dx≤∫supΩ¯:‖Ω¯−Ω‖&lt;δ(1−exp(−12xT(Ω¯−Ω)x))2p(Ω,x)dx≤∫supΩ¯:‖Ω¯−Ω‖&lt;δc″‖Ω¯−Ω‖2p(Ω,x)dx≤c″δ2.

By Lemma 2.1 of [20], the bracketing L2-entropy is bounded by the L2-metric entropy H(u,Fk) of Fk. By [14], for u ≥ ε2, H(u,Fk)≤c0∣S∣log(ep(p−1)∣S∣)+c0∣S∣logmin(c21∕2,1)u≤c0∣S∣logplog(1∕u),

where (ab)≤ab has been applied. Let ε=min(1,2c0c4−1log(2∕c3)(∣E0∣+∣F∣)∕n). Then supk∫ε2∕282εH1∕2(s∕c3,Fk)ds≤ε2(∣E0∣+∣F∣)log(2∕c3)≤c4n1∕2ε2. By Assumption 2, Cmin ≥ ε2.

An application of Theorem 1 of [30] yields that for some constant c2 &gt; 0, I≤4∑k1=0∣E0∣−1∑k2=1∣E0∣−k1∑k3=0∣F∣(∣E0∣k1)(p(p−1)−∣E0∣k2)(∣F∣k3)×exp(−c2n(c4(∣E0∣−k)Cmin−c6pτc5))≤∑k=1∣E0∣4exp(−c2n(kc4Cmin−c6pτc5)+k(log∣E0∣+log(p(p−1)−∣E0∣+1))+∣F∣log2)≤∑k=1∣E0∣4exp(−kc2c4nCmin∕2+k(log∣E0∣+log(p(p−1)−∣E0∣+1))+∣F∣log2)≤exp(−c2c4nCmin∕2+2log((p2−p+1)+∣F∣log2+3).

Hence, P(Ω^Ha≠Ω^E0∪D0)≤exp(−c2c4nCmin∕2+2log((p2−p+1)+∣F∣log2+3).

Similarly, we bound P(Ω^H0≠Ω^E0). This completes the proof.

Proof of Theorem 1: By Lemma 1, under H0 and Assumptions 1-3, P(U^H0=U^E0,U^Ha=U^D0∪E0)→1, implying that P(D^0=D0)→1. When D° = ∅, then P(Lr = 0) → 1, establishing (i).

Now consider the case of D0 ≠ ∅. For (ii) and (iii), it suffices to focus on event {U^H0=U^E0,U^Ha=U^D0∪E0}, where U^S denotes the maximizer of the likelihood l(U, σ) with the support index S. Let U·j denote the j-th column of matrix U. Then U^⋅jH0=(Ypaj0TYpaj0)−1Ypaj0TYj and U^⋅jHa=(Ypaj1TYpaj1)−1Ypaj1TYj, where paj0 and paj1 denote the parent variables of Yj in E0 and E0 ∪ D0, respectively. Note that log∑j=1p‖Yj−YU⋅j‖2∑j=1p‖Yj−YU⋅j0‖2=log(1−∑j=1p{2ejTY(U⋅j−U⋅j0)−‖Y(U⋅j−U⋅j0)‖2}∑j=1p‖ej‖2)=−∑k=1∞1k(∑j=1p{2ejTY(U⋅j−U⋅j0)−‖Y(U⋅j−U⋅j0)‖2}∑j=1p‖ej‖2)k,

provided that {∑j=1p(2ejTY(U⋅j−U⋅j0)−‖Y(U⋅j−U⋅j0)‖2)&lt;∑j=1p‖ej‖2}. On the event ⋂j=1p{ejTPpaj1ej&lt;‖ej‖2}, we have that 2Lr=nplog∑j=1p‖Yj−YU^⋅jH0‖2∑j=1p‖Yj−YU⋅j0‖2−nplog∑j=1p‖Yj−YU^⋅jHa‖2∑j=1p‖Yj−YU⋅j0‖2=1σ2∑j=1pejT{Ppaj1−Ppaj0}ej+(np∑j=1p‖ej‖2−1σ2)∑j=1pejT{Ppaj1−Ppaj0}ej−np∑k=2∞1k[(∑j=1pejTPpaj1ej∑j=1p‖ej‖2)k−(∑j=1pejTPpaj0ej∑j=1p‖ej‖2)k]≡T1+T2+T3,

where PS=YS(YSTYS)−1YST is the projection over subset S of predictors.

Let Yj1 ⪯ ⋯ ⪯ Yjp be a partial order of DAG G0. Taking the iterated expectation, we simplify the characteristic function ϕ(t) of T1 for any real t: ϕ(t)=E{E[∣exp(itσ−2∑j=1pejT{Ppaj1−Ppaj0}ej)∣Y{1,…,p}∖{jp}]}=(1−2it)−∣pajp1∣−∣pajp0∣2E(exp(itσ−2∑j=1p−1ejT{Ppaj1−Ppaj0}ej))=(1−2it)−∣D0∣2.

Thus, T1 follows χ∣D0∣2. Moreover, it follows immediately that ejTPpaj1ej∕σ2 are χ∣paj1∣2 distributed.

For T2, we have np(np∑j=1p‖ej‖2−1σ2)→dN(0,2σ−4). Then it follows from Assumption 4 that T2∕∣D0∣→p0.

To bound T3, note that, there exists some constant C′ &gt; 0 such that as n → ∞, ∣T3∣≤C′T1∑k=1∞(∑j=1pejTPpaj1ej∑j=1∞‖ej‖2)k≤C′T1∑k=1∞(max1≤j≤pejTPpaj1ej‖ej‖2)k=C′T1(max1≤j≤pejTPpaj1ej‖ej‖2)(1−max1≤j≤pejTPpaj1ej‖ej‖2)−1,

on an event ⋂j=1p{ejTPpaj1ej&lt;‖ej‖2}, where the inequality a1+⋯+apb1+⋯+bp≤max1≤j≤pajbj is used; 0 ≤ aj ≤ bj; j = 1,…,p. By Lemma 1 of [15], for any s &gt; 0, P(χr2&gt;r+2rs+2s)≤e−s and P(χr2&lt;r−2rs)≤e−s. Set s = nt2/16σ4 &lt; n for any 0 &lt; t &lt; 4σ2. By Assumption 4, P(max1≤j≤p∣‖ej‖2n−σ2∣&gt;t)≤P(∃j:∣‖ej‖2−nσ2∣&gt;4σ2ns)≤exp(2(logp−s))→0,

as n → ∞. Hence, ‖ej‖2∕n→pσ2. An application of Lemma 1 of [15] with s = (∣E0∣ + ∣D0∣) log p leads to P(max1≤j≤pejTPpaj1ej&gt;5σ2s)≤P(∃j:ejTPpaj1ej&gt;σ2(∣paj1∣+2∣paj1∣s+2s))≤exp(logp−s).

By Assumption 4, max1≤j≤pejTPpaj1ej=Op((∣E0∣+∣F∣)logp). It follows that ∣T3∣≤C′T1max1≤j≤p(ejTPpaj1ejn)(n‖ej‖2)=Op(∣D0∣(∣D0∣+∣E0∣)logpn).

Hence, T3∕∣D0∣→p0.

Finally, note that P(∃j:ejTPpaj1ej&gt;‖ej‖2)→0. Therefore, when ∣D0∣ is fixed, Lr→dχ∣D0∣2; when ∣D0∣ → ∞, (2∣D0∣)−1∕2(Lr−∣D0∣)→dN(0,1). This completes the proof.

Lemma 2 (Test of pathway) Assume Assumptions 1-3 are met. Let A={(ik,ik+1)∈F:Uik,ik+10=0} and F−k = F \ {(ik,ik+1)}. If κ = ∣E0 \ F∣ and τ = Cminc1/4p, then under H0, P(maxk:(ik,ik+1)∉Al(Ω^(k))−l(Ω0)≥0)→0,max(P(∃k:E^H0(k)≠E0∪F−k;(ik,ik+1)∈A),P(E^Ha≠E0∪F))→0.

Proof of Lemma 2: The basic idea of the proof is similar to that of Lemma 1.

Recall that ΩS = (I – US)T (I – US)/σ2 for any S that forms a DAG. Now, partition S into four parts, S = E1 ∪ E2 ∪ E3 ∪ E4, where E1 = S1 ∩ E0, E2 = S1 \ F, E3 = S2 ∩ E0, and E4 = S2 \ F, where S1 and S2 are defined the same as in Assumption 2. Let κ1 = ∣E0 \ F∣ and κ2 = ∣E0 ∩ F∣. Let k = (k1, k2, k3, k4) and Bk = {Ωτ : S1 ∪ S2 ⊅ E0, ∣S1∣ ≤ ∣E0 \ F∣, ∣Ei∣ = ki; i = 1, 2, 3, 4, c4(∣E0∣ – k1 – k3)Cmin – c6pτc5 ≤ h2(Ωτ, Ω0)}, where 0 ≤ k1 ≤ κ1, 0 ≤ k2 ≤ κ1 – k1, 0 ≤ k3 ≤ κ2, 0 &lt; k4 ≤ ∣F∣ – κ2, and k1 + k3 &lt; κ1 + κ2 = ∣E0∣. Thus, Bk contains elements with (κ1k1)(p(p−1)−∣F∣−κ1k2)(κ2k3)(∣F∣−κ2k4) different supports. Note that {Ωτ:S1∪S2⊅E0,∣S1∣≤∣E0∖F∣,c4(∣E0∣−k1−k3)Cmin−c6pτc5≤h2(Ωτ,Ω0)}⊂⋃kBk. Then P(maxk:(ik,ik+1)∉Al(Ω^(k))−l(Ω0)≥0)≤∑kP∗(supΩS1∪S2∈Bkl(ΩS1∪S2)−l(Ω0)≥0)≡I′,P(E^Ha≠E0∪F)≤I′,P(∃k:E^H0(k)≠E0∪F−k;(ik,ik+1)∈A)≤I′.

To apply Theorem 1 of [30] to bound I′, we verify Condition (3.1) of [30] using the similar argument of Lemma 1. Let ε=min(1,2c0c4−1log(2∕c3)(∣E0∣+∣F∣)∕n). Then supk∫ε2∕282εH1∕2(s∕c3,Fk)ds≤ε2(∣E0∣+∣D∣)log(2∕c3)≤c4n1∕2ε2.

By Assumption 5, Cmin ≥ ε2.

By Theorem 1 of [30], we have, for some constant c2 &gt; 0, I′≤∑k(κ1k1)(p(p−1)−∣F∣−κ1k2)(κ2k3)(∣F∣−κ2k4)×4exp(−c2n(c4(∣E0∣−k1−k3)Cmin−c6pτc5))≤∑k=1∣E0∣2∣F∣+2exp(−k(c2c4nCmin∕2−log∣E0∣−2log(p(p−1)−∣F∣)))≤5exp(−c2c4nCmin∕2+log∣E0∣+2log(p(p−1)−∣F∣)+∣F∣log2)→0.

Then desired result follows from the bound of I′. This completes the proof.

Proof of Theorem 2: It follows from Lemma 2 that P(E^Ha∖F=E0∖F)→1 and P(E^H0(k)∖F=E0∖F)→1 for k such that Uik,ik+10=0. Consider the event {E^Ha∖F=E0∖F}.

For (i), suppose E0 ∪ F does not form a DAG. Then there exists 1 ≤ k ≤ ∣F∣ such that (U^Ha)ik,ik+1=0. Thus, l(Ω^Ha)=l(Ω^H0(k)), establishing (i).

For (ii) and (iii), suppose E0 ∪ F forms a DAG. Then for (ik, ik+1) ∈ E0 ∩ F and (ik′,ik′+1) ∈ F \ E0, we have P(l(Ω^H0(k))&lt;l(Ω^H0(k′)))→1. It suffices to consider edges A={(ik,ik+1)∈F:Uik,ik+10=0}. Recall that paj1 denotes the parent variables of Yj in E^Ha. Similarly as in the proof of Theorem 1, for any (ik, ik+1) ∈ A, 2(l(Ω^Ha)−l(Ω^H0(k)))=1σ2eik+1T(Ppaik+11−Ppaik+11∖{ik})eik+1+(np∑j=1p‖ej‖2−1σ2)eik+1T(Ppaik+11−Ppaik+11∖{ik})eik+1+np∑k=2∞1k[(eik+1TPpaik+11eik+1∑j=1p‖ej‖2)k−(eik+1TPpaik+11∖{ik}eik+1∑j=1p‖ej‖2)k]≡T1(k)+T2(k)+T3(k).

Let ψ be the characteristic function of the joint distribution of T1(k); (ik, ik+1) ∈ A. Taking the iterated expectation, as in the proof of Theorem 1, we factorize ψ as follows: ψ(t)=∏(ik,ik+1)∈A(1−2itk)−1∕2. It follows immediately that T1(k); (ik, ik+1) ∈ A are asymptotically independently χ12 distributed.

To bound maxk ∣T2(k)∣, note that np(np∑j=1p‖ej‖2−1σ2)→dN(0,2σ−4). Similarly as in the proof of Theorem 1, we have maxk T1(k) = Op(log p). Hence, maxkd2∣T2(k)∣→p0.

It remains to bound ∣T3(k)∣. By Lemma 1 of [15], ‖ej‖2∕n→pσ2 provided that logpn→0. Consequently, ∣T3(k)∣≤C′∣T1(k)∣∑l=1∞(maxkeik+1TPpaik+11eik+1‖eik+1‖2)l≡∣T1(k)∣Δ for some constant C′ &gt; 0, where Δ=Op(∣E0∣logpn) when logpn→0.

When d = ∣A∣ is fixed, 2Lr→dΓd and Γd has the same distribution as min{X1,…,Xd}. If d → ∞, then (1−Δ)d2minkT1(k)−d2maxk∣T2(k)∣≤2d2Lr≤(1+Δ)d2minkT1(k)+d2maxk∣T2(k)∣.

By Assumption 6, Δ→p0 and maxkd2∣T2(k)∣→p0. Thus, it suffices to show that minkd2T1(k)→dΓ. Denote Fχ2 as the distribution function of χ12 random variable. The for every x &gt; 0, limd→∞dlog(1−Fχ2(x∕d2))=−limd→∞d∑k=1∞Fχ2k(x∕d2)k=2xπ. Hence, the limiting distribution function of 2d2Lr is (1−exp(−2x∕π))I(x&gt;0). This completes the proof.

Lemma 3 Assume that q &lt; n is allowed to depend on n and Yi. ~ N(0, Ω−1) be independently and identically distributed vectors in Rq; i = 1,…,n. If Assumption 1 is satisfied, then, for any 0 &lt; δ &lt; 1, there exists a constant c &gt; 0 such that P(∃S:‖n−1YST(I−PSc)YS−(ΩS,S)−1‖2&gt;c‖Ω−1‖2log(2δ)qn)≤δ,

where S ⊂ {1,…, q} and ∥ · ∥2 denotes the matrix 2-norm.

Proof of Lemma 3: First, it follows from Proposition 2.1 of [28] that P(‖n−1YTY−Ω−1‖2&gt;clog(2δ)qn≤δ. Let S ⊂ {1,…,q}. Note that n−1YST(I−PSc)YS=n−1(YSTYS−YSTYSc(YScTYSc)−1YScTYS)=((Ω−1)SS+ΔSS)−((Ω−1)SSc+ΔSSc)((Ω−1)ScSc+ΔScSc)−1((Ω−1)ScS+ΔScS)=(Ω−1)SS−(Ω−1)SSc(Ω−1)ScSc(Ω−1)ScS+O(‖Ω−1‖2Δ)=(ΩSS)−1+O(‖Ω−1‖2Δ),

where ΔSS = n−1YTY – (Ω−1)SS, ΔSSc=n−1YSTYSc−(Ω−1)SSc=ΔScST and Δ = n−1YTY – Ω−1. The fact that max(∥MSS∥2, ∥MSSc∥2) ≤ ∥M∥2 for any M∈Rq×q has been applied. The desired result follows immediately.

Proof of Theorem 3: Without loss of generality, assume σ = 1 and Y1 ⪯ ⋯ ⪯ Yp is the partial order of DAG G0.

For (i), if ∣D0∣ = 0, then for any E ⊂ F, E0 ∪ E is cyclic. However, since Un is acyclic, then Un = U0 and h = 0, establishing (i).

For (ii), suppose ∣D0∣ &gt; 0 is fixed. Define Dj0={(i,j)∈D0} and note that l(Un,σ2)−l(U0,σ2)=∑j=1pηDj0TnvecDj0(δ)−12∑j=1pnvecDj0(δ)T(1nYpaj1TYpaj1)Dj0,Dj0nvecDj0(δ),

where ηDj0=n−1∕2∂l(U,σ)∂UDj0∣U=U0=n−1∕2YT(Yj−YU⋅j0)=n−1∕2YDj0Tej. The local power of the proposed test is PUn(2Lr&gt;χ∣D0∣,1−α2)=EU0(I(2Lr&gt;χ∣D0∣,1−α2)exp(l(Un,σ2)−l(U0,σ2)))=EU0(I(2Lr&gt;χ∣D0∣,1−α2)exp(∑j=1pηDj0TnvecDj0(δ)−)(12∑j=1pnvecDj0(δ)T(1nYpaj1TYpaj1)Dj0,Dj0nvecDj0(δ))).

Under the assumptions of Theorem 1, with probability tending to 1 under PU0, we have 2Lr=∑j=1pejT(Ppaj1−Ppaj0)ej+op(1)=∑j=1p∑r=1∣Dj0∣(ajrTej)2+op(1), where Ppaj1−Ppaj0=∑r=1∣Dj0∣ajrajrT. Let A(j)=(aj1,…,aj,∣Dj0∣)T∈R∣Dj0∣×n; j = 1,…,p. Then ∣(A(j)ejηDj0)∣Y{1,…,j−1}≡(Z1(j)Z2(j))∼N(0,(I∣D0∣×∣D0∣n−1∕2A(j)YDj0n−1∕2YDj0TA(j)Tn−1YDj0YDj0)).

By simple matrix manipulations, Z2∣Z1=z1∼N(n−1∕2YDj0TA(j)Tz1,n−1YDj0T(In×n−A(j)TA(j))YDj0). After changing the measure, we have that lim infn→∞PUn(2Lr&gt;χ∣D0∣,1−α2) is lower-bounded by lim intn→∞EU0(I(∑j=1p‖A(j)ej‖2&gt;χ∣D0∣,1−α2))(×exp(∑j=1pηDj0TnvecDj0(δ)−12∑j=1pnvecDj0(δ)T(1nYpaj1TYpaj1)Dj0,Dj0nvecDj0(δ)))lim intn→∞E[exp(−12∑j=1pnvecDj0(δ)T(1nYpaj1TYpaj1)Dj0,Dj0nvecDj0(δ))][(×E(I(‖Z1‖2+∑1p−1‖A(j)ej‖2&gt;χ∣D0∣,1−α2)E(exp(nvecD0(δ)TZ2)∣Z1)∣Y1,…,p−1)]lim intn→∞E[exp(−12∑j=1pnvecDj0(δ)T(1nYpaj1TYpaj1)Dj0,Dj0nvecDj0(δ))][(×E(I(‖Z1‖2+∑1p−1‖A(j)ej‖2&gt;χ∣D0∣,1−α2)exp(vecD0(δ)TYpaj1TA(p)TZ1)∣Y1,…,p−1)]=lim intn→∞E[P(‖Z1+A(p)Ypaj1vecD0(δ)‖2+∑1p−1‖A(j)ej‖2&gt;χ∣D0∣,1−α2∣Y1,…,p−1)],

where ‖Z1+A(p)YDj0vecD0(δ)‖2Y1,…,p−1∼χ∣D0∣2(‖A(p)YDj0vecD0(δ)‖2), and χr2(μ2) denotes the non-central chi-squared distribution with the degrees of freedom r and non-centrality parameter μ2. By Lemma 3, for any 0 &lt; t &lt; 1, P(∀j:vecD0(δ)TYDj0TA(p)TA(p)YDj0vecD0(δ))(≥(1−t)nvecDj0(δ)T(ΩDj0,Dj0)−1nvecDj0(δ))→1,

under Assumption 4. Thus, proceeding above calculation for j = p – 1,…,1 yields that lim infn→∞PUn(2Lr&gt;χ∣D0∣,1−α2)≥P(χ∣D0∣2((1−t)∑1phjT(ΩDj0,Dj0)−1hj)≥χ∣D0∣,1−α2).

This leads to (ii).

Finally, when ∣D0∣ → ∞, a similar argument yields that for any 0 &lt; t &lt; 1, lim infn→∞PUn((2∣D0∣)−1∕2(2Lr−∣D0∣)&gt;z1−α)≥lim infn→∞PU0(χ∣D0∣2((1−t)∑1phjT(ΩDj0,Dj0)−1hj)&gt;∣D0∣+∣D0∣−1∕2z1−α)=P(N(0,1)&gt;z1−α−(1−t)λmax−1(Ω)h22),

where the fact that χr2(μ2)−r−μ22(r+2μ2)→dN(0,1) is used. This completes the proof.

Proof of Theorem 4: Suppose that E ∪ F is cyclic. Then the condition that Un is acyclic implies that Un = U0 and h = 0, establishing (i).

Suppose d &gt; 0 is fixed. Let Lr(k)=l(Ω^Ha)−l(Ω^H0(k));(ik,kk+1)∈A. For notational simplicity, let B = {k : (ik, ik+1) ∈ A} and assume B = {1,…, ∣A∣} without loss of generality. Using the argument in Theorem 3, for k ∈ B, 2Lr(k)=σ−2eik+1T{Ppaik+11−Ppaik+11∖{ik}}eik+1+op(1)=(akTeik+1)2+op(1),

and ∣(akTeik+1ηik+1)∣Y{i1,…,ik}≡(Z1(k)Z2(k))∼N(0,(1n−1∕2akTYikn−1∕2akTYikn−1YikTYik)).

Hence, taking iterated expectation as in the proof of Theorem 3 yields that lim infn→∞PUn(2Lr&gt;Γd,1−α)≥lim infn→∞PU0(f(χ12(h2∕Ωi1i1),…,χ12(h2∕Ωidid))&gt;Γd,1−α),

where f(x) = min1≤k≤d xk; x=(x1,…,xd)∈Rd. This establishes (ii).

Similarly, when d → ∞, lim infn→∞PUn(2Lr≥d−2Γ1−α)=lim infn→∞PU0(d2f(χ12(h2∕Ωi1i1),…,χ12(h2∕Ωidid))≥Γ1−α).

This completes the proof.

Proof of Theorem 5: The proof involves two parts: convergence of ADMM and convergence of DC programming.

For the ADMM part, we show that (11) reduces to a two-block ADMM. Then the desired result follows from Section 3.2.1 of [1]. Recall that the convex subproblem considered at (m + 1)th DC iteration is min(U,V,Λ,ξ)RSS(U)+μ∑(i,j)∉E1∣Vij∣I(∣U^ij[m]∣≤τ),subj toUE2=0,U−V=0,VijI(∣U^ij[m]∣≤τ)+τI(∣U^ij[m]∣&gt;τ)+ξijk1−τλjk−τI(i≠k)+τλik=0,VijI(∣U^ij[m]∣≤τ)−τI(∣U^ij[m]∣&gt;τ)−ξijk2+τλjk+τI(i≠k)−τλik=0,ξijk1,ξijk2≥0,i,j,k=1,…,p,i≠j.

Let g(V)=μ∑(i,j)∉E1∣Vij∣I(∣U^ij[m]∣≤τ) and let h(U, Λ, ξ) = RSS(U). Treating (U, Λ, ξ) as a variable, (11) exactly minimizes the objective function in (U, Λ, ξ)-direction at each ADMM iteration. Note that g and h are convex, proper, and closed. Moreover, the linear constraints implies the existence of Lagrangian multipliers for the unaugmented Lagrangian L0 defined in Section 3.2 of [1], which further implies the existence of a saddle point of L0. Moreover, (11) reduces to a standard two-block ADMM that satisfies Assumptions 1-2 of [1]. Then convergence is established.

For the DC programming part, note that the Karush-Kuhn-Tucker conditions imply that there exists Lagrangian multipliers μ ≥ 0 and ν = {νijk ≥ 0}i,j,k=1,…,p;i≠j such that (U[m*], Λ[m*]) minimizes the Lagrange function, where m* is the iteration index at termination, f(U,Λ)=RSS(U)=μ(∑(i,j)∉E1Jτ(Uij)−κ)+∑i,j,k=1,…,p;i≤jνijk(Jτ(Uij)−λik−I(j≠k)+λjk),

with respect to U. For the constrained MLEs defined in (7) and (8), 0 ≤ f(U[m], Λ[m]) = f[m+1](U[m], Λ[m]) ≤ f[m](U[m], Λ[m]) ≤ f[m](U[m−1], Λ[m−1]) = f(U[m−1], Λ[m−1]), where m is the DC iteration index and f[m] is the difference convex objective function at iteration m. By monotonicity, limm→∞ f(U[m], Λ[m]) = f(U[m*], Λ[m*]). The finite termination property follows from strict decreasingness of f[m](U[m], Λ[m]) in m and finite possible values of the subgradient of the trailing convex function. At termination f(U[m*], Λ[m*]) = f(U[m*−1], Λ[m*−1]); otherwise the iteration continues. It can be verified that (U[m*], Λ[m*]) satisfies the desired local optimality condition. This completes the proof.

Figure 1: Three types of graphs used in Examples 1-3.

Figure 2: Empirical null distribution of the proposed CLR linkage test based on the chi-squared approximation with n = 500 and ∣D0∣ = 1.

Figure 3: Empirical null distribution of the proposed CLR linkage test based on the normal approximation with n = 500 and ∣D0∣ = 30.

Figure 4: Empirical null distribution of the proposed CLR pathway test based on the minimum d^ chi-squared approximation with n = 500 and d = 5.

Figure 5: A subnetwork associated with BAD, consisting of dashed pathways denoted by P1-P3, for multiple hypothesis testing, where solid pathways are significant under level α = 0.01 after the Holm-Bonferroni correction and adjusted p-values of these pathways are given in parentheses for multiplicity.

Figure 6: Reconstructed gene networks for the Alzheimer disease and healthy groups.

Figure 7: Diagnostic plots of the reconstructed networks. First row: Side-to-side box plots of residuals of each gene for the AD and control groups. Second row: Normal quantile-quantile plots of residuals of the AD and control groups.

Table 1: Empirical size and power of the proposed CLR test for testing linkages (7) i in Examples 1-2, where the chi-squared or normal tests with α = 0.05 are used based on ∣D^0∣.

			CLR	Oracle LR	
Graph	∣D0∣	(p, n)	Size	Power	Size	Power	
Random	1	(50, 500)	0.053	(0.56, 0.99, 1.00)	0.051	(0.57, 0.99, 1.00)	
		(100, 500)	0.054	(0.57, 1.00, 0.99)	0.056	(0.59, 1.00, 1.00)	
		(200, 500)	0.039	(0.54, 0.98, 1.00)	0.050	(0.62, 1.00, 1.00)	
		(250, 200)	0.060	(0.46, 0.98, 1.00)	0.054	(0.55, 0.98, 1.00)	
	30	(50, 500)	0.050	(0.19, 0.62, 1.00)	0.052	(0.22, 0.67, 1.00)	
		(100, 500)	0.062	(0.17, 0.74, 0.99)	0.066	(0.20, 0.76, 1.00)	
		(200, 500)	0.047	(0.18, 0.70, 0.96)	0.063	(0.19, 0.81, 0.99)	
		(250, 200)	0.055	(0.09, 0.66, 0.96)	0.051	(0.11, 0.75, 0.99)	
Hub	1	(50, 500)	0.049	(0.65, 0.95, 1.00)	0.048	(0.65, 1.00, 1.00)	
		(100, 500)	0.043	(0.65, 0.93, 1.00)	0.053	(0.64, 0.99, 1.00)	
		(200, 500)	0.053	(0.63, 0.96, 0.99)	0.047	(0.65, 1.00, 1.00)	
		(250, 200)	0.043	(0.54, 1.00, 0.99)	0.038	(0.58, 1.00, 0.99)	
	30	(50, 500)	0.048	(0.16, 0.78, 1.00)	0.054	(0.15, 0.83, 1.00)	
		(100, 500)	0.059	(0.23, 0.75, 0.99)	0.057	(0.19, 0.82, 0.99)	
		(200, 500)	0.057	(0.20, 0.58, 0.91)	0.055	(0.20, 0.62, 1.00)	
		(250, 200)	0.041	(0.14, 0.53, 0.90)	0.040	(0.15, 0.60, 1.00)	

Table 2: Empirical size and power of the proposed likelihood ratio test for testing a directed pathway (8) in a chain graph in Example 3, where the minimum d^ chi-square test with α = 0.05 is used

	CLR	Oracle LR	
(p, n)	Size	Power	Size	Power	
(50, 500)	0.045	(0.84, 1.00, 1.00)	0.050	(0.91, 1.00, 1.00)	
(100, 500)	0.057	(0.78, 0.94, 0.99)	0.051	(0.90, 1.00, 1.00)	
(200, 500)	0.052	(0.73, 0.90, 0.94)	0.046	(0.91, 1.00, 1.00)	
(250, 200)	0.060	(0.59, 0.80, 0.92)	0.053	(0.80, 0.97, 1.00)	

Table 3: Percentage of agreement between the proposed CLR test and the oracle test in (7) based on 100 simulation replications.

(p, n)	Random	Hub	
(10, 200)	0.99	0.99	
(30, 600)	0.95	1.00	
(50, 1000)	0.97	0.99	


References

[1] Boyd S , Parikh N , Chu E , Peleato B , and Eckstein J . Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning, 3 (1 ):1–122, 2011.
[2] Breiman L and Cutler A . A deterministic algorithm for global optimization. Mathematical Programming, 58 (1-3 ):179–199, 1993.
[3] Bühlmann P , Peters J , Ernest J , Cam: Causal additive models, high-dimensional order search and penalized regression. The Annals of Statistics, 42 (6 ):2526–2556, 2014.
[4] Cheng J , Greiner R , Kelly J , Bell D , and Liu W . Learning bayesian networks from data: an information-theory based approach. Artificial intelligence, 137 (1-2 ):43–90, 2002.
[5] Cormen TH , Leiserson CE , Rivest RL , and Stein C . Introduction to algorithms. The MIT press, 2001.
[6] Edwards D . Introduction to graphical modelling. Springer Science &amp; Business Media, 2012.
[7] Foster TC , Sharrow KM , Masse JR , Norris CM , and Kumar A . Calcineurin links ca2+ dysregulation with brain aging. Journal of Neuroscience, 21 (11 ):4066–4073, 2001.11356894
[8] Fu F and Zhou Q . Learning sparse causal gaussian networks with experimental intervention: regularization and coordinate descent. Journal of the American Statistical Association, 108 (501 ):288–300, 2013.
[9] Gabay D and Mercier B . A dual algorithm for the solution of non linear variational problems via finite element approximation. Institut de recherche d’informatique et d’automatique, 1975.
[10] Geyer CJ . On the asymptotics of constrained m-estimation. The Annals of Statistics, 22 (4 ):1993–2010, 1994.
[11] Gu J , Fu F , and Zhou Q . Penalized estimation of directed acyclic graphs from discrete data. Statistics and Computing, pages 1–16, 2017.
[12] Horst R and Tuy H . Global optimization: Deterministic approaches. Springer Science &amp; Business Media, 2013.
[13] Kanehisa M and Goto S . Kegg: kyoto encyclopedia of genes and genomes. Nucleic acids research, 28 (1 ):27–30, 2000.10592173
[14] Kolmogorov A and Tikhomirov V . ε-entropy and ε-capacity of sets in function spaces. Uspekhi Matematicheskikh Nauk, 14 (2 ):3–86, 1959.
[15] Laurent B and Massart P . Adaptive estimation of a quadratic functional by model selection. Annals of Statistics, pages 1302–1338, 2000.
[16] Liu J . Monte Carlo strategies in statistical computing. Springer, New York, 2001.
[17] Liu Z , Zhang M , Xu G , Huo C , Tan Q , Li Z , and Yuan Q . Effective connectivity analysis of the brain network in drivers during actual driving using near-infrared spectroscopy. Frontiers in behavioral neuroscience, 11 :211, 2017.29163083
[18] Luo R and Zhao H . Bayesian hierarchical modeling for signaling pathway inference from single cell interventional data. The Annals of Applied Statistics, 5 (2A ):725, 2011.22162986
[19] Núñez-Antón VA and Zimmerman DL . Antedependence models for longitudinal data. Chapman and Hall/CRC, 2009.
[20] Ossiander M . A central limit theorem under metric entropy with l2 bracketing. The Annals of Probability, pages 897–919, 1987.
[21] Peters J and Bühlmann P . Identifiability of Gaussian structural equation models with equal error variances. Biometrika, 101 (1 ):219–228, 2014.
[22] Peters J , Bühlmann P , and Meinshausen N . Causal inference by using invariant prediction: identification and confidence intervals. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 78 (5 ):947–1012, 2016.
[23] Rockafellar R and Wets R . Variational analysis, volume 317 Springer, 2011.
[24] Rothenhäusler D , Bühlmann P , and Meinshausen N . Causal dantzig: fast inference in linear structural equation models with hidden variables under additive interventions. The Annals of Statistics, To appear, 2018.
[25] Sachs K , Perez O , Pe’er D , Lauffenburger DA , and Nolan GP . Causal protein-signaling networks derived from multiparameter single-cell data. Science, 308 (5721 ):523–529, 2005.15845847
[26] Shen X , Pan W , and Zhu Y . Likelihood-based selection and sharp parameter estimation. Journal of American Statistical Association, 107 :223–232, 2012.
[27] Tao PD The dc (difference of convex functions) programming and dca revisited with dc models of real world nonconvex optimization problems. Annals of operations research, 133 (1-4 ):23–46, 2005.
[28] Vershynin R . How close is the sample covariance matrix to the actual covariance matrix? Journal of Theoretical Probability, 25 (3 ):655–686, 2012.
[29] Webster JA , Gibbs JR , Clarke J , Ray M , Zhang W , Holmans P , Rohrer K , Zhao A , Marlowe L , Kaleem M , Genetic control of human brain transcript expression in alzheimer disease. The American Journal of Human Genetics, 84 (4 ):445–458, 2009.19361613
[30] Wong WH and Shen X . Probability inequalities for likelihood ratios and convergence rates of sieve mles. The Annals of Statistics, pages 339–362, 1995.
[31] Yuan Y , Shen X , Pan W , and Wang Z . Constrained likelihood for reconstructing a directed acyclic gaussian graph. Biometrika, 106 :109–125, 2019.30799877
