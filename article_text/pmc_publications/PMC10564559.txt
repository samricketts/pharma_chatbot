LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


8904467
21230
Neuropsychology
Neuropsychology
Neuropsychology
0894-4105
1931-1559

37276136
10564559
10.1037/neu0000888
NIHMS1877108
Article
Linking Self-Perceived Cognitive Functioning Questionnaires Using Item Response Theory: The Subjective Cognitive Decline Initiative
Rabin Laura A. PhD *12
Sikkes Sietske A.M. PhD 34
Tommet Douglas MS 5
Jones Richard N. ScD 5
Crane Paul K. MD, MPH 6
Elbulok-Charcape Milushka M. PhD 1
Dubbelman Mark A. M.S. 4
Koscik Rebecca PhD 78
Amariglio Rebecca E. PhD 9
Buckley Rachel F. PhD 910
Boada Mercè MD, PhD 11
Chételat Gaël PhD 12
Dubois Bruno MD, PhD 1314
Ellis Kathryn A. PhD, MPsych 10
Gifford Katherine A. PsyD 16
Jefferson Angela L. PhD 16
Jessen Frank MD 1718
Johnson Sterling PhD 1920
Katz Mindy J. MPH 2
Lipton Richard B. MD 22122
Luck Tobias PhD 23
Margioti Eleni PhDc 2425
Maruff Paul PhD 26
Molinuevo Jose Luis MD, PhD 27
Perrotin Audrey PhD 12
Petersen Ronald C. MD, PhD 2829
Rami Lorena PhD 27
Reisberg Barry MD 3031
Rentz Dorene M. PsyD 9
Riedel-Heller Steffi G. PhD, MPH 32
Risacher Shannon L. PhD 3334
Rodriguez-Gomez Octavio MD 11
Sachdev Perminder S. MD, PhD 35
Saykin Andrew J. PsyD 3334
Scarmeas Nikolaos MD 3637
Smart Colette PhD 3839
Snitz Beth E. PhD 40
Sperling Reisa A. MD 9
Taler Vanessa PhD 4142
van der Flier Wiesje M. PhD 3443
van Harten Argonde C. MD, PhD 42943
Wagner Michael PhD 1844
Wolfsgruber Steffen PhD 1845
Alzheimer’s Disease Neuroimaging Initiative, the Canadian Longitudinal Study on Aging, &amp; the Health and Aging Brain Study: Health Disparities (HABS-HD) Study Team, on behalf of the ISTAART Subjective Cognitive Decline Professional Interest Area
1 Department of Psychology, Brooklyn College, Brooklyn, NY, USA and The Graduate Center of CUNY, NY, NY, USA
2 Saul R. Korey Department of Neurology, Albert Einstein College of Medicine, Bronx, NY, USA
3 Epidemiology and Data Science, Vrije Universiteit Amsterdam, Amsterdam UMC location VUmc, Amsterdam, The Netherlands
4 Alzheimer Center Amsterdam, Neurology, Vrije Universiteit Amsterdam, Amsterdam UMC location VUmc, Amsterdam, The Netherlands
5 Department of Psychiatry and Human Behavior and Neurology, Warren Alpert Medical School, Brown University, Providence, RI, USA
6 Division of General Internal Medicine, University of Washington, Seattle, WA, USA
7 Wisconsin Alzheimer's Institute University of Wisconsin School of Medicine and Public Health Madison WI, USA
8 Department of Medicine, University of Wisconsin School of Medicine and Public Health Madison WI, USA
9 Department of Neurology, Brigham and Women’s Hospital, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA
10 Department of Psychiatry and Melbourne School of Psychological Sciences, University of Melbourne, Melbourne, Australia
11 Alzheimer Research Center and Memory Clinic of Fundació ACE, Institut Català de Neurociències Aplicades, Barcelona, Spain
12 Normandie Univ, UNICAEN, INSERM, U1237, PhIND "Physiopathology and Imaging of Neurological Disorders", NeuroPresage Team, Cyceron, 14000 Caen, France
13 Université Pierre et Marie Curie-Paris 6, AP-HP, Hôpital de la Salpêtrière, Paris, France
14 Centre des Maladies Cognitives et Comportementales, Institut du Cerveau et de la Moelle épinière (ICM), UMRS975, Paris, France
15 Department of Psychiatry, Academic Unit for Psychiatry of Old Age, University of Melbourne, Melbourne, Australia
16 Vanderbilt Memory &amp; Alzheimer’s Center, Department of Neurology, Vanderbilt University Medical Center, Nashville, TN, USA
17 Department of Psychiatry and Psychotherapy, Medical Faculty, University of Cologne, Cologne, Germany
18 German Center for Neurodegenerative Diseases (DZNE), Bonn, Germany
19 Geriatric Research Education and Clinical Center William S. Middleton Memorial Veterans Hospital Madison WI, USA
20 University of Wisconsin School of Medicine and Public Health, Madison WI, USA
21 Department of Psychiatry and Behavioral Medicine, Albert Einstein College of Medicine, Bronx, NY, USA
22 Department of Epidemiology &amp; Population Health, Albert Einstein College of Medicine, Bronx, NY, USA
23 Faculty of Applied Social Sciences, University of Applied Sciences Erfurt, Erfurt, Germany
24 Laboratory of Cognitive Neuroscience, School of Psychology, Aristotle University of Thessaloniki, Thessaloniki, Greece
25 Aviv Clinics, Jumeirah Lake Towers, Dubai, United Arab Emirates
26 Cogstate, Ltd., Melbourne, Australia
27 Alzheimer’s Disease and Other Cognitive Disorders Unit, IDIBAPS, Hospital Clinic, Barcelona, Spain
28 Department of Health Sciences Research, Mayo Clinic, Rochester, MN, USA
29 Department of Neurology, Mayo Clinic, Rochester, MN, USA
30 Department of Psychiatry, New York University Langone Medical Center, New York, NY, USA
31 Silberstein Aging and Dementia Research Center, New York University School of Medicine, New York, NY, USA
32 Institute of Social Medicine, Occupational Health and Public Health (ISAP), University of Leipzig, Leipzig, Germany
33 Department of Radiology and Imaging Sciences, Indiana University School of Medicine, Indianapolis, IN, USA
34 Indiana Alzheimer’s Disease Research Center, Indiana University School of Medicine, Indianapolis, IN
35 Centre for Healthy Brain Ageing (CHeBA), School of Psychiatry, University of New South Wales, Sydney, Australia
36 1st Department of Neurology, Aiginition Hospital, National and Kapodistrian University of Athens Medical School, Greece
37 Department of Neurology, Columbia University, New York, USA
38 Department of Psychology, University of Victoria, Victoria, BC, Canada
39 Centre on Aging, University of Victoria, Victoria, BC, Canada
40 Department of Neurology, University of Pittsburgh, Pittsburgh, PA, USA
41 School of Psychology, University of Ottawa, Ottawa, ON, Canada
42 Bruyère Research Institute, Ottawa, ON, Canada
43 Amsterdam Neuroscience, Neurodegeneration, Amsterdam, The Netherlands
44 Department of Neurodegenerative Diseases and Geriatric Psychiatry, University of Bonn, Bonn, Germany
45 Department of Psychiatry and Psychotherapy University of Bonn, Bonn, Germany
* Correspondence to: Laura A. Rabin, PhD; Department of Psychology, Brooklyn College/CUNY, 2900 Bedford Avenue, Brooklyn, NY 11210. lrabin@brooklyn.cuny.edu. Tel.: + 1 718 951 5601; Fax: + 1 718 951 4814.
21 9 2023
5 2023
01 5 2024
37 4 463499
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Objective:

Self-perceived cognitive functioning, considered highly relevant in the context of aging and dementia, is assessed in numerous ways—hindering comparison of findings across studies and settings. Therefore, the current study aimed to link item-level self-report questionnaire data from international aging studies.

Methods:

We harmonized secondary data from 24 studies and 40 different questionnaires with item response theory (IRT) techniques using a graded response model with a Bayesian estimator. We compared item information curves to identify items with high measurement precision at different levels of the self-perceived cognitive functioning latent trait. Data from 53,030 neuropsychologically intact older adults were included, from 13 English language and 11 non-English (or mixed) language studies.

Results:

We successfully linked all questionnaires and demonstrated that a single factor structure was reasonable for the latent trait. Items that made the greatest contribution to measurement precision (i.e., “top items”) assessed general and specific memory problems and aspects of executive functioning, attention, language, calculation, and visuospatial skills. These top items originated from distinct questionnaires and varied in format, range, time frames, response options, and whether they captured ability and/or change.

Conclusions:

This was the first study to calibrate self-perceived cognitive functioning data of geographically diverse older adults. The resulting item scores are on the same metric, facilitating joint or pooled analyses across international studies. Results may lead to the development of new self-perceived cognitive functioning questionnaires guided by psychometric properties, content, and other important features of items in our item bank.

subjective cognitive decline
measurement
item response theory
harmonization
self-perceived cognitive functioning
CLSA

pmcOlder adults commonly perceive changes in their own cognitive abilities, hereafter referred to as decline in self-perceived cognitive functioning (Jonker et al., 1996; 2000; Ponds et al., 1997; Röhr et al., 2020; van Harten et al., 2018). Although sometimes accompanied by impairment detected from assessment with objective neuropsychological tests, as in prodromal dementia conditions such as mild cognitive impairment (MCI), decline in self-perceived cognitive functioning can also be related to various medical conditions, mood or sleep disturbances, medications, personality traits, or physiological changes that occur with normal aging (Buckley et al., 2013; Comijs et al., 2002; Hill et al., 2016; Jessen et al., 2020; Rabin et al., 2017; Zlatar et al., 2014). For some older adults, a self-experienced persistent decline in cognitive functioning, in the absence of objective neuropsychological deficits (and unrelated to an acute event), may be an early manifestation of underlying neurodegenerative changes associated with an increased risk of future objective cognitive decline (Jessen et al., 2014; Jessen et al., 2020; Reisberg et al., 2008). This condition, referred to as subjective cognitive decline (SCD), may represent one of the first symptomatic manifestations of Alzheimer’s disease and related disorders (ADRD; Jessen et al., 2014; 2020; Molinuevo et al., 2017; Rabin et al., 2017; Reisberg &amp; Gauthier, 2008; Slot et al., 2019).

The assessment of self-perceived cognitive functioning offers the advantage of directly gathering information about important and potentially clinically significant aspects of cognition and function from a first-person perspective (Lai et al., 2014; Lucas &amp; Baird, 2006). Unfortunately, the field lacks a standardized approach for measuring self-perceived cognitive functioning in older adults, which greatly limits understanding of the construct of SCD and the ability to compare findings across studies and settings (Molinuevo et al., 2017; Röhr et al., 2020). Coincident with the conceptualization of the SCD condition as a manifestation of the late preclinical stage of Alzheimer’s disease (AD; Jack Jr. et al., 2018), there has been a proliferation of new questionnaires or adoption of existing questionnaires within international aging studies (Abdulrab &amp; Heun, 2008; Rabin et al., 2015; Reid &amp; MacLullich, 2006). Some measures have been adapted for application in multiple languages (Raimo et al., 2016; Şahin et al., 2013; Slot et al., 2018) and/or used internationally with culturally and linguistically diverse populations (Brucki &amp; Nitrini, 2009; Hao et al., 2017; Vlachos et al., 2019). A previous study documented the vast heterogeneity in questionnaires used to assess self-perceived cognitive functioning in 19 aging studies from Australia and countries in North America and Europe (Rabin et al., 2015). These studies were also diverse with respect to recruitment approaches, research settings, language in which assessments were conducted, and sample sizes. The study found that while items inquired about a variety of cognitive domains, those pertaining to memory were the most common (Rabin et al., 2015). Overall, results revealed little overlap among self-perceived cognitive functioning questionnaires and great variability in terms of key features of item format and content. Additionally, questionnaire and item selection decisions were mostly based on practical rather than psychometric considerations, with many measures lacking evidence of validity (Rabin et al., 2015).

The variability in questionnaires and item properties may account, in part, for discrepant findings with regard to whether decline in self-perceived cognitive functioning is associated with AD biomarkers and clinical progression (Amariglio et al., 2012; 2015b; 2021; Buckley et al., 2016; Jessen et al., 2010; Kryscio et al., 2014; Mielke et al., 2012; Mitchell et al., 2014; Mosconi et al., 2008; Perrotin et al., 2012; Peter et al., 2014; Reisberg et al., 2010; 2019; Risacher et al., 2015; Saykin et al., 2006; Scheef et al., 2012; Schultz et al., 2015; Slot et al., 2019; Snitz et al., 2018; van Harten et al., 2013; Visser et al., 2009) or is not associated with AD biomarkers and clinical progression (Chételat et al., 2010; Hollands et al., 2015; Zwan et al., 2016; see Colijn &amp; Grossberg, 2015; Lin et al., 2019; Lista et al., 2015; Sun et al., 2015 for reviews). Initiatives to understand the condition of SCD have led to efforts to develop a unified conceptual framework (Jessen et al., 2014; 2020). Additionally, there have been calls to pool data across studies to examine the psychometric properties and quality of items used to classify SCD (Jessen et al., 2020; Molinuevo et al., 2017, Rabin et al., 2017; Röhr et al., 2020). Investigation into the reliability and validity of self-perceived cognitive functioning measures and improvements in measurement development are critical to promoting understanding and replicability of study conclusions (Fried &amp; Flake, 2018; Flake &amp; Fried, 2020).

The application of psychometric modeling techniques, such as item response theory (IRT), to self-perceived cognitive functioning measurement could enable harmonization of data across studies with diverse assessment approaches. Additionally, such an approach could facilitate evaluation of the precision of items and subsequent modification of the instruments themselves. IRT comprises a collection of modeling techniques for the analysis of item level data, which can be used to evaluate the psychometric properties of existing scales and items, shorten scales, and calibrate items from different scales (Edelen &amp; Reeve, 2007). IRT modeling can help generate precise, valid, and relatively brief instruments that present minimal burden to respondents. One example of the use of IRT in healthcare research and clinical practice is the Patient-Reported Outcomes Measurement Information System (PROMIS ™), which consists of item banks and short forms of self-reported health measures that assess many aspects of physical, mental/cognitive, and social health in diverse adult and pediatric populations (Cella et al., 2010; Irwin et al., 2012; Northwestern University, 2022). The application of IRT to self-perceived cognitive functioning measurement has been performed in the context of oncology, thereby supporting the suitability of measuring cognitive concerns and abilities with a unidimensional item bank (Lai et al., 2014). In the field of cognitive aging, IRT has been utilized in two published studies researching item-level self-perceived cognitive functioning data. Snitz and colleagues (2011) examined the utility of IRT for items probing self-perceived cognitive functioning in 3,495 older adult participants from four community-based studies in Southwestern Pennsylvania, U.S. IRT scoring of questionnaire items was associated with objective cognitive test scores and provided additional information beyond a simple sum of items, making this approach ideal for capturing very subtle declines in self-perceived cognitive functioning. Gifford and colleagues (2015) sought to identify items that most reliably captured self-perceived cognitive functioning among 188 non-demented older adults recruited from a research registry in Boston, U.S. After post-hoc simulation using computerized adaptive testing, researchers identified nine of 21 items that represented the latent trait and differentiated normal controls from those with MCI. These items assessed self-perceived global and specific problems and changes related to memory functioning.

These previous studies supported the benefits of applying a modern psychometric approach to self-perceived cognitive functioning data. The current study expands upon this foundation by employing item banking and co-calibration to link questionnaires from international cognitive aging studies to provide a more generalizable model of self-perceived cognitive functioning. Using IRT methods, we sought to minimize measurement scale differences as a potential impediment to understanding the coherence of results across studies. We further aimed to identify items with both strong and weak psychometric characteristics based on item information functions. Harmonization results may be used to compare data from studies that use items with varied content and measurement properties and to identify optimal items to include on new self-perceived cognitive functioning questionnaires.

Methods

Figure 1 provides an overview of the 10 primary data coding and analytic processing steps, which are discussed below in the same order.

(1) Data Gathered, Coded, and Merged

Data Sources and Questionnaires

Data were obtained from members of the Subjective Cognitive Decline Initiative (SCD-I), part of the SCD Professional Interest Area of the Alzheimer’s Association International Society to Advance Alzheimer’s Research and Treatment (ISTAART SCD-PIA). The SCD-I is a working group of AD researchers with a specific interest in self-perceived cognitive functioning.

Participating researchers sent electronic copies of their published and unpublished cognitive and functional self-report questionnaires. For studies conducted in languages other than English, researchers sent translated versions of their questionnaires. For the Alzheimer’s Disease Neuroimaging Initiative (ADNI), Anti-Amyloid Treatment in Asymptomatic Alzheimer’s (A4), and Health and Aging Brain Study: Health Disparities (HABS-HD) studies, after obtaining permission we retrieved the questionnaires directly from the study databases (adni.loni.usc.edu, apps.unthsc.edu/itr/researchers, and a4study.org, respectively).

Categorization and Item Inclusion/Exclusion

Study authors reviewed all questionnaires to determine which merited inclusion by virtue of containing items related to self-perceived cognitive functioning. To make this determination, each item was assigned to one of eight primary cognitive domains: (1) memory, (2) attention/working memory/processing speed, (3) language, (4) executive function, (5) basic calculation and arithmetic tasks, (6) orientation, (7) general cognitive ability, and (8) visuospatial skills. Items that could not be assigned to a cognitive domain were excluded; such items assessed mood, health complaints, self-efficacy, perceived stress, personality, life satisfaction, basic activities of daily living, use of cognitive strategies, and other variables that are relevant to or associated with cognition but do not directly assess self-perceived cognitive functioning. Questionnaires that contained at least one self-perceived cognitive function item were retained.

For each self-perceived cognitive functioning item, beyond cognitive domain, we coded other relevant features such as the specific type(s) of response options, scaling methods, response time frames, and whether item stems were multi-barreled (i.e., containing two or more sub-questions within a single item). We also determined whether item stems and response options together inquired about the ability to perform a target cognitive task versus change (improvement or decline).

For these various coding procedures, author LAR carried out the initial coding. Two additional authors (CMS and SAMS) subsequently identified items that they considered to be miscoded. Items in dispute were then reviewed and discussed until a consensus was reached, occasionally after discussing disputed items with authors DT, RNJ, and PKC.1

Data Merged

Researchers from the different studies were asked to send item-level data—i.e., de-identified files that included responses to self-report items. For the ADNI, A4, and HABS-HD studies, we retrieved these data directly from the study databases. We included only the baseline (or first) assessment for each participant to ensure that observations were independent and to avoid the potential that previous exposure to a questionnaire affected subsequent responses. As we were interested in self-perceived cognitive functioning in neuropsychologically intact individuals, data from participants with prevalent or concurrently classified diagnoses of MCI, AD, or other dementia were excluded. Appendix A displays the definition of neuropsychologically intact or cognitively normal for each study.

(2) Item Overlap Examined: Determination of Identical, Equivalent, and Linking Items

After careful review of the database, a subset of authors (DT, LAR, SAMS, and RJ) noticed that some studies used multiple questionnaires (see Table 1), and there was overlap in questionnaires used among studies (see Table 2). These authors next sought to identify items from different questionnaires that were exactly the same, or identical. To be deemed identical, items were required to contain precisely the same item stems, response options, temporal referents (recall intervals), etc. Close examination of all items revealed that no identical items appeared on different questionnaires (i.e., the same exact item did not appear on more than one questionnaire). These authors then considered whether items with overlapping content were similar enough to be treated as equivalent in the analyses despite minor differences in wording. Such items contained overlapping content—i.e., addressed the same cognitive process, such as memory for recent events, but had slight differences in wording, and thus could not be deemed identical. Equivalent items were identified by consensus among authors DT, LAR, RNJ, SAMS. In some cases, response options for equivalent items were combined so that they would match across items. Appendix B presents sample equivalent items and recoding of response options. Items deemed equivalent were assigned a single code and subsequently treated as identical in study analyses. Both identical and equivalent items served as linking items in the analyses (i.e., were entered into the analysis as the same item). Our approach to linking test scores is known as the Non-Equivalent Anchor Test approach (NEAT; Dorans, Pommerich, &amp; Holland, 2007), and is commonly used when different tests are given to non-equivalent groups (but there are common items administered between the groups). As noted above, some of our links involved complete tests, others involved a small number of items, and sometimes the linking items were generated ad hoc using the process for determining item equivalence.

(3) Data Recoded

Items were recoded, as needed, so that for every item a higher response option corresponded to better self-perceived cognitive functioning. As an example, the original response options for item 56 from the Metamemory in Adulthood Questionnaire (MIA; Dixon et al., 1988), “My memory for dates has greatly declined in the last 10 years” ranged from 1= strongly disagree, 2 = disagree, 3 = undecided, 4 = agree, 5 = strongly agree. These were recoded—essentially reversed—so that the higher option categories matched better self-perceived cognitive functioning 1 = strongly agree, 2 = agree, 3 = undecided, 4 = disagree, 5 = strongly disagree. Also, item response categories were combined if a category had fewer than five respondents. This was the case for items that had Likert-type response scales where few participants endorsed categories at the extreme end(s) of the scale. These sparse extreme response categories were combined with the adjacent, less extreme category/categories, until the new combined category had five or more respondents.

(4) Assessed IRT Assumptions in the Reference Sample

The reference sample defines the latent trait in IRT analyses. The Mayo Clinic Study of Aging (MCSA), a large community-based sample of neuropsychologically intact older adults, served as the reference study for this analysis. The MCSA utilizes a fairly extensive assessment of self-perceived cognitive functioning that includes the Mayo Clinic Study of Aging, adapted Blessed Memory scale (Blessed et al., 1968; van Harten et al., 2018) and the Everyday Cognition- Subject/Self-Report (ECog Self; Farias et al., 2008), the latter of which assesses self-perceived cognitive functioning in multiple domains that include memory, language, visuospatial/perceptual ability, and executive functioning/divided attention. Moreover, the ECog Self is used in multiple studies, which facilitates linking of studies and items.

We used Mplus Version 8.5 (Muthén &amp; Muthén, 2008–2017) for IRT analyses and the R statistical software package Version 4.0 (R Core Team, 2021) for data management and other study analyses. IRT is a latent variable technique used to describe the relationship between item responses and the latent trait presumed to underlie those responses, which in our case was the level of self-perceived cognitive functioning. The latent trait is assumed to be normally distributed with a mean of 0 and a standard deviation of 1 (Lord, 1980). By fitting IRT models to item data, self-perceived cognitive functioning performance can be estimated conditional on the observed item responses and their respective item parameters; additionally, IRT methods be used to generate scores that are comparable regardless of what items were utilized in a particular study.

Several key assumptions underlie the IRT framework, including unidimensionality of the measured trait, local independence, and monotonicity (McHorney &amp; Cohen, 2000; Nguyen et al., 2014). We assessed the IRT assumptions in the MCSA sample by fitting a graded response IRT model (Samejima, 1977), which is typically used for ordered polytomous response data. All models were estimated using a Bayesian estimator (Haug, 2012; Winkler, 1993). A weakly informative prior distribution (N(0, 5)) was assumed for the model parameters. The Bayesian estimator allows for better performance in the small sample sizes that several studies provided (Hox et al., 2012; Lee &amp; Song, 2004).

Unidimensionality Assumption

Based on the previous literature (Gifford et al., 2015; Snitz et al., 2011), we hypothesized that a unidimensional (or single factor) model might provide an adequate representation of the self-perceived cognitive functioning trait. In other words, the construct being measured, self-perceived cognitive functioning, is considered to have a single, dominant factor that accounts for item endorsement and covariation among the items (with small factors present beyond the major factor). This has been shown to be the case in previous work with cancer patients—where abilities and concerns about cognition loaded on a single factor and were conceptualized as a single dimension despite measuring different aspects of self-perceived cognitive functioning (Lai et al., 2014). We also considered the possibility that our data were multidimensional with strong factors beyond the major factor (i.e., differing cognitive domains might induce some meaningful secondary structure/residual covariance). For self-perceived cognitive functioning data, it is reasonable to expect that multidimensionality will arise from differences in content domain (e.g., some items assess the ability to remember recent conversations, others inquire about language problems, visuospatial ability, or language skills), temporal referents (e.g., “Compared to 10 years ago, do you notice change in…” versus “Do you currently have difficulty with ...”), or other key features of the questionnaire and its items. In a given study, any of these differences in item properties could contribute to subdomain structures and cause an item to deviate from strict unidimensionality. Such deviations from unidimensionality complicate the linking of the latent self-perceived cognitive functioning trait across multiple studies that use similar but nonequivalent questionnaires/items such that using a unidimensional-based calibration in the IRT model results in bias.

Prior to data analysis, we categorized items into cognitive subdomains and considered a bifactor model, which allows for additional covariation among a set of items beyond the general factor, based on these cognitive domains. Fitting a bifactor model proved to be an intractable problem in our analysis given the various possible subdomain structures (beyond cognitive domain) such as temporal referents or item content and structure. We therefore prioritized the unidimensional model, using two approaches to characterize the extent to which our inferences were likely to be biased due to unmeasured multidimensionality. Both approaches made use of data collected in the MCSA because, as noted, this was the study used to set the metric of our latent self-perceived cognitive functioning trait. Moreover, with one study, there was only one pattern of multidimensionality to be addressed for the item set.

Item-level Fit of Unidimensional and Bifactor Models: MCSA study.

The first method used to characterize threats to interpreting parameter estimates due to ignoring multidimensionality involved contrasting the posterior predictive p-values (PPP) for each of the items in the model under a unidimensional and a bi-factor model. Our bifactor model specification was based on the cognitive domain assignments. To assess unidimensionality in the MCSA, we fit unidimensional and bifactor item response models, and examined PPP for each item in the model. The PPP compares the χ2 value from the model generated data to the χ2 from the observed data and is approximated by the proportion of times the model generated data χ2 is greater than the observed data χ2 (Gelman, 2013; Meng, 1994). A low PPP implies that it is unlikely that the observed data derive from a data generating model that is represented by the model used in the analysis. Conventionally, PPP less than .05 indicate poor fit. The distribution of PPP for all items is shown in Appendix C, Figure 1. This figure reveals that, overall, the fit was good. The mean PPP was higher in the unidimensional case relative to the bifactor case (.38 vs .28, respectively). In both models for the MCSA, all items had PPP greater than .05. Therefore, we inferred that for the MCSA self-perceived cognitive functioning items, the pattern of correlations was consistent with a unidimensional model.

Differences in Common Latent Trait Estimates Under Unidimensional and Multidimensional Models.

The second method used to probe the level of misfit introduced with the assumption of unidimensionality involved examining the estimated factor scores derived from a unidimensional and a priori specified bifactor model. Results of these analyses are summarized in Appendix C, Figure 2 (left and right panels). These plots show the scatterplot of factor scores (left) and the difference in factor scores as a function of the average of the two factor scores (right). In our work, we typically consider absolute differences in factor scores of greater than 0.3 to be large and meaningful (Gibbons et al., 2017). Only 3% of the participants in the MCSA had a greater than 0.3 difference in factor scores. Therefore, the unidimensional model-derived factor score estimate would be deemed sufficiently precise for 97% of the sample. Further inspection of Appendix C, Figure 2 revealed that there was a region where the unidimensional factor scores seemed to produce a biased high estimate of the latent trait: values greater than +2 on the latent trait distribution, or the expected top 2.5% of scores. Thus, bias was apparent in the estimates from the unidimensional models, but it was restricted to the upper tail of self-perceived cognitive functioning (i.e., best performers/lowest cognitive concerns). As higher values on the latent trait indicated better self-perceived cognitive functioning, these 2.5% of respondents were of the least interest, clinically, if the goal was to identify individuals with higher levels of concern about their cognitive functioning.

Item-level Fit of Unidimensional and Bifactor Models: All Studies.

Further support for the assumption of unidimensionality came from examining the PPP for all items included in our analytic models, in all studies, from a unidimensional model and a bifactor model (Appendix C, Figure 3). The secondary structure was specified according to a priori assignment of items to specific domains based on manifest item content. For the PPP obtained, assuming unidimensionality, 96 of 1,112 had PPP less than .05, suggesting that for the vast majority of items, the data were consistent with the assumption of a data generating model that was unidimensional. For the bifactor models, 76 of 1,112 had PPP less than .05, suggesting that for this fraction of items even our bifactor specification was insufficient to account for the observed covariation. For these items, it is likely that additional covariation among items other than due to the manifest cognitive domain was responsible for the misfit, and we suspect that other item features (e.g., temporal referent, format and range of response options, whether items tapped ability or change) could be responsible, or that our a priori domain assignments did not conform to observed patterns of covariation among the items.

Local Independence and Monotonicity Assumptions

The next assumption, local independence, means that for a given latent trait (in our case self-perceived cognitive functioning), item responses are unrelated (Edwards et al., 2018); the assumption is usually tested for pairs of items (Kim et al., 2011) and meeting this assumption can be an additional indication of adequate model fit. In the MCSA study, we checked for and eliminated items with factor loadings &gt; 1, which implies that there was a strong residual correlation or logical dependency with another item. The monotonicity assumption means that as the trait level increases, the probability of a correct response also increases (Kang et al., 2018; Nguyen et al., 2014)—i.e., the higher the factor score the more likely a respondent is to endorse concerns about cognitive functioning. In the MCSA sample, we checked for and eliminated items that demonstrated a common factor loading qualitatively different from theoretical expectations (loadings &lt; 0), which implies that the directionality of the item is incorrect and may indicate the measurement of a distinct construct.

(5) Decision to Utilize a Unidimensional Model

In sum, across a set of models assuming unidimensionality and another set assuming multidimensionality (modeled with the bifactor approach), we compared item level fit and values estimated for latent traits. We found that item level fit was superior under the assumption of multidimensionality. However, we also found that in our reference sample, the item fits (PPP) were consistent with the assumption of unidimensionality, and in our overall sample only 9% of items demonstrated poor fit (PPP &lt;. 05) under the assumption of unidimensionality, and 7% of items demonstrated poor fit in models intending to capture multidimensionality. While this result favors the bifactor approach, it also reveals that the bifactor approach alone is insufficient to account for the poor fit of all items in our large item set, and the gain in fit of a bifactor approach over a unidimensional approach was not large. We then examined differences in factor score estimates obtained in the reference sample under a unidimensional and bifactor model. For 97% of the sample, the differences were less than 0.3 standard errors, an acceptable level to assume equivalence. Bias was apparent in the estimates from the unidimensional models, but it was restricted to the upper tail of self-perceived cognitive functioning performance (i.e., best performers). Based on these results, we concluded that there was little evidence of important bias that would result from using a unidimensional model, and we proceeded with this approach.

(6) Examination of Differential Item Functioning

We performed a brief analysis of uniform differential item functioning (DIF) with respect to study to determine whether participants with the same latent trait level across different studies differed in their response patterns on identical items. To be included in the DIF analysis, an item needed to be present across at least two studies. For most studies, the number of linking items was small and not conducive to formal DIF testing. This limited us to studies that used the same questionnaire. The studies that were most useful for a DIF analysis were the five that included the ECog Self: MCSA, ADNI, Dartmouth Memory and Aging Study/Indiana Memory and Aging Study (Dart-Indiana), HABS, and the Indiana Alzheimer’s Disease Center Cohort (IADC).

(7) Saved MCSA Item Parameters to Item Bank

An item bank is a collection of item parameters calibrated by using IRT models. It is created by saving the estimated item parameters from the IRT model with new items added to the bank from calibrating subsequent studies. Item banks can be used by instrument developers to refine existing measures by selecting the “best” set of questions for a particular purpose or for developing new instruments including using computerized adaptive testing (CAT) platforms and/or static, fixed-length short forms (Lai et al., 2003; 2014). The two sets of parameters were the item discrimination (or measurement slope) and item difficulties or thresholds (i.e., locations on an item-level latent response variable at which the most likely response moves from a lower to a higher value). The item bank was initiated with parameter estimates, taken as the medians of the posterior distribution for each of the IRT item parameters, from the MCSA.

(8) Item Linking/Harmonization in MCSA

We accomplished the statistical harmonization of questionnaires using a sequenced estimation of IRT models. There are two broad approaches to item linking—common item anchoring and common group equating. In common group anchoring, an assumption is that the groups are equivalent on the trait of interest—and the different questionnaires can simply be linked. However, we could not make that assumption given inherent differences in our samples for key sociodemographic and other variables. Instead, we utilized the common items anchoring approach, where there are identical or equivalent items across different questionnaires, and we fit a series of IRT models using item banking. The linking transformation served to place the items on the same scale (Vale, 1986).

To perform statistical harmonization (or linking) of the questionnaires, we used co-calibration (i.e., putting the questionnaires on the same scale) based on IRT in a series of steps. We initiated the harmonization sequence with the MCSA and its two questionnaires, ECog Self and MCSA adapted Blessed Memory scale (MCSA Blessed; Blessed et al., 1968; van Harten et al., 2018). This approach anchored the self-perceived cognitive functioning latent trait to a community-based sample with no neuropsychological impairment. As the reference population, the mean trait level in MCSA was set to 0 (with SD set to 1), affording comparability with other studies as they were harmonized. As an example, if the mean trait level for a study entered after MCSA was 0.5, this would indicate that the average participant in that study was .5 SD higher on the self-perceived cognitive functioning trait than the average MCSA participant. Figure 2 shows the ordering of studies in the harmonization process, with MCSA and its questionnaires entered first. The order in which subsequent studies were harmonized after MCSA was determined by considering item overlap with previous studies and sample size. As described above, response categories for certain items were combined. Decisions related to combining response categories for a given item were made for the first study in the harmonization process to use the item. For example, for the ECog Self item “finding my way around a familiar neighborhood,” the response options of “consistently a little worse” and “consistently much worse” were combined. These decisions were then carried forward to subsequent studies that used the item (i.e., to the four other studies that used the ECog Self, see Table 2).

(9) Algorithm Carried Through to Subsequent Studies

After MCSA, we analyzed other studies sequentially. If subsequent studies included items already calibrated in the item bank, we constrained those item parameters to values in the item bank, and freely estimated parameters for items not already in the bank. New items and their parameters were thus added to the item bank. This approach (banking and linking) required that—apart from the reference study—each subsequent study had at least one item in common with a previously calibrated item in the bank. This implies that studies with no overlap of items could not be included in the linking process, and to improve the quality of the estimates we needed to balance the size of the study and number of items represented in the bank in choosing the order in which items were added. As was done in MCSA (discussed above), we performed data quality checks and preliminary model checks for items with measurement slopes that corresponded to standardized factor loadings that were problematic (i.e., &lt; 0 or &gt;1). This was an additional quality check on whether the direction and potential recoding for each item were done correctly. It also enabled us to identify items where we had made an error, necessitating reverse coding of items that we had erroneously failed to reverse code. In this way, we were able to use the signs for the loadings as a further check on the directionality of each item as included in the final model. Beyond coding discrepancies, several other items were excluded via two iterations of a cycle of excluding items, re-harmonizing remaining items, and examining factor loadings until all factor loadings were between 0 and 1 for each study.

(10) Calculated Item Information and Identified Items with the Highest Information Values (“Top” Items)

Item information was determined by the derivative of the item response function—i.e., the increasing probability of endorsing an item response in a higher category as a function of the underlying trait level. The amount of information at a given latent trait level is the inverse of its standard error of measurement (SEM) squared; therefore, the larger the amount of information provided by the item, the greater the precision of the measurement (Hays et al., 2000). The amount of information (and precision) varies across levels of the latent trait. The location on the latent trait with the maximum amount of information for a binary or dichotomous item is where the probability of positively or negatively endorsing a response category is equal.

We plotted item information curves (Hambelton &amp; Cook, 1977), with item information plotted against the latent trait. Item information curves are useful because the item parameters and the latent trait are on the same scale, and items can be selected based on their measurement ability in regions of interest on the latent trait (Baker &amp; Kim, 2017). For example, measuring self-perceived cognitive functioning on the “higher” end might be of interest when studying healthy older adults living in the community, whereas the “lower” end might be more interesting in individuals who present to a memory clinic with concerns about cognition. Some items or questionnaires may provide more information in one region of the latent trait and less in a different region. For the current analysis, we determined several regions of interest on the latent trait. The first region was from 0 to +1 SD above the mean of the latent trait, which may capture individuals with better self-perceived cognitive functioning—i.e., no or few concerns about cognitive function. A second region was from the mean to -1 SD below the mean, which may capture individuals with a mild level of self-perceived cognitive functioning concerns. A third region was from -1 to -2 SDs below the mean of the latent trait, which may capture individuals with worse self-perceived cognitive functioning—i.e., a moderate to high level of cognitive concerns. From the regions of interest, we identified “top items” with the highest information values.

Results

Participant and Study Characteristics

Data were available for 61,141 participants. Because we were interested in individuals with normal performance on neuropsychological tests, we excluded one of the studies that only contributed data for cognitively impaired individuals (i.e., Pre-Al, Hôpital de la Salpêtrière, AP-HP). We also excluded subsets of cognitively impaired participants from 18 of the 24 remaining studies (see Table 1). After removing these individuals (n = 8,111), the final sample contained 53,030 neuropsychologically intact participants with data on self-perceived cognitive functioning items. Table 1 presents key features of the 24 participating working group studies. Two of the participating sites (i.e., Einstein Aging Study and University of Pittsburgh) had substudies as shown in Table 1 and Figure 2, but for the purposes of this study were considered a single site/study, unless otherwise specified. Contributing studies had sites in the U.S., Canada, Australia, Germany, United Kingdom, the Netherlands, Spain, Greece, France, and Japan. In addition, various research environments were represented including memory clinics (n = 4), community-based samples (n = 7), volunteer samples (n = 3), population-based samples (n = 3), a general practice registry (n = 1), and mixed sampling approaches (n = 6).

Questionnaire Characteristics and Linking Items

Forty questionnaires qualified for inclusion (Tables 1 and 2). As shown in Table 1, for the 24 primary studies (i.e., excluding the Einstein Aging Study and University of Pittsburgh substudies), the number of questionnaires used per study ranged from 1 to 8 (mean 2.3; median 2.0). Also, there was considerable variability in the number of usable items per study, ranging from 1 to 173 (mean 36.2; median 27.5; inter-quartile interval 46.5–17.0). There was minimal overlap of questionnaires across studies, with the majority (n = 30, 75%) used only within a single study. Appendix D shows the number of studies in which a given questionnaire was utilized. In terms of item content, as shown in Table 3, over half of the items related to memory (57%), followed by executive function (16%), attention/working memory/processing speed (10%), and language (9%).

Table 2 presents key features of the questionnaires including the total number of original items from each questionnaire with a total across questionnaires of 963 items (this total includes the 64-item version of the MFQ). In the penultimate column, we present the number of items relevant for the current analysis because they relate to self-perceived cognitive functioning (total n = 690). We excluded 273 items that related to other characteristics such as mood, personality, health complaints, basic activities of daily living, use of memory/other cognitive strategies, etc. Of the 690 items, 55 were subsequently discarded during the data analysis process, leaving 635 items. For example, we dropped items initially included but later determined to have critical content or response category limitations such as: “I am impulsive” and “Do you fail to listen to people’s names when you are meeting them?”. These items could not be categorized within the eight cognitive domains and could capture something other than self-perceived cognitive functioning. Similarly, items such as “If your memory was 100% when you were 30 years old, what % would you say it is now?” and “How long ago did your memory problems start?” had free-response formats not easily handled by our modeling approach. As noted above, during statistical harmonization, we also dropped items with loadings &lt; 0 or &gt; 1.

As described above, we also considered items with overlapping content that were similar enough to be treated as equivalent in the analyses despite minor differences in wording. Equivalent items were given the same item number and treated as a single item in the analysis; therefore, we lost one item for every replicate of an equivalent item. There were 27 sets of equivalent items: 22 items had one replicate, 3 items had two replicates, and 2 items had three replicates. In total, 34 (22 + 6 + 6) replicates were lost from the item total because they were considered equivalent items. Thus, we began with 635 items but after the equivalence process that yielded 11 sets of equivalent items, our final item count was 635 – 34 = 601. These equivalent items (n = 27) in combination with the identical items (n = 220), comprised the linking items (n = 247), which were used to link studies in the IRT analyses. As noted above, identical items were items from questionnaires that were used in more than one study.

Every study had at least one item in common with another study (equivalent or identical)—i.e., all studies had at least one linking item. Appendix E shows the number of linking items between pairs of studies. As shown in bold in Appendix E, the highest number of linking items between two studies was 60 for ADNI and the IADC, which both utilized the ECog Self and the Cognitive Change Index (CCI). For study pairs that had linking items among them (e.g., MCSA and IADC had 40, Memory Clinic - Fundació ACE and the Bonn Memory Clinic had one), the mean number of linking items between studies was 11.1 (SD = 12.6). As shown in Appendix F, each study shared linking items with an average of 6.2 other studies SD = 3.2 (range 1 to 14).

Figure 2 shows the ordering of studies for the IRT analysis and overlap among self-perceived cognitive functioning items across studies including the substudies. In the top panel, the horizontal black and white bars consist of multiple dots that represent items administered within a study. The bars that align vertically represent identical items that come from the same questionnaire. The bars that are black, at the top of the vertical-colored regions, indicate the study used to calibrate the items for the item bank. The white bars are identical to items in the black bars with which they vertically align, and represent items already calibrated by the top-most study above it. Equivalent items are single dots found within a colored region that indicate items from different instruments merged for study analysis. Items that are within a colored region (both black dots and white bars) provide the linkage for a study between previously calibrated items and items to be calibrated.

As shown in the top panel of Figure 2, there was very little item overlap across studies, and no single item represented across all studies. In some cases, a small number of items provided the linkage between specific studies. For example, the Barcelona Group had two items that linked to other studies. This is represented by a circle around two dots: (1) the Barcelona Group study was linked to the Bonn Memory Clinic and Canadian Longitudinal Study on Aging (CLSA) by a single item (single dot in the tan region); and (2) the Barcelona Group was linked to the Vanderbilt Memory and Alzheimer’s Center (VMAC) study by a single item (single dot in the purple region). Another example is the three items from the IMAP Caen Group, which were equivalent to those from the Bonn Memory Clinic (three dots circled in the tan region). A final example from the figure is the VMAC study, which had links to 14 other studies. Here we highlight the single dot circled in the teal region, which is an item from the VMAC study that is equivalent to an item from the Einstein Aging Study.

The bottom panel displays additional detail for the portion of the top panel enclosed in a rectangle. In this panel, each dot reflects an item from a given questionnaire (dots are ordered so that all of a given questionnaire’s items are grouped together). MCSA was the first study to be harmonized and is at the top (MCSA has the ECog Self and MCSA Blessed). ADNI was then harmonized and has the ECog Self and CCI questionnaires. The ECog Self provides the link to MCSA. This is the first encounter with the CCI, and it will therefore be calibrated with the ADNI sample. The IADC has two questionnaires (ECog Self and CCI), both of which were previously calibrated; therefore, the IADC does not provide any new questionnaires to be calibrated. The HABS will be linked through the ECog Self and will calibrate the Memory Functioning Questionnaire (MFQ) and Adapted from Structured Telephone Dementia Assessment (STDA).

Differential Item Functioning Analysis

As discussed above, to lend credibility to the harmonization process, we conducted a DIF analysis with respect to study on the subset of items identified as linking items from the ECog Self in five studies (n = 5,742). As shown in Appendix G, we found evidence of DIF using a statistical significance criterion for flagging items with DIF; 36 of 160 study-item pairs (23%) had evidence of DIF, which is not surprising given the large sample size. Accounting for DIF in the estimation of latent traits accounted for between 2% and 19% of the DIF-naïve group differences in the self-perceived cognitive functioning trait. Moreover, the absolute differences in the mean level of the ECog Self common latent trait were between 0.01 and 0.03 standard deviation units (Appendix G), which are considered very small (i.e., the latent trait estimates do not meaningfully change after accounting for DIF).

Item Content Examination

Higher scores on the underlying latent self-perceived cognitive functioning trait represented better self-perceived cognitive functioning. In support of the idea that these items actually measured the trait of interest, the vast majority of items (575 of 601) had standardized factor loadings greater than 0.3, and the median (and inter-quartile interval) was 0.61 (0.50 – 0.71). The ranges over which we present item information values for selected items reflected different levels of the latent trait, and these tables (see below) highlight items that might be most relevant for individuals within a given range.

Tables 4a and 4b present the 30 items with the highest information values and lowest SEM in the underlying latent trait ranges of −2 to −1 SDs and 0 to +1 SD, reflecting psychometrically sound items likely to be endorsed by participants with high and low levels of concern about their cognitive functioning, respectively. Items in the middle range (−1 to 0 SD) almost complete content overlap with items in the −2 to −1 or 0 to +1 SD ranges, and are presented in Appendix H. Of the top 15 items with good measurement precision in the higher concern range of −2 to −1, memory accounted for 80% of items (n = 12). By contrast, of the top 15 items in the higher concern range of 0 to +1, there was more variability in cognitive domains represented, with 33% (n = 5) of items related to memory, and the remaining items related executive function (n = 5), language (n = 3), calculation (n = 1), and attention and concentration (n = 1). Across the ranges of interest, most items (70%, n = 21) assessed perceptions of change (“C”) in ability or function from some prior state or level, while 30% (n = 9) assessed current ability (designated “A”). With respect to response option types, of the top 30 items 67% (n = 20) used Likert-type and rankordered/categorical item scales; notably, all of the dichotomous items (n = 10) came from the higher concern range of −2 to −1.

Figure 3 presents the item level information plots for all 601 items (i.e., those with both high and low information values). The items that appear in blue have the highest information in the two ranges, and these are the items presented in Tables 4a and 4b). Also, items that are dichotomous have only one threshold and therefore a single peak. Polytomous/Likert-scaled items have multiple thresholds and therefore can have multiple peaks. For polytomous items with multimodal curves, information typically covers a broader range—i.e., there is a higher level of information over a broader range of ability level. Notably, most of the peaks fell within the 0 to −2 range, reflecting worse self-perceived cognitive functioning, consistent with the design of these items in terms of capturing self-perceived difficulties and/or declines in cognitive functioning.

Appendix I presents the 15 items with the highest SEM in the underlying latent trait range of −4 to +4 SDs, reflecting items with weak psychometric properties across the range of the latent trait. For the items included in this analysis, additional parameters and features (e.g., item discrimination, item difficulty thresholds, summary of item content) are available upon request from the corresponding author.

Discussion

Overview

The current study harmonized self-perceived cognitive functioning questionnaires across international aging studies, with over 53,000 neuropsychologically intact participants, using an IRT item banking approach. The measurement properties of 601 items from studies of various sizes and settings were characterized, and items with the strongest psychometric properties were identified. The challenges we encountered in linking items and harmonizing these data speak to the effort involved in reviewing item content, determining equivalences among items, managing the data files, and performing statistical analyses across the 24 studies and 40 questionnaires. Results may lead to the development of new questionnaires guided by psychometric properties, content, and other important features of items in our item bank.

Dimensionality

We were able to replicate and expand upon earlier work in linking self-perceived cognitive functioning items and placing them on a common scale using IRT (Gifford et al., 2015; Snitz et al., 2011). We selected a unidimensional measurement model as our final modeling strategy. Overall, results did not provide convincing evidence to go forward with a bifactor model over a unidimensional model based on the estimated factor scores (which did not significantly differ between the two models) and the PPP for the individual items (which suggested a good fit for both models). As the secondary structure did not markedly impact scores, loadings, or fit, we determined that the single factor model was appropriate for modeling self-perceived cognitive functioning. However, we cannot rule out that a different approach with a multidimensional factor structure for the multiple domains of self-perceived cognitive functioning might have presented a more nuanced representation. Nonetheless, we found the specification and estimation of multidimensional models intractable given the sparse coverage of domains and limited overlap of items across studies. As we evaluated the approach in this study, we found that if the structure of the secondary or specific factors was different in different studies, the meaning (and expected population values) of secondary factor loadings were also different. The implication is that for each study, the common and specific factors must be included in the linking operation, and this is an important area for future methodological and applied research.

The finding that a unidimensional model fit the data lends support to the idea that self-perceived cognitive functioning can reasonably be conceptualized as a unitary construct for measurement purposes, regardless of the specific domains tapped by items on a given questionnaire. In fact, in the original criteria set forth by Jessen and colleagues (2014), the authors stated that “cognitive” refers to any cognitive domain and is not restricted to memory. The term cognitive, as opposed to memory, was specifically chosen for the SCD criteria because the first symptoms of AD may not be limited to memory decline, and older adults often report memory decline when they actually experience decline in other cognitive domains such as language or executive functioning and vice versa (e.g., reporting poor memory when the difficulty is actually in language or attention). Additionally, work by van Harten and colleagues (2018) showed that all ECog Self subdomains and multidomain scores (generated from items across cognitive domains) were associated with MCI. In this study, the multidomain score was slightly better than the separate domain scores, lending support to the idea that a general self-perceived cognitive functioning score rather than a specific domain score might be most predictive of underlying neurodegenerative change (van Harten at al., 2018).

Features of Psychometrically Most Robust Items

Examination of the most robust items—those with the lowest SEM/highest information values from the specified ranges of interest—revealed several notable features. Top items in the low self-perceived cognitive functioning (high concern) range almost exclusively related to memory, both general (e.g., memory problems or decline relative to one year or five years ago) and specific (e.g., difficulty remembering conversations, remembering what you intended to, remembering appointments). By contrast, top items in the high self-perceived cognitive functioning (low concern) range assessed various aspects of cognition in addition to memory, most notably executive functioning (e.g., focusing on goals, decision making, shifting between activities, managing a medication schedule) and language (e.g., word finding, self-expression, understanding instructions). Additionally, several items in the low self-perceived cognitive functioning (high concern) range tapped into the consequences of the memory problems (e.g., “Do you feel that your everyday life is difficult now due to your memory decline?”; “Do memory problems make it harder to complete tasks that used to be easy?”), which was not the case for the high self-perceived cognitive functioning (low concern) range. Together these results raise the possibility that different types of items might be most relevant for neuropsychologically intact older adults in different stages of SCD. If this is the case, then ultimately it may be possible to select items based on their ability to distinguish between (or capture concerns most associated with) specific levels of SCD. For example, items from the higher concern range, which focused on memory and included various comparisons and consequences or impact on everyday life, might be most suitable for identifying those at risk for future dementia. By contrast, items from the lower concern range, which related mainly to higher order executive cognitive abilities (e.g., carrying out plans, making decisions, shifting set, being distracted, managing medications) or language (e.g., wording finding, self-expression), might be more suitable for older adults at lower risk of progression to AD. These various possibilities will need to be investigated through prospective data collection and longitudinal follow-up of neuropsychologically intact older adults.

Another finding was that items from the low self-perceived cognitive functioning (high concern) range tended to have fewer response options. Almost all items (14 of 15) were either dichotomous or had three response options (e.g., no; maybe; yes), with the reverse pattern occurring for the high self-perceived cognitive functioning (low concern) range where almost all items (13 of 15) utilized 5- and 7-point Likert-type scales. Follow-up research should determine whether fewer response options accurately capture the experiences of neuropsychologically intact older adults with worse self-perceived cognitive functioning (such as those presenting to a memory clinic). By contrast, a wider range of options may be necessary to adequately assess concerns among those with better self-perceived cognitive functioning, as it may allow these individuals to endorse subtle levels of difficulty or change across time. Given that self-perceived cognitive functioning likely falls along a continuum, Likert-type scales with a sufficient number of response options (i.e., 5 to 7) might be most appropriate to capture variability and change over a broad range of function for this complex construct. There is also research suggesting that rating scales with a small number of response options may be less preferred by respondents (Jones, 1968; Preston &amp; Coleman, 2000), including older adults, who in one study perceived dichotomous scales as being too restrictive (Carp, 1989). Ultimately, the choice of response options will be based on multiple study-specific considerations, including but not limited to the purpose of the measurement and characteristics of the target sample (Lozano et al., 2008).

There were no identical items that appeared as top items in both the low and high concern ranges of interest. Despite this, items that captured the ability to remember appointments—from different questionnaires—appeared in both ranges, suggesting that this specific content warrants inclusion in questionnaires targeting older adults with varying levels of self-perceived cognitive functioning. In addition, prospective memory items (“Remembering what I intended to do”; “Remembering appointments or meetings”) emerged as top items in both self-perceived cognitive functioning ranges. Although most aging studies objectively assess retrospective memory, prospective memory is integral to the maintenance of independent and successful living as it is the cognitive ability that maintains, updates, and monitors our to-do list (Brandimonte et al., 1996). Moreover, failures of prospective memory have important ramifications for older adults’ everyday functioning, emotional well-being, and safety (Kliegel et al., 2016; Mogle et al., 2019; Woods et al., 2012), suggesting a benefit for the inclusion of prospective memory items on questionnaires.

Also, while time referents for top items varied, comparisons to five years ago and the present (including current functioning and the past two weeks) were the most common, and accounted for approximately three quarters of responses, followed by one year ago. Only two items referenced more distant time frames—i.e., high school or college. Based on these results, it may be advisable to avoid items with referents that target the distant past, which could pose difficulties for older adults trying to recall specific instances of remembering or forgetting and lead to inaccurate or biased reports (Cavanaugh et al., 1998; Robinson &amp; Clore, 2002a, 2002b). Another finding was that approximately one third of the top items captured ability, while the majority assessed change. Reporting ability requires appraisal of current status only; reporting change requires appraisal of current and past abilities and contrasting them. The predominance of items that focused on change is consistent with the idea that SCD assesses intraindividual change in cognitive functioning (Jessen et al., 2020).

An important issue is whether our results align with proposed SCD plus features—i.e., characteristics of SCD presumed to be associated with increased risk of cognitive decline (Jessen et al., 2014; 2020). Consistent with the SCD plus framework, we found an overrepresentation of memory items among the top items, compared to other cognitive domains, particularly in the high concern range. Also, while time referents for top items varied, all but two targeted the last five years or a more recent time referent, consistent with the onset of SCD within the last five years. A top item related to worry about memory. This corresponds to the SCD plus feature of worry and with research showing that older adults who express concern or worry about their perceived cognitive difficulties have an increased risk of future objective cognitive decline or dementia (Jessen et al., 2010; St. John &amp; Montgomery, 2002; van Harten et al., 2018; Verfaillie et al., 2019). Although the current study cannot be used to validate the SCD plus concept, results may be used to inform measurement selection in research aimed at refining or expanding SCD plus criteria by suggesting possible items to measure self-perceived cognitive functioning (inclusion of some iteration of the item “I worry about my memory ability”).

Items identified as psychometrically strong should also be considered in relation to previous research and broader trends. Rabin and colleagues (2015) previously identified the 10 most frequently occurring item themes on questionnaires used by participating SCD-I working groups. Items that fell within eight of these previously identified themes (memory change; memory for names of people; general memory problems; losing objects; word finding; remembering appointments; remembering recent conversations; memory for intentions/prospective memory) appeared as top items in the current study. In addition, one of the most frequently occurring self-report items “Compared with one year ago, do you have trouble remembering things?” was identified as a psychometrically poor item in the current analysis. However, a similar item capturing memory change over the same time interval (“Compared with one year ago, do you feel your memory has declined substantially?”) was identified as a psychometrically strong item. These results highlight the need to re-examine items and to consider not only general content and psychometric issues but also nuances in wording and response options when modifying existing questionnaires or designing new ones.

Finally, approximately one-third of our identified top items had stems that would typically be viewed as problematic by virtue of having multiple sub-questions within a single item (Oppenheim, 1992). Some of these items would be considered multi-barreled—i.e., the item asks respondents to rate or respond to two or more different issues while allowing for only one response (Bradburn et al., 2004; Menold, 2020), such as “More trouble recalling names, finding the right word, or completing sentences.” Other top items had stems that inquired about a single aspect of cognition, but were followed by a series of examples, such as “Compared to one year ago, do you have more difficulty managing money (e.g., paying bills, calculating change, completing tax forms)?” Although survey design researchers typically advise against the inclusion of multi-barreled items, which can be confusing or difficult to interpret (DeWalt et al., 2007), they are still frequently used. After analysis of multi-barreled items, Menold (2020) concluded that respondents likely attend to the aspect of the item that is most relevant to them, and that these items did not have inferior reliability, compared to single-barreled questions (Menold, 2020). Additional research would be required to explore how older adults understand and respond to items that are single- versus multi-barreled, and to guide decisions about the inclusion of multi-barreled items in questionnaires targeting this population.

Features of Psychometrically Poor Items

We identified items with poor psychometric properties (Appendix I), which had a few notable features. Some items inquired about issues that may not be highly relevant for most older adults (e.g., “Remembering trivia”). Time referents for some items were very different when compared to those found in psychometrically strong items; two specific time referents, appearing in 6 of 15 items, required ambiguous comparisons (“than you used to be” and “ever before”). Several items referenced very broad or vague areas that may have been difficult to interpret (e.g., “My ability to recall things that happened during my childhood is”; “Are you worried about these complaints”). One had a vague time referent: “Remembering things that happened a long time ago.” Another item was possibly confusing due to the wording: “When I forget to do something I had planned to do, it is usually not because I forgot what I had to do but because I forgot when I had to do it.” Two items came from a measure with a 9-point Likert-type scale, with response options ranging from −4 to +4, which might overwhelm some older adults. Finally, several items inquired about complaints related to the same aspects of cognition that also appear among the top items (language/word finding and attention/concentration), suggesting that older adults may better understand qualifiers such as difficulty, problems, or change (as opposed to complaints) when reporting on their cognitive functioning. Together, these results call attention to the importance of utilizing items with simple, straightforward language, and clear time frames, particularly for older adults (Jobe &amp; Mingay, 1990).

Strengths and Limitations

The current study has notable strengths. The large sample size was undeniably a strength because it diminished sampling variability effects on the population parameter estimates used in the reference study. We included numerous items covering multiple cognitive domains and participants with varying degrees of cognitive concerns. The application of an IRT model to self-perceived cognitive functioning measurement had several advantages. IRT models allow for a variety of data types to be included (Gibbons et al., 2007), and provide an acceptable trait estimate despite the use of non-identical items (Hays et al., 2000). Moreover, IRT can keep item parameters constant even when utilizing different samples (Nguyen et al., 2014) and identify the problematic features of poorly performing items thereby helping researchers avoid these characteristics when developing future items and measures (Hays et al., 2000). IRT is also useful in for implementing CAT, which has the possibility to reduce participant burden during assessments (Bandalos, 2018; Hays et al., 2000). However, items contained in the item bank for the current study cannot be used directly in a CAT without modification due to the vast heterogeneity in important item features (temporal referents, response options, etc.). In addition, although access to and facility with computers is widespread, this may not always be the case in clinical and research settings where diverse older adults are assessed—and fixed-length short forms, which can show strong precision along a trait continuum (Lai et al., 2011) may be useful alternatives.

Several limitations should be noted. Study analyses were specific to the group of items to which we had access, the samples in which they were tested, and the order in which we chose to proceed through our calibration steps. For example, the current study was anchored using the ECog Self measure in the MCSA. Using another measure may have yielded different results and thus, we should consider the current results as preliminary. We chose to evaluate data only from the first occasion that each participant responded to the self-perceived cognitive functioning items. This choice ensured that all data would be independent. Some studies provided multiple waves of data, but others only provided a single wave of data. We could have incorporated all of these data with (much) more complicated models but for this initial work we focused on the simpler one-observation-per-participant data set.

We carried out a small DIF study for the five studies that used the ECog Self (i.e., in a subset of items that were identified as linking items) to assess how the different populations in the different studies would affect the estimation of the item parameters. Importantly, although our results demonstrated that cross-study DIF was present and could be detected at conventional levels of statistical significance, it was responsible for very small impact at the latent trait level. This lends support to the viability of harmonization across studies. Unfortunately, we were not able to carry out DIF testing across different language studies to ensure measurement invariance (or even linguistic equivalence) across different language versions of the questionnaires prior to merging the data. If the same questionnaires were to be used in different studies in different countries or linguistic groups, the approach to DIF analyses would be relatively straightforward. Also, the need for harmonization and co-calibration would be much simpler or unnecessary (in the absence of DIF). However, when different tests or measures are used across studies, to accomplish the harmonization goal we must first identify linking items, which we assume are equivalent (and free from DIF) across country and language. For many cross-study links, the number of linking items was small and not conducive to formal DIF testing.

Relatedly, the geographic and linguistic diversity of our sample, which can be viewed as a strength, also posed challenges in completing the co-calibration, and it placed limits on our ability to use psychometric methods to evaluate the assumptions used to complete the co-calibration activity. In practical terms, while items that were identical or similarly worded (deemed equivalent) may appear well-suited for analyses, subtleties in target languages and cultural differences can lead to participants interpreting and responding differently (Chan et al., 2015). These are important considerations to bear in mind as we use the current results to inform the creation and validation/norming of new self-perceived cognitive functioning questionnaires for use with culturally and linguistically diverse populations. Despite these challenges, we feel that the geographic and linguistic diversity provided inferential strength in the representativeness and generalizability of our results, to the extent that our links were valid. Relatedly, although great effort was made to obtain and include questionnaires and participant data from culturally diverse countries, most of the contributing studies were North American and European; we recognize this as both a limitation and an important future direction. Additionally, diverse study settings were aggregated for the analysis. Given that rates of cognitive concerns are typically lower in population settings (Archer et al., 2015; Jonker et al., 1996), it is possible that conducting the analysis by separating memory clinic and population-based studies may have yielded different results though IRT methods do not require any particular distribution of the underlying trait for calibration.

Finally, we limited our analyses to neuropsychologically intact participants because of the gradual and progressive lack of awareness of cognitive dysfunction that manifests in the middle to late stages of MCI through AD (Galeone et al., 2011; Vogel et al., 2004; Wolfsgruber et al., 2014). We reasoned that the meaning of self-appraisals of cognition in individuals with objective cognitive impairment could be fundamentally different from self-appraisals in those who are neuropsychologically intact—and thus, that separate models might be needed to capture the latent trait in these two populations. By focusing only on neuropsychologically intact individuals, we potentially restricted the range of self-perceived cognitive functioning that could be observed, as reflected by several items with very few responses in the category reflecting the greatest degree of self-perceived cognitive impairment. Nevertheless, there was considerable heterogeneity across neuropsychologically intact older adults in self-perceived cognitive functioning present in each study, including many with significant concerns about how their brains are functioning (while they perform well on objective cognitive tests).

Additional Implications for Scale Construction and Future Directions

An important application of our harmonization effort, and one the field has repeatedly called for, is the utilization of standardized and valid questionnaires (Molinuevo et al., 2017; Röhr et al., 2020). Although our results can be used to inform questionnaire development, it is not possible to create a new questionnaire by simply combining all the items with the smallest SEM within particular ranges. Identification of top items does not imply that if taken together, these items would necessarily result in a reliable and valid questionnaire. Items with psychometric support in the current study necessitate independent validation studies to confirm adequate properties. This validation can use the quality criteria as identified by the Consensus-based Standards for the selection of health Measurement Instruments (COSMIN) approach to quality of measurement (https://www.cosmin.nl), which was developed to standardize the evaluation of clinical outcome assessments. In addition, the top items had widely varying features (temporal referents, response option formats), which would make their combination into a single questionnaire problematic from both content and measurement perspectives. Also, these items may not comprehensively assess the self-perceived cognitive functioning construct and feedback from content experts would be critical. Finally, the unidimensional model may have failed to adequately model non-memory items embedded within questionnaires with predominantly memory items, and future research might revisit and attempt to refine the latent factor using a bifactor model.

In light of these considerations, our immediate next step will be to use our item bank to derive and validate self-perceived cognitive functioning factor scores for existing questionnaires. When validated against relevant outcomes such as objective cognition, biomarkers, and clinical progression, these factor scores will be shared across international studies (Sikkes et al., 2021). After validation of the factor scores, researchers and clinicians from around the globe, who have questionnaire items in common with those from our bank, will be able to derive factor scores for their own participants using our item bank. We also plan to use the current item bank for the construction of targeted questionnaires based on various item features and psychometric considerations. Prior to questionnaire development we plan to carry out focus groups and cognitive interviewing with racial/ethnic and culturally diverse, community-dwelling older adults to enable informed decision making about item content and key aspects of questionnaire structure/design (e.g., temporal referent, number and wording of response options, whether and how to capture change, ability, or both). Also, the input from experts in the SCD field, as well as co-creation with participants experiencing low levels of self-perceived cognitive functioning, is necessary to construct a meaningful questionnaire. Finally, we will refine the new self-perceived cognitive functioning questionnaire(s) based on results of pilot studies, with consideration of reliability and validity evidence.

Conclusions

This study was the first to employ IRT methods to harmonize self-perceived cognitive functioning data across a large number of international studies. In carrying out the analyses, the authors encountered substantial measurement challenges that placed limits on the extent to which assumptions underlying the harmonization could be tested. An implication is that validity tests need to use external variables to further support the use of the resulting item bank. Another immediate future goal is to use the current results to derive screening measures that enable reliable identification of subtle cognitive changes in clinically normal individuals. Such tools can be utilized in multi-study initiatives and may facilitate large-scale screening efforts and targeting of at-risk populations for early intervention and tracking of treatment-related changes.

Acknowledgements

The authors would like to thank the Alzheimer’s Association and the International Society to Advance Alzheimer’s Research and Treatment (ISTAART) Subjective Cognitive Decline Professional Interest Area (SCD-PIA). This research was made possible using the data collected by the Canadian Longitudinal Study on Aging. Funding for the Canadian Longitudinal Study on Aging is provided by the Government of Canada through the Canadian Institutes of Health Research (CIHR) under grant reference LSA 94473 and the Canada Foundation for Innovation, as well as the following provinces, Newfoundland, Nova Scotia, Quebec, Ontario, Manitoba, Alberta, and British Columbia. This research has been conducted using the CLSA dataset [Follow-up 1 Comprehensive Data set version 3.2], under Application Number [2203008]. The opinions expressed in this manuscript are the authors’ own and do not reflect the views of the Canadian Longitudinal Study on Aging.

Appendices

Appendix

Appendix C

Figure 1 Raincloud Plot of Posterior Predictive P-Values (PPP) for Items the Mayo Clinic Study of Aging (MCSA) from a Unidimensional and Bifactor Model

Figure 2 Left. Scatterplot of Factor Score Estimates Under Bifactor (y-axis) and Unidimensional Model (x-axis)

Right. Scatterplot of Differences in Factor Score Estimates as a Function of the Average of the Two Factor Scores

Figure 3 Raincloud Plot of Posterior Predictive P-Values (PPP) for All Items from All Studies from a Unidimensional and Bifactor Model

Appendix D

Number of Studies in which Each of 40 Study Questionnaires was Utilized

Note. The total number of studies = 24 (substudies are not included); please refer to Table 2 for the definition of questionnaire abbreviations.

Appendix A Definitions of ‘Neuropsychologically Intact’ by Participating Studies

Study name	Criteria for defining ‘neuropsychologically intact’	
Alzheimer’s Disease Center Clinical Core and Center for
Brain Health (ADC-NYU)	No objective evidence of memory deficit on clinical interview. Performed normally on the objective portion of the Brief Cognitive Rating Scale, which includes tests of concentration and calculation, memory, orientation, and functional abilities, carried out during the clinical interview.	
	
Alzheimer’s Disease Neuroimaging Initiative (ADNI)	Normal subjects: CDR score = 0; MMSE range 24–30, delayed recall one 1 paragraph from the Logical Memory II subscale of the Wechsler Memory Scale– Revised (maximum score of 25) with cutoffs as follows: ≥9 for 16 years of education, ≥5 for 8–15 years of education, ≥3 for 0–7 years of education.	
	
Amsterdam Dementia Cohort (Ams Dem Cohort)	No objective impairment as judged by a multidisciplinary team in the university memory clinic, based (amongst others) on the neuropsychological evaluation.	
	
Anti-Amyloid Treatment in Asymptomatic Alzheimer’s Study (A4)	Cognitively unimpaired defined by scores &gt;25 on the MMSE and CDR=0.	
	
Australian Imaging Biomarkers and Lifestyle Flagship
Study of Ageing (AIBL)	MMSE scores 27–30; normal performance on Logical Memory; no evidence of significant difficulty on standardized neuropsychological tests of memory, language, attention, executive functioning, and psychomotor speed; CDR =0.	
	
Barcelona Group (Barcelona)	Healthy control participants were volunteers presenting no cognitive decline and normal scores on two screening tests: MMSE and Memory Alteration Test. Also performed in the normal range for age and education on standardized tests of global cognition, verbal and visual episodic memory, visuospatial functioning, language, verbal fluency, working memory, and executive functions.	
	
Bonn Memory Clinic (Bonn)	No cognitive deficit: no score greater than 1.5 SD below age- and education-adjusted norms on at least one subtest of the CERAD-NP battery.	
	
Canadian Longitudinal Study on Aging	Participants were defined as cognitively unimpaired if trained interviewers determined at baseline assessment that they were able to understand the purpose of the study and could provide reliable data. Participants who self-reported at Follow-up 1 that they had received a formal diagnosis of memory problems or dementia by a physician were excluded.	
	
Dartmouth Memory and Aging Study/Indiana Memory and Aging Study (Dart-Indiana)	Objective cognition: scores within 1.5 standard deviations of the mean established for age- and education-matched controls on standardized neuropsychological testing of memory, attention, executive function, language, spatial ability, general intellectual functioning, psychomotor speed, and standard dementia screens.	
	
Einstein Aging Study (EAS) and substudies	No score greater than 1.5 SD below the age-adjusted mean on neuropsychological tests of memory, attention, executive function, visuospatial ability, or language. Tests included: Free and Cued Selective Reminding Test, Logical Memory I from the Wechsler Memory Scale-Revised, Trail Making Test, Digit Span, Letter Fluency, Block Design, Digit Symbol, Category Fluency task (animals, vegetables, and fruits), and the Boston Naming Test.	
	
German Study on Ageing, Cognition, and Dementia in Primary Care Patients (AgeCoDe)	Performed no greater than 1.0 SD below the normative domain scores on the neuropsychological test battery of the Structured Interview for Diagnosis of Dementia of Alzheimer type, Multi-infarct dementia and dementia of other etiology according to DSM-III-R, DSM-IV and ICD-10 (SIDAM).	
	
Harvard Aging Brain Study (HABS)	Cognitively unimpaired: global CDR = 0; MMSE ≥ 27 with educational adjustment (for low education, scores ≥25); and performance in the normal range within education-adjusted norms on the Logical Memory II Delayed Recall Index from the Wechsler Memory Scale.	
	
Health &amp; Aging Brain Study, Health Disparities (HABSHD)	CDR sum of boxes score = 0 and cognitive test scores broadly within normal limits as defined by performance of no more than 1.5 SDs below the mean of the normative range on any neuropsychological test.	
	
Hellenic Longitudinal Investigation of Aging and Diet (HELIAD)	No objective impairment on any cognitive domain (&gt;1.5 SD below age and education expected levels) as part of an extensive neuropsychological battery covering global cognition, verbal and visual memory, visuospatial functioning, language, attention-speed and executive functions.	
	
IMAP Caen Group	Performed in the normal range for age and education on standardized tests of global cognition, verbal and visual episodic memory, visuospatial functioning, language, verbal fluency, working memory, and executive functions.	
	
Indiana Alzheimer’s Disease Center Cohort (IADC)	Without a measurable cognitive deficit.	
	
Leipzig Longitudinal Study of the Aged (LEILA 75+)	Performed no greater than 1.0 SD below the normative domain scores on the neuropsychological test battery of the Structured Interview for Diagnosis of Dementia of Alzheimer type, Multi-infarct dementia and dementia of other etiology according to DSM-III-R, DSM-IV and ICD-10 (SIDAM).	
	
Mayo Clinic Study of Aging (MCSA)	Cognitively unimpaired participants were cognitively and functionally normal as determined by a consensus panel based on clinical and neuropsychological assessment.	
	
Memory Clinic -Fundació ACE (Fundació)	Performed in the normal range for age and education on the standardized Fundació ACE Neuropsychological Battery.	
	
Sydney Memory and Ageing Study (Sydney)	Classified as cognitively normal if performance on all test measures was above the 6.68 percentile (−1.5 SDs) or equivalent score compared to normative published values, controlling for age, sex and education.	
	
University of Pittsburgh Study/ Monongahela-
Youghiogheny Health Aging Team (MYHAT); Pittsburgh (Pitt) Substudy	Cognitively normal: composite scores in all domains within 1.0 standard deviation of the mean for the individual’s age-sex- education group. Domains included attention/processing speed, executive function, language, memory, and visuospatial function) – with a composite score for each domain.	
	
Vanderbilt Memory and Alzheimer’s Center (VMAC)	NACC diagnostic criteria: cognitively unimpaired on neuropsychological tests covering 3 cognitive domains, including memory (Logical Memory I and II, NAB List Learning), executive function (Trail Making Test parts A, B, Digits Backward), and language (Animal Fluency Test, Boston Naming Test).	
	
Victoria Subjective Cognitive Decline Study (Victoria SCDS)	Cognitively intact defined as: scored &gt;136 on the DRS-2 Total Score; no score less than -1.5SD on the delayed recall trials of the CVLT-2; scored &gt; 25/30 on the MMSE-2.	
	
Wisconsin Registry for Alzheimer’s Prevention (WRAP)	Cognitively unimpaired determined in one of two ways as described in Johnson et al. (2018): 1) perform within 2SD on all cognitive tests relative to robust norms accounting for age, sex, WRAT-III reading; 2) individuals were flagged for committee review but determined to be unimpaired after considering all available information.	
Note. Neuropsychologically intact includes individuals with varying levels of self-perceived cognitive functioning difficulties.

Appendix B Sample Equivalent Items

	Measure	Study, Language	Item	Response options	Time frame	
	
Set 1	Multifactorial Memory Questionnaire, MMQ	Bonn Memory Clinic, German	A: Forget a telephone number you use frequently	0=always;	previous two weeks	
				1=often;		
				2= sometimes;		
				3= rarely;		
				4= never		
	Cognitive Difficulties Scale, CDS-Q	IMAP Caen Group, French	B: Trouble recalling frequently used phone numbers	0=never;	lately	
				1=rarely;		
				2=sometimes;		
				3=often;		
				4=very often;		
	
Set 2	Structured Telephone Dementia Assessment, STDA	Harvard Brain Aging Study, English	C: Do you have trouble remembering things from one second to the next?	0=no; 1=yes	current	
	VMAC Cognitive Complaint Questionnaire, VMAC CCQ	Vanderbilt Memory and Alzheimer’s Center, English	D: Do you have trouble remembering things from one moment to the next?	0=no; 1=yes	current	
Note. Highlighted response options (rarely, never) for items A and B in Set 1 were combined for purposes of data harmonization due to the categories having fewer than five respondents (see Data Recoded). In addition, highlighted response options (often, very often) for item B in Set 1 were combined to establish equivalent response categories (see Item Overlap).

Appendix E Number of Linking Items Between Studies

Study	ADC-NYU	ADNI	Ams Dem	A4	AIBL	Barcelona	Bonn	CLSA	Dart-Indiana	EAS	EAS Sub-	EAS Sub-	Age-CoDe	HABS-HD	HABS	HELI-AD	IMAP Caen	IADC	LEILA75+	MCSA	Fundació	Sydney	MYHAT	Pitt Sub-	VMAC	Victoria SCDS	WRAP	
ADC-NYU	4	-	-	4	4	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	4	-	
ADNI	-	60	20	-	-	-	-	-	59	-	-	20	-	-	39	-	-	60	-	40	-	-	-	-	-	-	-	
Ams Dem Cohort	-	20	27	-	-	-	-	-	19	-	-	20	-	-	1	-	-	20	-	-	-	-	-	1	-	-	1	
A4	4	-	-	18	5	-	-	-	1	1	1	-	-	1	-	1	-	-	-	-	-	-	-	-	1	6	-	
AIBL	4	-	-	5	6	-	-	-	-	-	-	-	-	-	-	-	-	-	1	-	-	1	-	-	1	5	1	
Barcelona	-	-	-	-	-	26	1	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	1	-	-	
Bonn	-	-	-	-	-	1	32	20	-	-	-	-	-	-	-	-	3	-	-	-	1	-	-	-	-	-	-	
CLSA	-	-	-	-	-	-	20	21	-	-	-	1	1	-	-	-	2	-	-	-	1	-	-	-	-	-	-	
Dart-Indiana	-	59	19	1	-	-	-	-	173	1	33	19	-	4	39	1	-	59	-	40	-	15	-	-	1	16	-	
EAS	-	-	-	1	-	-	-	-	1	17	4	-	-	1	-	1	-	-	-	-	-	-	-	-	2	1	-	
 EAS Substudy 1	-	-	-	1	-	-	-	-	33	4	121	-	-	1	-	1	-	-	-	-	-	-	-	-	1	33	-	
 EAS Substudy 2	-	20	20	-	-	-	-	1	19	-	-	42	1	-	-	-	-	20	-	-	-	-	-	-	-	-	-	
AgeCoDe	-	-	-	-	-	-	-	1	-	-	-	1	5	1	1	-	-	-	-	-	-	-	-	-	2	-	-	
HABS-HD	-	-	-	1	-	-	-	-	4	1	1	-	1	18	1	1	-	-	-	-	-	-	-	-	11	4	-	
HABS	-	39	1	-	-	-	-	-	39	-	-	-	1	1	93	-	-	39	-	39	-	-	-	48	2	-	34	
HELIAD	-	-	-	1	-	-	-	-	1	1	1	-	-	1	-	15	-	-	-	-	-	-	-	-	2	1	-	
IMAP Caen Group	-	-	-	-	-	-	3	3	-	-	-	-	-	-	-	-	32	-	-	-	2	-	-	-	-	-	-	
IADC	-	60	20	-	-	-	-	-	59	-	-	20	-	-	39	-	-	60	-	40	-	-	-	-	-	-	-	
LEILA75+	-	-	-	-	1	-	-	-	-	-	-	-	-	-	-	-	-	-	1	-	-	1	-	-	1	-	1	
MCSA	-	40	-	-	-	-	-	-	40	-	-	-	-	-	39	-	-	40	-	45	-	-	-	-	-	-	-	
Fundacio	-	-	-	-	-	-	1	1	-	-	-	-	-	-	-	-	2	-	-	-	28	-	-	-	-	-	-	
Sydney	-	-	-	-	1	-	-	-	15	-	-	-	-	-	-	-	-	-	1	-	-	32	-	-	1	-	1	
MYHAT																							17	17	-	-	-	
 Pitt Substudy	-	-	1	-	-	-	-	-	-	-	-	-	-	-	48	-	-	-	-	-	-	-	17	81	-	-	34	
VMAC	-	-	-	1	1	1	-	-	1	2	1	-	2	11	2	2	-	-	1	-	-	1	-	-	51	1	1	
Victoria SCDS	4	-	-	6	5	-	-	-	16	1	33	-	-	4	-	1	-	-	-	-	-	-	-	-	1	53	-	
WRAP	-	-	1	-	1	-	-	-	-	-	-	-	-	-	34	-	-	-	1	-	-	1	-	34	1	-	35	
Average Number of Linking Items a	4.0	39.7	11.7	2.3	2.6	1.0	6.3	5.2	21.9	1.6	10.6	13.5	1.2	2.8	24.3	1.1	2.3	40.0	1.0	40.0	1.3	3.8	17.0	25.0	2.0	7.9	10.4	
Note. Because substudies are included, the total number of studies = 27; Numbers on the diagonal show the number of items administered by a given study.

a Does not include items on the diagonal. The mean number of linking items between studies was 11.1.

Appendix F Number of Studies with which Each Study Shares Linking Items

Study Abbreviation	Number of Studies	
ADC-NYU	3	
ADNI	6	
Ams Dem Cohort	7	
A4	9	
AIBL	7	
Barcelona	2	
Bonn	4	
CLSA	5	
Dart-Indiana	14	
EAS	7	
 EAS Substudy 1	7	
 EAS Substudy 2	5	
AgeCoDe	5	
HABS-HD	9	
HABS	10	
HELIAD	7	
IMAP Caen Group	3	
IADC	6	
LEILA75+	4	
MCSA	4	
Fundació	3	
Sydney	5	
MYHAT	1	
 Pitt Substudy	4	
VMAC	14	
Victoria SCDS	9	
WRAP	7	
Average	6.2	
Note. Because substudies are included, the total number of studies = 27

Appendix G Differences in Mean Level of ECog Self Common Latent Variable Means (and standard errors) Relative to the MCSA Under Assumptions of Measurement Invariance (MI) and Partial Measurement Invariance (N = 5,742)

Study	MI	Partial MI	% Difference	Absolute difference	
	
ADNI	−.580 (.040)	−.569 (.042	2	.011	
Dart-Indiana	−.329 (.191)	−.317 (.193)	4	.012	
HABS	−.103 (.049)	−.121 (.064)	17	.018	
IADC	−.171 (.078)	−.139 (.079)	19	.032	
Note. Entries under MI report the estimated mean difference (and standard error) for the named study relative to the MCSA from a model that assumes measurement invariance (i.e., no DIF). Entries under Partial MI reported estimated mean differences from a model that allows for some items to have DIF across study.

Appendix H 15 Items with the Smallest SEM in the Range of -1 to 0

	Questionnaire abbreviation	Cognitive domain	Item stem	Response optionsa	Temporal referent	Ability versus change	SEM; Information	
1.	VMAC CCQ	memory	Do you think you have problems with your memory?b	no; yes	current	A	0.32; 9.93	
	
2.	CFI	memory	Compared to one year ago, do you feel that your memory has declined substantially?b	no; maybe; yes	one year ago	C	0.37; 7.45	
	
3.	VMAC CCQ	memory	Do you have problems with your memory compared to the way it was 5 years ago?b	no problems; some minor problems; major problems	5 years ago	C	0.39; 6.53	
	
4.	CFI	memory	Have you been misplacing things more often?d	no; maybe; yes	one year ago	C	0.39; 6.49	
	
5.	CFI	language	Do you have more trouble recalling names, finding the right word, or completing sentences?c	no;
maybe; yes	one year ago	C	0.40; 6.26	
	
6.	CFI	memory	Do you find that you are relying more on written reminders (e.g., shopping lists, calendars)?c	no;
maybe; yes	one year ago	C	0.42; 5.71	
	
7.	VMAC CCQ	memory	Do you have difficulty remembering a conversation from a few days agob	no; yes	current	A	0.42; 5.69	
	
8.	VMAC CCQ	memory	Overall, do you feel you can remember things as well as you used to?d	no; yes	unclear	C	0.42; 5.65	
	
9.	VMAC CCQ	memory	Do you have complaints about your memory in the last 2 years?b	no; yes	past 2 years	A	0.43; 5.50	
	
10.	ADL Abbrev	memory	Remembering what I intended to dob	much better; slightly better;	5 years ago	C	0.43; 5.37	
				no change;				
				slightly worse, slightly to moderately worse; much worsea				
	
11.	CFI	executive	Compared to one year ago, do you have more difficulty managing money (e.g., paying bills, calculating change, completing tax forms)?b	no; maybe; yes	one year ago	C	0.43; 5.35	
	
12.	VMAC CCQ	memory	Do you think that your memory is worse than 5 years ago?d	no; yes	5 years ago	C	0.45; 5.00	
	
13.	VMAC CCQ	memory	Do you lose objects more often than you did previously?b	no; yes	unclear	C	0.45; 4.87	
	
14.	CFI	attention	Do you have more trouble following the news, or the plots of books, movies, or TV shows?b	no; maybe; yes	one year ago	C	0.46; 4.78	
	
15.	HELIAD SCI	memory	Do you have difficulty remembering things that you just read or heard?b	no problems; problems	current	A	0.46; 4.70	
a Highlighted response options were combined for purposes of data harmonization due to the categories having fewer than five respondents.

b Item also found among the top 15 items within the -2 to -1 range (n= 10 in total)

c Item also found among the top 15 items within the 0 to 1 range (n = 2 in total)

d Item not found among the top 15 items for either the -2 to -1 range or 0 to 1 range (n = 3 in total)

Note. SEM = Standard Error of Measurement; CFI = Cognitive Function Index; ADL = Activities of Daily Living Rating Scale Self-Version; HELIAD SCI = HELIAD Subjective Cognitive Items; MAC-Q (a) = Memory Complaint Questionnaire; MMQ = Multifactorial Memory Questionnaire; VMAC CCQ = Vanderbilt Memory and Alzheimer’s Center Cognitive Complaint Questionnaire.

Appendix I 15 Items with the Highest SEM in the Range of −4 to +4

	Questionnaire abbreviation	Cognitive domain	Item stem	Response optionsa	Temporal referent	Ability versus change	SEM; Information	
1.	IQCODE – Short	executive	Handling money for shopping	much improved; bit improved;b	compared with 10 years ago	C	73.40; 0.00	
				not much change; a bit worse; much worse				
	
2.	CAPM-C	memory	When I forget to do something I had planned to do, it is usually not because I forgot what I had to do but because I forgot when I had to do it	strongly disagree; disagree;	current	A	13.79; 0.01	
				agree; strongly agree				
	
3.	Einstein HSA	memory	Compared with one year ago, do you have trouble remembering things?	less often; about the same; more often	compared with one year ago	C	10.22; 0.01	
	
4.	MIA	memory	I am poor at remembering trivia	disagree; strongly disagree;	current	A	8.14; 0.02	
				undecided;				
				strongly agree agree				
	
5.	Squire	memory	My ability to recall things that happened during my childhood is	better than ever before; almost better than ever before; slightly more of a change a little bit of a change;	“ever before”	C	7.84; 0.02	
				no change;				
				almost no change; slightly worse than ever before; a little worse than ever before; worse than ever before				
	
6.	Ams Dem Cohort CC	general	Are you worried about these complaints?	no; yes	current	A	7.33; 0.02	
	
7.	SCCS	orientation	Remembering what day/date/month it is?	better; worse; the same;	“than you used to be”	C	6.81; 0.02	
	
8.	MATS	memory	Any other problems with your memory?	no; yes	current	A	6.04; 0.03	
	
9.	Squire	memory	My ability to recall things that happened a long time ago is	better than ever before; almost better than ever before; slightly more of a change; a little bit of a change;	“ever before”	C	5.76; 0.03	
				no change;				
				almost no change; slightly worse than ever before; a little worse than ever before; worse than ever before				
	
10.	SCCS	memory	Remembering where you’ve put things that you use often? (keys, watch, glasses, etc.)	better; the same; worse	“than you used to be”	C	5.71; 0.03	
	
11.	Ams Dem Cohort CC	language	Do you have complaints about language or difficulty finding the right words?	no; yes	current	A	5.54; 0.03	
	
12.	CFQ	language	Do you find yourself suddenly wondering whether you’ve used a word correctly?	never; very rarely;	in the past 6 months	A	5.43; 0.03	
				occasionally; quite often; very often;				
	
13.	Ams Dem Cohort CC	attention	Do you have complaints about your attention and concentration?	no; yes	current	A	5.41; 0.03	
	
14.	SCCS	memory	Remembering things (events, people, etc.) from a long time ago?	better; the same; worse	“than you used to be”	C	5.33; 0.04	
	
15.	SCCS	memory	Finding the right word to use to describe something you know well? (names of familiar objects etc., not names of people)	better; the same; worse	“than you used to be”	C	5.04; 0.04	
a Highlighted response options were combined for purposes of data harmonization due to the categories having fewer than five respondents.

Note. Ams Dem Cohort CC = Amsterdam Dementia Cohort, subjective cognitive concerns screener; CAPM-C = Comprehensive Assessment of Prospective Memory- Section C; CFQ = Cognitive Function Index; Einstein HSA = Albert Einstein Health Self- Assessment; IQCODE – Short = Short Form of the Informant Questionnaire on Cognitive Decline in the Elderly, self-report version; MATS = Memory and Aging Telephone Screen; MIA = Metamemory in Adulthood Questionnaire; SCCS = Subjective Cognitive Complaint Scale-also called the Subjective Memory Scale; Squire = Squire Memory Self-Rating Questionnaire.

Figure 1 Sequence of Data Coding and Analytic Procedures

Figure 2 Overlap Among Self-Perceived Cognitive Functioning Items Across Studies

Figure 2 displays the overlap between self-perceived cognitive functioning items in the studies (including substudies) and shows how the different SCD-I working group studies and items are linked together. In the top panel, the bars/dots represent items administered within a study. The bottom panel displays additional detail for the portion of the top panel enclosed in a gray rectangle. Overall, the figure reveals very little item overlap across studies and no single item represented across all studies.

Note. The figure displays 27 instead of 24 studies because the EAS Substudy 1, EAS Substudy 2 and Pitt Substudy were linked separately from EAS and University of Pittsburgh/MYHAT studies. Please refer to Table 1 for the definitions of the study abbreviations. Please refer to Table 2 for information about study items and questionnaires.

Figure 3 Item Information Plots

Figure 3 presents the item information plots for the 601 items included in the analysis. Items presented in blue have the highest information in the ranges of interest (-2 to -1 SDs and 0 to +1 SDs), and these are the items presented in Tables 4a and 4b. All remaining items are illustrated with gray lines.

Table 1 Key Features of Participating Studies

Study name (Abbreviation)	Institutional affiliation(s)	Country (Language)	Research environment	Number of participants: neuropsychologically intact / total	Number of questionna ires	Final usable number of items	
	
1.	Alzheimer’s Disease Center Clinical Core and Center for Brain Health (ADC-NYU)	New York University School of Medicine	United States (English)	Volunteer	245 / 788	1	4	
2.	Alzheimer’s Disease Neuroimaging Initiative (ADNI)	Over 100 international affiliates:
http://adni.loni.usc.edu	United States
Canada
Australia
Germany
United Kingdom
(English;
German)	Volunteer and memory clinic	938 / 1,729	2	60	
3.	Amsterdam Dementia Cohort (Ams Dem Cohort)	VU University Medical Center	Netherlands
(Dutch)	Memory clinic	569 / 569	3	27	
4.	Anti-Amyloid Treatment in Asymptomatic Alzheimer’s Study (A4)	Multiple sites across the United States, Canada, and Japan:
https://a4study.org/locations/	United States
Canada
Japan
(English;
Spanish;
Japanese)	Community-based	5,667 / 6,945	3	18	
5.	Australian Imaging Biomarkers and Lifestyle Flagship Study of Ageing (AIBL)	University of Melbourne	Australia
(English)	Volunteer and physician referred	595 / 851	2	6	
6.	Barcelona Group (Barcelona)	IDIBAPS, Hospital Clinic, Barcelona	Spain
(Spanish)	Volunteer and memory clinic	186 / 186	1	26	
7.	Bonn Memory Clinic (Bonn)	University of Bonn and the German Center for Neurodegenerative Diseases, Bonn	Germany
(German)	Memory clinic	121/ 121	1	32	
8.	Canadian Longitudinal Study on Aging (CLSA)	Multiple sites across Canada: https://www.clsa-elcv.ca	Canada (English; French)	Population-based	27,229 / 27,760	2	21	
9.	Dartmouth Memory and Aging Study/Indiana Memory and Aging Study (Dart-Indiana)	Dartmouth Medical School, Indiana University School of Medicine	United States (English)	Volunteer and physician referral	141 / 271	8	173	
10.	Einstein Aging Study (EAS)	Albert Einstein College of Medicine	United States (English)	Community-based	1,399 / 1,953	3	17	
	EAS Substudy 1a				224 / 258	7	121	
	EAS Substudy 2				292 / 447	1	41	
11.	German Study on Ageing, Cognition, and Dementia in Primary Care Patients (AgeCoDe)	University of Bonn and 5 other German universities	Germany
(German)	General practice registry-based	2,422 / 3,327	2	5	
12.	Health and Aging Brain Study, Health Disparities (HABS-HD)	University of North Texas Health Science Center	United States (English)	Community-based	1,842 / 2,370	2	18	
13.	Harvard Aging Brain Study (HABS)	Harvard Medical School, Brigham and Women’s Hospital and Massachusetts General Hospital	United States (English)	Volunteer	237 / 237	3	93	
14.	Hellenic Longitudinal Investigation of Aging and Diet (HELIAD)	Aiginition Hospital, National and Kapodistrian University of Athens Medical School	Greece
(Greek)	Population-based	1,550 / 1,943	3	15	
15.	IMAP Caen Group	Inserm, University and Hospital of Caen	France
(French)	Memory clinic	123 / 209	1	32	
16.	Indiana Alzheimer’s Disease Center Cohort (IADC)	Indiana Alzheimer Disease Center; Indiana University School of Medicine	United States (English)	Memory clinic	226 / 350	2	60	
17.	Leipzig Longitudinal Study of the Aged (LEILA 75+)	University of Leipzig	Germany
(German)	Population-based	732 / 1,692	1	1	
18.	Mayo Clinic Study of Aging (MCSA)	MCSA	United States (English)	Community-based	4,200 / 4,200	2	45	
19.	Memory Clinic -Fundació ACE (Fundació)	Fundació ACE Barcelona Alzheimer Treatment and Research Center	Spain
(Spanish)	Community-based	132 / 201	1	28	
20.	Sydney Memory and Ageing Study (Sydney)	University of New South Wales	Australia
(English)	Community-based	504 / 873	3	32	
21.	University of Pittsburgh Study/ Monongahela-	University of Pittsburgh	United States (English)	Clinic-community
volunteer	1,916 / 1,916	1	17	
	Youghiogheny Health Aging Team (MYHAT)			sample and population- based	101 / 174		81	
	Pittsburgh (Pitt) Substudyb					3		
22.	Vanderbilt Memory and Alzheimer’s Center (VMAC)	Vanderbilt University School of Medicine	United States (English)	Memory clinic, physician referral, and community- based	115 / 191	1	51	
23.	Victoria Subjective Cognitive Decline Study (Victoria SCDS)	University of Victoria	Canada
(English)	Volunteer	42 / 42	4	53	
24.	Wisconsin Registry for Alzheimer’s Prevention (WRAP)	University of Wisconsin- Madison	United States (English)	Community-based	1,282 / 1,538	2	35	
	
TOTAL (including substudies)				53,030 / 61,141	65	1,112	
a A subset of participants (n = 260) received all seven questionnaires (ADL Abbrev, BRIEF-A, CAPM-C, CERAD-self, Einstein HSA, GDS Short, MIA); the remaining participants received three questionnaires (Einstein HSA, CERAD-self, GDS Short).

b A subset of participants from the University of Pittsburgh (Pitt Substudy, n = 174) received all three questionnaires (MFQ, CFQ, SCCS); the remaining participants (from the MYHAT study) received one questionnaire (SCCS).

Table 2 Key Features of Questionnaires Used by Participating Studies

Questionnaire/Item abbreviation	Questionnaire/Item full name	Study abbreviation(s)	References	Total number of original items	Number (percentage) of items relevant for analysisa	Final number of items retained	
	
1.	ADL	Activities of Daily Living Rating Scale Self-Version	Dart-Indiana	Saykin, 1992	63	33 (52%)	33 (52%)	
2.	ADL
Abbrev	Activities of Daily Living Rating Scale Self-Version, Abbreviated	EAS Substudy 1	Saykin, unpublished	50	45 (90%)	43 (86%)	
3.	AgeCoDe
MQ	AgeCoDe Study Memory Questions	AgeCoDe	Jessen et al., 2007	2	2 (100%)	1 (50%)	
4.	AIBL
Screen	Melbourne Australian Imaging Biomarkers and Lifestyle Flagship Study of Ageing, Memory Screen Item	AIBL	Ellis et al., 2009	1	1 (100%)	1 (100%)	
5.	Ams Dem Cohort CC	Amsterdam Dementia Cohort, subjective cognitive concerns screener	Ams Dem Cohort	van der Flier &amp; Scheltens, 2018	5	5 (100%)	5 (100%)	
6.	Blessed
FAQ	Blessed Functional Activities Scale	HELIAD	Blessed et al., 1968	8	6 (75%)	6 (75%)	
7.	BRIEF-A	Behavioral Rating Inventory of Executive Function- Adult Version	Dart-Indiana; EAS Substudy 1	Roth et al., 2005	75	36 (48%)	32 (43%)	
8.	CAPM-C	Comprehensive Assessment of Prospective Memory- Section C	EAS Substudy 1	Chau et al., 2007	15	13 (87%)	10 (67%)	
9.	CCI	Cognitive Change Index	ADNI; Ams Dem Cohort; Dart- Indiana; IADC	Rattanabannakit et al., 2016; Saykin et al., 2006	20	20 (100%)	20 (100%)	
10.	CCI-40	Cognitive Change Index - extended 40 item version	EAS Substudy 2	Nester et al., 2022 [forthcoming]	41	41 (100%)	41 (100%)	
11.	CDS-Q	Cognitive Difficulties Scale	IMAP Caen Group	McNair &amp; Kahn, 1983	39	33 (85%)	32 (82%)	
12.	CERAD-self	Consortium to Establish a Registry for Alzheimer’s Disease- Self version	EAS/EAS Substudy 1	Morris et al., 1989	36	22 (61%)	12 (33%)	
13.	CFI	Cognitive Function Instrument, Self Report	A4	Amariglio et al., 2015a	15	12 (80%)	12 (80%)	
14.	CFQ	Cognitive Failures Questionnaire	Pitt Substudy	Broadbent et al., 1982	25	17 (68%)	11 (44%)	
15.	CLSA
SCD/worry	Canadian Longitudinal Study in Aging, SCD/worry item	CLSA	Raina et al., 2009; 2019	1	1 (100%)	1 (100%)	
16.	ECog Self	Everyday Cognition- Subject/Self-Report	ADNI; Dart- Indiana; HABS; IADC; MCSA	Farias et al., 2008	40	40 (100%)	40 (100%)b	
17.	Einstein
HSA	Albert Einstein Health SelfAssessment	EAS/EAS Substudy 1	Derby et al., 2013	20	6 (30%)	4 (20%)	
18.	GDS Long	Geriatric Depression Scale - long version	Dart-Indiana; Victoria SCDS; HABS-HD	Yesavage et al., 1982	30	4 (13%)	4 (13%)	
19.	GDS Short	Geriatric Depression Scale - short version	A4; EAS/EAS Substudy 1; HELIAD	Sheikh &amp; Yesavage, 2005	15	1 (7%)	1 (7%)	
20.	HELIAD
SCI	HELIAD Subjective Cognitive Items	HELIAD	Margioti et al., 2020	7	7 (100%)	7 (100%)	
21.	IQCODE
Short	Short Form of the Informant Questionnaire on Cognitive Decline in the Elderly, self-report version	Dart-Indiana;
Sydney	Jorm, 1994	16	15 (94%)	15 (94%)	
22.	LEILA 75+ Questions	Leipzig Longitudinal Study of the Aged Questionnaire	LEILA 75+	Luck et al., 2010	4	4 (100%)	1 (25%)	
23.	MAC-Q (a) d	Memory Complaint Questionnaire	A4; AIBL; ADC- NYU; Victoria SCDS	Riedel-Heller et al., 1999	6	6 (100%)	5 (83%)	
24.	MAC-Q (b)	Memory Complaint Questionnaire	Sydney	Crook et al., 1992	6	6 (100%)	5 (183%)	
25.	MATS	Memory and Aging Telephone Screen	Dart-Indiana; Victoria SCDS	Rabin et al., 2007	13	13 (100%)	12 (92%)	
26.	MCSA
Blessed	Mayo Clinic Study of Aging, adapted Blessed Memory scale	MCSA	Blessed et al., 1968; van Harten et al., 2018	6	5 (83%)	5 (83%)	
27.	MFE-30	Memory Failures Everyday	Fundacio	Lozoya-Delgado et al., 2012	30	29 (97%)	26 (87%)	
28.	MFQ	Memory Functioning Questionnaire	HABS; Pitt Substudy; WRAP	Gilewski et al., 1990	63, 64, or 54d	49 (78%); 50 (78%); or 39 (72%)	48 (78%); 49 (78%); or 35 (90%)	
29.	MIA	Metamemory in Adulthood Questionnaire	EAS Substudy 1; Victoria SCDS	Dixon et al., 1988	108	35 (32%)	32 (30%)	
30.	MMQ	Multifactorial Memory Questionnaire	Bonn Memory Clinic; CLSA	Troyer &amp; Rich, 2002	57; 20e	32 (56%)	32 (56%)	
31.	SCCS	Subjective Cognitive Complaint Scale-also called the Subjective Memory Scale	MYHAT; Pitt Substudy	Ganguli et al., 2010	30	27 (90%)	21 (70%)f	
32.	SCD-Q: Part 1 MyCog	Subjective Cognitive Decline Questionnaire: Part 1 My Cognition	Barcelona Group	Rami et al., 2014	27	26 (96%)	26 (96%)	
33.	SMCQ	Subjective Memory Complaints Questionnaire	HABS-HD	Youn et al., 2009; O’Bryant et al., 2022	14	14 (100%)	14 (100%)	
34.	Amsterdam
SCF	Subjective Cognitive Functioning	Ams Dem Cohort	Aalten et al., 2014	4	2 (50%)	1 (25%)	
35.	SMDS	Subjective Memory Decline Scale	AgeCoDe	Jorm et al., 2001	4	4 (100%)	4 (100%)	
36.	Squire	Squire Memory Self-Rating Questionnaire	Dart-Indiana	Squire et al., 1979	18	18 (100%)	18 (100%)	
37.	STDA	Adapted from Structured Telephone Dementia Assessment	HABS	Go et al., 1997	7	7 (100%)	6 (86%)	
38.	Sydney- SCQ Wave 1	Sydney Subjective Complaint Questions, Wave 1	Sydney	Slavin et al., 2010	18	16 (89%)	12 (66%)	
39.	VMAC
CCQ	Vanderbilt Memory and Alzheimer’s Center Cognitive Complaint Questionnaire	VMAC	Gifford et al., 2014	57	56 (98%)	51 (90%)	
40.	WRAP
Memory
Item	Wisconsin Registry for Alzheimer’s Prevention, Memory Problem Item	WRAP	Nicholas et al., 2017	1	1 (100%)	1 (100%)	
	
	TOTAL				963 g	690 h	635 i	
a Items relevant for the current analysis relate to the self-perceived cognitive functioning (see Methods and Results for details about eliminated items).

b In the HABS study, data were available for 39 of 40 ECog Self items.

c The MAC-Q was separated into versions a and b because of different timeframes referenced (high school or college for A4, AIBL, NYU, and Victoria SCDS studies versus five years ago for the Sydney study). Also, the ADC-NYU version of the MAC-Q contains a different item stem for item 4, which was not used in the current study (bringing the total number of MAC-Q items to one less for the NYU study).

d The Pitt Substudy, HABS, and WRAP study versions of the MFQ contain 64, 63, and 54 items, respectively.

e The MMQ has three subscales, of which the CLSA only includes one (i.e., Memory mistakes scale with 20 items).

f In the University of Pittsburgh MYHAT study, data were available for 17 of the 21 SCCS items.

g This total exclude 35 items from the CCI and GDS Short, as items from these questionnaires also appear on the lengthier versions of these questionnaires.

h This total excludes 21 items from the CCI and GDS Short, as items from these questionnaires also appear on the lengthier versions of these questionnaires.

i This total includes the 49-item version of the MFQ.

Table 3 Percentage of 601 Items Within Each of Eight Cognitive Domains

Cognitive domain	Number of items (Percentage)	Description	
	
memory	344 (57%)	includes short-term/long-term/episodic/semantic/prospective memory, and learning new information	
executive
function	97 (16%)	includes organizing, planning, switching, initiating, multi-tasking, reasoning, judgment, problem solving, decision-making, handling emergencies, impulsivity and self-regulation, clarity of mind, learning or operating machinery, handling money, and self-awareness of problems	
attention
working memory processing speed	63 (10%)	includes basic attention, sustained attention, focused attention, concentration, divided attention, and alertness	
language	52 (9%)	includes expressive and receptive language, word finding, reading, and spelling	
visuospatial skills	23 (4%)	includes visuoperception, route finding, and directional orientation	
orientation	9 (2%)	includes orientation to person, time, place, or situation	
calculation	7 (1%)	includes basic calculation and arithmetic tasks	
general cognitive ability	6 (1%)	includes memory and other thinking abilities grouped together in a single item	

Table 4a 15 Items with the Smallest SEM in the Range of -2 to -1

	Questionnaire abbreviation	Cognitive domain	Item stem	Response optionsa	Temporal referent	Ability versus change	SEM; Information	
1.	VMAC CCQ	memory	Do you think you have problems with your memory?	no;
yes	current	A	0.37; 7.20	
	
2.	VMAC CCQ	memory	Do you have problems with your memory compared to the way it was 5 years ago?	no problems; some minor problems; major problems	compared to 5 years ago	C	0.39; 6.53	
	
3.	VMAC CCQ	memory	Do you feel that your everyday life is difficult now due to your memory decline?	no;
yes	current	A	0.42; 5.65	
	
4.	VMAC CCQ	memory	Do you have difficulty remembering a conversation from a few days ago?	no;
yes;	current	A	0.42; 5.56	
	
5.	ADL Abbrev	memory	Remembering what I intended to do	much better; slightly better; no change;	ability compared to 5 years ago	Cb	0.43; 5.29	
				slightly worse;				
				slightly to moderately worse; moderately worse; much worseb				
	
6.	CFI	executive	Compared to one year ago, do you have more difficulty managing money (e.g., paying bills, calculating change, completing tax forms)?	no;
maybe;
yes;	compared to one year ago	C	0.44; 5.27	
	
7.	CFI	memory	Compared to one year ago, do you feel that your memory has declined substantially?	no;
maybe;
yes;	compared to one year ago	C	0.44; 5.09	
	
8.	HELIAD SCI	memory	Do you have difficulty
remembering things that you just read or heard?	no problems; problems	current	A	0.46; 4.69	
	
9.	CFI	attention	Do you have more trouble following the news or the plots of books, movies, or TV shows?	no;
maybe;
yes;	with reference to one year ago	C	0.47; 4.46	
	
10.	SMCQ	memory	Do you have difficulty in remembering an appointment made a few days ago?	no;
yes	current	A	0.48; 4.41	
	
11.	VMAC CCQ	memory	Do memory problems make it harder to complete tasks that used to be easy?	no;
yes	current	A	0.48; 4.39	
	
12.	VMAC CCQ	memory	Do you consider your own memory to be worse than others that are your same age?	no;
yes	current	A	0.48; 4.26	
	
13.	VMAC CCQ	memory	Do you have complaints about your memory in the last 2 years?	no;
yes	in the last 2 years	A	0.49; 4.17	
	
14.	VMAC CCQ	memory	Do you lose objects more often than you did previously?	no;
yes	current	C	0.49; 4.13	
	
15.	CFI	visuospatial	Are you more likely to become disoriented, or get lost, for example when traveling to another city?	no;
yes	one year ago	C	0.50; 3.94	
a Highlighted response options were combined for purposes of data harmonization due to the categories having fewer than five respondents.

b The ADL Abbrev scale uses a time referent of compared to 5 years ago to capture current ability level on certain tasks, skills, or problem areas in relation to previous ability. As such, even though labeled as “C”, indicating that it assesses change, the ADL Abbrev also taps into ability.

Note. SEM = Standard Error of Measurement; ADL Abbreviated = Activities of Daily Living Rating Scale Self-Version, Abbreviated; CFI = Cognitive Function Index; HELIAD SCI = HELIAD Subjective Cognitive Items; SMCQ = Subjective Memory Complaints Questionnaire; VMAC CCQ = Vanderbilt Memory and Alzheimer’s Center Cognitive Complaint Questionnaire

Table 4b 15 Items with the Smallest SEM in the Range of 0 to +1

	Questionnaire abbreviation	Cognitive domain	Item stem	Response optionsa	Temporal referent	Ability versus change	SEM; Information	
1.	ADL Abbrev	executive	Focusing on goals or carrying out a plan	much better; slightly better;b	ability compared to 5 years ago	Cb	0.50; 4.08	
				no change;				
				slightly worse slightly to moderately worse; moderately worse; much worse				
	
2.	CFI	language	Do you have more trouble recalling names, finding the right word, or completing sentences?	no;
maybe;
yes;	reference to one year ago	C	0.52; 3.77	
	
3.	ADL Abbrev	memory	Remembering appointments or meetings	much better; slightly better;	ability compared to 5 years ago	C	0.54; 3.48	
				no change;				
				slightly worse slightly to moderately worse; moderately worse; much worse				
	
4.	MMQ	memory	I worry about my memory ability	strongly disagree; disagree; undecided; agree; strongly agree	feelings over the past two weeks	A	0.55; 3.29	
	
5.	ADL Abbrev	attention	Remaining on task and not getting distracted by external stimuli	much better; slightly better;	ability compared to 5 years ago	C	0.57; 3.03	
				no change;				
				slightly worse slightly to moderately worse; moderately worse; much worse	ability compared to 5 years ago	C	0.57; 3.03	
	
6.	ADL Abbrev	executive	Shifting easily from one activity to the next	much better; slightly better;	ability compared to 5 years ago	C	0.60; 2.75	
				no change; slightly worse;				
				slightly to moderately worse; moderately worse; much worse				
	
7.	ADL Abbrev	executive	Making decisions on everyday matters	much better; slightly better;	ability compared to 5 years ago	C	0.61; 2.65	
				no change;				
				slightly worse; slightly to moderately worse; moderately worse; much worse				
	
8.	MAC-Q (a)	memory	Remembering
specific facts from a newspaper or magazine article you have just finished reading	much better now; somewhat better now;	as compared to high school or college	C	0.62; 2.63	
				about the same; somewhat poorer no much poorer now				
	
9.	MAC-Q (a)	memory	Remembering the name of a person just introduced to you	much better now; somewhat better now; about the same;	as compared to high school or college	C	0.62; 2.59	
				somewhat poorer now; much poorer now				
	
10.	CFI	memory	Compared to one year ago, do you find that you are relying more on written reminders (e.g., shopping lists, calendars)?	no; maybe;
yes;	reference to one year ago	C	0.62; 2.59	
	
11.	ADL Abbrev	executive	Reasoning through a complicated problem	much better; slightly better; no change; slightly worse;	ability compared to 5 years ago	C	0.63; 2.56	
				slightly to moderately worse; moderately worse; much worse				
	
12.	ADL Abbrev	language	Expressing myself through speech	much better; slightly better;	ability compared to 5 years ago	C	0.63; 2.54	
				no change; slightly worse slightly to moderately worse;				
				moderately worse; much worse				
	
13.	ADL Abbrev	executive	Organizing and managing my medication schedule	much better; slightly better; no change;	ability compared to 5 years ago	C	0.63; 2.54	
				slightly worse; slightly to moderately worse; moderately worse; much worse				
	
14.	ADL Abbrev	language	Understanding instructions or directions	much better; slightly better;	ability compared to 5 years ago	C	0.63; 2.54	
				no change;				
				slightly worse; slightly to moderately worse; moderately worse; much worse				
	
15.	ADL Abbrev	calculation	Handling everyday arithmetic problems
(knowing how much food to buy, how long it’s been between visits from family and friends)	much better; slightly better;	ability compared to 5 years ago	C	0.63; 2.49	
				no change; slightly worse; slightly to moderately worse; moderately worse; much worse				
				slightly worse; slightly to moderately worse; moderately worse; much worse				
a Highlighted response options were combined for purposes of data harmonization due to the categories having fewer than five respondents.

b The ADL Abbrev scale uses a time referent of compared to 5 years ago to capture current ability level on certain tasks, skills, or problem areas in relation to previous ability. As such, even though labeled as “C”, indicating that it assesses change, the ADL Abbrev also taps into ability.

Note. SEM = Standard Error of Measurement; ADL Abbreviated = Activities of Daily Living Rating Scale Self-Version, Abbreviated; CFI = Cognitive Function Index; MAC-Q (a) = Memory Complaint Questionnaire; MMQ = Multifactorial Memory Questionnaire.

Key Points

Question:

Can item response theory be used to link questionnaires of self-perceived cognitive functioning with varied item properties?

Findings:

We harmonized and identified the psychometric properties of 601 self-report items from 40 different questionnaires of 24 aging studies in a secondary data analysis that used an IRT item banking approach.

Importance:

Resulting item scores were on the same metric, facilitating joint or pooled analyses across international aging studies; item data also may be useful to investigators proposing to measure self-perceived cognitive functioning in clinical and research settings.

Next Steps:

Future research will utilize the current results to develop new questionnaires and to determine associations of self-perceived cognitive functioning with relevant outcomes in the context of aging and dementia research.

In addition to the authors above, data were obtained from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, numerous investigators within ADNI (in addition to those listed above) contributed to the design and implementation of ADNI and/or provided data but did not participate in the analysis or writing of this specific manuscript. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf

In addition to the authors above, data were obtained from the Anti-Amyloid Treatment in Asymptomatic Alzheimer’s study (A4) (https://a4study.org). The A4 Study included older individuals (ages 65–85) who have normal thinking and memory function but who may be at risk for memory loss due to AD. The A4 Study is coordinated by the University of Southern California Alzheimer’s Therapeutic Research Institute, with study sites in multiple locations.

HABS-HD MPIs include: Sid E O’Bryant, Kristine Yaffe, Arthur Toga, Robert Rissman, &amp; Leigh Johnson; and the HABS-HD Investigators: Meredith Braskie, Kevin King, James R. Hall, Melissa Petersen, Raymond Palmer, Robert Barber, Yonggang Shi, Fan Zhang, Rajesh Nandy, Roderick McColl, David Mason, Bradley Christian, Nicole Philips, Stephanie Large, and Rocky Vig.

Conflict of Interest

SCJ serves on an advisory boards to Roche Diagnostics, Prothena, and Eisai in the past two years and has received research support from Cerveau Technologies. JLM is a full time employee at H. Lundbeck A/S. RCP is a consultant for Roche, Inc., Merck, Inc., Biogen, Inc., Genentech, Inc., Eisai, Inc., and Nestle, Inc. PSS was a Member of Advisory Committees for Biogen Australia and Roche Australia in 2020 and 2021. AJS receives support from multiple NIH grants (P30 AG010133, P30 AG072976, R01 AG019771, R01 AG057739, U19 AG024904, R01 LM013463, R01 AG068193, T32 AG071444, and U01 AG068057 and U01 AG072177). He has also received support from Avid Radiopharmaceuticals, a subsidiary of Eli Lilly (in kind contribution of PET tracer precursor); Bayer Oncology (Scientific Advisory Board); Eisai (Scientific Advisory Board); Siemens Medical Solutions USA, Inc. (Dementia Advisory Board); NIH NHLBI (MESA Observational Study Monitoring Board); Springer-Nature Publishing (Editorial Office Support as Editor-in-Chief, Brain Imaging and Behavior). NS is Chair of the Data Safety Monitoring Board for an NIH funded study at The Albert Einstein College of Medicine. NS is also a local site PI of a phase III industry sponsored study (Semaglutide - Novonordisc), with funding to the Institution.

1 Coding of most items was carried out as part of a previous SCD-I study that served as a precursor to the current harmonization effort (Rabin et al., 2015). Two questionnaires included in the previous study were excluded from the current analysis: (1) Self-Evaluation of Cognition Questionnaire (Pre-Al SCQ, with 14 usable items) because the parent study did not enroll neuropsychologically intact participants; and (2) Subjective Cognitive Decline Self-Identification Item (Victoria SCDS, with one usable item; Smart et al., 2014) because this item was used to classify participants and was not a self-report item, per se. Also, for the current analysis, we added several new questionnaires: Amsterdam Dementia Cohort, Subjective Cognitive Concerns screener (van der Flier &amp; Scheltens, 2018), Blessed Functional Activities Scale (Blessed et al., 1968), Canadian Longitudinal Study on Aging (CLSA) SCD/worry item (Raina et al., 2009; 2019), Cognitive Function Instrument (Amariglio et al., 2015a), Hellenic Longitudinal Investigation of Aging and Diet Study (HELIAD) Subjective Cognitive Items (Margioti et al., 2020), Mayo Clinic Study of Aging (MCSA), adapted Blessed Memory scale (Mielke et al., 2012), Subjective Memory Complaints Questionnaire (SMCQ; Youn et al., 2009), and the WRAP Memory Item (Nicholas et al., 2017). Together these new questionnaires contributed 51 usable items. Authors LAR, MEC, and SAMS independently carried out cognitive domain coding for the new items, with complete agreement.


References

Aalten P , Ramakers IH , Biessels GJ , de Deyn PP , Koek HL , OldeRikkert MG , ... &amp; van der Flier WM (2014). The Dutch Parelsnoer Institute-Neurodegenerative diseases; methods, design and baseline results. BMC Neurology, 14 (1 ), 1–8. 10.1186/s12883-014-0254-4 24383721
Abdulrab K , &amp; Heun R . (2008). Subjective Memory Impairment. A review of its definitions indicates the need for a comprehensive set of standardised and validated criteria. European Psychiatry, 23 (5 ), 321–330. 10.1016/j.eurpsy.2008.02.004 18434102
Amariglio RE , Becker JA , Carmasin J , Wadsworth LP , Lorius N , Sullivan C , … &amp; Rentz DM (2012). Subjective cognitive complaints and amyloid burden in cognitively normal older individuals. Neuropsychologia, 50 (12 ), 2880–2886. 10.1016/j.neuropsychologia.2012.08.011 22940426
Amariglio RE , Donohue MC , Marshall GA , Rentz DM , Salmon DP , Ferris SH , … &amp; Sperling RA (2015a). Tracking early decline in cognitive function in older individuals at risk for Alzheimer disease dementia: the Alzheimer’s Disease Cooperative Study Cognitive Function Instrument. JAMA Neurology, 72 (4 ), 446–454. doi:10.1001/jamaneurol.2014.3375 25706191
Amariglio RE , Mormino EC , Pietras AC , Marshall GA , Vannini P , Johnson KA , … &amp; Rentz DM (2015b). Subjective cognitive concerns, amyloid-β, and neurodegeneration in clinically normal elderly. Neurology, 85 (1 ), 56–62. doi: 10.1212/WNL.0000000000001712 26048028
Amariglio RE , Sikkes SAM , Marshall GA , Buckley RF , Gatchel JR , Johnson KA , … &amp; Sperling RA (2021). Item-level investigation of participant and study partner report on the Cognitive Function Index from the A4 Study screening data. The Journal of Prevention of Alzheimer's Disease, 1–6. 10.14283/jpad.2021.8
Archer HA , Newson MA , &amp; Coulthard EJ (2015). Subjective memory complaints: symptoms and outcome in different research settings. Journal of Alzheimer's Disease, 48 (s1 ), S109–S114. doi: 10.3233/JAD-150108
Baker FB &amp; Kim S-H (2017). The basics of item response theory using R. Springer.
Bandalos DL (2018). Measurement Theory and Applications for the Social Sciences. Guilford Publications.
Blessed G , Tomlinson BE , &amp; Roth M . (1968). The association between quantitative measures of dementia and of senile change in the cerebral grey matter of elderly subjects. The British Journal of Psychiatry, 114 (512 ), 797–811. 10.1192/bjp.114.512.797 5662937
Bradburn NM , Sudman S , &amp; Wansink B . (2004.) Asking Questions: The Definitive Guide to Questionnaire Design: For Market Research, Political Polls, and Social and Health Questionnaires. San Francisco: Jossey-Bass.
Brandimonte MA , Einstein GO , &amp; McDaniel MA (1996). Prospective Memory: Theory and Applications. Lawrence Erlbaum Associates Inc.
Broadbent DE , Cooper PF , FitzGerald P , &amp; Parkes KR (1982). The cognitive failures questionnaire (CFQ) and its correlates. British journal of clinical psychology, 21 (1 ), 1–16.7126941
Brucki SMD , &amp; Nitrini R . (2009). Subjective memory impairment in a rural population with low education in the Amazon rainforest: An exploratory study. International Psychogeriatrics, 21 (1 ), 164–171. 10.1017/S1041610208008065 19019263
Buckley RF , Maruff P , Ames D , Bourgeat P . Martins RN , Masters CL , … &amp; Ellis KA (2016). Subjective memory decline predicts greater rates of clinical progression in preclinical Alzheimer’s disease. Alzheimer’s &amp; Dementia, 12 , 796–804.
Buckley R , Saling MM , Ames D , Rowe CC , Lautenschlager NT , Macaulay SL , … &amp; Lifestyle Study of Aging (AIBL) Research Group. (2013). Factors affecting subjective memory complaints in the AIBL aging study: biomarkers, memory, affect, and age. International Psychogeriatrics, 25 (8 ), 1307–1315. 10.1017/S1041610213000665 23693133
Carp FM (1989). Maximizing data quality in community studies of older people. In: Lawton MP &amp; Herzog AR (Eds.), Special research methods for gerontology (pp. 93–122). Baywood Publishing Co. Inc.
Cella D , Riley W , Stone AA , Rothrock N , Reeve BB , Yount S , Amtmann D , D. B , Choi S , , Cook K , (2010). Initial adult health item banks and first wave testing of the Patient-Reported Outcomes Measurement Information System (PROMIS™) Network: 2005–2008. Journal of Clinical Epidemiology 63 , 1179–1194. doi:10.1016/j.jclinepi.2010.04.011 20685078
Cavanaugh JC , Feldman JM , &amp; Hertzog C . (1998). Memory beliefs as social cognition: A reconceptualization of what memory questionnaires assess. Review of General Psychology, 2 (1 ), 48–65. 10.1037/1089-2680.2.1.48
Chan KS , Gross AL , Pezzin LE , Brandt J , &amp; Kasper JD (2015). Harmonizing measures of cognitive performance across international surveys of aging using item response theory. Journal of Aging and Health, 27 (8 ), 1392–1414. 10.1177/0898264315583054 26526748
Chau LT , Lee JB , Fleming J , Roche N , &amp; Shum D . (2007). Reliability and normative data for the Comprehensive Assessment of Prospective Memory (CAPM). Neuropsychological Rehabilitation, 17 (6 ), 707–722. 10.1080/09602010600923926 17852758
Chételat G , Villemagne VL , Bourgeat P , Pike KE , Jones G , Ames D , … &amp; Australian Imaging Biomarkers and Lifestyle Research Group. (2010). Relationship between atrophy and β‐amyloid deposition in Alzheimer disease. Annals of Neurology, 67 (3 ), 317–324. 10.1002/ana.21955 20373343
Colijn MA , &amp; Grossberg GT (2015). Amyloid and tau biomarkers in subjective cognitive impairment. Journal of Alzheimer's Disease, 47 (1 ), 1–8. doi: 10.3233/JAD-150180
Comijs HC , Deeg DJH , Dik MG , Twisk JWR , &amp; Jonker C . (2002). Memory complaints; the association with psycho-affective and health problems and the role of personality characteristics: a 6-year follow-up study. Journal of Affective Disorders, 72 (2 ), 157–165. 10.1016/S0165-0327(01)00453-0 12200206
Crook TH , Feher EP , &amp; Larrabee GJ (1992). Assessment of memory complaint in age-associated memory impairment: the MAC-Q. International Psychogeriatrics, 4 (2 ), 165–176. 10.1017/S1041610292000991 1477304
Derby CA , Burns LC , Wang C , Katz MJ , Zimmerman ME , L’Italien G , … &amp; Lipton RB (2013). Screening for predementia AD: time-dependent operating characteristics of episodic memory tests. Neurology, 80 (14 ), 1307–1314. 10.1212/WNL.0b013e31828ab2c9 23468542
DeWalt DA , Rothrock N , Yount S , &amp; Stone AA (2007). Evaluation of item candidates: the PROMIS qualitative item review. Medical Care, 45 (5 Suppl 1), S12. doi: 10.1097/01.mlr.0000254567.79743.e2
Dixon RA , Hultsch DF , &amp; Hertzog C . (1988). The metamemory in adulthood (MIA) questionnaire. Psychopharmacology Bulletin, 24 (4 ), 671–688.3249770
Dorans NJ , Pommerich M , &amp; Holland PW (Eds.). (2007). Linking and aligning scores and scales. Springer Science + Business Media. 10.1007/978-0-387-49771-6
Edelen MO , &amp; Reeve BB (2007). Applying item response theory (IRT) modeling to questionnaire development, evaluation, and refinement. Quality Life Research, 16 , 5–18.
Edwards MC , Houts CR , &amp; Cai L . (2018). A diagnostic procedure to detect departures from local independence in item response theory models. Psychological Methods, 23 (1 ), 138–149. 10.1037/met0000121 28368176
Ellis KA , Bush AI , Darby D , De Fazio D , Foster J , Hudson P , … &amp; AIBL Research Group. (2009). The Australian Imaging, Biomarkers and Lifestyle (AIBL) study of aging: methodology and baseline characteristics of 1112 individuals recruited for a longitudinal study of Alzheimer's disease. International Psychogeriatrics, 21 (4 ), 672–687. 10.1017/S1041610209009405 19470201
Farias ST , Mungas D , Reed BR , Cahn-Weiner D , Jagust W , Baynes K , &amp; DeCarli C . (2008). The measurement of everyday cognition (ECog): scale development and psychometric properties. Neuropsychology, 22 (4 ), 531. 10.1037/0894-4105.22.4.531 18590364
Flake JK , &amp; Fried EI (2020). Measurement schmeasurement: Questionable measurement practices and how to avoid them. Advances in Methods and Practices in Psychological Science, 3 (4 ), 456–465. 10.1177/2515245920952393
Fried EI , &amp; Flake JK (2018). Measurement matters. APS Observer, 31 (3 ).
Galeone F , Pappalardo S , Chieffi S , Iavarone A , &amp; Carlomagno S . (2011). Anosognosia for memory deficit in amnestic mild cognitive impairment and Alzheimer's disease. International Journal of Geriatric Psychiatry, 26 (7 ), 695–701. 10.1002/gps.2583 21495076
Ganguli M , Chang CCH , Snitz BE , Saxton JA , Vanderbilt J , &amp; Lee CW (2010). Prevalence of mild cognitive impairment by multiple classifications: The Monongahela-Youghiogheny Healthy Aging Team (MYHAT) project. The American Journal of Geriatric Psychiatry, 18 (8 ), 674–683. 10.1097/JGP.0b013e3181cdee4f 20220597
Gelman A . (2013). Understanding posterior p-values. Electronic Journal of Statistics, 7 , 2595–2602.
Gibbons LE , Fredericksen R , Batey DS , Dant L , Edwards TC , Mayer KH , … &amp; Crane PK ; Centers for AIDS Research Network of Integrated Clinical Systems (CNICS). (2017). Validity assessment of the PROMIS fatigue domain among people living with HIV. AIDS Research and Therapy, 11 , 21. doi: 10.1186/s12981-017-0146-y
Gibbons RD , Immekus JC , Bock RD , &amp; Gibbons RD (2007). The added value of multidimensional IRT models. Multidimensional and Hierarchical Modeling Monograph, 1.
Gifford KA , Liu D , Lu Z , Tripodis Y , Cantwell NG , Palmisano J , … &amp; Jefferson AL (2014). The source of cognitive complaints predicts diagnostic conversion differentially among nondemented older adults. Alzheimer's &amp; Dementia, 10 (3 ), 319–327. 10.1016/j.jalz.2013.02.007
Gifford KA , Liu D , Romano RR , Jones RN , &amp; Jefferson AL (2015). Development of a subjective cognitive decline questionnaire using item response theory: a pilot study. Alzheimer's &amp; Dementia: Diagnosis, Assessment &amp; Disease Monitoring, 1 (4 ), 429–439. 10.1016/j.dadm.2015.09.004
Gilewski MJ , Zelinski EM , &amp; Schaie KW (1990). The Memory Functioning Questionnaire for assessment of memory complaints in adulthood and old age. Psychology and Aging, 5 (4 ), 482.2278670
Go RCP , Duke LW , Harrell LE , Cody H , Bassett SS , Folstein MF , … &amp; Blacker D . (1997). Development and validation of a structured telephone interview for dementia assessment (STIDA): the NIMH Genetics Initiative. Journal of Geriatric Psychiatry and Neurology, 10 (4 ), 161–167. 10.1177/089198879701000407 9453683
Hambleton RK , &amp; Cook LL (1977). Latent trait models and their use in the analysis of educational test data. Journal of Educational Measurement, 14 (2 ), 75–94.
Hao L , Wang X , Zhang L , Xing Y , Guo Q , Hu X , … &amp; Han Y . (2017). Prevalence, risk factors, and complaints screening tool exploration of subjective cognitive decline in a large cohort of the Chinese population. Journal of Alzheimer's Disease, 60 (2 ), 371–388. doi: 10.3233/JAD-170347
Haug A . (2012). Bayesian estimation and tracking: A practical guide. Hoboken, NJ: John Wiley &amp; Sons, Incorporated.
Hays RD , Morales LS , &amp; Reise SP (2000). Item response theory and health outcomes measurement in the 21st century. Medical Care, 38 (9 Suppl), II28.
Hill NL , Mogle J , Wion R , Munoz E , DePasquale N , Yevchak AM , &amp; Parisi JM (2016). Subjective cognitive impairment and affective symptoms: a systematic review. The Gerontologist, 56 (6 ), e109–e127. 10.1093/geront/gnw091 27342440
Hollands S , Lim YY , Buckley R , Pietrzak RH , Snyder PJ , Ames D , … &amp; AIBL Research Group. (2015). Amyloid-β related memory decline is not associated with subjective or informant rated cognitive impairment in healthy adults. Journal of Alzheimer's Disease, 43 (2 ), 677–686. doi: 10.3233/JAD-140678
Hox JJCM , van de Schoot R , &amp; Matthijsse S . (2012). How few countries will do? Comparative survey analysis from a Bayesian perspective. Survey Research Methods, 6 , 87–93. 10.18148/srm/2012.v6i2.5033
Irwin DE , Gross HE , Stucky BD , Thissen D , DeWitt EM , Lai JS , … &amp; DeWalt DA (2012). Development of six PROMIS pediatrics proxy-report item banks. Health and Quality of Life Outcomes, 10 , 22. 10.1186/1477-7525-10-22 22357192
Jack CR Jr. , Bennett DA , Blennow K , Carrillo MC , Dunn B , Haeberlein SB , … &amp; Silverberg N . (2018). NIA‐AA research framework: toward a biological definition of Alzheimer's disease. Alzheimer's &amp; Dementia, 14 (4 ), 535–562. 10.1016/j.jalz.2018.02.018
Jessen F , Amariglio RE , Buckley RF , van der Flier WM , Han Y , Molinuevo JL , … &amp; Wagner M . (2020). The characterisation of subjective cognitive decline. The Lancet Neurology, 19 (3 ), 271–278. 10.1016/S1474-4422(19)30368-0 31958406
Jessen F , Amariglio RE , Van Boxtel M , Breteler M , Ceccaldi M , Chételat G , … &amp; Subjective Cognitive Decline Initiative (SCD‐I) Working Group. (2014). A conceptual framework for research on subjective cognitive decline in preclinical Alzheimer's disease. Alzheimer's &amp; Dementia, 10 (6 ), 844–852. 10.1016/j.jalz.2014.01.001
Jessen F , Wiese B , Bachmann C , Eifflaender-Gorfer S , Haller F , Kölsch H , … &amp; Bickel H . (2010). Prediction of dementia by subjective memory impairment: effects of severity and temporal association with cognitive impairment. Archives of General Psychiatry, 67 (4 ), 414–422. doi:10.1001/archgenpsychiatry.2010.30 20368517
Jessen F , Wiese B , Cvetanovska G , Fuchs A , Kaduszkiewicz H , Kölsch H , … &amp; Bickel H . (2007). Patterns of subjective memory impairment in the elderly: association with memory performance. Psychological Medicine, 37 (12 ), 1753–1762. 10.1017/S0033291707001122 17623488
Jobe JB , &amp; Mingay DJ (1990). Cognitive laboratory approach to designing questionnaires for surveys of the elderly. Public Health Reports, 105 , 518–524.2120731
Johnson SC , Koscik RL , Jonaitis EM , Clark LR , Mueller KD , Berman SE , … &amp; Sager MA (2018). The Wisconsin Registry for Alzheimer's Prevention: A review of findings and current directions. Alzheimer's &amp; Dementia: Diagnosis, Assessment &amp; Disease Monitoring, 10 , 130–142. 10.1016/j.dadm.2017.11.007
Jones RR (1968). Differences in response consistency and subjects’ preferences for three personality inventory response formats. Proceedings of the 76th Annual Convention of the American Psychological Association. San Francisco, CA: American Psychological Association.
Jonker C , Geerlings MI , &amp; Schmand B . (2000). Are memory complaints predictive for dementia? A review of clinical and population‐based studies. International Journal of Geriatric Psychiatry, 15 (11 ), 983–991. 10.1002/1099-1166(200011)15:11&amp;lt;983::AID-GPS238&amp;gt;3.0.CO;2-5 11113976
Jonker C , Launer LJ , Hooijer C , &amp; Lindeboom J . (1996). Memory complaints and memory impairment in older individuals. Journal of the American Geriatrics Society, 44 (1 ), 44–49. 10.1111/j.1532-5415.1996.tb05636.x 8537589
Jorm AF (1994). A short form of the Informant Questionnaire on Cognitive Decline in the Elderly (IQCODE): development and cross-validation. Psychological Medicine, 24 (1 ), 145–153. 10.1017/S003329170002691X 8208879
Jorm AF , Christensen H , Korten AE , Jacomb PA , &amp; Henderson AS (2001). Memory complaints as a precursor of memory impairment in older people: a longitudinal analysis over 7–8 years. Psychological Medicine, 31 (3 ), 441–449. 10.1017/S0033291701003245 11305852
Kang HA , Su YH , &amp; Chang HH (2018). A note on monotonicity of item response functions for ordered polytomous item response theory models. The British Journal of Mathematical and Statistical Psychology, 71 (3 ), 523–535. 10.1111/bmsp.12131 29516492
Kim D , De Ayala R , Ferdous AA , &amp; Nering ML (2011). The comparative performance of conditional independence indices. Applied Psychological Measurement, 35 , 447–471. doi: 10.1177/0146621611407909
Kliegel M , Ballhausen N , Hering A , Ihle A , Schnitzspahn KM , &amp; Zuber S . (2016). Prospective memory in older adults: Where we are now and what is next. Gerontology, 62 (4 ), 459–466. 10.1159/000443698 26950339
Kryscio RJ , Abner EL , Cooper GE , Fardo DW , Jicha GA , Nelson PT , … &amp; Schmitt FA (2014). Self-reported memory complaints: implications from a longitudinal cohort with autopsies. Neurology, 83 (15 ), 1359–1365. 10.1212/WNL.0000000000000856 25253756
Lai JS , Cella D , Chang CH , Bode RK , &amp; Heinemann AW (2003). Item banking to improve, shorten and computerize self-reported fatigue: an illustration of steps to create a core item bank from the FACIT-Fatigue Scale. Quality of Life Research: An International Journal of Quality of Life Aspects of Treatment, Care and Rehabilitation, 12 (5 ), 485–501. 10.1023/a:1025014509626 13677494
Lai JS , Cella D , Choi S , Junghaenel DU , Christodoulou C , Gershon R , &amp; Stone A . (2011). How item banks and their application can influence measurement practice in rehabilitation medicine: a PROMIS fatigue item bank example. Archives of Physical Medicine and Rehabilitation, 92 (10 Suppl), S20–S27. 10.1016/j.apmr.2010.08.033 21958919
Lai JS , Wagner LI , Jacobsen PB , &amp; Cella D . (2014). Self-reported cognitive concerns and abilities: two sides of one coin? Psycho-Oncology, 23 , 1133–1141. doi: 10.1002/pon.3522 24700645
Lee S-Y , &amp; Song X-Y (2004). Evaluation of the Bayesian and maximum likelihood approaches in analyzing structural equation models with small sample sizes. Multivariate Behavioral Research, 39 (4 ), 653–686. 10.1207/s15327906mbr3904_4 26745462
Lin Y , Shan PY , Jiang WJ , Sheng C , &amp; Ma L . (2019). Subjective cognitive decline: preclinical manifestation of Alzheimer’s disease. Neurological Sciences, 40 (1 ), 41–49.30397816
Lista S , Molinuevo JL , Cavedo E , Rami L , Amouyel P , Teipel SJ , … &amp; Hampel H . (2015). Evolving evidence for the value of neuroimaging methods and biological markers in subjects categorized with subjective cognitive decline. Journal of Alzheimer's Disease, 48 (s1 ), S171–S191. doi: 10.3233/JAD-150202
Lord F . (1980). Applications of item response theory to practical testing problems. Hillsdale, NJ: Lawrence Erlbaum Associates, Publishers.
Lozano LM , García-Cueto E , &amp; Muñiz J . (2008). Effect of the number of response categories on the reliability and validity of rating scales. Methodology, 4 (2 ), 73–79. doi: 10.1027/1614-2241.4.2.73
Lozoya-Delgado P , Ruiz-Sánchez de León JM , &amp; Pedrero-Pérez EJ (2012). Validación de un cuestionario de quejas cognitivas para adultos jóvenes: relación entre las quejas subjetivas de memoria, la sintomatología prefrontal y el estrés percibido. Revista de Neurología, 54 , 137–150.22278890
Lucas RE , &amp; Baird BM (2006). Global Self-Assessment. In Eid M . &amp; Diener E . (Eds.), Handbook of multimethod measurement in psychology (pp. 29–42). American Psychological Association.
Luck T , Luppa M , Briel S , Matschinger H , König HH , Bleich S , … &amp; Riedel‐Heller SG (2010). Mild cognitive impairment: incidence and risk factors: results of the Leipzig longitudinal study of the aged. Journal of the American Geriatrics Society, 58 (10 ), 1903–1910. 10.1111/j.1532-5415.2010.03066.x 20840461
Margioti E , Kosmidis MH , Yannakoulia M , Dardiotis E , Hadjigeorgiou G , Sakka P , … &amp; Scarmeas N . (2020). Exploring the association between subjective cognitive decline and frailty: the Hellenic Longitudinal Investigation of Aging and Diet Study (HELIAD). Aging &amp; Mental Health, 24 (1 ), 137–147. 10.1080/13607863.2018.1525604 30621435
McHorney CA , &amp; Cohen AS (2000). Equating health status measures with item response theory: Illustrations with functional status items. Medical Care, 38 (9 Suppl), II43–II59. 10.1097/00005650-200009002-00008 10982089
McNair D , &amp; Kahn R . (1983). Self-assessment of cognitive deficits. In Crook T , Ferris S , Bartus R. R . (Eds.), Assessment in Geriatric Psychopharmacology. New Canaan, Conn: Mark Powley and Associates, Incorporated.
Meng X-L (1994). Posterior predictive p-values. The Annals of Statistics, 22 , 1142–1160.
Menold N . (2020). Double barreled questions: An analysis of the similarity of elements and effects on measurement quality. Journal of Official Statistics, 36 (4 ), 855–886. doi:10.2478/jos-2020-0041
Mielke MM , Wiste HJ , Weigand SD , Knopman DS , Lowe VJ , Roberts RO , … &amp; Jack CR (2012). Indicators of amyloid burden in a population-based study of cognitively normal elderly. Neurology, 79 (15 ), 1570–1577. 10.1212/WNL.0b013e31826e2696 22972644
Mitchell AJ , Beaumont H , Ferguson D , Yadegarfar M , &amp; Stubbs B . (2014). Risk of dementia and mild cognitive impairment in older people with subjective memory complaints: meta‐analysis. Acta Psychiatrica Scandinavica, 130 (6 ), 439–451. 10.1111/acps.12336 25219393
Mogle J , Muñoz E , Hill NL , Smyth JM , &amp; Sliwinski MJ (2019). Daily memory lapses in adults: Characterization and influence on affect. The Journals of Gerontology. Series B, Psychological Sciences and Social Sciences, 74 (1 ), 59–68. 10.1093/geronb/gbx012 28329832
Molinuevo JL , Rabin LA , Amariglio R , Buckley R , Dubois B , Ellis KA , … &amp; Subjective Cognitive Decline Initiative. (2017). Implementation of subjective cognitive decline criteria in research studies. Alzheimer's &amp; Dementia, 13 (3 ), 296–311. 10.1016/j.jalz.2016.09.012
Morris JC , Heyman A , Mohs RC , Hughes JP , van Belle G , Fillenbaum GDME , … &amp; Clark C . (1989). The consortium to establish a registry for Alzheimer's disease (CERAD): I. Clinical and neuropsychological assessment of Alzheimer's disease. Neurology, 39 (9 ), 1159–1165. 10.1212/WNL.39.9.1159 2771064
Mosconi L , De Santi S , Brys M , Tsui WH , Pirraglia E , Glodzik-Sobanska L , … &amp; de Leon MJ (2008). Hypometabolism and altered cerebrospinal fluid markers in normal apolipoprotein E E4 carriers with subjective memory complaints. Biological Psychiatry, 63 (6 ), 609–618. 10.1016/j.biopsych.2007.05.030 17720148
Muthén LK , &amp; Muthén BO (1998-2017). Mplus user’s guide. Eighth edition. Muthén &amp; Muthén.
Nicholas CR , Dowling NM , Racine AM , Clark LR , Berman SE , Koscik RL , … &amp; Johnson SC (2017). Longitudinal assessment of self-and informant-subjective cognitive complaints in a sample of healthy late-middle aged adults enriched with a family history of Alzheimer’s disease. Journal of the International Neuropsychological Society, 23 (8 ), 617–626. 10.1017/S1355617717000509 28693655
Nester CO , Mogle JA , Katz MJ , Saykin AJ Lipton RB , &amp; Rabin LA (2022, February). The Cognitive Change Index (CCI-40): Broadening the assessment of subjective cognitive concerns in demographically diverse community dwelling older adults [Conference presentation]. International Neuropsychological Society 50th Annual Meeting, New Orleans, Louisiana, United States.
Nguyen TH , Han HR , Kim MT , &amp; Chan KS (2014). An introduction to item response theory for patient-reported outcome measurement. The Patient-Patient-Centered Outcomes Research, 7 (1 ), 23–35. doi.10.1007/s40271-013-0041-0 24403095
University Northwestern . (2022). Health measures: Transforming how health is measured. (2022) www.healthmeasures.net
O'Bryant SE , Zhang F , Petersen M , Hall JR , Johnson LA , Yaffe K , … &amp; HABLE Study Team (2022). A blood screening tool for detecting mild cognitive impairment and Alzheimer's disease among community-dwelling Mexican Americans and non-Hispanic Whites: A method for increasing representation of diverse populations in clinical research. Alzheimer's &amp; Dementia, 18 (1 ), 77–87. 10.1002/alz.12382
Oppenheim AN (1992.) Questionnaire Design, Interviewing, and Attitude Measurement. New York: St. Martin’s Press.
Perrotin A , Mormino EC , Madison CM , Hayenga AO , &amp; Jagust WJ (2012). Subjective cognition and amyloid deposition imaging: a Pittsburgh Compound B positron emission tomography study in normal elderly individuals. Archives of Neurology, 69 (2 ), 223–229. doi:10.1001/archneurol.2011.666 22332189
Peter J , Scheef L , Abdulkadir A , Boecker H , Heneka M , Wagner M , … &amp; Alzheimer's Disease Neuroimaging Initiative. (2014). Gray matter atrophy pattern in elderly with subjective memory impairment. Alzheimer's &amp; Dementia, 10 (1 ), 99–108. 10.1016/j.jalz.2013.05.1764
Ponds RWMH , Commissaris KJAM , &amp; Jolles J . (1997). Prevalence and covariates of subjective forgetfulness in a normal population in The Netherlands. The International Journal of Aging and Human Development, 45 (3 ), 207–221. 10.2190/MVQ1-WB58-875H-Y4X0 9438876
Preston CC , &amp; Coleman AM (2000). Optimal number of response categories in rating scales: reliability, validity, discriminating power, and respondent preferences. Acta Psychologica, 104 (1 ), 1–15. 10.1016/s0001-6918(99)00050-5 10769936
R Core Team (2021). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria: URL https://www.R-project.org/.
Rabin LA , Saykin AJ , Wishart HA , Nutter-Upham KE , Flashman LA , Pare N , &amp; Santulli RB (2007). The memory and aging telephone screen: Development and preliminary validation. Alzheimer's &amp; Dementia, 3 (2 ), 109–121. 10.1016/j.jalz.2007.02.002
Rabin LA , Smart CM , &amp; Amariglio RE (2017). Subjective cognitive decline in preclinical Alzheimer's disease. Annual Review of Clinical Psychology, 13 , 369–396. 10.1146/annurev-clinpsy-032816-045136
Rabin LA , Smart CM , Crane PK , Amariglio RE , Berman LM , Boada M , … &amp; Sikkes SA (2015). Subjective cognitive decline in older adults: an overview of self-report measures used across 19 international research studies. Journal of Alzheimer's Disease, 48 (s1 ), S63–S86. doi: 10.3233/JAD-150154
Raimo S , Trojano L , Siciliano M , Cuoco S , D’Iorio A , Santangelo F , … &amp; Santangelo G . (2016). Psychometric properties of the Italian version of the multifactorial memory questionnaire for adults and the elderly. Neurological Sciences, 37 (5 ), 681–691.27032401
Raina P , Wolfson C ., Kirkland S , Griffith LE , Balion C , Cossette B , … &amp; Young L . (2019) Cohort profile: The Canadian Longitudinal Study on Aging (CLSA). International Journal of Epidemiology, 48 (6 ), 1752–1753j. 10.1093/ije/dyz173 31633757
Raina PS , Wolfson C , Kirkland SA , Griffith LE , Oremus M , Patterson C , … &amp; Brazil K . (2009). The Canadian Longitudinal Study on Aging (CLSA). Canadian Journal on Aging, Special issue on the CLSA, 28 (3 ), 221–229. doi: 10.1017/S0714980809990055
Rami L , Mollica MA , García-Sanchez C , Saldaña J , Sanchez B , Sala I , … &amp; Molinuevo JL (2014). The subjective cognitive decline questionnaire (SCD-Q): a validation study. Journal of Alzheimer's Disease, 41 (2 ), 453–466. doi: 10.3233/JAD-132027
Rattanabannakit C , Risacher SL , Gao S , Lane KA , Brown SA , McDonald BC , … &amp; Farlow MR (2016). The cognitive change index as a measure of self and informant perception of cognitive decline: relation to neuropsychological tests. Journal of Alzheimer's Disease, 51 (4 ), 1145–1155. doi: 10.3233/JAD-150729
Reid LM , &amp; MacLullich AMJ (2006). Subjective memory complaints and cognitive impairment in older people. Dementia and Geriatric Cognitive Disorders, 22 (5–6 ), 471–485. 10.1159/000096295 17047326
Reisberg B , &amp; Gauthier S . (2008). Current evidence for subjective cognitive impairment (SCI) as the pre-mild cognitive impairment (MCI) stage of subsequently manifest Alzheimer's disease. International Psychogeriatrics, 20 (1 ), 1–16. doi: 10.1017/S1041610207006412 18072981
Reisberg B , Prichep L , Mosconi L , John ER , Glodzik-Sobanska L , Boksay I , … &amp; de Leon MJ (2008). The pre-mild cognitive impairment, subjective cognitive impairment stage of Alzheimer's disease. Alzheimer's &amp; Dementia, 4 (1 Suppl 1), S98–S108. 10.1016/j.jalz.2007.11.017
Reisberg B , Shulman MB , Torossian C , Leng L , &amp; Zhu W . (2010). Outcome over seven years of healthy adults with and without subjective cognitive impairment. Alzheimer's &amp; Dementia, 6 (1 ), 11–24. 10.1016/j.jalz.2009.10.002
Riedel-Heller SG , Matschinger H , Schork A , &amp; Angermeyer MC (1999). Do memory complaints indicate the presence of cognitive impairment? – Results of a field study. European Archives of Psychiatry and Clinical Neuroscience, 249 (4 ), 197–204. 10.1007/s004060050087 10449595
Risacher SL , Kim S , Nho K , Foroud T , Shen L , Petersen RC , … &amp; Alzheimer's Disease Neuroimaging Initiative (ADNI). (2015). APOE effect on Alzheimer's disease biomarkers in older adults with significant memory concern. Alzheimer's &amp; Dementia, 11 (12 ), 1417–1429.
Robinson MD , &amp; Clore GL (2002a). Episodic and semantic knowledge in emotional self-report: Evidence for two judgment processes. Journal of Personality and Social Psychology, 83 (1 ), 198–215. 10.1037/0022-3514.83.1.198 12088126
Robinson MD , &amp; Clore GL (2002b). Belief and feeling: Evidence for an accessibility model of emotional self-report. Psychological Bulletin, 128 (6 ), 934–960. 10.1037/0033-2909.128.6.934 12405138
Roth RM , Gioia GA , &amp; Isquith PK (2005). BRIEF-A: Behavior Rating Inventory of Executive Function--adult Version. Psychological Assessment Resources.
Röhr S , Pabst A , Riedel-Heller SG , Jessen F , Turana Y , Handajani YS , … &amp; Sachdev PS (2020). Estimating prevalence of subjective cognitive decline in and across international cohort studies of aging: a COSMIC study. Alzheimer's Research &amp; Therapy, 12 (1 ), 1–14.
Şahin S , Yüksel N , Utku Ç , Bodur NE , Karapıçak ÖK , Birer NÇ , &amp; Kaya D . (2013). [Validity and Reliability of Turkish version of the Memory Functioning Questionnaire] Bellek İşlevselliği Anketi'nin Türkçe Geçerlik ve Güvenilirlik Çalışması. Klinik Psikiyatri, 16 , 135–147.
Samejima F . (1997). Graded response model. In: Linden W. van der &amp; Hambleton R (Eds.), Handbook of modern item response theory (pp. 85–100). Springer.
Saykin AJ [unpublished]. Activities of Daily Living Rating Scale Self-Version, Abbreviated.
Saykin AJ (1992). Neurobehavioral function and activities of daily living rating scale (NBFADL-63 item version). Hanover: Dartmouth Medical School.
Saykin AJ , Wishart HA , Rabin LA , Santulli RB , Flashman LA , West JD , … &amp; Mamourian AC (2006). Older adults with cognitive complaints show brain atrophy similar to that of amnestic MCI. Neurology, 67 (5 ), 834–842. 10.1212/01.wnl.0000234032.77541.a2 16966547
Scheef L , Spottke A , Daerr M , Joe A , Striepens N , Kölsch H , … &amp; Jessen F . (2012). Glucose metabolism, gray matter structure, and memory decline in subjective memory impairment. Neurology, 79 (13 ), 1332–1339. 10.1212/WNL.0b013e31826c1a8d 22914828
Schultz SA , Oh JM , Koscik RL , Dowling NM , Gallagher CL , Carlsson CM , … &amp; Okonkwo OC (2015). Subjective memory complaints, cortical thinning, and cognitive dysfunction in middle-age adults at risk of AD. Alzheimer's &amp; Dementia: Diagnosis, Assessment &amp; Disease Monitoring, 1 (1 ), 33–40. 10.1016/j.dadm.2014.11.010
Sheikh JI , &amp; Yesavage JA (1986). Geriatric Depression Scale (GDS): recent evidence and development of a shorter version. Clinical Gerontologist: The Journal of Aging and Mental Health, 5 (1–2 ), 165–173. 10.1300/J018v05n01_09
Sikkes SAM , Dubbelman MA , Tommet D , &amp; Jones RN , Crane PK , &amp; Rabin L . (2021, July). The relationship between Subjective Cognitive Decline and demographic characteristics is moderated by study setting: Findings from the SCD-I Item Analysis Working Group. Presented at the 2021 Alzheimer’s Association International Conference, Virtual Conference.
Slavin MJ , Brodaty H , Kochan NA , Crawford JD , Trollor JN , Draper B , &amp; Sachdev PS (2010). Prevalence and predictors of “subjective cognitive complaints” in the Sydney Memory and Ageing Study. The American Journal of Geriatric Psychiatry, 18 (8 ), 701–710.21491631
Slot RE , Verfaillie SC , Overbeek JM , Timmers T , Wesselman LM , Teunissen CE , … &amp; Van der Flier WM (2018). Subjective Cognitive Impairment Cohort (SCIENCe): study design and first results. Alzheimer's Research &amp; Therapy, 10 (1 ), 1–13.
Slot RE , Sikkes SAM , Berkhof J , Brodaty H , Buckley R , Cavedo E , … &amp; van der Flier WM (2019). Subjective cognitive decline and rates of incident Alzheimer's disease and non–Alzheimer's disease dementia. Alzheimer's &amp; Dementia, 15 (3 ), 465–476. 10.1016/j.jalz.2018.10.003
Smart CM , Segalowitz SJ , Mulligan BP , &amp; MacDonald SW (2014). Attention capacity and self-report of subjective cognitive decline: a P3 ERP study. Biological Psychology, 103 , 144–151. 10.1016/j.biopsycho.2014.08.016 25204705
Snitz BE , Wang T , Cloonan YK , Jacobsen E , Chang CCH , Hughes TF , … &amp; Ganguli M . (2018). Risk of progression from subjective cognitive decline to mild cognitive impairment: The role of study setting. Alzheimer's &amp; Dementia, 14 (6 ), 734–742. 10.1016/j.jalz.2017.12.003
Snitz BE , Yu L , Crane PK , Chang CCH , Hughes TF , &amp; Ganguli M . (2011). Subjective cognitive complaints of older adults at the population level: An item response theory analysis. Alzheimer Disease and Associated Disorders, 26 (4 ), 344. doi: 10.1097/WAD.0b013e3182420bdf
Squire LR , Wetzel CD , &amp; Slater PC (1979). Memory complaint after electroconvulsive therapy: assessment with a new self-rating instrument. Biological Psychiatry, 14 (5 ), 791–801.497304
St. John P , &amp; Montgomery P . (2002). Are cognitively intact seniors with subjective memory loss more likely to develop dementia? International Journal of Geriatric Psychiatry, 17 (9 ), 814–820. 10.1002/gps.559 12221654
Sun Y , Yang FC , Lin CP , &amp; Han Y . (2015). Biochemical and neuroimaging studies in subjective cognitive decline: progress and perspectives. CNS Neuroscience &amp; Therapeutics, 21 (10 ), 768–775. 10.1111/cns.12395
Tian X , &amp; Dai B . (2020). Developing a Computerized Adaptive Test to assess stress in Chinese college students. Frontiers in Psychology, 11 , 7. 10.3389/fpsyg.2020.00007 32116885
Troyer AK , &amp; Rich JB (2002). Psychometric properties of a new metamemory questionnaire for older adults. The Journals of Gerontology Series B: Psychological Sciences and Social Sciences, 57 (1 ), P19–P27. 10.1093/geronb/57.1.P19 11773220
Vale CD (1986). Linking item parameters onto a common scale. Applied Psychological Measurement, 10 (4 ), 333–344. 10.1177/014662168601000402
van der Flier WM &amp; Scheltens P . (2018). Amsterdam Dementia Cohort: Performing research to optimize care. Journal of Alzheimer’s Disease, 62 , 1091–1111. doi: 10.3233/JAD-170850
van Harten AC , Mielke MM , Swenson-Dravis DM , Hagen CE , Edwards KK , Roberts RO , … &amp; Petersen RC (2018). Subjective cognitive decline and risk of MCI: the Mayo Clinic Study of Aging. Neurology, 91 (4 ), e300–e312. 10.1212/WNL.0000000000005863 29959257
van Harten AC , Visser PJ , Pijnenburg YA , Teunissen CE , Blankenstein MA , Scheltens P , &amp; van der Flier WM (2013). Cerebrospinal fluid Aβ42 is the best predictor of clinical progression in patients with subjective complaints. Alzheimer's &amp; Dementia, 9 (5 ), 481–487. 10.1016/j.jalz.2012.08.004
Verfaillie SC , Timmers T , Slot RE , Van Der Weijden CW , Wesselman LM , Prins ND , … &amp; Van Der Flier WM (2019). Amyloid-β load is related to worries, but not to severity of cognitive complaints in individuals with subjective cognitive decline: the SCIENCe project. Frontiers in Aging Neuroscience, 11 , 7. 10.3389/fnagi.2019.00007 30760996
Visser PJ , Verhey F , Knol DL , Scheltens P , Wahlund LO , Freund-Levi Y , … &amp; Blennow K . (2009). Prevalence and prognostic value of CSF markers of Alzheimer's disease pathology in patients with subjective cognitive impairment or mild cognitive impairment in the DESCRIPA study: a prospective cohort study. The Lancet Neurology, 8 (7 ), 619–627. 10.1016/S1474-4422(09)70139-5 19523877
Vlachos GS , Cosentino S , Kosmidis MH , Anastasiou CA , Yannakoulia M , Dardiotis E , … &amp; Scarmeas N . (2019). Prevalence and determinants of subjective cognitive decline in a representative Greek elderly population. International Journal of Geriatric Psychiatry, 34 (6 ), 846–854. 10.1002/gps.5073 30714214
Vogel A , Stokholm J , Gade A , Andersen BB , Hejl AM , &amp; Waldemar G . (2004). Awareness of deficits in mild cognitive impairment and Alzheimer’s disease: Do MCI patients have impaired insight? Dementia and Geriatric Cognitive Disorders, 17 (3 ), 181–187. 10.1159/000076354 14739542
Winkler RL (1993). Bayesian statistics: An overview. In Keren G &amp; Lewis C (Eds.), A handbook for data analysis in the behavioral sciences: Statistical issues (pp. 201–232). Lawrence Erlbaum Associates, Inc.
Wolfsgruber S , Wagner M , Schmidtke K , Frölich L , Kurz A , Schulz S , … &amp; Jessen F . (2014). Memory concerns, memory performance and risk of dementia in patients with mild cognitive impairment. PloS One, 9 (7 ), e100812. 10.1371/journal.pone.0100812 25019225
Woods SP , Weinborn M , Velnoweth A , Rooney A , &amp; Bucks RS (2012). Memory for intentions is uniquely associated with instrumental activities of daily living in healthy older adults. Journal of the International Neuropsychological Society, 18 (1 ), 134–138. 10.1017/S1355617711001263 22032776
Yesavage JA , Brink TL , Rose TL , Lum O , Huang V , Adey M , &amp; Leirer VO (1982). Development and validation of a geriatric depression screening scale: a preliminary report. Journal of Psychiatric Research, 17 (1 ), 37–49. 10.1016/0022-3956(82)90033-4 7183759
Youn JC , Kim KW , Lee DY , Jhoo JH , Lee SB , Park JH , … &amp; Woo JI (2009). Development of the Subjective Memory Complaints Questionnaire. Dementia and Geriatric Cognitive Disorders, 27 (4 ), 310–317. doi:10.1159/000205512 19252402
Zlatar ZZ , Moore RC , Palmer BW , Thompson WK , &amp; Jeste DV (2014). Cognitive complaints correlate with depression rather than concurrent objective cognitive impairment in the successful aging evaluation baseline sample. Journal of Geriatric Psychiatry and Neurology, 27 (3 ), 181–187. 10.1177/0891988714524628 24614203
Zwan MD , Villemagne VL , Doré V , Buckley R , Bourgeat P , Veljanoski R , … &amp; Rowe CC (2016). Subjective memory complaints in APOE ɛ4 carriers are associated with high amyloid-β burden. Journal of Alzheimer's Disease, 49 (4 ), 1115–112. doi: 10.3233/JAD-150446
