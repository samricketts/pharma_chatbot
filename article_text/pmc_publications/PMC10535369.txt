LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


8100437
6047
Neurobiol Aging
Neurobiol Aging
Neurobiology of aging
0197-4580
1558-1497

36442416
10535369
10.1016/j.neurobiolaging.2022.10.005
NIHMS1923772
Article
Predicting time-to-conversion for dementia of Alzheimer’s type using multi-modal deep survival analysis
Mirabnahrazam Ghazal a1
Ma Da ba**
Beaulac Cédric ca
Lee Sieun da
Popuri Karteek ea
Lee Hyunwoo f
Cao Jiguo g
Galvin James E i
Wang Lei h
Beg Mirza Faisal a*
Alzheimer’s Disease Neuroimaging Initiative2
a School of Engineering, Simon Fraser University, Burnaby, British Columbia, Canada
b School of Medicine, Wake Forest University, Winston-Salem, NC, USA
c Department of Mathematics and Statistics, University of Victoria, Victoria, British Columbia, Canada
d Mental Health &amp; Clinical Neurosciences, School of Medicine, University of Nottingham, Nottingham, UK
e Department of Computer Science, Memorial University of Newfoundland, St. John’s, Newfoundland &amp; Labrador, Canada
f Division of Neurology, Department of Medicine, University of British Columbia, Vancouver, British Columbia, Canada
g Department of Statistics and Actuarial Science, Simon Fraser University, Burnaby, British Columbia, Canada
h Psychiatry and Behavioral Health, Ohio State University Wexner Medical Center, Columbus, OH, USA
i Comprehensive Center for Brain Health, Department of Neurology, University of Miami Miller School of Medicine, Miami, FL, USA
1 First Author

2 Data used in preparation of this article were obtained from the Alzheimer’s disease Neuroimaging Initiative (ADNI) database (http://adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf

* Corresponding author at: Michael Smith Foundation for Health Research Scholar, School of Engineering Science, Simon Fraser University, Burnaby, British Columbia, Canada. Phone: 778 782-5696, faisal-lab@sfu.ca (M.F. Beg)
** Corresponding author at: School of Medicine, Wake Forest University, Winston-Salem, NC, USA. Phone: 336 713-6172. dma@wakehealth.edu (D. Ma).
22 9 2023
1 2023
17 10 2022
28 9 2023
121 139156
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Dementia of Alzheimer’s Type (DAT) is a complex disorder influenced by numerous factors, and it is difficult to predict individual progression trajectory from normal or mildly impaired cognition to DAT. An in-depth examination of multiple modalities of data may yield an accurate estimate of time-to-conversion to DAT for preclinical subjects at various stages of disease development. We used a deep-learning model designed for survival analyses to predict subjects’ time-to-conversion to DAT using the baseline data of 401 subjects with 63 features from MRI, genetic, and CDC (Cognitive tests, Demographic, and CSF) data in the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database. Our study demonstrated that CDC data outperform genetic or MRI data in predicting DAT time-to-conversion for subjects with Mild Cognitive Impairment (MCI). On the other hand, genetic data provided the most predictive power for subjects with Normal Cognition (NC) at the time of the visit. Furthermore, combining MRI and genetic features improved the time-to-event prediction over using either modality alone. Finally, adding CDC to any combination of features only worked as well as using only the CDC features.

Alzheimer’s disease
Deep learning
Survival analysis
Early detection
Multi-modal data
Neuroimage genomics

pmc1. Introduction

Alzheimer’s disease (AD) or clinically defined Dementia of Alzheimer’s Type (DAT) is a progressive neurodegenerative condition characterized by psychiatric, cognitive, and structural deterio-rations that accounts for 60% –80% of all dementia cases. One of every 3 elderly individuals die due to Alzheimer’s or other types of dementia, accounting for more deaths than breast and prostate cancers combined (Alzheimer’s Association, 2021). Since effective cure for AD is still currently limited, there is substantial interest in better understanding the characteristics of the disease, developing methods to detect those at risk at an early stage of the disease before symptomatic onset and predicting the progression of the disease for those affected.

Many factors contribute to the development and progression of Alzheimer’s disease, but the role of each factor is still not fully understood. It is critical to thoroughly investigate the phenotype, genotype, and lifestyle factors in the development and progression of Alzheimer’s. Although a clinical diagnosis of Alzheimer’s is based on cognitive symptoms, various biomarkers have been investigated for accurately detecting DAT in its early, possibly pre-symptomatic stages. Magnetic resonance imaging (MRI) is the most widely used data modality for identifying specific structural atrophy in the brain associated with DAT progression (Hua et al., 2008; Vemuri and Jack, 2010; Popuri et al., 2020). Cerebrospinal Fluid (CSF) biomarkers, such as abnormal amyloid and tau levels, have been extensively studied in relation to Alzheimer’s disease (Olsson et al., 2016; Finehout et al., 2007; Anoop et al., 2010). In particular, genetic information has been shown promising in predicting the likelihood of developing DAT even before pathological changes begin (Mirabnahrazam et al., 2022). Several genetic risk factors have been linked to DAT, with the APOE-ε 4 allele accounting for 20%–25% of cases (Lambert et al., 2013). Multiple genome-wide association studies (GWAS) have also found possible links between Single Nucleotide Polymorphisms (SNPs) and DAT (Jansen et al., 2019; Kunkle et al.,2019; Schwartzentruber et al., 2021). At the time of writing this manuscript, 20 genes have been reported to be associated with AD via GWAS, although the majority of them had moderate to small effect sizes (Lambert et al., 2013). Other factors studied alone or in combination with other modalities to predict Alzheimer’s disease progression include socio-demographic and clinical data, as well as cognitive performance tests (Grassi et al., 2019; Lei et al., 2020; Devanand et al., 2008). The growing availability of databases containing multiple data modalities, such as the Alzheimer’s Disease Neuroimaging Initiative (ADNI), has allowed researchers to investigate prediction of DAT risk using multi-modal data (Venugopalan et al., 2021; An et al., 2017; Zhou et al., 2019). While these previous findings suggest that combining different data modalities can improves diagnosis performance, there is still incomplete understanding about how each modality contributes to DAT diagnosis, and translation of this understanding into practical usage is still limited.

Early diagnosis is critical for successful disease management and the potential use of disease-modifying treatments. In the current clinical practice, a DAT diagnosis cannot be made until the patient exhibits clear signs of cognitive decline. Therefore, methods for predicting the probability of a patient developing Alzheimer’s disease as a function of time, collectively known as survival analysis, are important tools in helping understanding the characteristics of DAT. Compared to typical binary classification approach of predicting whether a subject would convert to AD, survival analysis provides additional information on the subject’s time-to-AD-conversion, describing the level of risk. Furthermore, compared with traditional regression methods, one of the most important advantages of survival analysis is that it can account for censored individuals (i.e., who are not followed up to their dementia onset time), allowing for the utilization of all the data. Survival analysis has received substantial recent attention in the machine learning literature. The application of neural networks to survival analysis was first introduced by Faraggi and Simon (1995) where they extended the classical Cox proportional hazard model (Cox, 1972) by using one hidden layer multilayer perceptron (MLP) to learn the relationship of the covariates to the hazard function. Recent advances in deep learning have enabled researchers to develop several cutting-edge deep learning-based survival analysis models that can overcome the constraints of the traditional models, such as the linearity assumption between the covariates and the hazard function. These models have been shown to be more successful at accurately estimating the underlying relationship between the covariates and the event of interest in complex problems than the traditional models.

In this work, we demonstrate multi-modal survival analysis to predict the probability of a preclinical subject being diagnosed with DAT as a function of time, for the potential clinical utility and a better understanding of how different data inform the time-to-diagnosis prediction. To the best of our knowledge, this is the first study that performs a comprehensive survival analysis on the prediction of the time to conversion to DAT for subjects in various stages of the disease. Moreover, we use multimodal data and explicitly compare the predictive power of each data modality and the effect of each modality on the disease diagnosis and progression.

2. Material

2.1. Data

Data used in this study was obtained from the publicly available Alzheimer’s Disease Neuroimaging Initiative (ADNI) database (http://adni.loni.usc.edu ). ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI has been to test whether serial MRI, PET, other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimer’s disease (AD), which are defined clinically at the time of each participant visit. In addition, ADNI aims to provide researchers with the opportunity to combine genetics with imaging and clinical data to help investigate mechanisms of the disease.

2.2. Data selection and stratification

A total of 401 subjects from the first phase of ADNI (ADNI1; Mueller et al., 2005) who had the following 5 data modalities available at baseline were included in the study: MRI data;

Genetic data including Single Nucleotide Polymorphism (SNP) + APOE information (GEN);

Cognitive tests (COG) such as the Mini Mental State Examination (MMSE);

Demographic data (DEM) such as age, sex, education, and marital status;

Cerebrospinal fluid (CSF) data.

A data stratification method based on the subjects’ past, current, and future clinical diagnosis (Popuri et al., 2018; 2020; Mirabnahrazam et al., 2022) was used to divide the subjects into five subgroups using the information available throughout the entire ADNI study period, as described in Table 1. Details about the data stratification method can be found in our previous publication (Mirabnahrazam et al., 2022). Subjects from the stable Normal Cognition (sNC), unstable(u) NC, progressive(p) NC, stable Mild Cognitive Impairment (sMCI), and progressive(p) MCI stratified groups were included in this study. These groups were divided into 2 categories based on whether they received a clinical diagnosis of DAT in a future time point or not: Nonprogressive (right-censored): This category includes subjects from the sNC, uNC, and sMCI stratified groups, who did not receive a clinical diagnosis of DAT throughout the study period.

Progressive (uncensored): This category includes subjects from the pNC and pMCI groups, who received a DAT diagnosis after their initial visit during the study window.

The prediction labels for each subject in the study include (a) an event indicator of 0 or 1 indicating whether the subject was progressive (1) or non-progressive (0), and (b) a duration indicating the time between the first visit and the time when the DAT diagnosis was confirmed for progressive subjects, and the time between the first and the last visit for nonprogressive subjects.

2.3. Feature preprocessing for the Multimodal input data

We used all of the available features from the Cognitive tests (10 features), Demographics (4 features), and CSF (7 features) categories in the ADNI database and created a new set of 21 features called CDC. To perform a fair comparison between the feature sets, we selected the top 21 most important features each from the MRI and genetic data. The feature selection process was described in our previous work (Mirabnahrazam et al., 2022). All 63 features chosen for this study are listed in Table A.1, available in Section A of the Supplementary Material.

To avoid removing subjects, missing values were replaced by an out-of-range value as suggested by Twala et al. (Twala, Jones, and Hand, 2008). Section B in Supplementary Material includes a comparison between this method and 2 other methods for handling missing values. Feature scaling was performed to ensure a consistent set of feature ranges (Ma et al., 2019). Standardization (x˙=x−x¯σ) was performed on the features with either categorical or continuous data types, while binary features remained unchanged. In the previous equation, x˙ is the standardized feature vector, x is the original feature vector, x¯ is the mean of that feature vector, and σ is its standard deviation. Section C in Supplementary Material compares the performance of our pre-processing method with two other methods.

3. Methods

3.1. DeepSurv survival model

Survival analysis, or time-to-event analysis, is used to estimate the time until an individual or a group of individuals experience an event of interest. However, it is common in time-to-event data that some individuals are not followed up on their event time for a variety of reasons, including leaving the study or experiencing another event that prevents them from experiencing the event of interest, resulting in censored times rather than event times. While many analyses ignore these observations, one of the most important contributions of survival analysis methods is to account for them.

In this work, we have utilized a deep-learning-based survival analysis model called DeepSurv (Katzman et al., 2018), which extends the classic Cox proportional hazard model, to predict, analyze, and compare the time-to-conversion to DAT. Cox regression model (Cox, 1972) provides a semiparametric specification of the hazard rate: (1) h(t∣x)=h0(t)exp[g(x)],g(x)=βTx,

where h0(t) is a non-parametric baseline hazard, and exp[g(x)] is the hazard ratio or risk score. Here, x is a covariate vector or a vector of features included in the study and β is a parameter vector. The hazard ratio exp[g(x)] is the parametric part of the model which consists of a linear predictor g(x)=βTx. The Cox partial likelihood, with Breslow’s method for handling tied event times (Breslow 1972), is given by: (2) Lcox=∏i(exp[g(xi)]∑j∈Riexp[g(xj)])Di

The negative partial log-likelihood can then be used as a loss function: (3) loss=∑iDilog(∑j∈Riexp[g(xj)−g(xi)]),

where i denotes an individual, Di is an event indicator labelling a progressive (uncensored; Di=1) or non-progressive (right-censored; Di=0) observation, and Ri is the set of all individuals at risk at time Ti (not censored and have not experienced the event before time Ti). The negative partial log-likelihood was minimized using Newton-Raphson’s method.

To construct a nonlinear version of the Cox model, the linear predictor g(x)=βTx in the relative risk function above is replaced a nonlinear function, in which g(x) is parametrized by a neural network. The predictions are obtained by estimating the survival function, S^(t∣x)=exp[−H^(t∣x)], where H^(t∣x) is the cumulative hazard function, which is commonly used for specifying different survival models, and is defined as: and in practice can be estimated by: (4) H(t∣x)=∫0th(s∣x)ds=∫0th0(s)exp[g(x)]ds,

and in practice can be estimated by: (5) H^(t∣x)=∑Ti≤tΔH0^(Ti)exp[g^(x)],

where ΔH0^(Ti) is an increment of the Breslow estimate (Breslow, 1972): (6) ΔH0^(Ti)=Di∑j∈Riexp[g^(xj)]

and g^(x) is the estimate of g(x) obtained from by fitting a neural network.

In order to evaluate the performance of the above model, we have trained our data using the Cox model (Cox, 1972) as benchmark, as well as 4 other best-performing deep learning-based models in the literature and reported the results in section D of Supplementary Material.

3.2. Evaluation metrics

3.2.1. Concordance index

Concordance index or C-index (Harrell et al., 1982) is arguably the most widely used metric for global assessment of prognostic models in survival analysis. The C-index estimates the likelihood that the predicted survival times of a random pair of individuals will have the same ordering as their true survival times among all pairs of subjects that can be ordered. The C-index attempts to describe the performance of a model based on the assumption that patients who lived longer should be assigned a lower risk than patients who lived shorter. A “good” model, according to the C-index (C = 1), is the one that always assigns a higher score to the subject who have experienced the event earlier.

Fig. 1 illustrates the graphical representation of C-index computation in the presence of censored data, inspired by a graphical representation proposed by Steck et al. (2008). When calculating the C-index between 2 data points, we can determine the order of the events if both data points are progressive (uncensored). If one of the data points is non-progressive (right-censored), concordance can be calculated only if the censoring occurs after the event for the progressive (uncensored) data point. Concordance cannot be evaluated for a pair if both data points are nonprogressive (right-censored) or if both events occur at the same time.

The C-index is computed at the initial time of observation and only depends on the ordering of the predictions; hence it cannot reflect the possible change in the risk over time. Therefore, here we use the time-dependent concordance index (Ctd-index) (Antolini, Boracchi, and Biganzoli, 2005), which estimates the probability that observations i and j are concordant provided that they are comparable: (7) Ctd=P{S^(Ti∣xi)〈S^(Tj∣xj)|Ti&lt;Tj,Di=1}.

3.2.2. Brier score

The Brier score (BS) (Brier, 1950) is used to evaluate the accuracy of a predicted survival function. It represents the average squared distances between the observed survival status, yi∈{0,1}, and the predicted survival probability, pi^ and is always a number between 0 and 1, with 0 being the best possible value. (8) BS=1N∑i(yi−p^i)2,

where N is the number of observations. To get binary outcomes from time-to-event data, we choose a fixed time t and label data according to whether an individual’s event time is shorter or longer than t. To account for censored data, the Brier score has been generalized (Graf et al., 1999) by re-weighting the scores by the inverse censoring distribution, (9) BS(t)=1N∑i=1N[S^(t∣xi)21{Ti≤t,Di=1}G^(Ti)+(1−S^(t∣xi))21{Ti&gt;t}G^(t)]

Here N is the number of observations, G^(Ti) and G^(t) are the Kaplan-Meier (Kaplan and Meier, 1958) estimates of censoring distribution at times Ti and t, and it is assumed that the censoring times and survival times (i.e., time-to-conversion) are independent. The Brier score can be extended from a single duration t to an interval by computing the integrated Brier score (IBS): (10) IBS=1t2−t1∫t1t2BS(s)ds.

3.3. Network architecture

The base neural network used to train the data is a multilayer perceptron (MLP) with the same number of nodes in each hidden layer, rectified linear unit (ReLU) activation function, and batch normalization between the layers. For regularization, we used dropout (Srivastava et al., 2014), normalized decoupled weight decay (Loshchilov and Hutter, 2017) and early stopping. We utilized the cyclic AdamWR (Loshchilov and Hutter, 2017) optimizer with an initial cycle length of one epoch. The optimizer multiplies the learning rate with 0.8 and doubles cycle length after every cycle. The initial learning rate was found using the methods proposed by Smith (2017). The output of the network is a single node that estimates the hazard rate in the Cox model (equation (1)). We then obtain the predictions by estimating the survival function, S^(t∣x)=exp[−H^(t∣x), from the estimated cumulative hazard by following equations (4–6).

We performed hyperparameter search using the repeated random sub-sampling approach, also known as the Monte Carlo cross-validation (Xu and Liang, 2001), with 100 splits on our data including all 63 features. In each split, 80% of the subjects were chosen at random for training, with the remaining 20% reserved for validation. The data was stratified so that each time, 80% of the subjects from the sNC, uNC, pNC, sMCI, and pMCI groups were included in the training set. This method ensures that the network is exposed to a representative subset of data in each split, resulting in a more accurate learning experience. We ran hyperparameter search on the parameters listed in Table 2 and chose the model with the highest validation set score calculated from the loss function in equation (3). The hyperparameter values highlighted in bold in Table 2 were used as a fixed set of parameters to train the data using different feature combinations across all experiments. Fig. 2 illustrates our network architecture.

4. Experiments

4.1. Multimodal survival comparison

Using Monte Carlo cross-validation (Xu and Liang, 2001) with 10 splits, each time we randomly selected 80% of the subjects for training and 20% of the subjects for testing. The train-test split was performed in a stratified fashion such that each time 80% of the subjects in each of the sNC, uNC, pNC, sMCI, and pMCI were included in the training set. In each split, 20% of the training subjects were randomly selected for internal validation. The number of subjects included in each of the 10 training, validation, and testing sets is shown in Table 3.

Seven experiments were conducted using identical hyper-parameters for the model using the following features: Genetic data only (GEN; 21 features),

MRI data only (MRI; 21 features),

The combination of cognitive test data, demographic, and CSF measures (CDC; 21 features),

Combined MRI and genetic data (GEN + MRI; 42 features),

Combined genetic and CDC data (GEN + CDC; 42 features),

Combine MRI and CDC data (MRI + CDC; 42 features),

All features combined (GEN + MRI + CDC; 63 features).

In each split, our method estimates the survival rate for each subject over a 10-year period. To evaluate and compare the performance of the model, we reported the average of time-dependent concordance index (Ctd-index) and the Integrated Brier score (IBS) over 10 splits.

4.2. Feature importance analysis

To assess the significance of the features used in the previous step, we used a method called Permutation Importance (Breiman, 2001), which allows us to treat and inspect fitted machine learning models as black-box estimators. The technique computes the importance of a feature by measuring how the evaluation score changes when the feature is not available. This is accomplished by shuffling the values in the original feature to generate random noise with the same distribution as the original feature. This procedure removes any relationship between the feature and the target, and the drop in the model score reflects how much of the model performance depended on the particular feature.

The importance of each feature j (a column of the dataset) is defined as: (11) ij=s−1K∑k=1Ksk,j

where s is the reference score of the trained model on the unshuffled data, K is the number of times column j was shuffled, and sk,j is the calculated score on the data including the shuffled column j at iteration k. Column j is randomly shuffled k times, and the resulting scores are averaged; the difference between the reference score and the averaged score from the shuffled data is defined as the importance of feature j. Positive feature importance (ij&gt;0) denotes a decrease in the score in the absence of feature j, and thus indicates a contribution from feature j on the model performance, while negative feature importance (ij&lt;0) denotes an increase in the score in the absence of the feature and a potential negative effect the feature can have on the performance of the model.

We analyzed the feature importance in the GEN, MRI, CDC, and GEN+MRI+CDC feature sets to investigate the significance of each feature type alone and in combination. Ctd-index has been used as the evaluating score, and each feature was shuffled 10 times. The scores were calculated on the trained models from 3.4.1 and using the data in the testing sets.

Based on the feature importance analysis, we removed features with negative feature importance (ij&lt;0) from each of the MRI, GEN, CDC, and MRI+GEN+CDC feature sets, and using the same setting to investigate whether including these features reduced the overall performance of the model.

4.3. Progressive versus nonprogressive survival analysis

To compute the survival estimates over time, in each split, we used our trained model to estimate the survival curve for 80 subjects in the testing set. Next, we averaged the survival curves of the subjects who were in more than one testing sets to create the final set of survival estimates across 10 splits. Some of the subjects were never included in the testing set. Table 4 shows the number of subjects who were included in the testing set at least once across 10 splits.

A good survival model should predict a high survival rate for non-progressive subjects, whereas the progressive subjects should be associated with a low survival rate. To validate this, we used the survival estimates of the 206 nonprogressive and 150 progressive subjects obtained using all available features (MRI+GEN+CDC) and examined the survival trend of the subjects in these 2 groups. We investigated the survival trend over 1, 2, 5, and 10 year durations, starting from the initial clinical visit for each subject.

4.4. Performance comparison between different survival models

Several studies have attempted to compare the performance of different continuous-time and discrete-time survival analysis models on real-life datasets (Spooner et al., 2020; Beaulac et al., 2020; Kvamme and Borgan, 2019). In order to evaluate the performance of our model, we compared the prediction performance using all 63 features by both the DeepSurv and the traditional Cox proportional hazard (CoxPH) model (Cox, 1972), which served as the benchmark, as well as several best-performing deep learning-based models in the literature. The following deep learning-based survival analysis models were included in the comparison: DeepHit (Lee et al., 2018): DeepHit is a discrete-time survival analysis model that estimates the survival distribution’s probability mass function (PMF) and combines the log-likelihood of the censored data with a ranking loss for improved discriminative performance.

Nnet-survival or Logistic-Hazard (Gensheimer and Narasimhan, 2019): Logistic-Hazard is a discrete-time survival model which parametrizes the discrete-time hazard rate with a neural network to optimize the survival likelihood.

PC-Hazard (Kvamme and Borgan, 2019): Piecewise Constant Hazard is a continuous-time survival model in which the hazard rate is assumed to be piecewise constant in predefined intervals.

Cox-Time (Kvamme, Borgan, and Scheel 2019): Cox-time is a nonlinear and nonproportional extension of the classic Cox regression model. The hazard ratio in the Cox-Time model is defined to include time as a regular covariate (g(t,x)), allowing for model interactions between time and other covariates.

5. Results

5.1. Multimodal survival comparison

Fig. 3 illustrates the performance comparison of the 7 different feature sets used to train our model. The top graph represents the Ctd-index performance results, where higher scores indicate superior performance, and the bottom graph shows the IBS results, where lower scores are preferable. When comparing the results obtained from a single modality (GEN, MRI, and CDC), CDC (green) showed a significantly better performance in both Ctd-index (0.822) and IBS (0.111) compared to GEN (Ctd-index = 0.589, p-value: 2 × 10−7); IBS = 0.206, p-value: 1.38 × 10−5) and MRI (Ctd-index = 0.727, p-value: 2.18 × 10−6; IBS IBS = 0.160, p-value: 2.45 × 10−5). Combining MRI and GEN features (red) improved model performance over using either GEN (blue) or MRI (orange) features alone using both metrics (Ctd-index: 0.76 vs. 0.589 and 0.727; IBS: 0.148 vs. 0.206 and 0.16). This improvement was statistically significant using both metrics when compared to GEN (Ctd-index p-value: 3.57 × 10−5; IBS p-value: 0.0017) and using Ctd-index when compared to MRI (p-value: 0.0334).

Adding CDC to any feature set (GEN+CDC (purple), MRI+CDC (brown), and MRI+GEN+CDC (pink)) improved performance over using that feature set without CDC (GEN (blue), MRI (orange), MRI+GEN (red)). However, when compared to using CDC features alone, combining CDC with other features did not result in statistically significant improvement in performance. This is an interesting result given that deep learning models are known to benefit from a large amount of data, this suggests that different modalities contribute in different ways in the prediction of the survival variable and that more is not always better. The combination of MRI and CDC features (brown) had the best overall performance, closely followed by the results obtained using only CDC features (Ctd-index: 0.831 (MRI+CDC) and 0.822 (CDC); IBS: 0.105 (MRI+CDC) and 0.111 (CDC)).

5.2. Feature importance analysis

Fig. 4 shows the results of feature importance analysis for the models trained using GEN, MRI and CDC feature sets. The top graph depicts the feature importance results for GEN features. Fourteen14 of the 21 features in the features set have been shown to have a positive effect on the performance. The most important feature in this feature set is the well-known AD biomarker APOEε4, followed by rs2883782 on chromosome 2 and rs10510985, rs7627954, and rs6773506 on chromosome 3. The middle graph in Fig. 4 shows the feature importance results for MRI features. Fifteen of the 21 features used were shown to have a positive effect on the performance. The hippocampus region on the left hemisphere is the most important feature in this feature set and its importance rate is at least twice larger than the importance rate of any other features. Other important features include amygdala (left hemisphere), hippocampus (right hemisphere), inferior parietal lobule (right hemisphere), and supramarginal gyrus (left hemisphere). The feature importance results for CDC features are shown in the bottom graph of Fig. 4. Most of the features in this features set were found to be contributive, with only 2 showing negative importance rates. Eight of the top 10 most important features were drawn from cognitive tests, with the Delayed Recall variable from the Logical Memory Test (LDEL-Total) being the most important. Sex and education were also among the top 10.

The results of the feature importance analysis on models trained with all available features (GEN+MRI+CDC) is shown in Fig. 5. We found that 27 of the 63 features, including 6 GEN features, 9 MRI features, and 12 CDC features, were shown to have a positive effect. The top 5 most important features were cognitive test features in the CDC feature set, with the CDRSB (Clinical Dementia Rating Scale) being the most important, closely followed by LDEL-Total. The hippocampus on the left hemisphere was the most important MRI feature, ranking among the top 10 in this feature set.

The large confidence bands in Figs. 4 and 5 suggested the individual feature importance had a high variability and further investigation was warranted. To do so, we trained our model again after dropping all the variables with negative importance. Table 5 shows the impact of removing these features on the model performance using Ctd-index as the evaluation metric. As it can be seen, removing features with negative importance rate improved the performance in all cases, and this improvement was statistically significant (p &lt; 0.05) for GEN and GEN+MRI+CDC feature sets. This shows that these predictors were indeed confounding and supports the results of our feature importance analysis. Table 6 demonstrates a similar result using IBS as the evaluation metric.

5.3. Progressive versus nonprogressive survival analysis

Fig. 6 displays the final survival probability across 10 splits for the subjects in the progressive and nonprogressive groups at the end of various time durations. A high survival probability indicates a high likelihood of NOT developing DAT or a low likelihood of developing DAT, whereas a low survival probability indicates a high likelihood of developing DAT within the given time period.

One year after the initial visit (top left graph), approximately 74% of the nonprogressive subjects had above 90% chance of survival while only 23% of the progressive subjects had this chance. Over a 2-year period (top left graph), more than 85% of nonprogressive subjects had a chance of survival greater than 50% (top 5 bars combined), and more than 58% had over 90% chance of survival. However, only half of the progressive subjects showed a survival chance of more that 50% with only 13% had over 90% survival probability.

The survival probability 5 years after the initial visit is shown in the bottom left graph. As can be seen, approximately 40% of nonprogressive subjects still had a 90% chance of survival, while less than 10% of progressive subjects had this chance. The proportion of the progressive subjects with the lowest survival chance (&lt; 10%) was more than 3 times higher (34%) than the proportion of the nonprogressive subjects (10%) with the same survival probability. Ten years after the initial visit (bottom right graph), more than half of the nonprogressive subjects still showed greater than 50% chance (bottom 5 bars combined) of survival, while about 27% showed a very low chance (&lt; 10%) of survival. In the progressive group, 78% of the subjects had a very low chance of survival (&lt; 10%), and only 8% had a chance of survival greater than 50%.

The true time-to-conversion to Alzheimer’s disease (event time) is available for the progressive subjects and can be compared to the predicted time-to-conversion. Fig. 7 shows a histogram of the differences between the predicted and true event times for progressive subjects (150 subjects) using the GEN+MRI+CDC feature set. Here, the predicted time is defined as the time when a subject’s survival probability reaches 50%. If a subject’s predicted survival likelihood does not drop below 50% during the 10-year time-frame, it means the model regarded the subject to be at low risk of developing DAT and thus a nonconverter based on the input information provided; otherwise, the subject is considered a converter. To obtain the time differences for all progressive subjects, we set the time-to-conversion as 20 years from the initial visit for those progressive subjects whose predicted survival probability did not reach 50% at the end of the 10-year period.

In Fig. 7, each bar represents the number of subjects with a specific range of time difference. The bar at zero, for example, represents the number of subjects whose predicted event time −− true event time was between −0.5 and 0.5 years, and the bar at 2 shows the number of subjects with predicted event time −− true event time ∈ (1.5, 2.5). The true and predicted event time difference was less than 1 year for 40 subjects (26.7%). More than half of the progressive subjects (80 of 150, or 53.4%) had a time difference of less than 1.5 years, as shown by the 3 bars at −1, 0, and 1. The predicted event time was earlier than the actual event time for 37 subjects (24.7%; bars with negative time difference), indicating that our model detected the risk of developing DAT for those subjects prior to the actual event. Despite the difference between the true and predicted event times, 92% of the subjects were correctly predicted as converters and only 8% (12 outlier subjects) of them were predicted as nonconverters based on the survival data.

6. Discussion

6.1. Survival analysis to predict the time to conversion of Alzheimer’s disease

The application of survival analysis methods to predict the time to conversion of Alzheimer’s disease is crucial for identifying at-risk populations and planning early interventions. The available studies in the literature have mostly focused on using single data modalities as predictive features (Aschwanden et al., 2020 ; Nakagawa et al., 2020 ; Orozco-Sanchez et al., 2019), or only on predicting the time to DAT conversion for patients with Mild Cognitive Impairment (MCI), or time to conversion to MCI for healthy subjects (Li et al., 2019 ; Liu et al., 2017; Lu &amp; Colliot, 2021 ; Pölsterl et al., 2019 ; Spooner et al., 2020 ; H. Zhou et al., 2019) rather than predicting the conversion time for subjects in all stages of the disease. The current study performs comprehensive analysis to predict the time to conversion to DAT for subjects in various stages of the disease using multimodal data. Also, it compares the predictive power of each data modality and the effect of each modality on the disease diagnosis and progression.

One of the main focuses of the study is to evaluate and compare the predictive powers of different data types, individually and in combination, within a single deep survival analysis framework. A similar approach of multi-modal prediction of DAT through survival analysis has been recently reported by Yang et al. (2021). In Yang et al., the composite score experiment compared (1) ADAS-Cog score only, (2) T1 MRI patterns only, (3) ADAS-Cog + T1 MRI patterns, and (4) ADAS-Cog + T1 MRI patterns + CSF Aβ/pTau status, where the MRI patterns of imaging-derived sub-phenotypes were computed from regional brain volumes using a generative adversarial framework (Smile-GAN). In comparison, our experiments used (1) multiple cognitive scores in addition to ADAS-Cog score, (2) regional brain volumes as MRI features, and (3) genetic information but not Abeta/pTau status. In Yang et al.’s experiment, the predictive performance improved by combining the ADAS-Cog score and the MRI patterns, compared to ADAS-Cog only. This finding may be explained by the results of our feature importance analysis, where we noted that multiple cognitive test scores other than ADAS-Cog were shown to be highly contributive for predicting conversion. Also, Yang et al.’s smile-GAN-derived MRI patterns showed that the effective sub-phenotyping to describe AD-related neurodegeneration can be more conducive for conversion prediction than using raw MRI regional volumes. We also note that in Yang et al. experiment, adding CSF Aβ/pTau status to the ADAS-Cog/MRI Patterns did not bring significant predictive performance improvement. Another difference between the 2 studies is the approach to survival analysis. In Yang et al., survival analysis is used to differentiate the disease progression among different groups, while in this study, we predicted the survival trajectory for each subject separately, enabling individualized prediction of dementia onset time.

6.2. Feature importance analysis

The order of the feature importance rates shown in Fig. 5 closely reflects the results of the performance comparison using different feature sets shown in Fig. 3. Having 7 of the top 10 most important features from the CDC modality demonstrates the importance of these features on the prediction performance and explains why adding the CDC features to other feature sets results in an improved performance. Based on the results shown in Fig. 5, we can summarize the relative contributions of different features as that GEN features contribute the least, followed by MRI features and CDC features, with CDC features contributing the most to the model performance. The same pattern can be seen in the performance comparison results between GEN (blue), MRI (orange), and CDC (green) feature sets displayed in Fig. 3.

Cognitive test features (COG) were found to play an important role in our analysis. Our study included a total of 10 COG features, and the feature importance analysis using the CDC feature set showed that all ten had a positive effect on the prediction performance (Fig. 4, bottom graph). In the feature importance analysis using all feature types, 7 COG features were shown to contribute positively, with an importance rate higher than all other feature sets (Fig. 5). CSF and genetic factors, on the other hand, were found to be less important. There were 7 CSF and 21 GEN features in total, and in single modality prediction 14 of 21 GEN features (Fig. 4, top graph) and 5 of 7 CSF features (Fig. 4, bottom graph) were found to be contributive. The only 2 features with negative feature importance in the CDC feature sets were CSF measures. Furthermore, the feature importance results using all features (Fig. 5) only identified 6 GEN and 2 CSF features as significant when COG data were available.

6.3. Evaluation of time-to-conversion estimates and their benefits

Using survival analysis techniques to estimate time-to-conversion to Alzheimer’s disease has several advantages over other methods such as regression. First, there is no need to exclude subjects who did not develop DAT during the study period, which allows us to benefit from data collected from all study participants and ensure we do not accidentally bias the study by excluding these subjects. Second, survival analysis estimates the survival probability over time, allowing us to compute the survival probability at multiple time points and describe the overall trend of survival for each patient given various phenotype, genotype, clinical and demographic information.

To evaluate the time-to-conversion estimates and to assess their applicability in a clinical setting, we randomly selected 4 subjects from each of the nonprogressive and progressive groups and displayed their predicted survival times along with the true censoring or event times in Fig. 8. Fig. 8A–D (left side) belong to the nonprogressive subjects, and their censoring time (green line) has been displayed along with the estimated survival probability, whereas Fig. 8 E–H (right side) belong to the progressive subjects, and their event time (red line) has been displayed along with the estimated survival probability.

The uNC subject in A and the sNC subjects in C were censored around 10 years after their initial visit. At the end of the time window, both subjects still showed a very high survival probability, indicating they are at a low risk of developing DAT. The sMCI subject in B was censored 6 months after the initial visit and had a survival probability of around 60% at the time of censorship. After 4 years, this subject’s survival chance was dropped to 0%, indicating that the subject is likely to develop DAT in the future. The sNC subject in D was censored immediately after the initial visit and had a survival probability of 100% at the time of censoring. The subject’s chance of survival decreased over time, reaching 20% at the end of the 10-year time window, indicating that they may develop DAT 7–10 years after their initial visit.

The pMCI subjects in graphs Fig. 8 E, G, and, H were all diagnosed with Alzheimer’s disease around the same time, from 1 to 2 years after their initial visit. All 3 pMCI subjects had a similar survival curve, which could indicate similar disease severity among the subjects. The pNC subject in Fig. 8F developed DAT symptoms 6 years after the initial visit. Despite having a higher chance of survival than the other progressive subjects at the event time, this subject’s survival probability dropped from 100% to 20% over a 10-year period, placing the subject in the high-risk category.

We emphasize that for all subjects in the study, only the information obtained at the initial visit (time = 0) was used as covariates in our model. For example, for pNC subjects, the model was only exposed to information when those subjects were clinically assessed to have normal cognition. This highlights the potential clinical utility of the work, as practitioners only have access to the information gathered at the current time point when at-risk subjects visit them for the first time. Being able to accurately estimate the survival chance over time using only the baseline information is extremely valuable because it provides practitioners with extra information to plan appropriate care for each patient ahead of time based on their future survival probability. Accurate time-to-conversion estimate for at-risk patients can also provide critical information for the development of preventative measures as well as drug trials. For example, such information may enhance the selection of the most appropriate cohort of patients for clinical trials.

6.4. Evaluate the predicted time-to-conversion for pNC versus pMCI subjects using different feature sets

The progressive group includes subjects from the pNC and the pMCI stratified subgroups. The pNC subjects are those who were healthy at their initial visit but develop DAT at a later point in time. Therefore, the MRI, CSF, and cognitive test data gathered during their initial visits reflect their health conditions at the time. Genetic data, on the other hand, remains constant over time and thus, is the only factor that may point to these subjects’ potential risk of developing Alzheimer’s disease during the initial visit. The pMCI subjects are those who had MCI at their initial clinical visit and developed DAT at a future timepoint. In addition to genetic data, MRI, CSF, and cognitive test data may provide useful information about the MCI stage in these subjects.

Fig. 9 shows the difference between the predicted and true event times for subjects in the pNC (left; 13 subjects) and the pMCI (right; 137 subjects) stratified groups using single modality (GEN, MRI, and CDC) feature sets as well as the combined data modality (GEN+MRI+CDC) feature set. As expected, for pNC subjects, using GEN features (A, left side) resulted in the most accurate prediction for time-to-conversion in comparison to using other feature sets. More than half of the pNC subjects (53.9%) had a time difference of less than 1.5 years. There were no outliers when GEN features were used, and all 13 subjects were correctly predicted to be DAT converters. Using MRI features (B, left side), 6 pNC subjects (46.2%) were correctly predicted as converters, while the remaining subjects were predicted as nonconverters. Using CDC features (C, left side), only 1 pNC subject was correctly predicted as a converter, while using combined features (D, left side), 4 subjects were predicted as converters. Overall, GEN features were found to be most helpful for in time-to-conversion prediction for pNC subjects, while CDC features were found to be the least helpful.

For pMCI subjects, CDC features (C, right side) resulted in the best time-to-conversion prediction among the single modality feature sets. 62.5% of pMCI subjects had a time difference of less than 1.5 years with prediction using only CDC features. There were only 2 outliers (1.4%), and 98.6% of the subjects were correctly classified as DAT converters. Using MRI features (B, right side) resulted in 11 outliers (8%), whereas using GEN features (A, right side) resulted in 4 outliers (2.9%). Although using GEN features resulted in fewer outliers, the time differences were more scattered when compared to using MRI features. Using combined features (D, right side) produced a histogram that was similar to the histogram produced by CDC features, indicating that CDC features are the most effective features in time-to-event prediction for pMCI subjects. Overall, all 3 data modalities were shown to be useful in time-to-event prediction for pMCI subjects, with CDC having the greatest contribution.

We discovered that genetic data (GEN) has the potential to detect the risk of developing DAT in the future for currently cognitively normal subjects, while other modalities have a lower predictive power at this very early disease stage. This information can be used in a clinical setting to determine the order of data acquisition for patients at different stages of the disease. Cognitive tests are fast and inexpensive to acquire, and therefore can be performed first to determine the state of a patient’s health. If a patient is determined to be cognitively healthy at the initial visit, genetic data can then be obtained to determine the likelihood of developing DAT. Other data modalities, such as MRI and CSF data, can be collected during subsequent follow-up visits to closely study the patients’ disease progression.

6.5. Performance comparison between different survival models

Comparison of different survival analysis models based on the Ctd-index is shown in Table 7. The traditional CoxPH model performed very similarly to our main model (DeepSurv; (Katzman et al., 2018)). Using the GEN and GEN+MRI+CDC feature sets, CoxPH outperformed DeepSurv with statistical significance. DeepSurv outperformed CoxPH in 4 of 7 cases, but the differences were not statistically significant. When compared to other deep learning-based models, DeepSurv performed the best across all feature combinations. The differences with DeepSurv were statistically significant when compared to the Logistic-Hazard model, and almost all of the differences were statistically significant when compared to the PC-Hazard model, with the exception of when the GEN+MRI+CDC feature set was used. DeepHit and Cox-Time model outcomes were more comparable to DeepDurv outcomes. DeepSurv outperformed the DeepHit model statistically in 4 of 7 cases, while the results were significantly better in 2 of 7 cases when compared to Cox-Time.

Table 8 displays the model comparison results using IBS as the evaluation metric. The traditional CoxPH model performed very similarly to DeepSurv. DeepSurv outperformed CoxPH in 5 of the 7 cases, while CoxPH performed better in the remaining 2. However, none of the differences were statistically significant. Our main model, DeepSurv, outperformed all deep learning-based models. However, contrary to the trend seen in Table 7, Logistic-Hazard and PC-Hazard performed most similarly to DeepSurv. DeepHit performed the worst in terms of IBS, and when compared to DeepSurv results, the differences were statistically significant in most cases, except when the GEN feature sets were used. When the MRI+CDC feature set was used, the IBS increase for the Cox-Time model was statistically significant compared to DeepSurv, and overall, Cox-Time was the second worst performing model.

7. Limitations

Our results are limited by the sample size and characteristics of the subjects selected from the ADNI database. An approach to address this limitation would be to include additional AD related databases such as the NACC/NIAGADS dataset (https://naccdata.org/ and https://www.niagads.org) to perform independent evaluation, which can lead to a more robust model.

In addition, the standard deviation appears to be high for all cases in Figs. 4 and 5, which may be an indication of the Permutation Importance method’s high sensitivity to the input data. The Permutation Importance approach provides a highly compressed, global insight into the model’s behavior and, to the best of our knowledge, is the best model inspection technique for black-box estimators. However, the method is highly dependent on both the main feature effect and the interaction effects with other features, and estimates how important a feature is for a specific model by taking into account the interaction between the features. As a result, when interpreting feature importance using this method, it is important to consider that changing the feature set used to train the model can affect the order of importance for the features.

Furthermore, in this study, we have performed the hyper-parameters search and evaluated the model performance and feature importance on the network architecture with the highest validation performance (Table 2). On the other hand, there are chances that the derived feature importance might be model-specific. Future work could include a comprehensive evaluation on the robustness of the features identified as important by studying the effect of model hyper-parameters variation with these features.

Finally, the MRI-based neuroimaging features used in this study were derived from the FreeSurfer segmented structural volumes. However, deep learning methods have shown superior performance by learning features from voxel-level whole-brain data. Therefore, potential improvement of the neuroimaging features could be achieved by learning the representations from the raw MRI data (Abrol et al., 2021; Peng et al., 2021; Yee et al., 2021; Yee et al., 2022). On the other hand, MRI data inherit biases coming from confounding factors such as scanner and coil differences, as well as demographic diversity in the training population such sex, age, and racial difference, and harmonization is necessary to reduce such intrinsic bias (Ma et al., 2019). Therefore, special care is required when training and applying predictive models using voxel-level whole brain MRI, for which the data harmonization and confounding factor removal are less trivial than in predefined MRI-derived metrics (Ma et al., 2021, 2019; Popuri et al., 2020; Yee et al., 2021).

Supplementary Material

Supplemental Material

Acknowledgements

Funding for this research is gratefully acknowledged from Alzheimer Society Research Program, National Science Engineering Research Council (NSERC), Canadian Institutes of Health Research (CIHR), Fondation Brain Canada, Pacific Alzheimer’s Research Foundation, the Michael Smith Foundation for Health Research (MSFHR), the National Institute on Aging (R01 AG055121-01A1, R01 AG069765-01, R01 AG071514-01), National Institute of Neurological Disorders and Stroke (NINDS) (R01 NS101483-01A1), Precision Imaging Beacon, University of Nottingham, Canadian Statistical Sciences Institute (CANSSI), and Wake Forest School of Medicine Start-up Funds, Wake Forest Alzheimer’s Disease Research Center with funding from the National Institute on Aging under award number (P30AG072947). We thank Compute Canada for the computational infrastructure provided for the data processing in this study.

Data collection and sharing for this project was funded by the Alzheimer’s Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie, Alzheimer’s Association; Alzheimer’s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research &amp; Development, LLC.; Johnson &amp; Johnson Pharmaceutical Research &amp; Development LLC.; Lumosity; Lundbeck; Merck &amp; Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer’s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.

Fig. 1. Graphical representation of C-index computation. Each circle indicates the predicted survival time for a data point. The red circles represent the progressive (uncensored) data points and the blue circles represent the non-progressive (right-censored) data points. The figure illustrates the pairs of data points for which an order of events can be established.

Fig. 2. Network architecture used as the base model. Input data includes a subject’s feature vector (x), including MRI, genetic, or CDC features and the network’s output is the estimated hazard rate for that subject. The survival estimate for a subject is calculated from the estimated hazard rate using S^(t∣x)=exp[−H^(t∣x)] where H^(t∣x) is the cumulative hazard rate.

Fig. 3. Performance comparison between different feature sets using time the dependant concordance index (Top row), and Integrated Brier score (Bottom row). Each bar represents the mean C-index over ten splits, with the standard deviation indicated by a vertical error bar. The mean value has been printed above each bar. The name of each feature set (number of features) is shown on x asis.

Fig. 4. Feature importance results for GEN (top), MRI (middle), and CDC (bottom) feature sets. Each bar represents the mean score over ten splits, with the standard deviation indicated by a vertical error bar. X axis labels are color-coded: The colors on the top graph (GEN) indicate different chromosomes. In the middle graph (MRI), red shows the right (R) and blue shows the left (L) hemisphere of the brain. CSF, cognitive test (COG), and demographic (DEM) data are color-coded on the bottom graph.

Fig. 5. Feature importance results for the GEN+MRI+CDC feature set. Each bar represents the mean score over ten splits, with the standard deviation shown as a horizontal error bar. Data modalities have been color coded on y axis for ease of view (GEN, MRI, CDC). GEN labels indicate SNP (Chromosome number), MRI labels indicate Hemisphere-ROI name, and CDC labels indicate feature (data modality). COG, cognitive test data; DEM, demographic data.

Fig. 6. Estimated survival probability for progressive versus nonprogressive subjects over various time periods using the GEN+MRI+CDC feature set. The survival probability is divided into 10 equal percentile and each bar represents the proportion of the subjects in each percentile for both groups. The legend displays the total number of subjects in each group. The cyan bars represent the nonprogressive subjects, and the red bars represent the progressive subjects.

Fig. 7. Histogram of the difference between the predicted and true event times for 150 progressive subjects using the GEN+MRI+CDC feature set. The predicted event time is the time when a subject’s survival probability reaches 50%. If a subject’s survival probability does not reach 50% by the end of the 10-year period, the subjects is considered a DAT nonconverter (shown in dark purple), and the time difference is calculated by setting the predicted event time to an out-of-range value (20 years). The percentage of subjects with a specific time difference is represented by a number printed above each bar.

Fig. 8. Comparison between the predicted survival estimates versus actual censoring times (left) or event times (right) for 8 random subjects. The predicted event time is defined as the time when a subject’s survival probability reaches 0.5. The horizontal dotted line represents a survival probability of 0.5, and the intersection of this line and the survival estimate curve (shown with a filled circle) represents the predicted event time for the subjects.

Fig. 9. Histograms of the differences between the predicted and true event times for pNC (13 subjects, left) and pMCI (137 subjects, right) groups using (A) GEN, (B) MRI, (C) CDC, and (D) GEN+MRI+CDC feature sets. The predicted event time is the time a subject’s survival probability reaches 50%. If a subject’s survival probability does not reach 50% by the end of the 10-year period, the subjects is considered a DAT nonconverter (shown in dark red and dark green for pNC and pMCI respectively). The percentage of the subjects with a specific time difference range is represented by a number printed above each bar.

Table 1 Demographic information and progression group division for the ADNI subjects included in the study. Each subject is assigned a membership in a group in the form of ‘prefix{Group}’, where ‘Group’ is the clinical diagnosis at baseline, and ‘prefix’ indicates the future clinical diagnoses. The stratified groups were divided into 2 categories based on whether or not they received a clinical diagnosis of DAT in a future time point. The nonprogressive category includes subjects from the sNC, uNC, and sMCI stratified groups, who did not receive a clinical diagnosis of DAT during the study period, and the progressive category includes subjects from the pNC and pMCI groups who received a DAT diagnosis after their initial visit during the study window

Dementia trajectory	Group name	Clinical diagnosis at baseline	Clinical progression	Subjects [M:F]	Agec [Years]	CSFa, c [t-tau/Aβ1–42]	
Nonprogressiveb	sNC: stable NC	NCa	NCd → NC	58:51	75.79 (4.93)	0.34 (0.23)	
Nonprogressive	uNC: unstable NC	NC	NC → MCI	14:8	76.57 (3.70)	0.39 (0.19)	
Nonprogressive	sMCI: stable MCI	MCIa	MCId → MCI	65:36	74.70 (7.35)	0.67 (0.52)	
Progressiveb	pNC: progressive NC	NC	NC → MCI → DATa	6:8	76.49 (4.33)	0.75 (0.42)	
Progressive	pMCI: progressive MCI	MCI	MCI → DAT	99:56	73.85 (6.85)	0.82 (0.45)	
a Aβ1–42, beta amyloid 1–42; CSF, cerebrospinal fluid; DAT, dementia of Alzheimer’s type; MCI, mild cognitive impairment; NC, normal control; t-tau, total tau.

b Nonprogressive: right-censored, subjects who did not receive a DAT diagnosis within the study window, Progressive: uncensored, subjects who received a diagnosis of DAT during the study window,

c The mean (standard deviation) age and CSF measure values within each group are given; CSF measures were only available for a subset of subjects in each of the groups: sNC (57), uNC (17), sMCI (55), pNC (8), pMCI (88),

d Clinical diagnoses at baseline are shown in bold under the ”Clinical progression” column.

Table 2 Hyperparameter search space for model optimization

Hyperparameter	Values	
Hidden layers	{1, 2, 3a, 4, 5, 6}	
Nodes per layer	{10, 25, 32, 50, 64, 75, 100}	
Dropout	{0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7}	
Weight decay	{0, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5}	
Batch size	{16, 32, 64, 128, 256, 512}	
a Hyperparameter values used as the fixed parameters in the network architecture are highlighted in bold.

Table 3 Number of subjects included in the training, testing, and validation sets

Groups	Training set	Validation set	Testing set	Total	
sNC	70	17	22	109	
uNC	14	4	4	22	
pNC	9	2	3	14	
sMCI	65	16	20	101	
pMCI	99	25	31	155	
Total	257	64	80	401	

Table 4 Number of subjects included in the testing set at least one time in 10 splits. Our trained model was used to estimate a survival curve for these subjects

Stratified group	sNC	uNC	sMCI	pNC	pMCI	
# subjects (testing set/total)	96/109	20/22	90/101	13/14	137/155	
Group	Non-progressive			progressive		
# sum (testing set/total)	206/232			150/169		

Table 5 Performance comparison with Ctd-index as evaluation method before and after removing features with negative importance using the Permutation Importance method. (the larger the better)

Feature set (# step 1 / # step 2)a	Ctd-index using all features (step 1 results)	Ctd-index using features with ij&gt;0 (step 2 results)	
GEN (21/14)	0.589 ± 0.049*	0.628 ± 0.028 b	
MRI (21/15)	0.727 ± 0.025	0.744 ± 0.022	
CDC (21/19)	0.822 ± 0.022	0.826 ± 0.027	
GEN+MRI+CDC (63/27)	0.798 ± 0.026*	0.831 ± 0.017	
* paired t-test with p &lt; 0.05.

a (number of features in the main feature set /number of features with positive feature importance score),

b mean ± standard deviation over 10 splits, best performance in each row has been highlighted in bold.

Table 6 Performance comparison with IBS as evaluation method before and after removing features with negative importance using the Permutation Importance method. (the smaller the better)

Feature set (# step 1 / # step 2)a	IBS using all features (step 1 results)	IBS using features with ij &gt; 0 (step 2 results)	
GEN (21/14)	0.206 ± 0.026	0.194 ± 0.020 b	
MRI (21/15)	0.160 ± 0.013	0.157 ± 0.016	
CDC (21/19)	0.111 ± 0.019	0.116 ± 0.021	
GEN+MRI+CDC (63/27)	0.122 ± 0.016	0.109 ± 0.014	
Best performance in each row has been highlighted in bold.

a (number of features in the main feature set / number of features with positive feature importance score),

b mean ± standard deviation over 10 splits.

Table 7 Model performance comparison using Ctd-index as the evaluation metric. The performance of our main model, DeepSurv, is compared with the Cox proportional hazard model as benchmark, as well as 4 high-performing deep learning-based survival analysis models

Feature set	CoxPH (Cox, 1972)	DeepHit (Lee et al., 2018)	LogisticHazard (Gensheimer and Narasimhan, 2019)	PCHazard (Kvamme and Borgan, 2019)	CoxTime (Kvamme, Borgan, and Scheel, 2019)	DeepSurv (main (Katzman et al., 2018))	
GEN	0.651 (0.027) *	0.541 (0.050) *	0.556 (0.062)*	0.532 (0.049)*	0.589 (0.053)	0.589 (0.049)	
MRI	0.739 (0.039)	0.702 (0.044)*	0.669 (0.061)*	0.686 (0.037)*	0.718 (0.040)	0.727 (0.025)	
CDC	0.817 (0.028)	0.810 (0.020)	0.763 (0.049)*	0.779 (0.027)*	0.811 (0.036)	0.822 (0.022) a	
GEN+MRI	0.737 (0.027)	0.736 (0.050)	0.730 (0.037)*	0.710 (0.048)*	0.726 (0.035)*	0.760 (0.045)	
GEN+CDC	0.811 (0.022)	0.790 (0.036) *	0.757 (0.044) *	0.783 (0.049)*	0.795 (0.021)	0.812 (0.019)	
MRI+CDC	0.829 (0.022)	0.814 (0.023) *	0.775 (0.051)*	0.770 (0.051)*	0.799 (0.026)*	0.831 (0.028)	
GEN+MRI+CDC	0.822 (0.021) *	0.785 (0.027)	0.773 (0.040)*	0.784 (0.040)	0.799 (0.030)	0.800 (0.027)	
* paired t-test with p &lt; 0.05 when compared to the main method.

a mean (standard deviation) over 10 splits, best performance in each row has been highlighted in bold.

Table 8 Model performance comparison using IBS as the evaluation metric. The performance of our main model, DeepSurv, is compared with the Cox proportional hazard model as benchmark, as well as 4 high-performing deep learning-based survival analysis models

Feature set	CoxPH (Cox, 1972)	DeepHit (Lee et al., 2018)	LogisticHazard (Gensheimer and Narasimhan, 2019)	PCHazard (Kvamme and Borgan, 2019)	CoxTime (Kvamme, Borgan, and Scheel, 2019)	DeepSurv (main (Katzman et al., 2018))	
GEN	0.197 (0.009) a	0.216 (0.011)	0.208 (0.017)	0.208 (0.012)	0.215 (0.032)	0.206 (0.026)	
MRI	0.160 (0.020)	0.186 (0.010)*	0.162 (0.010)	0.162 (0.009)	0.178 (0.021)	0.160 (0.013)	
CDC	0.117 (0.016)	0.150 (0.016)*	0.113 (0.011)	0.113 (0.012)	0.124 (0.018)	0.111 (0.019)	
GEN+MRI	0.151 (0.013)	0.180 (0.014)*	0.151 (0.024)	0.150 (0.016)	0.169 (0.021)	0.148 (0.023)	
GEN+CDC	0.125 (0.011)	0.148 (0.015)*	0.123 (0.013)	0.122 (0.013)	0.134 (0.020)	0.121 (0.016)	
MRI+CDC	0.107 (0.012)	0.145 (0.013)*	0.107 (0.014)	0.107 (0.010)	0.132 (0.025)*	0.106 (0.016)	
GEN+MRI+CDC	0.111 (0.015)	0.157 (0.016)*	0.124 (0.010)	0.123 (0.015)	0.132 (0.015)	0.122 (0.016)	
* paired t-test with p &lt; 0.05 when compared to the main method.

a mean (standard deviation) over 10 splits, best performance in each row has been highlighted in bold.

Disclosure statement

The authors have no conflict of interest to report.

Supplementary materials

Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.neurobiolaging.2022.10.005.


References

Alzheimer’s Association, 2021. 2021 Alzheimer’s Disease Facts and Figures Special Report Race, Ethnicity and Alzheimer’s in America. Alzheimer’s &amp; Dementia. Alzheimer’s Assoc. 17 (3 ), 327–406.
An Le , Adeli Ehsan , Liu Mingxia , Zhang Jun , Lee Seong Whan , Shen Dinggang , 2017. A hierarchical feature and sample selection framework and its application for alzheimer’s disease diagnosis. Sci. Rep 7 (1 ), 1–11. doi:10.1038/srep45269.28127051
Anoop A , Singh Pradeep K , Jacob Reeba S , Maji Samir K , 2010. CSF biomarkers for alzheimer’s disease diagnosis. Int. J. Alzheimer’s Dis 2010 , 1–12. doi:10.4061/2010/606802.
Antolini Laura , Boracchi Patrizia , Biganzoli Elia , 2005. A time-dependent discrimination index for survival data. Stats. Med 24 (24 ), 3927–3944. doi:10.1002/sim.2427.
Aschwanden Damaris , Aichele Stephen , Ghisletta Paolo , Terracciano Antonio , Kliegel Matthias , Sutin Angelina R. , Brown Justin , Allemand Mathias , 2020. Predicting cognitive impairment and dementia: a machine learning approach. J. Alzheimer’s Dis 75 (3 ), 717–728. doi:10.3233/JAD-190967.32333585
Beaulac C , Rosenthal JS , Pei Q , Friedman D , Wolden S , Hodgson D , 2020. An evaluation of machine learning techniques to predict the outcome of children treated for Hodgkin-Lymphoma on the AHOD0031 trial: A report from the Children’s Oncology Group. Applied artificial intelligence. AAI 34 (14 ), 1100–1114. 10.1080/08839514.2020.1815151.33731974
Breiman Leo ., 2001. Random forests. Machine Learning. 45 (1 ), 5–32. doi:10.1023/A:1010933404324.
Breslow Norman E. , 1972. Contribution to discussion of paper by DR Cox. J. Roy. Statist. Soc., Ser. B 34 , 216–217.
Brier Glenn W. , 1950. Verification of forecasts expressed in terms of probability. Monthly Weather Rev. 78 (1 ), 1–3.
Cox DR , 1972. Regression Models and Life-Tables. Journal of the Royal Statistical Society. Series B (Methodological) 34 (2 ), 187–220. http://www.jstor.org/stable/2985181.
Devanand Davangere P. , Liu Xinhua , Tabert Matthias H. , Pradhaban Gnanavalli , Cuasay Katrina , Bell Karen , Leon , Mony J.de , Doty , Richard L , Stern , Yaakov Pelton , Gregory H , 2008. Combining early markers strongly predicts conversion from mild cognitive impairment to Alzheimer’s disease. Biol. Psychiatr 64 (10 ), 871–879. doi:10.1016/j.biopsych.2008.06.020.
Faraggi David , Simon Richard , 1995. A neural network model for survival data. Stats. Med 14 (1 ), 73–82. doi:10.1002/sim.4780140108.
Finehout Erin J. , Franck Zsofia , Choe Leila H. , Relkin Norman , Lee Kelvin H. , 2007. Cerebrospinal fluid proteomic biomarkers for Alzheimer’s disease. Ann Neurol 61 (2 ), 120–129. doi:10.1002/ana.21038.17167789
Gensheimer Michael F. , Narasimhan Balasubramanian , 2019. A scalable discrete-time survival model for neural networks. PeerJ. PeerJ Inc doi:10.7717/peerj.6257.
Graf Erika , Schmoor Claudia , Sauerbrei Willi , Schumacher Martin , 1999. Assessment and comparison of prognostic classification schemes for survival data. Stat. Med 18 , 2529–2545.10474158
Grassi Massimiliano , Rouleaux Nadine , Caldirola Daniela , Loewenstein David , Schruers Koen , Perna Giampaolo , Dumontier Michel , 2019. A novel ensemble-based machine learning algorithm to predict the conversion from mild cognitive impairment to Alzheimer’s disease using socio-demographic characteristics, clinical information, and neuropsychological measures. Front. Neurol 10 . doi:10.3389/fneur.2019.00756.
Harrell Frank E. , Calif Robert M. , Pryor David B. , Lee Kerry L. , Rosati Robert A. , 1982. Evaluating the yield of medical tests. JAMA. 247 (18 ), 2543. doi:10.1001/jama.1982.03320430047030.7069920
Hua Xue , Leow , Alex D , Parikshak Neelroop , Lee Suh , Chiang Ming Chang , Toga Arthur W , Jack Clifford R , Weiner Michael W , Thompson Paul M , 2008. Tensor-based morphometry as a neuroimaging biomarker for Alzheimer’s disease: An MRI Study of 676 AD, MCI, and normal subjects. NeuroImage. 43 (3 ), 458–469. doi:10.1016/j.neuroimage.2008.07.013.18691658
Jansen , Iris E , Savage , Jeanne E , Watanabe Kyoko , Bryois Julien Williams , Dylan M , Steinberg Stacy , Sealock Julia , Karlsson Ida K , Hägg Sara , Athanasiu Lavinia , Voyle Nicola , Proitsi Petroula , Witoelar Aree , Stringer Sven , Aarsland Dag , Almdahl , Ina S , Andersen Fred Bergh , Sverre Bettella , Francesco , Sigurbjorn Brækhus , Anne Bråthen , Geir Leeuw , Christiaan de Desikan , Rahul S , Djurovic Srdjan , Dumitrescu Logan , Fladby Tormod , Hohman Timothy J , Jonsson , Palmi V , Kiddle , Steven J , Rongve Arvid , Saltvedt Ingvild Sando , Sigrid B , Selbæk Geir , Shoai Maryam Skene , Nathan G , Snaedal , Jon Stordal , Eystein Ulstein , Ingun D , Wang Yunpeng White , Linda R , Hardy , John Hjerling-Leffler , Jens Sullivan , Patrick F , van der Flier , Wiesje M , Dobson Richard Davis , Lea K , Stefansson Hreinn Stefansson , Kari Pedersen , Nancy L , Ripke , Stephan Andreassen , Ole A , Posthuma Danielle , 2019. Genome-wide meta-analysis identifies new loci and functional pathways influencing Alzheimer’s disease risk. Nat. Genet 51 (3 ), 404–413. doi:10.1038/s41588-018-0311-9.30617256
Kaplan EL , Meier Paul , 1958. Nonparametric estimation from incomplete observations. J. Am. Stats. Assoc 53 (282 ), 457–481. doi:10.1080/01621459.1958.10501452.
Katzman Jared L. , Shaham Uri , Cloninger Alexander , Bates Jonathan , Jiang Tingting , Kluger Yuval , 2018. DeepSurv: personalized treatment recommender system using a cox proportional hazards deep neural network. BMC Med. Res. Methodol 18 (1 ). doi:10.1186/s12874-018-0482-1.
Kunkle , Brian W , Grenier-Boley Benjamin , Sims Rebecca Bis , Joshua C , Damotte Vincent Naj , Adam C , Boland Anne , , 2019. Genetic meta-analysis of diagnosed Alzheimer’s disease identifies new risk loci and implicates Aβ, Tau, immunity and lipid processing. Nat. Genet 51 (3 ), 414–430.30820047
Kvamme Håvard , and Borgan Ørnulf . 2019. “Continuous and discrete-time survival prediction with neural networks.” Available at: https://github.com/havakv/pycox Access date: 2018-04-26.
Kvamme Håvard , Borgan Ørnulf , Scheel Ida , 2019. Time-to-event prediction with neural networks and cox regression. J. Mach. Learn. Res 20 , 1–30. Available at: http://jmlr.org/papers/v20/18-424.html. Access date: 2020-06.
Lambert Jean Charles , Ibrahim-Verbaas Carla A. , Harold Denise , Naj Adam C. , Sims Rebecca , Bellenguez Céline , Jun Gyungah , , 2013. Meta-analysis of 74,046 individuals identifies 11 new susceptibility loci for Alzheimer’s disease. Nat. Genet 45 (12 ), 1452–1458. doi:10.1038/ng.2802.24162737
Lee Changhee , Zame William , Yoon Jinsung , van der Schaar Mihaela , 2018. Deep-Hit: A Deep Learning Approach to Survival Analysis With Competing Risks. Proceedings of the AAAI Conference on Artificial Intelligence 32 (1 ). doi:10.1609/aaai.v32i1.11842, Access date:2019-10-28.
Lei Baiying , Yang Mengya , Yang Peng , Zhou Feng , Hou Wen , Zou Wenbin , Li Xia , Wang Tianfu , Xiao Xiaohua , Wang Shuqiang , 2020. Deep and joint learning of longitudinal data for Alzheimer’s disease prediction. Pattern Recogn. 102 , 107247. doi:10.1016/j.patcog.2020.107247.
Li Y , Wang L , Zhou J , Ye J , 2019. Multi-task learning based survival analysis for multi-source block-wise missing data. Neurocomputing 364 , 95–107.
Liu K , Chen K , Yao L , Guo X , 2017. Prediction of mild cognitive impairment conversion using a combination of independent component analysis and the cox model. Front. Hum. Neurosci 11 .
Loshchilov Ilya , and Hutter Frank . 2017. “Decoupled Weight Decay Regularization,” November.
Lu Pascal , Colliot Olivier , 2021. Multilevel survival modeling with structured penalties for disease prediction from imaging genetics data. IEEE J. Biomed. Health Informat 1 . doi:10.1109/JBHI.2021.3100918, –1.
Ma D , Yee E , Stocks JK , Jenkins LM , Popuri K , Chausse G , Wang L , Probst S , Beg MF , 2021. Blinded clinical evaluation for dementia of Alzheimer’s type classification using FDG-PET: a comparison between feature-engineered and non-feature-engineered machine learning methods. J. Alzheimers Dis. JAD 80 , 715–726. doi:10.3233/JAD-201591.33579858
Ma Da , Popuri Karteek , Bhalla Mahadev , Sangha Oshin , Lu Donghuan , Cao Jiguo , Jacova Claudia , Wang Lei , Beg Mirza Faisal , 2019. Quantitative assessment of field strength, total intracranial volume, sex, and age effects on the goodness of harmonization for volumetric analysis on the ADNI database. Hum. Brain Mapp 40 (5 ), 1507–1527. doi:10.1002/hbm.24463.30431208
Mirabnahrazam Ghazal , Ma Da , Lee Sieun , Popuri Karteek , Lee Hyunwoo , Cao Jiguo , Wang Lei , Galvin James E. , Beg Mirza Faisal , Alzheimer’s Disease Neuroimaging Initiative, 2022. Machine learning based multimodal neuroimaging genomics dementia score for predicting future conversion to Alzheimer’s disease. J. Alzheimers Dis 87 (3 ), 1345–1365. doi:10.3233/JAD-220021.35466939
Mueller , Susanne G , Weiner Michael W , Thal Leon J , Petersen Ronald C , Jack Clifford R , Jagust William , Trojanowski , John Q , Toga Arthur W , Beckett Laurel , 2005. Ways toward an early diagnosis in Alzheimer’s Disease: the Alzheimer’s Disease Neuroimaging Initiative (ADNI). Alzheimer’s &amp; Dement. 1 (1 ), 55–66.
Nakagawa Tomonori , Ishida Manabu , Naito Junpei , Nagai Atsushi , Yamaguchi Shuhei , Onoda Keiichi , 2020. Prediction of conversion to Alzheimer’s disease using deep survival analysis of MRI images. Brain Commun. 2 (1 ). doi:10.1093/braincomms/fcaa057.
Olsson Bob , Lautner Ronald , Andreasson Ulf , Öhrfelt Annika , Portelius Erik , Bjerke Maria , Hölttä Mikko , , 2016. CSF and blood biomarkers for the diagnosis of Alzheimer’s disease: a systematic review and meta-analysis. Lancet Neurol. 15 (7 ), 673–684. doi:10.1016/S1474-4422(16)00070-3.27068280
Orozco-Sanchez Jorge , Trevino Victor , Emmanuel Martinez-Ledesma Joshua Farber , and Jose Tamez-Peña . 2019. “Exploring survival models associated with MCI to AD conversion: a machine learning approach.” BioRxiv Preprint.
Peng H , Gong W , Beckmann CF , Vedaldi A , Smith SM , 2021. Accurate brain age prediction with lightweight deep neural networks. Med. Image Anal 68 , 101871. doi:10.1016/j.media.2020.101871.33197716
Pölsterl Sebastian , Sarasua Ignacio , Benjamín Gutiérrez-Becker , and Christian Wachinger . 2019. “A wide and deep neural network for survival analysis from anatomical shape and tabular clinical data,” 453–64. 10.1007/978-3-030-43823-4_37.
Popuri Karteek , Balachandar Rakesh , Alpert Kathryn , Lu Donghuan , Bhalla Mahadev , Mackenzie Ian R , Hsiung , Robin Ging Yuek , Wang Lei Beg , Mirza Faisal , 2018. Development and validation of a novel Dementia of Alzheimer’s Type (DAT) score based on metabolism FDG-PET imaging. NeuroImage 18 , 802–813. doi:10.1016/j.nicl.2018.03.007.29876266
Popuri Karteek , Ma Da , Wang Lei , Beg Mirza Faisal , 2020. Using machine learning to quantify structural MRI neurodegeneration patterns of Alzheimer’s disease into dementia score: independent validation on 8,834 images from ADNI, AIBL, OASIS, and MIRIAD databases. Hum Brain Mapp. 41 (14 ), 4127–4147. doi:10.1002/hbm.25115.32614505
Schwartzentruber Jeremy , Cooper Sarah , Liu , Jimmy Z , Barrio-Hernandez Inigo , Bello Erica , Kumasaka Natsuhiko , Young , Adam MH , Frabjkub , Robin JM , Johnson „ Toby Estrada , Karol Gaffney , Daniel J , Beltrao Pedro , Bassett Andrew , 2021. Genome-wide meta-analysis, fine-mapping and integrative prioritization implicate new Alzheimer’s disease risk genes. Nat. Genet 1–11.33414547
Smith Leslie N. , 2017. Cyclical Learning Rates for Training Neural Networks. In: 2017 IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE, pp. 464–472. doi:10.1109/WACV.2017.58.
Spooner Annette , Chen Emily , Sowmya Arcot , Sachdev Perminder , Kochan Nicole A. , Trollor Julian , Brodaty Henry , 2020. A comparison of machine learning methods for survival analysis of high-dimensional clinical data for dementia prediction. Sci. Rep 10 (1 ), 20410. doi:10.1038/s41598-020-77220-w.33230128
Srivastava Nitish , Hinton Geoffrey , Krizhevsky Alex , Salakhutdinov Ruslan , 2014. Dropout: a simple way to prevent neural networks from overfitting. J. Mach. Learn. Res 15 , 1929–1958.
Steck Harald , Krishnapuram Balaji , Dehing-oberije Cary , Lambin Philippe , and Raykar Vikas C 2008. “On ranking in survival analysis: bounds on the concordance index.” In Advances in Neural Information Processing Systems, edited by Platt J , Koller D , Singer Y , and Roweis S . Vol. 20 . Vancouver: Cur-ran Associates, Inc. Available at: https://proceedings.neurips.cc/paper/2007/file/33e8075e9970de0cfea955afd4644bb2-Paper.pdf Access date: 2007.
Twala BETH , Jones MC , Hand DJ , 2008. Good methods for coping with missing data in decision trees. Pattern Recognition Lett. 29 (7 ), 950–956. doi: 10.1016/j.patrec.2008.01.010.
Vemuri Prashanthi , and Clifford R Jack . 2010. “Role of structural MRI in Alzheimer’s disease.” Alzheimer’s research and therapy. BioMed Central. 10.1186/alzrt47.
Venugopalan Janani , Tong Li , Hassanzadeh Hamid Reza , Wang , May D , 2021. Multimodal deep learning models for early detection of Alzheimer’s disease stage. Sci. Rep 11 (1 ), 1–13. doi:10.1038/s41598-020-74399-w.33414495
Xu Qing-Song , Liang Yi-Zeng , 2001. Monte Carlo Cross Validation. Chemometr. In-tell. Laborat. Syst 56 (1 ), 1–11. doi:10.1016/S0169-7439(00)00122-2.
Yee E , Ma D , Popuri K , Wang L , Beg MF Initiative, and for the A.D.N., Ageing, and the A.I.B. and L. flagship study of, 2021. Construction of MRI-Based Alzheimer’s disease score based on efficient 3D convolutional neural network: comprehensive validation on 7,902 images from a multi-center dataset. J. Alzheimers Dis 79 , 47–58. doi:10.3233/JAD-200830.33252079
Zhou Tao , Thung Han , Kim Zhu , Xiaofeng Shen , Dinggang , 2019. Effective feature learning and fusion of multimodality data using stage-wise deep neural network for dementia diagnosis. Hum. Brain Mapp 40 (3 ), 1001–1016. doi:10.1002/hbm.24428.30381863
Yang Z , Nasrallah IM , Shou H , Wen J , Doshi J , Habes M , Erus G , Abdulkadir A , Resnick SM , Albert MS , Maruff P , 2021. A deep learning framework identifies dimensional representations of Alzheimer’s Disease from brain structure. Nature communications 12 (1 ), 1–15.
Abrol Anees , Fu Zening , Salman Mustafa , Silva Rogers , Du Yuhui , Plis Sergey , and Calhoun Vince . 2021. “Deep Learning Encodes Robust Discriminative Neuroimaging Representations to Outperform Standard Machine Learning.” Nature Communications 12 (1 ): 353. 10.1038/s41467-020-20655-6.
Yee E , Ma D , Popuri K , Chen S , Lee H , Chow V , Ma C , Wang L , Beg MF , 2022. 3D hemisphere-based convolutional neural network for whole-brain MRI segmentation. Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society 95 , 102000. doi:10.1016/j.compmedimag.2021.102000.
