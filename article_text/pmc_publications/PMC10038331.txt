LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


101770895
49929
IEEE Trans Emerg Top Comput Intell
IEEE Trans Emerg Top Comput Intell
IEEE transactions on emerging topics in computational intelligence
2471-285X

36969108
10038331
10.1109/tetci.2021.3136587
NIHMS1758563
Article
ADCoC: Adaptive Distribution Modeling Based Collaborative Clustering for Disentangling Disease Heterogeneity from Neuroimaging Data
Liu Hangfan Neuroimage Analytics Laboratory (NAL) and Biggs Institute Neuroimaging Core, Glenn Biggs Institute for Neurodegenerative Disorders, University of Texas Health Science Center at San Antonio, San Antonio, Texas, USA; Center for Biomedical Image Computing and Analytics, University of Pennsylvania, Philadelphia, PA 19104, USA.

Grothe Michel J. Unidad de Trastornos del Movimiento, Servicio de Neurología y Neurofisiología Clínica, Instituto de Biomedicina de Sevilla (IBiS), Hospital Universitario Virgen del Rocío/CSIC/Universidad de Sevilla, Seville, Spain.

Rashid Tanweer Neuroimage Analytics Laboratory (NAL) and Biggs Institute Neuroimaging Core, Glenn Biggs Institute for Neurodegenerative Disorders, University of Texas Health Science Center at San Antonio, San Antonio, Texas, USA.

Labrador-Espinosa Miguel A. Unidad de Trastornos del Movimiento, Servicio de Neurología y Neurofisiología Clínica, Instituto de Biomedicina de Sevilla (IBiS), Hospital Universitario Virgen del Rocío/CSIC/Universidad de Sevilla, Seville, Spain; Centro de Investigación Biomédica en Red sobre Enfermedades Neurodegenerativas (CIBERNED), Madrid, Spain.

Toledo Jon B. Department of Neurology, University of Florida College of Medicine, Gainesville, and also with Fixel Institute for Neurologic Diseases, University of Florida, Gainesville.

Habes Mohamad Neuroimage Analytics Laboratory (NAL) and Biggs Institute Neuroimaging Core, Glenn Biggs Institute for Neurodegenerative Disorders, University of Texas Health Science Center at San Antonio, San Antonio, Texas, USA; Center for Biomedical Image Computing and Analytics, University of Pennsylvania, Philadelphia, PA 19104, USA.

Corresponding author: Hangfan Liu, hfliu@upenn.edu; Mohamad Habes, habes@uthscsa.edu
28 11 2021
4 2023
05 1 2022
01 4 2023
7 2 308318
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Conventional clustering techniques for neuroimaging applications usually focus on capturing differences between given subjects, while neglecting arising differences between features and the potential bias caused by degraded data quality. In practice, collected neuroimaging data are often inevitably contaminated by noise, which may lead to errors in clustering and clinical interpretation. Additionally, most methods ignore the importance of feature grouping towards optimal clustering. In this paper, we exploit the underlying heterogeneous clusters of features to serve as weak supervision for improved clustering of subjects, which is achieved by simultaneously clustering subjects and features via nonnegative matrix tri-factorization. In order to suppress noise, we further introduce adaptive regularization based on coefficient distribution modeling. Particularly, unlike conventional sparsity regularization techniques that assume zero mean of the coefficients, we form the distributions using the data of interest so that they could better fit the non-negative coefficients. In this manner, the proposed approach is expected to be more effective and robust against noise. We compared the proposed method with standard techniques and recently published methods demonstrating superior clustering performance on synthetic data with known ground truth labels. Furthermore, when applying our proposed technique to magnetic resonance imaging (MRI) data from a cohort of patients with Parkinson’s disease, we identified two stable and highly reproducible patient clusters characterized by frontal and posterior cortical/medial temporal atrophy patterns, respectively, which also showed corresponding differences in cognitive characteristics.

Clustering
MRI
Parkinson’s disease
neuroimaging
feature selection

pmcI. Introduction

Most of the neurodegenerative diseases such as Alzheimer’s disease and Parkinson’s disease (PD) are clinically heterogeneous, with distinct disease subtypes encompassed within the same clinical diagnosis [1]. Heterogeneity in brain diseases makes it more difficult to find suitable treatment or develop markers that could capture true signals of the underlying disease. In recent years the application of data-driven clustering coupled with high dimensional neuroimaging data has made huge steps for our understanding of heterogeneous disease biology and assigning specific patients groups to individualized treatments.

As an important category of machine learning techniques for many applications, including neuroimaging, a flurry of clustering methods have been developed in the past few decades [2-10]. K-means [11-13] and k-medoids [14, 15] are centroid models that partition data points into non-overlapping clusters. Connectivity models, including hierarchical clustering [16, 17], are based on distance connectivity. These schemes were proved to be effective in certain applications, but in general they did not consider exploiting the underlying correlation within the high-dimensional features that drive the clustering. However, covariance in the features carries important information that could facilitate more robust clustering solutions [18]. In recent years, deep learning based clustering methods [19, 20] have been developed that utilize deep neural networks to learn clustering memberships. This category of methods generally relies on large training datasets, which are usually not available in neuroimaging applications, thus they tend to suffer from the risk of overfitting.

The nonnegative matrix tri-factorization (NMTF) [21-26] method, as an extension of conventional nonnegative matrix factorization [27], offers a potential alternative way to capture underlying differences of both samples and features via simultaneously clustering samples and features. Specifically, the NMTF technique factorizes a nonnegative matrix into three matrices, with two of them containing group information of the column and row vectors of the original matrix respectively, and the third reflecting the magnitude of the mapping to corresponding groups upon different dimensions and the interactions between the other two matrices. The NMTF approach has many variants that incorporate different regularization techniques, including symmetric regularization [23], graph regularization [24], manifold regularization [26] etc. Nonetheless, all of these approaches explicitly consider reducing the noise in the data. In practice, it is usually inevitable to have noisy neuroimaging data due to external factors including motion and device related artifacts, but also noise associated with processing of the data. The existence of noise could severely influence the clustering performance.

In an attempt to eliminate noise, sparsity regularization based NMTF [25] was proposed for improved dimension reduction of radiomic features, and achieved better results than the approaches without denoising. The technique views two of the matrices generated by the NMTF as a pair of semi-orthogonal dictionaries and the third one as a coefficient matrix. Essentially, the sparsity regularization in [25] assumes that the coefficients conform to zero-mean Laplace distributions. However, since the coefficients are produced by nonnegative matrix tri-factorization, apparently they are all nonnegative, and thus it is highly unlikely that their expectations could be zero. Such inaccurate modeling would lead to information loss.

Inspired by data-driven distribution modeling approaches [28-30], in this paper we propose to adaptively model the coefficient distributions. Considering the different statistical characteristics of coefficients in different bands after transform, the distribution of each coefficient is modeled separately. In particular, instead of assuming the expectations of the distributions to be zero, we adaptively estimate the distribution parameters of each coefficient. The solution to the corresponding optimization problem comes down to band-wise adaptive Wiener filtering. In this way, the informative signal in the data is significantly better preserved, while the noise is effectively removed.

The major contributions of this paper are three-fold:

In order to suppress noise while preserving the informative signals, we adaptively model the distribution of coefficients in the transform domain instead of using conventional sparsity regularization. Particularly, the coefficients are allowed to have non-zero expectations and the contribution of regularization is controlled by variance of the distribution;

We exploit the covariance of the features to facilitate the clustering of subjects. Specifically, we utilize nonnegative matrix tri-factorization to reduce the dimensionality and capture the covariance in the features by clustering them. This incorporates the interaction of subject clustering and reduced dimensionality in features, so that the information on feature covariance patterns can provide weak supervision for the clustering of subjects. Thus, the feature covariance patterns will not only inform us about the biology of the disease and potential mechanism, but will also be exploited to increase the robustness in subjects clustering.

Our clustering results in neuroimaging data from a PD cohort showed highly reproducible atrophy subtypes of PD patients that advance our understanding of the heterogeneous neurodegenerative and clinical manifestations of the disease.

II. Method

A. Overall Framework

The proposed approach utilizes regularization based on the distribution of the transform-domain coefficients. Suppose Y∈RS×F is the matrix stacked by F features of S subjects, the overall objective function is formulated as: (1) {ΦS,X,ΦF}=argminΦ,X,Θ≥0‖Λ⋅(X−μ)‖F2+β‖Y−ΦSXΦF‖F2s.t.ϕSTΦS=IS,ΦFΦFT=IF,

where ‖Y−ΦSXΦF‖F2 is the data fidelity term, while ‖Λ⋅(X−μ)‖F2 is the regularization term based on adaptive distribution modeling: (2) ‖Λ⋅(X−μ)‖F2=∑i=1kS∑j=1kF[λij(xij−μij)]2.

ΦS, X, ΦF are obtained via the regularized non-negative matrix tri-factorization of Y. Essentially, ΦS∈R+S×kS contains the membership information of S subjects from the kS subject clusters, ΦF∈R+kF×F encodes the mapping of F features to kF feature clusters (or covariance patterns), and X∈R+kS×kF indicates the interactions between ΦS and ΦF as well as the magnitude of the mappings. The matrix μ∈R+kS×kF contains expectations of corresponding elements in X, and Λ∈R+kS×kF contains element-wise adaptive regularization parameters controlling the relative contribution of the two terms. Specifically, λij ∈ Λ is the regularization parameter assigned to xij ∈ X. The multiplication “·” is element-wise. IS and IF are identity matrices.

Algorithm 1. The proposed adaptive distribution based collaborative clustering scheme.

Input:Feature matrixY;noise varianceσn2;number of clusterskS,kF.Initialization:Preliminary dictionary learning by solving Eq. (10);CalculateΛandβby Eq. (6);EstimateμandΣby Eq.(7)∼Eq. (9);Fori=1,2,…,IDoCalculateX~by computing Eq. (15);UpdateY~by computing Eq. (16);UpdateΦ~SandΦ~Fby solving Eq.(10);Chooseβ(i+1)≥β(i);EndForObtainlSandlFby Eq.(17);Output:Cluster label vectors of subjectslSand featureslF.

	

From the perspective of dictionary learning, ΦS and ΦF are a pair of semi-orthogonal dictionaries that decompose the feature matrix Y, and X is the corresponding coefficient matrix. With Y known, Eq. (1) pursues a noise-free representation X in the space spanned by ΦS and ΦF, based on which better clustering can be achieved after the noise in Y is reduced. The overall framework of the proposed scheme is summarized in Fig. 1.

B. Adaptive Regularization Based on Distribution Modeling

The proposed method adaptively determinates the near-optimal regularization parameters in Λ in a Bayesian framework. Since X is a non-negative matrix, it is more plausible to set expectations of coefficients in X to be positive, rather than all zeros. Suppose xij conform to Gaussian distributions with expectation μij and variance σij2, and the observation Y is polluted by Gaussian white noise, then we have (3) P(X)∝exp(−‖X−μ‖F22Σ2),P(Y∣X)∝exp(−‖Y−ΦXΘ‖F22σn2),

where Σ2=Σ⋅Σ∈R+kS×kF includes the variances σij2 of the coefficients in X, and σn2 is the variance of noise.

Given Y, the maximum a posterior estimate of noise-free coefficients X is: (4) X~=argmaxX≥0P(X∣Y)=argmaxX≥0P(Y∣X)P(X)P(Y).

After taking a log transform, Eq. (4) can be rewritten as X~=argmaxX≥0logP(Y∣X)+logP(X),

which is equivalent to (5) X~=argminX≥01σn2‖Y−ΦXΘ‖F2+‖X−μ‖F2Σ2.

Comparing Eq. (1) with Eq. (5), we have (6) Λ=1Σ,λij=1σij,β=1σn2.

Ideally, μ and Σ could be estimated from the coefficients calculated from the clean data, which are not available in practice. To tackle this problem, we need to find a sufficient number of data samples derived from the same distribution as X. To this end, suppose we have N datasets Yk (k = 1 … N) of size kP × kF that are independently distributed and share the same statistical characteristics as Y. For each Yk, solve the following optimization problem: (7) {ΦS(k),X(k),ΦF(k)}=argminΦ≥0,X≥0,Θ≥0‖Yk−ΦS(k)X(k)ΦF(k)‖F2s.t.ΦS(k)TΦS(k)=IS,ΦF(k)ΦF(k)T=IF.

Then we can estimate μ as: (8) μ~=1N∑k=1NX(k).

Since we consider the additive noise is independent of the data of interest, the standard deviation matrix of X can be estimated as: (9) Σ~=max(1N∑k=1N(X(k)−μ~)2−σn2,0).

With μ and Σ estimated, the near-optimal regularization parameter matrix Λ can be determined accordingly.

C. Potential Advantages of the Proposed Approach

The potential advantages of the proposed approach are mainly brought by 1) the adaptive regularization based on the distribution modeling for data denoising, and 2) the Integration of the collaborative clustering.

On the one hand, the tri-factorization procedure collaboratively clusters the subjects and the features in Y, with the cluster membership information contained in Φ~S and Φ~F respectively. In such collaborative clustering, the clustered features serve as weak supervision for the clustering of subjects, which in return facilitate the clustering of features, so that improved clustering performance could be achieved.

On the other hand, different from the conventional sparsity regularization used in [25] that assumes all coefficients to be zero, the proposed approach allows the expectations of coefficients to be adaptively estimated as positive numbers, which in general can be more accurate since the coefficients are generated by non-negative tri-factorization. Thresholding all the coefficients towards zero could lead to loss of useful information, while our adaptive filtering approach that fuses both the observation and the estimated could better preserve the information contained in the coefficients, and meanwhile suppress the influence of noise.

Furthermore, the collaborative clustering and adaptive denoising could benefit each other. The collaborative clustering is also a process of dictionary learning, which serves as a decorrelation procedure that could separate feature information from the noise [31-33]. This is because the features of interest are generally correlated with each other, while the noise is usually considered to be independently distributed in nature. After decorrelation, most of the feature information would concentrate on only a few coefficients, while the distribution of noise still roughly remains the same. This enables us to decide the optimal noise removal strategy according to the statistical characteristics of the coefficients and the noise. Then the reduction in noise contributes to better clustering, eventually leading to more reliable clinical analysis.

III. Numerical Solutions

The optimization problem (1) is difficult to solve directly, since it aims to simultaneously solve a matrix tri-factorization problem and a denoising problem. In this paper, we adopt an alternating-direction approach [34-36] to split the problem into two sub-problems that can be solved efficiently.

A. Dual Dictionary Training

To begin with, we need to train an initial pair of dictionaries ΦS and ΦF using the current version of Y. To this end, we apply matrix tri-factorization to Y by optimizing (10) {Φ~S,Φ~F}=argminΦ≥0,X≥0,Θ≥0‖Yk−ΦSXΦF‖F2s.t.ΦSTΦS=IS,ΦFΦFT=IF,

which can be solved by an iterative scheme described in [21].

B. Band-Wise Adaptive Wiener Filtering

With ΦS, ΦF fixed, let (11) f(X)=‖Λ⋅(X−μ)‖F2+β‖Y−ΦSXΦF‖F2.

Since ΦS, ΦF are semi-orthogonal, i.e. ΦSTΦS=I and ΦFΦFT=I, based on the isometry property we have (12) ‖Y−ΦSXΦF‖F2=‖ΦST(Y−ΦSXΦF)ΦFT‖F2=‖ΦSTYΦFT−X‖F2.

Let V=ΦSTYΦFT, then (13) f(X)=‖Λ⋅(X−μ)‖F2+β‖V−X‖F2.

X can be solved by setting the derivative to zero: (14) df(X)dX=0.

It is not difficult to find out the desired estimate of X, which is calculated as: (15) X~=ββ+Λ⋅V+Λβ+Λ⋅μ.

where all the calculations are element-wise. Evidently, the estimated X~ is a weighted average of the expectation of coefficients that can be estimated by (8) and the coefficients calculated from the observation, with the weights commensurate with the reliability of the estimate μ~ or the observed data Y.

C. Improved Collaborative Clustering

After the denoised coefficients are obtained, it is easy to calculate the relatively clean version of Y: (16) Y~=Φ~SX~Φ~F.

Then we can repeat the collaborative clustering procedure described in Section III-A to get improved clustering results.

In order to further improve the performance, we can optionally extend the proposed method to an iterative scheme. In each iteration the feature matrix Y~ with less noise is used for better clustering. Besides, since noise has been reduced in former iterations, the noise variance σn2 should decrease and thus the regularization parameter β should be updated to a larger value, which essentially means to put more weight on the fidelity term because the feature matrix has become more reliable.

Finally, we can use the latest version of Φ~S and Φ~F to obtain the cluster labels of both subjects and features. This can be achieved by simply identifying the index of the largest element in each row of Φ~S or each column of Φ~F; or we may also apply an existing clustering method (e.g., k-means) to row vectors of Φ~S or column vectors of Φ~F: (17) lS=g(Φ~S,kS),lF=g(Φ~FT,kF),

where lS∈RS×1 and lF∈RF×1 are the vectors containing the clustering labels of subjects and features respectively, g(Φ, k) is a function that returns the clustering labels dividing the row vectors of Φ into k clusters.

The main procedure of the proposed method is summarized in Algorithm 1.

IV. Experiments on Synthetic Data

A. Evaluation of Sample Clustering

In this section we examine the performance of the Adaptive Distribution modeling based COllaborative Clustering (ADCoC). We test its superiority on high dimensional noisy synthetic data. For this purpose, we created a dataset of images in which each image contains one object (see Fig. 2). The objects have two different shapes and two different sizes, ending up with four image clusters. Using this synthetic dataset we can infer different meanings that deserve to be explored in real life data. Differences between the detected shapes among the different individuals could be a surrogate for the ability of the algorithm to cluster disease manifestation patterns or subtypes. Besides, the size of the involved area and the extent of the difference would be a surrogate of disease stages, in real life datasets that include subjects at different stages of disease. There are 144 samples in total, with 36 samples in each cluster. All the image samples are polluted by additive Gaussian white noise with a variance of 50.

We compared the proposed ADCoC method with k-means [11], k-medoids [14], Ward's linkage [16], Orthogonal Nonnegative Matrix Factorization (ONMF) [27], CC [22] Robust CC (RCC) [25], and HDBSCAN [37]. Ward's linkage is a representative hierarchical clustering method, ONMF is a conventional matrix factorization based clustering approach, while CC and RCC are tri-factorization based schemes. All the competing methods are implemented in MATLAB. For k-means, k-medoids, Ward's linkage we used functions provided by MATALB toolbox with default settings. For ONMF we used executables released by the authors without changing the parameter settings. The methods are tested on 4 subsets containing 115 samples that are randomly collected from the noisy images. The images are reshaped into row vectors and stacked together to form the feature matrix. The agreement of the clustering results and ground truth labels are measured by adjusted Rand index (ARI) [38]. ARI takes values between −1 and 1, where 1 stands for perfect agreement between the two compared clusters.

The task is challenging due to the existence of noise and the different locations of the objects. With the ability to suppress noise while preserving information within the data, the proposed ADCoC achieved evidently superior results, with an average gain of around 63.4% over k-means, 67.7% over k-medoids, 51.8% over Ward’s linkage, 67% over ONMF, 56.1% over CC, 52.4% over RCC, and 30.6% over HDBSCAN. By taking covariance patterns into account, the matrix tri-factorization based methods CC, RCC and ADCoC outperform the famous benchmarks k-means, k-medoids, Ward’s linkage as well as the conventional matrix factorization based method ONMF. By reducing the influence of noise, collaborative clustering schemes integrated with denoising techniques RCC and ADCoC achieve better performance than the basic CC. By pursuing the actual distribution of the coefficients and thus effectively preserving information within the data, the proposed ADCoC attains significantly better results than the sparsity based RCC method.

We list the adjusted rand index (ARI) at each iteration in Table 3. On average, the ARI score improves evidently by each iteration. In Table 3, Iteration 0 represents the collaborative clustering stage without using adaptive wiener filtering. We can see that, by introducing adaptive wiener filtering, the average ARI increased 0.138 (or 56.1%). Besides, we further tested the clustering performance of ADCoC at different noise levels, as shown in Table 4. As expected, ADCoC gets less effective when noise is too heavy, especially when noise variance is over 400. This is mainly because: 1) heavier noise means less informative observation; 2) noise could affect the effectiveness of the preliminary dictionary learning; 3) larger noise variance makes it more challenging to accurately estimate parameters such as Λ in Eq. (1).

When we set the number of samples to form the coefficient distribution N = 30, the unoptimized MATLAB implementation takes less than 1 hour (59.8min) for the training procedure. Since the calculations of the N = 30 sets of coefficients are independent of each other and thus are highly parallelizable, using parallel computation techniques could significantly further reduce the time cost of the training procedure. The testing procedure costs 2.61 min for each subset. The experiments are performed in MATLAB R2018b on the computer with i5-4570S CPU. The code can be found at https://github.com/UTHSCSA-NAL/ADCoC-Code.

B. Illustration of Feature Clustering

Collaborative feature clustering is another potential strength of ADCoC. Conventional clustering methods like k-means, Ward's linkage and HDBSCAN only cluster the subjects while ignoring the underlying feature clusters, while ADCoC is able to simultaneously cluster both subjects and features. In order to illustrate the feature clustering of ADCoC with better clarity, we consider the synthetic dataset consisting of 80 noisy images with 4 kinds of patterns (as shown in Fig 3), and apply the proposed ADCoC method. The feature cluster labels are generated from Φ~F, as indicated by Eq.(17). Since each feature (pixel) corresponds to a feature label, we can map the labels back to the image space, as shown in Fig. 4. We can see that ADCoC well captured the patterns and is robust against the noise.

V. Experiments on Neuroimaging Data

A. Data

We studied high-resolution structural MRI data from patients with Parkinson’s disease (PD) and healthy controls enrolled in the Parkinson Progression Markers Initiative (PPMI). Participants were selected from the PPMI for the current study if they had a baseline T1-weighted MRI scan acquired on a Tim Trio 3T scanner (Siemens), resulting in a study sample of 170 PD patients and 77 healthy controls. MRI scans were acquired using a 3D magnetization-prepared rapid acquisition gradient echo (MP-RAGE) sequence with the following parameters: sagittal section thickness, 1.0 mm; no gap; repetition time, 2300 ms; echo time, 2.98 ms; flip angle, 9°; field of view, 240 x 256 mm; matrix size, 240 x 256; inversion time, 900 ms; voxel size, 1 x 1 x 1 mm3.

Regional imaging features were extracted from the structural MRI data using a standard voxel-based morphometry approach implemented in the Computational Anatomy Toolbox (CAT12, http://dbm.neuro.uni-jena.de/cat/) of SPM12 (https://www.fil.ion.ucl.ac.uk/spm/software/spm12/). Briefly, this involved tissue-type segmentation of the MRI scans into grey matter (GM), white matter, and cerebrospinal fluid partitions, followed by high-dimensional spatial registration to the Montreal Neurological Institute (MNI) stereotactic standard space. Deformation-fields resulting from this registration were used to spatially normalize the GM segments and voxel values were modulated by the Jacobians of the deformation field in order to preserve the total amount of GM volume present in native space. For each individual, regional gray matter volumes were then calculated for 84 different cortical and subcortical brain regions (42 per hemisphere), as defined in the Desikan-Killiany anatomical atlas [39], by summing up the modulated GM voxel values within the respective atlas labels. In order to account for inter-individual differences in head size, all regional volumes were divided by the total intracranial volume (ICV), calculated as the total volume of GM, white matter, and cerebrospinal fluid partitions.

B. Parameter Estimation

In order to get the optimal number of subject clusters and covariance patterns in the features, we investigate the reproducibility of the clustering results under different settings, with the subject cluster number ranging from 2 to 6, and the covariance patterns number from 4 to 11. We perform the collaborative clustering 30 times, each time randomly extracting 80% of the PD subjects for testing, and measure the adjusted Rand index (ARI) of the C302 pairs of clustering results. Then the reproducibility is assessed by the average ARI. The average ARI scores are shown in Table 2. We observed that the variances of the ARI scores for each cluster number are no greater than 0.015 and generally less than 0.001, which are insignificant compared with the differences between the mean ARI scores. Therefore, 2 subject clusters with 9 covariance patterns is the optimal setting in terms of both median and mean ARI.

After setting the cluster numbers, we estimate the noise level of the brain data in a similar way. To be specific, we examined reproducibility of the ADCoC algorithm with assumed noise variance η ranging from 2−11~2−5 after normalizing the elements in feature matrix Y to the range [0, 1]. For each tested noise level, we applied the proposed ADCoC 150 times to randomly sampled subsets containing 80% of the subjects, and observed the mean adjusted rand index. As can be seen in Fig. 5, the optimal estimate for the noise standard deviation is around 2−4.

C. Characterization of Patient Clusters

We compared the distribution of ICV normalized grey matter volumes in different regions between the two patient clusters and the healthy control group by student’s t-test with false discovery rate (FDR) correction [40]. Test statistic values of regions with FDR corrected p-values smaller than 0.05 are plotted using Surf Ice in Fig. 6 (the corresponding covariance patterns of features are shown in supplementary figure 1).

Comparisons to the healthy control group show that PD cluster P1 (encompassing 54.7% of the PD sample) is characterized by a posterior cortical-medial temporal atrophy pattern, whereas atrophy in PD cluster P2 is mainly limited to frontal lobe areas. Analysis of neuropsychological test data further demonstrates that these MRI-defined patient subtypes also show differences in clinical presentation, where patients with a posterior cortical-medial temporal atrophy pattern (P1) show statistically significant lower cognitive performance compared to those with limited frontal atrophy (P2) (Montreal Cognitive Assessment [MoCA] scores: 27.1 ± 2.4 [P1] vs 27.9 ± 1.7 [P2], p = 0.017). Comparison of a more comprehensive set of clinical and demographic characteristics is included in supplementary table 1.

Furthermore, we observed that the clustering results highly agree with each other. To be specific, when running ADCoC on PD dataset 10 times and comparing the C102=45 pairs of clustering results, the average ARI is 0.908 (with a variance of 0.003), which is close to exact agreement between each other, and thus the resulted patterns are generally the same. Therefore, we believe that the PD clusters identified by ADCoC is stable and highly reproducible.

VI. Discussion

The proposed ADCoC is based on nonnegative matrix tri-factorization (NMTF), which plays two roles simultaneously. On the one hand, the collaborative clustering is achieved by applying NMTF to the feature matrix, and the cluster membership information of subjects and features is contained in the two semi-orthogonal matrices respectively. On the other hand, we view the two semi-orthogonal matrices as a pair of dictionaries that decorrelate the informative signals within the feature data. Since noise is generally uncorrelated in nature, it can be well separated from the informative signals after decorrelation and eliminated through regularization techniques [31-33]. ADCoC aims to effectively remove noise while maximally preserving the informative signals so as to attain improved clustering performance and, by extension, clinical analysis.

For data denoising, it is straightforward to adopt sparsity regularization [25, 41], which assumes that correlated signals can be sparsely represented by decorrelation transforms thus most of the coefficients should be zero or close to zero. However, for collaborative clustering, since the coefficients are generated by nonnegative tri-factorization, it is obvious that all the coefficients are nonnegative, hence employing conventional sparsity regularization tends to erroneously threshold nonnegative coefficients towards zero, leading to information loss. From the Bayesian point of view, the conventional sparsity regularization basically assumes that the coefficients conform to a zero-mean distribution, which is inaccurate for nonnegative coefficients. To solve this problem, we proposed a data-driven regularization technique based on adaptive coefficient distribution modeling. Instead of using a fixed zero-mean distribution model, we use the coefficients generated by data of the same or similar statistical characteristics to form the distributions and estimate the distribution parameters. In this way, rather than setting expectations of all the coefficients to zero, we can obtain much more accurate estimates of the coefficient distributions, so that our model can better fit the data of interest and the resulting regularization can better preserve the information when removing the noise.

After the interference of noise is significantly reduced, the matrix tri-factorization based collaborative clustering can be more stable and reliable. Besides considering the differences between samples as conventional clustering approaches do, ADCoC simultaneously takes the underlying differences between features into account, so that the clustering of samples and features could interact with and benefit from each other.

The past few years have seen many developments of deep learning based medical image analysis schemes [42-44]. They rely on labeled data, which are usually insufficient or even unavailable in many applications. When only a limited number of training samples are available, the risk of overfitting is fairly high. In contrast, the proposed ADCoC is an unsupervised learning approach that does not rely on any external dataset or labeled data, which is desirable for many neuroimaging applications. Experimental results on synthetic data demonstrated the superiority of the proposed method over previous clustering approaches.

When applied to a real world clinical dataset of MRI data from PD patients, the ADCoC approach identified two stable and highly reproducible patient clusters characterized by frontal and posterior cortical-medial temporal atrophy patterns, respectively, which also showed corresponding differences in clinical presentation. Although the ground truth clusters are unknown in this dataset, we note that similar frontal and posterior atrophy subtypes of PD patients in the PPMI cohort have also been described in a previous study applying standard Ward’s hierarchical cluster analysis to regional MRI features [45] . However, since this clustering approach is known to be sensitive to noise in the data, strict quality control procedures were applied to the MRI data before analysis, which resulted in a markedly reduced sample size (77 PD patients) compared to our present study. Similar to our findings, the posterior atrophy subtype in this previous study was also found to perform worse on cognitive testing when compared to healthy controls, but statistically significant cognitive differences between the two patient clusters could not be demonstrated with this limited sample size.

ADCoC identified nine components (Supplementary Fig. S1), that were used to identified the different clusters in the PPMI PD subjects (Fig. 6). Among these components, component 7 showed the largest differences between the groups [46] . Component 7 included several of the areas that previously correlated with brain aging (with a frontal, inferior parietal and superior temporal involvement). Component 9 included superior temporal, rostral temporal and precental gyrus, these areas have been described also atrophic in PD previously [47]. Component 2 also showed significant differences between the clusters and included precuneus and lateral temporal areas which partially overlaps with the dysexecutive pattern seen in Alzheimer’s disease [48].

It is worth noting that, although we focused on the discussion of application on neuroimaging data in this paper, the proposed approach could also be promising in other medical image analysis tasks. For instance, in radiomic studies [22, 25], the so-called meta-features M=X~Φ~F can be obtained after calculating Eq. (16) and fed into prediction models for improved performance.

The main weaknesses of ADCoC include: 1) Relatively high space complexity. ADCoC could be space demanding for large-scale or high-dimensional data due to the matrix computations involved in the tri-factorization procedure [21]. Suppose the feature matrix Y∈RS×F, D = max(S, F), then the space requirement of the tri-factorization procedure is above D2. 2) Less effective for overly heavy noise. The effectiveness of ADCoC relies on accurate estimation of the distribution of the coefficients, as explained in Section II-B. When the noise is too heavy, the estimates would tend to be inaccurate, leading to insufficient or excessive denoising. In the former case the noise in the data could still affect the clustering, while in the latter case useful information in the data could be removed from along with the noise.

A potential way to further improve the ADCoC method is to replace Gaussian coefficient model with a distribution that can optimally fit the real-life data, and explore the actual distribution of noise in practice, at the cost of increased complexity in the numerical solutions and the algorithm. In scenarios where labeled data are available, it is of interest to fuse cluster information obtained by ADCoC with that generated by supervised learning approaches, which remains a future work.

VII. Conclusion

In this paper, we presented an Adaptive Distribution based Collaborative Clustering (ADCoC) method for analyzing disease heterogeneity using neuroimaging data. Our approach takes advantage of a dual clustering algorithm in which we cluster the patients and group them in specific disease subtypes on an individual level and at the same time reduce the dimensionality of the feature space by capturing the covariance patterns in the data. Such covariance patterns could inform us more on disease biology. Considering the fact that neuroimaging data are usually contaminated by noise, which could severely affect the effectiveness of clustering as well as clinical interpretation, we integrated an information-preserving denoising technique into the collaborative clustering scheme. Such denoising is achieved by viewing the semi-orthogonal matrices generated by the tri-factorization as decorrelation bases, and apply distribution-based content-adaptive regularization to the coefficients. Experimental results on the synthetic dataset demonstrated the outstanding clustering performance of ADCoC, and application to a real-world data from a cohort of patients with Parkinson’s disease identified two patient subtypes with significant differences in cognitive characteristics.

Supplementary Material

Supplementary Material

This study was supported in part by the National Institute of Health (NIH) grant R01 HL127659-04S and P30AG066546 (South Texas Alzheimer’s Disease Research Center). Michel J. Grothe is supported by the "Miguel Servet" program [CP19/00031] and a research grant [PI20/00613] of the Instituto de Salud Carlos III-Fondo Europeo de Desarrollo Regional (ISCIII-FEDER). Miguel A. Labrador-Espinosa is supported by a PhD scholarship of the University of Seville [USE-19094-G].

Hangfan Liu received the Ph.D. (with hons.) degree in computer science from Peking University, Beijing, China, in 2018. Since 2018, he has been a Postdoc with the University of Pennsylvania, Philadelphia, PA, USA. His research interests include image processing, computer vision, machine learning, and medical image analysis. He was the recipient of the Best Student Paper Award at the 2017 IEEE Visual Communications and Image Processing, the 2019 Doctoral Dissertation Award of the Beijing Society of Image and Graphics, and the co-recipient of the Best Paper Award at the 2019 MICCAI Workshop on Clinical Image-Based Procedures.

Michel J. Grothe was formally trained in physics and biology at the University of Cologne, Germany. He obtained his PhD in experimental psychiatry from Rostock University Medical Faculty and completed his postdoctoral training at the German Center for Neurodegenerative Diseases (DZNE). His research focuses on the use of multimodal neuroimaging techniques for studying neurodegenerative disease pathology in-vivo. While most of his work evolved around neuroimaging and biomarker research in Alzheimer’s disease, he recently also became interested in using these in-vivo techniques to study the pathologic correlates of cognitive decline and dementia associated with Parkinson’s disease. Currently he is a senior researcher leading the Neuroimaging section of the Movement Disorders Group at the Instituto de Biomedicina de Sevilla (IBiS), Spain.

Tanweer Rashid received his BSc in Computer Engineering from North South University, Dhaka, Bangladesh. He completed his MSc and PhD in Modeling and Simulation from Old Dominion University in Norfolk, VA, USA. He has previously worked on the development of algorithms for 2-manifold surface mesh generation and multi-material deformable surface meshes. Tanweer has also done research work in functional MRI analysis for Parkinson’s disease subjects treated with deep brain stimulation. Tanweer’s primary research interests are in machine learning/deep learning and their applications in brain aging, small vessels disease, postmortem brains and neurological disorders such as Parkinson’s and Alzheimer’s disease.

Miguel Á. Labrador-Espinosa was formally trained in Health Engineering at the University of Seville, Spain. Looking for an interdisciplinary profile, he intensified his technical training and clinical neuroscience knowledge through MSc studies in Data Science and Big Data as well as in Biomedical Research at the University of Seville. Currently, he is developing his PhD at the Neuroimaging section of the Movement Disorders Group at the Instituto de Biomedicina de Sevilla (IBiS), Spain, with a competitive PhD fellowship from the Department of Medicine of the University of Seville. His research focuses on the use of multimodal neuroimaging techniques to better understand the pathophysiology of Parkinson's disease, and to find clinically useful neuroimaging biomarkers that may help early diagnosis and more accurate prognosis of the disease.

Jon B. Toledo received his PhD and MD from Universidad de Navarra, Pamplona, Spain. He completed his neurology residence in the University Clinic of Navarra, Spain. He moved to the USA where he worked at the University of Pennsylvania as a post-doctoral fellow. He completed his second neurology residency in the Houston Methodist Hospital. Currently he is completing his Movement Disorders fellowship in the University of Florida College of Medicine, Gainesville.

Mohamad Habes completed his master’s project in the Institute of Neuroscience and Medicine in Julich Research Center, Germany. He obtained his PhD in medical image analysis methods from the University of Greifswald, Germany. During his PhD, he joined the Radiology Department at the University of Pennsylvania as visiting scholar. He continued his postdoctoral training in artificial intelligence and neuroimaging in the Center for Biomedical Image Computing, Radiology Department at the University of Pennsylvania. Currently he is the director of Biggs Institute Neuroimaging Core, at the Biggs Institute for Neurodegenerative Diseases and the director of the Biomedical Image Analytics Division at the Research Imaging Institute and an assistant professor of Radiology and Epidemiology with University of Texas Health Science Center at San Antonio, Texas, USA.

Fig. 1. Illustration of the proposed adaptive distribution modeling based collaborative clustering for disentangling disease heterogeneity from neuroimaging data.

Fig. 2. A subset of the synthetic images.

Fig. 3. A subset of the synthetic data for illustrating feature clustering. Warmer color indicates larger intensity value.

Fig. 4. Feature cluster labels mapped back to the image space. The three feature labels are marked as cyan, yellow-green and yellow respectively, while the empty background is filled by blue.

Fig. 5. Mean adjusted rand index with different estimates for noise variance η.

Fig. 6. Difference in regional grey matter volumes between the discovered Parkinson’s disease subtypes (P1 and P2) and healthy controls (C1). Color scale represents log transformed coefficients

Table 1. Adjusted rand index comparison between k-means, k-medoids, Ward's linkage, CC, RCC, HDBSCAN and the proposed ADCoC tested on the 4 synthetic subsets of noisy high dimensional samples.

Subset	k-means	k-medoids	linkage	ONMF	CC	RCC	HDBSCAN	ADCoC	
1	0.211	0.228	0.218	0.178	0.243	0.244	0.269	0.294	
2	0.274	0.223	0.262	0.231	0.232	0.232	0.335	0.428	
3	0.243	0.244	0.268	0.224	0.272	0.276	0.257	0.416	
4	0.211	0.222	0.262	0.286	0.235	0.257	0.316	0.398	
Average	0.235	0.229	0.253	0.230	0.246	0.252	0.294	0.384	

Table 2. Average adjusted rand index (median, mean) of different cluster numbers in the clinical MRI dataset. Each column contains average scores of 2~6 subject clusters and each row contains those of 4~11 covariance patterns.

S \ F	4	5	6	7	8	9	10	11	
2	0.208,0.219	0.202,0.204	0.197,0.234	0.224,0.270	0.216,0.241	0.265,0.290	0.194,0.188	0.224,0.248	
3	0.184,0.154	0.181,0.152	0.168,0.144	0.173,0.148	0.171,0.144	0.176,0.156	0.174,0.154	0.180,0.167	
4	0.220,0.205	0.222,0.209	0.191,0.172	0.242,0.246	0.209,0.193	0.226,0.217	0.219,0.213	0.239,0.236	
5	0.178,0.172	0.178,0.156	0.186,0.185	0.178,0.171	0.177,0.177	0.153,0.140	0.187,0.175	0.157,0.150	
6	0.147,0.135	0.135,0.131	0.168,0.163	0.159,0.152	0.153,0.150	0.161,0.158	0.148,0.143	0.154,0.147	

Table 3. Adjusted rand index of ADCoC tested at each iteration.

Iteration
Number	Iteration 0	Iteration 1	Iteration 2	
Subset 1	0.243	0.310	0.294	
Subset 2	0.232	0.369	0.428	
Subset 3	0.272	0.429	0.416	
Subset 4	0.235	0.318	0.398	
Average	0.246	0.357	0.384	

Table 4. Adjusted rand index of ADCoC tested at different noise levels.

Noise
variance	25	50	200	400	
Subset 1	0.346	0.294	0.291	0.182	
Subset 2	0.444	0.428	0.394	0.253	
Subset 3	0.385	0.416	0.350	0.026	
Subset 4	0.356	0.398	0.302	0.225	
Average	0.383	0.384	0.334	0.172	


References

[1] Habes M , Grothe MJ , Tunc B , McMillan C , Wolk DA , and Davatzikos C , "Disentangling heterogeneity in Alzheimer’s disease and related dementias using data-driven methods," Biological Psychiatry, 2020.
[2] Szekely GJ and Rizzo ML , "Hierarchical clustering via joint between-within distances: Extending Ward's minimum variance method," Journal of Classification, vol. 22 , pp. 151–183, 2005.
[3] Coelli S , Maggioni E , Rubino A , Campana C , Nobili L , and Bianchi AM , "Multiscale functional clustering reveals frequency dependent brain organization in type ii focal cortical dysplasia with sleep hypermotor epilepsy," IEEE Transactions on Biomedical Engineering, vol. 66 , pp. 2831–2839, 2019.30716026
[4] Dong A , Honnorat N , Gaonkar B , and Davatzikos C , "CHIMERA: Clustering of heterogeneous disease effects via distribution matching of imaging patterns," IEEE Transactions on Medical Imaging, vol. 35 , pp. 612–621, 2015.26452275
[5] Chen R , Jiang T. a. , Lu F , Wang K , and Kong D , "Semiautomatic radiofrequency ablation planning based on constrained clustering process for hepatic tumors," IEEE Transactions on Biomedical Engineering, vol. 65 , pp. 645–657, 2017.28600235
[6] Zhang J , Li C-G , Zhang H , and Guo J , "Low-rank and structured sparse subspace clustering," in IEEE Visual Communications and Image Processing, 2016, pp. 1–4.
[7] Peng B , Lei J , Fu H , Zhang C , Chua T-S , and Li X , "Unsupervised video action clustering via motion-scene interaction constraint," IEEE Transactions on Circuits and Systems for Video Technology, 2018.
[8] Luo H , Xiao G , and Wang H , "Simple iterative clustering on graphs for robust model fitting," in IEEE Visual Communications and Image Processing, 2018, pp. 1–4.
[9] Lian C , Ruan S , Denreux T , Li H , and Vera P , "Spatial evidential clustering with adaptive distance metric for tumor segmentation in FDG-PET images," IEEE Transactions on Biomedical Engineering, vol. 65 , pp. 21–30, 2017.28371772
[10] Li B , Lu H , Zhang Y , Lin Z , and Wu W , "Subspace clustering under complex noise," IEEE Transactions on Circuits and Systems for Video Technology, vol. 29 , pp. 930–940, 2018.
[11] Coates A and Ng AY , "Learning feature representations with k-means," in Neural Networks: Tricks of the Trade, ed: Springer, 2012, pp. 561–580.
[12] Lloyd S , "Least squares quantization in PCM," IEEE Transactions on Information Theory, vol. 28 , pp. 129–137, 1982.
[13] Arthur D and Vassilvitskii S , "k-means++: The advantages of careful seeding," in Annual ACM-SIAM Symposium on Discrete Algorithms, 2007, pp. 1027–1035.
[14] Park H-S and Jun C-H , "A simple and fast algorithm for K-medoids clustering," Expert Systems with Applications, vol. 36 , pp. 3336–3341, 2009.
[15] Sheng W and Liu X , "A genetic k-medoids clustering algorithm," Journal of Heuristics, vol. 12 , pp. 447–466, 2006.
[16] Ward JH Jr , "Hierarchical grouping to optimize an objective function," Journal of the American Statistical Association, vol. 58 , pp. 236–244, 1963.
[17] Sharma A , Boroevich KA , Shigemizu D , Kamatani Y , Kubo M , and Tsunoda T , "Hierarchical maximum likelihood clustering approach," IEEE Transactions on Biomedical Engineering, vol. 64 , pp. 112–122, 2016.27046867
[18] Habes M , Sotiras A , Erus G , Toledo JB , Janowitz D , Wolk DA , , "White matter lesions: Spatial heterogeneity, links to risk factors, cognition, genetics, and atrophy," Neurology, vol. 91 , pp. e964–e975, 2018.30076276
[19] Xie J , Girshick R , and Farhadi A , "Unsupervised deep embedding for clustering analysis," in International Conference on Machine Learning, 2016, pp. 478–487.
[20] Guo X , Liu X , Zhu E , and Yin J , "Deep clustering with convolutional autoencoders," in International conference on neural information processing, 2017, pp. 373–382.
[21] Ding C , Li T , Peng W , and Park H , "Orthogonal nonnegative matrix tri-factorizations for clustering," in ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2006, pp. 126–135.
[22] Liu H , Li H , Boimel P , Janopaul-Naylor J , Zhong H , Xiao Y , , "Collaborative clustering of subjects and radiomic features for predicting clinical outcomes of rectal cancer patients," in IEEE International Symposium on Biomedical Imaging, Venice, Italy, 2019, pp. 1303–1306.
[23] Gligorijević V , Panagakis Y , and Zafeiriou S , "Non-negative matrix factorizations for multiplex network analysis," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 41 , pp. 928–940, 2018.29993651
[24] Pei Y , Chakraborty N , and Sycara K , "Nonnegative matrix tri-factorization with graph regularization for community detection in social networks," in International Joint Conference on Artificial Intelligence, 2015.
[25] Liu H , Li H , Li Y , Yin S , Boimel P , , "Adaptive sparsity regularization based collaborative clustering for cancer prognosis," in International Conference on Medical Image Computing and Computer-Assisted Intervention, Shenzhen, China, 2019, pp. 583–592.
[26] Xu X , Shen F , Yang Y , Zhang D , Tao Shen H , and Song J , "Matrix tri-factorization with manifold regularizations for zero-shot learning," in IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 3798–3807.
[27] Pompili F , Gillis N , Absil P-A , and Glineur F , "Two algorithms for orthogonal nonnegative matrix factorization with application to clustering," Neurocomputing, vol. 141 , pp. 15–25, 2014.
[28] Liu H , Xiong R , Song Q , Wu F , and Gao W , "Image super-resolution based on adaptive joint distribution modeling," in IEEE Visual Communications and Image Processing, 2017.
[29] Liu H , Rashid T , and Habes M , "Cerebral microbleed detection via fourier descriptor with dual domain distribution modeling," in IEEE International Symposium on Biomedical Imaging Workshops, 2020, pp. 1–4.
[30] Liu H , Xiong R , Zhang X , Zhang Y , Ma S , and Gao W , "Nonlocal gradient sparsity regularization for image restoration," IEEE Transactions on Circuits and Systems for Video Technology, vol. 27 , pp. 1909–1921, 2017.
[31] Zhang Y , Kang R , Peng X , Wang J , Zhu J , Peng J , , "Image denoising via structure-constrained low-rank approximation," Neural Computing and Applications, 2020.
[32] Zha Z , Yuan X , Wen B , Zhou J , Zhang J , and Zhu C , "From rank estimation to rank approximation: Rank residual constraint for image restoration," IEEE Transactions on Image Processing, vol. 29 , pp. 3254–3269, 2019.
[33] Liu H , Xiong R , Zhang J , and Gao W , "Image denoising via adaptive soft-thresholding based on non-local samples," in IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 484–492.
[34] Douglas J and Gunn JE , "A general formulation of alternating direction methods," Numerische Mathematik, vol. 6 , pp. 428–453, 1964.
[35] Liu H , Xiong R , Fan X , Zhao D , Zhang Y , and Gao W , "CG-Cast: scalable wireless image SoftCast using compressive gradient," IEEE Transactions on Circuits and Systems for Video Technology, vol. 29 , pp. 1832–1843, 2019.
[36] Liu H , Xiong R , Liu D , Wu F , and Gao W , "Low rank regularization exploiting intra and inter patch correlation for image denoising," in IEEE Visual Communications and Image Processing, St. Petersburg, USA, 2017.
[37] Campello RJ , Moulavi D , Zimek A , and Sander J , "Hierarchical density estimates for data clustering, visualization, and outlier detection," ACM Transactions on Knowledge Discovery from Data, vol. 10 , pp. 1–51, 2015.
[38] Hubert L and Arabie P , "Comparing partitions," Journal of Classification, vol. 2 , pp. 193–218, 1985.
[39] Desikan RS , Ségonne F , Fischl B , Quinn BT , Dickerson BC , Blacker D , , "An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest," Neuroimage, vol. 31 , pp. 968–980, 2006.16530430
[40] Benjamini Y and Yekutieli D , "False discovery rate–adjusted multiple confidence intervals for selected parameters," Journal of the American Statistical Association, vol. 100 , pp. 71–81, 2005.
[41] Aharon M , Elad M , and Bruckstein A , "K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation," IEEE Transactions on Signal Processing, vol. 54 , pp. 4311–4322, 2006.
[42] Liu Y , Yang G , Mirak SA , Hosseiny M , Azadikhah A , Zhong X , , "Automatic prostate zonal segmentation using fully convolutional network with feature pyramid attention," IEEE Access, vol. 7 , pp. 163626–163632, 2019.
[43] Yin S , Peng Q , Li H , Zhang Z , You X , , "Multi-instance deep learning with graph convolutional neural networks for diagnosis of kidney diseases using ultrasound imaging," in Uncertainty for Safe Utilization of Machine Learning in Medical Imaging and Clinical Image-Based Procedures, 2019, pp. 146–154.31893285
[44] Liu Y , Yang G , Hosseiny M , Azadikhah A , Mirak SA , Miao Q , , "Exploring uncertainty measures in bayesian deep attentive neural networks for prostate zonal segmentation," IEEE Access, vol. 8 , pp. 151817–151828, 2020.33564563
[45] Uribe C , Segura B , Baggio HC , Abos A , Garcia-Diaz AI , Campabadal A , , "Cortical atrophy patterns in early Parkinson's disease patients using hierarchical cluster analysis," Parkinsonism &amp; Related Disorders, vol. 50 , pp. 3–9, 2018.29449187
[46] Habes M , Janowitz D , Erus G , Toledo J , Resnick S , Doshi J , , "Advanced brain aging: relationship with epidemiologic and genetic risk factors, and overlap with Alzheimer disease atrophy patterns," Translational Psychiatry, vol. 6 , pp. e775–e775, 2016.27045845
[47] Pagonabarraga J , Corcuera-Solano I , Vives-Gilabert Y , Llebaria G , García-Sánchez C , Pascual-Sedano B , , "Pattern of regional cortical thinning associated with cognitive deterioration in Parkinson’s disease," PLOS One, vol. 8 , p. e54980, 2013.23359616
[48] Ossenkoppele R , Pijnenburg YA , Perry DC , Cohn-Sheehy BI , Scheltens NM , Vogel JW , , "The behavioural/dysexecutive variant of Alzheimer’s disease: clinical, neuroimaging and pathological features," Brain, vol. 138 , pp. 2732–2749, 2015.26141491
