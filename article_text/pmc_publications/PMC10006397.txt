LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


101468753
34789
J Neuropsychol
J Neuropsychol
Journal of neuropsychology
1748-6645
1748-6653

36124357
10006397
10.1111/jnp.12289
NIHMS1845900
Article
The impact of conventional versus robust norming on cognitive characterization and clinical classification of MCI and dementia
Kaser Alyssa N. http://orcid.org/0000-0003-3224-1637
1
Kaplan David M. 2
Goette William 1
Kiselica Andrew M. http://orcid.org/0000-0002-9514-0668
3
1 Department of Psychiatry, University of Texas Southwestern Medical Center, Dallas, Texas, USA
2 Department of Economics, University of Missouri, Columbia, Missouri, USA
3 Department of Health Psychology, University of Missouri, Columbia, Missouri, USA
AUTHOR CONTRIBUTIONS

Alyssa N. Kaser: Formal analysis; project administration; resources; visualization; writing – original draft; writing – review and editing. David M. Kaplan: Conceptualization; methodology. William Goette: Formal analysis; methodology; software. Andrew M. Kiselica: Conceptualization; funding acquisition; methodology; supervision; writing – original draft; writing – review and editing.

Correspondence: Alyssa N. Kaser, 5323 Harry Hines Blvd, University of Texas Southwestern Medical Center, Dallas, TX 75235, USA. alyssa.kaser@utsouthwestern.edu
6 11 2022
3 2023
19 9 2022
11 3 2023
17 1 108124
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
We examined the impact of conventional versus robust normative approaches on cognitive characterization and clinical classification of MCI versus dementia. The sample included participants from the National Alzheimer’s Coordinating Center Uniform Data Set. Separate demographically adjusted z-scores for cognitive tests were derived from conventional (n = 4273) and robust (n = 602) normative groups. To assess the impact of deriving scores from a conventional versus robust normative group on cognitive characterization, we examined likelihood of having a low score on each neuropsychological test. Next, we created receiver operating characteristic (ROC) curves for the ability of normed scores derived from each normative group to differentiate between MCI (n = 3570) and dementia (n = 1564). We examined the impact of choice of normative group on classification accuracy by comparing sensitivity and specificity values and areas under the curves (AUC). Compared with using a conventional normative group, using a robust normative group resulted in a higher likelihood of low cognitive scores for individuals classified with MCI and dementia. Comparison of the classification accuracy for distinguishing MCI from dementia did not suggest a statistically significant advantage for either normative approach (Z = −0.29, p = .77; AUC = 0.86 for conventional and AUC = 0.86 for robust). In summary, these results indicate that using a robust normative group increases the likelihood of characterizing cognitive performance as low. However, there is not a clear advantage of using a robust over a conventional normative group when differentiating between MCI and dementia.

cognition
diagnosis
dementia
mild cognitive impairment
normative data
robust

pmcINTRODUCTION

As the ageing population rapidly grows, age-related neurodegeneration takes on increasing importance as a public health issue (Alzheimer’s Association, 2018). The dramatic increase in the number of individuals diagnosed with conditions like mild cognitive impairment (MCI) and dementia is likely to cause numerous health care and economic problems (Alzheimer’s Association, 2020). Proper diagnosis of these conditions is necessary for timely and appropriate management, and requires reliable and valid diagnostic methods. Typically, age-related cognitive conditions like MCI and dementia are diagnosed via neuropsychological testing, with cognitive impairment indicated by lower-than-expected performance based on norm-referenced scores (Albert et al., 2011; McKhann et al., 2011). Norms are developed by examining performance in groups of putatively cognitively healthy individuals (Kendall et al., 1999; Lezak et al., 2012).

The conventional method for developing normed scores is to analyse data from a group of individuals judged to be cognitively unimpaired at a baseline evaluation (Kendall et al., 1999). While these samples exclude individuals with current cognitive impairment, they may include some individuals who eventually go on to develop cognitive impairment (Ritchie et al., 2007). The presence of such individuals in a normative group creates the possibility that subtle cognitive impairments are being missed in normative comparisons, as prior research has shown that individuals who go on to develop MCI and dementia typically show preclinical signs of cognitive decline (Dubois et al., 2016; Kiselica &amp; Alzheimer’s Disease Neuroimaging Initiative, 2021; Saxton et al., 2004; Thomas et al., 2018).

An alternative to using a conventional normative group is to use a so-called ‘robust’ normative group that excludes individuals who go on to develop cognitive impairment in longitudinal monitoring (Sliwinski et al., 1996). In comparison with scores derived from a robust normative group, Sliwinski et al. (1996) found that scores derived from a conventional normative group tend to be characterized by lower means and heightened variance. These properties can result in underestimation of truly ‘normal’ cognitive performance in older adults. Normed scores derived from a robust normative group are therefore thought to provide a more accurate depiction of both normal and pathological ageing, improving accuracy of cognitive characterization and clinical classification. In summary, there currently exist two competing conceptualizations of the best approach for operationalizing cognitive normality for the purpose of creating a normative sample. While most studies consider individuals designated as cognitively healthy at a baseline evaluation (i.e. a conventional normative group) to be appropriate for the development of a normative sample, others utilize an approach in which individuals must be deemed cognitively healthy across repeated evaluations (i.e. a robust normative group).

Several studies have provided support for use of robust normative groups. Holtzer et al. (2008) observed better cognitive test performance in their robust normative sample compared with initially cognitively normal individuals who developed dementia or were lost to follow-up. Additionally, they suggested that norm scores derived from a robust normative group offer a number of diagnostic benefits that those derived from conventional normative groups do not. For example, they argued that utilizing a longitudinal approach ultimately provides a more accurate representation of normal cognitive functioning. In another study, De Santi et al. (2008) observed greater baseline cognitive test performance in individuals who remained cognitively unimpaired for at least four years compared with individuals who developed dementia during the same time period. They found that deriving norms from the robust group provided a more sensitive approach than use of a conventional sample in identifying future progression from healthy cognition to impairment. This finding of increased sensitivity when using a robust normative group has been replicated in at least two subsequent studies (Grober et al., 2015; Pedraza et al., 2010).

Despite the increased use of robust normative samples, conventional normative groups are still more commonly employed in clinical practice. For example, the widely used Wechsler tests and the Neuropsychological Assessment Battery both utilize conventional normative groups (Stern &amp; White, 2003; Wechsler et al., 2009). Furthermore, controversies remain regarding the proposed benefits of using robust normative groups. De Santi et al. (2008) did not observe an advantage of using a robust normative group in more cognitively impaired individuals, as scores derived from conventional and robust normative groups similarly predicted progression from MCI to dementia. Additionally, a few studies exploring the impact of use of robust normative groups have found that scores derived from conventional normative groups are similarly accurate as those derived from robust norms in identifying future pathological ageing (Marcopulos &amp; McLain, 2003; Ritchie et al., 2007). Finally, debate remains as to whether use of a robust normative group can meaningfully change the cognitive characterization of samples and impact clinical classification (Hassenstab et al., 2016). More specifically, further research is needed to determine (a) the extent to which cognitive characterization of samples differs substantially when conventional versus robust normative groups are used; and (b) whether one normative approach carries an advantage over the other in terms of distinguishing between MCI and dementia.

Research into the use of robust versus conventional normative groups is of critical importance in large data sets of older adults, as the choice of normative approach may have important implications for clinical classification and longitudinal prediction. For example, to our knowledge, there has not been research done to examine use of robust versus conventional normative groups in the National Alzheimer’s Coordinating Center Uniform Data Set (UDS) neuropsychological battery. The UDS is appropriate for such an investigation because it contains extensive longitudinal data collected from participants across Alzheimer’s Disease Research Centers (ADRCs) and includes a variety of clinical and cognitive data. Prior work has been done to explore the UDS3NB through the development of conventional normed scores (Sachs et al., 2020; Weintraub et al., 2018), factor scores (Kiselica, Webber, &amp; Benge, 2020a), change scores (Kiselica, Kaser, et al., 2020), derived and discrepancy scores (Devora et al., 2019) and futile testing profiles (Kiselica et al., 2021). In the present study, we aim to contribute to this line of research on the UDS3NB by investigating robust versus conventional normative sampling approaches.

The goals of the current manuscript were to (1) describe the effect of using norms derived from a conventional versus robust normative sample on the cognitive characterization of individuals diagnosed with MCI and dementia; (2) examine the impact of using norms derived from a conventional versus robust normative sample on the ability to distinguish between levels of cognitive severity, namely MCI versus dementia; and (3) explore the overall classification accuracy of MCI versus dementia when using a conventional versus a robust normative group.

METHODS

Sample

UDS data was requested through the virtual National Alzheimer’s Coordinating Center (NACC) portal on 2/19/2021. This data set included participant information collected at 39 Alzheimer’s Disease Research Centers (ADRCs) and contained 43,517 unique cases. Participants are enrolled using each centre’s designated protocol, following a clinician referral, self-referral or community recruitment. UDS protocol requires annual follow-up evaluations to maintain longitudinal data collection. Data are collected through a standardized evaluation process carried out by trained assessors, during which all data is recorded on electronic or hard copy UDS forms. All participants provided written informed consent upon enrolment at their designated centres. Further information regarding the UDS sample and data collection have been described in previous literature (Beekly et al., 2007; Morris et al., 2006; Weintraub et al, 2018).

Our initial sample selection process began with excluding individuals who did not receive the UDS 3.0 at their baseline visit because of our interest in the most recent version of the neuropsychological battery, limiting the sample to participants assessed from March 2015 through December 2020. Since proficiency in English is needed for a majority of measures included in the UDS3NB, we then excluded all individuals whose first language was not English. Next, we limited our sample to individuals aged 50 and over due to our focus on age-related cognitive impairment. We used this group (n = 9407) to develop our samples for analysis.

We broke this sample down into three groups: a conventional normative group, a robust normative group and a clinical validation group. The conventional normative sample included all individuals who were classified as cognitively normal at baseline (n = 4273). The robust normative sample, created as a subset of the conventional normative sample, included individuals who maintained a status of cognitively normal for at least three follow-up visits and did not develop incident cognitive impairment (n = 602). Individuals developing incident cognitive impairment tended to be less educated and performed worse on neuropsychological tests at baseline (see Table 1). Finally, the clinical validation sample included all individuals who were not defined as cognitively normal during their baseline visit (n = 5134). This sample included individuals with MCI (n = 3570) and dementia (n = 1564). Figure 1 displays our sample selection process.

Clinical staging

The Clinical Dementia Rating® (CDR) Scale was used for clinical staging (Morris, 1993). The reliability and validity of this clinical interview has been established, and it continues to be widely used as a dementia staging measure (Fillenbaum et al., 1996; Morris, 1997). The CDR provides a global rating of cognitive impairment (0 = cognitively normal, 0.5 = MCI, 1 = mild dementia, 2 = moderate dementia, 3 = severe dementia). In the present study, the clinical validation sample was comprised of individuals with a CDR score higher than zero at baseline.

Measures

Cognitive assessments

The UDS3NB is a neuropsychological test battery that has been described in detail elsewhere (Besser et al., 2018; Weintraub et al., 2018) and captures a broad range of cognitive abilities (Kiselica, Webber, &amp; Benge, 2020b). In brief, we utilized core measures in our study, including (1) the Benson Figure, a measure of visuoconstruction abilities and delayed visual recall (Possin et al., 2011); (2) verbal fluency, measured by semantic (animals and vegetables) and letter (F- and L-) word generation tests; (3) Trail Making Test Parts A and B, which measure processing speed and executive functioning (Partington &amp; Leiter, 1949); (4) the Craft Story, an immediate and delayed recall test for verbally presented story information (Craft et al., 1996); (5) Number Span Forward and Backward Test, a digit repetition test that indexes attention and working memory; and (6) the Multilingual Naming Test (MINT), a confrontation naming measure (Gollan et al., 2012; Ivanova et al., 2013). Measure performance for each sample group is described in Tables 1 and 2.

Defining a low score

We defined low scores as those falling at or below the 9th percentile (i.e. z &lt; −1.33) of the normative group using demographically adjusted z-scores (adjusted for demographic factors, including age, sex, education and race using a regression-based approach) (Brooks et al., 2007, 2008). Calculation of regression-based z-scores followed the methods of Shirk et al. (2011) and Weintraub et al. (2018). Specifically, each cognitive test score was regressed onto age, sex, education and race (results of linear regressions shown in Tables S1 and S2). Predicted scores and standard errors of the estimates (SEE) were derived from these regressions, with demographically adjusted z-scores calculated using the following formula: zdemographically adjusted=(observed score−predicted score)/SEE

This process was used to create separate demographically adjusted z-scores derived from the conventional and robust normative groups, respectively. In other words, after developing the two normative samples, the same regression-based approach was applied to each sample to derive two sets of normed scores (one set derived from the conventional normative group and one from the robust normative group). Normed scores in the clinical validation sample were then calculated based on the norms from both the conventional and robust normative groups. Analyses then explored whether deriving normed scores from conventional versus robust normative groups resulted in meaningful changes to cognitive characterization and clinical classification for individuals classified with MCI and dementia.

Recent studies have examined additional regression-based norming methods, such as nonparametric alternatives to linear regression (Crompvoets et al., 2021; Lenhard &amp; Lenhard, 2021). In context of the UDS, Sherwood et al. (2016) explored the use of quantile regression as an alternative to ordinary linear regression-based approaches, suggesting improved performance compared to traditional regression methods. We considered both parametric and semiparametric approaches by conducting ordinary linear regression and quantile regression. Additionally, we explored non-linear relationships between predictor and outcome variables, as well as interactions among predictors, in the quantile regression models. The estimates for numbers of low scores differed across modelling approaches. However, the pattern of findings regarding the main study aims was nearly identical. That is, regardless of the method used for modelling normed scores, rates of low scores derived from a conventional normative group were lower than when derived from a robust normative group. Similarly, regardless of the method used for modelling normed scores, there was not a meaningful difference in ability to distinguish between MCI and dementia when deriving normed scores from conventional versus robust normative groups (see Tables S3–S5 and Figures S1–S3 for a summary of these findings). Given that the results did not change substantively across modelling methods, we only discuss results from the ordinary linear regression method to produce approachable results that fit with the more widely accepted and understood clinical practices of regression-based norming.

Statistical analyses

Descriptive statistics

Demographic characteristics and raw cognitive test performance collected at baseline for the conventional and robust normative groups are summarized in Table 1. Descriptives for the clinical validation sample are provided in Table 2, and comparisons between individuals diagnosed with MCI versus dementia were made using independent groups t-tests (for continuous variables) or chi-square tests of independence (for categorical variables).

Impact of conventional versus robust norms on cognitive characterization of clinical groups

We first examined the impact of using conventional versus robust norms on likelihood of classifying a score as low on individual cognitive tests. Specifically, we dichotomized each individuals demographically corrected cognitive test score as low or not low, based on our previously described low-score definition (≤9th percentile). Next, we examined the proportion of individuals within each diagnostic category (MCI and dementia) scoring low on each individual cognitive test using norms calculated from the conventional versus robust normative samples via McNemar’s tests (paired samples equivalent of a chi-square test).

In addition to examining individual tests, we evaluated the number of low scores detected across the entire UDS3NB within diagnostic categories. This approach was used to examine the extent to which the overall level of evidence of cognitive impairment within a diagnostic group would change when deriving normed scores from a conventional normative sample versus a robust normative sample. Comparisons were made using paired samples t-tests.

Impact of conventional versus robust norms on clinical classification

Next, we examined the impact of using conventional versus robust normative groups on clinical classification of MCI and dementia. First, we compared the ability of individual tests to distinguish between MCI and dementia by examining Cohen’s d effect sizes from paired samples t-tests. If one normative group selection method (conventional vs. robust) yielded higher effect sizes, such a finding would indicate better differentiation of MCI and dementia.

Second, we examined the impact of using conventional versus robust normative samples on classification accuracy. Clinical classification was assessed using a number of low scores approach (Kiselica, Webber, &amp; Benge, 2020a; Oltra-Cucarella et al., 2018). It is an empirical method of staging the severity of cognitive decline by examining the number of low scores observed across an entire test battery. Obviously, individuals with more severe cognitive impairment would be expected to have more low scores, such that the number of low scores observed can help to distinguish between individuals at different levels of severity (in this case, MCI vs. dementia). We completed this process of predicting clinical stage from number of low test scores using normed scores derived from both conventional and robust normative groups, comparing classification accuracy of the two methods by examining receiver operating characteristic (ROC) curves and classification accuracy statistics.

ROC curves were constructed using the pROC package (Robin et al., 2011) in R (version 4.0.4; R Foundation for Statistical Computing, Vienna, Austria). Coordinates on the ROC curves were used to report the paired sensitivity and specificity values for various low test score cut-off points when derived from robust and conventional normative groups. Areas under the curves (AUC) were used as measures of overall classification accuracy, with AUC comparisons across conventional and robust normative grouping approaches accomplished using the methods put forth by DeLong et al. (1988). This popular method implements a nonparametric approach using the Mann–Whitney U-statistic to assess for significant differences in AUCs constructed from paired samples.

RESULTS

Descriptive statistics

Within the clinical validation sample, education and race significantly differed between MCI and dementia sub-groups (see Table 2). Individuals with dementia tended to have slightly fewer years of education and were more likely to be White on average. As anticipated, cognitive scores were higher in the MCI group (p &lt; .001).

Impact of conventional versus robust norms on cognitive characterization of clinical groups

The proportion of individuals with a low score on each cognitive test when deriving scores using conventional versus robust normative groups is presented in Table 3. A higher proportion of low scores was found within MCI and dementia groups when using a robust normative group across all measures except for Numbers Backward. McNemar’s test results were significant among both clinical groups for all cognitive tests aside from the Benson Copy in the dementia group (see Table 3).

Next, we examined the impact of using a conventional versus robust normative group on number of low scores across the entire neuropsychological battery. Individuals with dementia demonstrated more low scores when scores were calculated from a robust normative group [M = 7.42, SD = 2.62] than a conventional normative group [M = 7.01, SD = 2.70], t(1331) = −21.53, p &lt; .001; d = 0.18. Similar results were found in individuals with MCI, with more low scores when calculated from a robust normative group [M = 4.01, SD = 2.85] than a conventional normative group [M = 3.51, SD = 2.76], (3504) = −39.20, p &lt; .001; d = 0.15.

In addition to the ≤9th percentile cut-off, we examined whether these findings changed when using different cut-off scores (≤2, ≤5, ≤16), and found the results to be similar (see Tables S6–S8). Ultimately, when examining individual test and battery wide performance, the robust normative approach resulted in a higher likelihood of characterizing cognitive performance as low.

Impact of conventional versus robust norms on clinical staging

Independent samples t-tests were conducted for cognitive test performance between MCI and dementia groups using conventional and robust norms. Cohen’s d effect sizes for these statistical comparisons using scores derived from robust and conventional normative samples are summarized in Figure 2. As can be seen, the difference of effect sizes between the two approaches was negligible. Findings suggest that there is not a clear advantage of choosing conventional versus robust norms in distinguishing MCI from dementia using individual scores.

Similarly, classification accuracy for categorizing individuals with MCI or dementia using a number of low scores approach did not significantly differ when using robust versus conventional normative groups. Figure 3 presents the ROC curves and AUC results to compare classification accuracy. Table 4 compares the paired sensitivity and specificity values when using conventional versus robust norms at different low test score cut-offs. The robust normative approach demonstrated a slight increase in sensitivity and specificity when compared to conventional norms, although the size of differences was small (~1–10%). Statistical comparison of the conventional (AUC = 0.860) and robust (AUC = 0.860) normative approaches did not suggest an advantage for either normative approach (Z = −0.29, p = .77).

DISCUSSION

Accurate assessment of age-related cognitive impairments is paramount for appropriate management. Conditions like mild cognitive impairment (MCI) and dementia are typically diagnosed via neuropsychological assessment, in which norm-referenced scores are used to evaluate cognitive performance. Due to debate surrounding the most appropriate way to define a normative group, we explored the impact of using conventional versus robust normative groups on cognitive characterization and classification accuracy in individuals with MCI and dementia using data from the UDS 3.0.

Impact of conventional versus robust normative groups on cognitive characterization

As can be seen in Table 3, using a robust normative group increased the likelihood of detecting a low score on nearly all cognitive tests among both individuals with MCI and dementia. Furthermore, when examining findings from the test battery overall, using a robust normative group increased the number of scores characterized as low when compared to use of a conventional normative sample. Thus, using a robust normative group tends to result in a higher likelihood of characterizing an individual as having cognitive impairment both when examining individual tests and whole test batteries. This increased sensitivity of the robust approach is a common finding in previous studies (Clark et al., 2016; Grober et al., 2015; Pedraza et al., 2010), and one potential advantage of a robust normative group.

Surprisingly, though, this increase in sensitivity did not appear to be very clinically meaningful. Indeed, the average increase in the prevalence of low scores on individual tests was only 4.76% in the MCI group and 3.11% in the dementia group. Furthermore, though there was a statistically significant increase in the number of low scores detected across the entire battery when using a robust normative group, this difference was less than one additional test score on average. Thus, use of a robust normative group increases the likelihood that an individual will be characterized as cognitively impaired, but this effect is small in size. Of course, the value of increased sensitivity for detecting cognitive impairment goes beyond sample characterization and is more important for issues of classification accuracy. We turn to these issues now.

Impact of conventional versus robust normative groups on diagnostic accuracy

To examine the impact of conventional versus robust normative groups on the ability to differentiate between MCI and dementia, we first assessed effect sizes for differences in cognitive test performance between individuals with MCI and dementia. If one normative approach yielded larger effect sizes for the differences between MCI and dementia, it would be considered advantageous for purposes of clinical classification. As can be seen in Figure 2, effect sizes were nearly identical when using conventional versus robust normative groups. These results suggest that at the level of individual tests, there is not a clear advantage of one normative approach versus the other when trying to differentiate between MCI and dementia.

A second important question was whether using a robust versus conventional normative group would aid in differential diagnosis of MCI versus dementia. We addressed this issue by examining diagnostic accuracy when applying a whole battery, number of low scores approach (Kiselica, Webber, &amp; Benge, 2020a; Oltra-Cucarella et al., 2018). Specifically, we examined paired sensitivity and specificity values for differentiating MCI from dementia when normed scores were derived from a conventional versus a robust normative group (see Table 4). While scores derived from the robust normative group demonstrated slightly higher sensitivity and specificity values across the majority of low test score cutoffs, the value differences between conventional and robust were at best modest (~1%–10%) and not likely to be clinically meaningful.

A similar pattern emerged when comparing AUC curves for robust versus conventional normative approaches. When applying the DeLong method of AUC comparison (DeLong et al., 1988), there was not a statistically significant difference in the AUCs for differentiating between MCI and dementia when using scores derived from a conventional versus a robust normative group. As has been noted in prior work, this method is highly sensitive to even very small differences in AUC values due to accounting for the correlation between ROC curves derived from the same sample (Robin et al., 2011). Closer examination of Figure 1 and the associated AUC values (.8601 for conventional vs. .8604 for robust) reveals that classification curves were remarkably similar using scores derived from conventional and robust normative groups, both falling in the excellent range (Mandrekar, 2010).

These results imply that when differentiating between MCI and dementia, the choice of whether to derive normed scores from a conventional versus robust normative group does not have much practical impact on clinical classification, consistent with findings from Hassenstab et al. (2016). Of course, there may be situations where the advantages of one approach versus the other may be more obvious. For example, Clark et al. (2016) reported that when differentiating MCI from normal cognition, use of normed scores from a robust normative group yielded a more symptomatic and longitudinally stable group. Using the current data, such an evaluation was impractical because applying an empirical approach to MCI classification would have required use of some participants in both the normative group and the clinical validation group, introducing a confound. Thus, future research should examine the impact of using conventional versus robust normative groups on classification of MCI versus cognitive normality in an independent sample.

Overall, these findings reveal the importance of operationally defining the normative group. Based on our findings, clinicians choosing among available instruments with different normative sets should be cautioned that using a robust normative group may result in a higher likelihood of obtaining low scores for a given patient than using a conventional normative group. However, this choice may or may not impact clinical classification, depending on the intended use of the tests. Thus, a clear description of the normative group should be included in test manuals so that clinicians can make informed choices about how the type of normative group will impact clinical interpretation.

Uniform data set 3.0

The UDSNB 3.0 neuropsychological battery assesses a number of cognitive skills. Kiselica, Webber, and Benge (2020a) investigated the factor structure of the UDS3NB and found the battery to capture a higher order general cognitive factor, as well as lower order attention, memory, language, processing speed/executive and visual factors. Decline in these cognitive domains in individuals with MCI and dementia has been well-established (Knopman &amp; Petersen, 2014; Wilson et al., 2011), similar to the presented findings. Thus, the current study may provide results generalizable to situations in which other neuropsychological assessments may be employed.

Limitations

There are some relevant limitations to this research. First, we implemented a widely used approach for creating robust norms (Clark et al., 2016; Grober et al., 2015; Pedraza et al., 2010; Ritchie et al., 2007), which involved removing individuals from the sample who went on to develop cognitive impairment in longitudinal examination. There are other methods for creating a robustly normal group. For example, Hassenstab et al. (2016) removed individuals with positive Alzheimer’s disease biomarkers to create a robustly normal group. One could envision a scenario in which either individuals with positive biomarkers or evidence of subsequent cognitive impairment are removed to create a ‘robustly robust’ normative sample. Such approaches should be tested in future research.

Second, though our data seem to suggest that use of conventional versus robust normative groups would not be likely to change clinical decision making, our methods were not suitable for directly answering this question. A more appropriate approach to answer this question would be experimental in nature. For instance, one could provide neuropsychologists with case scenarios containing results from robust versus conventional normed approaches and measure the extent to which diagnostic and staging decisions change (Caramazza &amp; McCloskey, 1988; Shallice, 1979). Finally, it must be noted that the Uniform Data Set sample consists of research participants who may differ in important ways from individuals in clinical settings, limiting generalizability of findings (Kukull &amp; Ganguli, 2012).

CONCLUSIONS

In summary, we evaluated the impacts of using conventional versus robust normative groups on cognitive characterization and clinical classification of individuals with MCI and dementia. Results suggested that use of a robust normative group yields a higher likelihood of low scores, such that an individual with a given condition would be described as more cognitively impaired than if scores were derived from a conventional normative group. Nonetheless, deriving normed values from a robust normative group did not yield a substantial improvement in the ability to distinguish between MCI and dementia using cognitive tests. Findings suggest that for this select purpose, using either approach is likely appropriate. Nonetheless, more research is necessary to determine the appropriateness of using robust versus conventional normative groups to differentiate individuals with MCI from individuals who are cognitively unimpaired. Furthermore, more work needs to be done to assess for the impact of using robust versus conventional normative groups on actual clinical decision making.

Supplementary Material

Supplemental Tables

ACKNOWLEDGEMENTS

The NACC database is funded by NIA/NIH Grant U24 AG072122. NACC data are contributed by the NIA-funded ADRCs: P30 AG019610 (PI Eric Reiman, MD), P30 AG013846 (PI Neil Kowall, MD), P50 AG008702 (PI Scott Small, MD), P50 AG025688 (PI Allan Levey, MD, PhD), P50 AG047266 (PI Todd Golde, MD, PhD), P30 AG010133 (PI Andrew Saykin, PsyD), P50 AG005146 (PI Marilyn Albert, PhD), P50 AG005134 (PI Bradley Hyman, MD, PhD), P50 AG016574 (PI Ronald Petersen, MD, PhD), P50 AG005138 (PI Mary Sano, PhD), P30 AG008051 (PI Thomas Wisniewski, MD), P30 AG013854 (PI Robert Vassar, PhD), P30 AG008017 (PI Jeffrey Kaye, MD), P30 AG010161 (PI David Bennett, MD), P50 AG047366 (PI Victor Henderson, MD, MS), P30 AG010129 (PI Charles DeCarli, MD), P50 AG016573 (PI Frank LaFerla, PhD), P50 AG005131 (PI James Brewer, MD, PhD), P50 AG023501 (PI Bruce Miller, MD), P30 AG035982 (PI Russell Swerdlow, MD), P30 AG028383 (PI Linda Van Eldik, PhD), P30 AG053760 (PI Henry Paulson, MD, PhD), P30 AG010124 (PI John Trojanowski, MD, PhD), P50 AG005133 (PI Oscar Lopez, MD), P50 AG005142 (PI Helena Chui, MD), P30 AG012300 (PI Roger Rosenberg, MD), P30 AG049638 (PI Suzanne Craft, PhD), P50 AG005136 (PI Thomas Grabowski, MD), P50 AG033514 (PI Sanjay Asthana, MD, FRCP), P50 AG005681 (PI John Morris, MD), P50 AG047270 (PI Stephen Strittmatter, MD, PhD).

FUNDING INFORMATION

This work was supported by an Alzheimer’s Association Research Fellowship [2019-AARF-641693 to A.M.K.].

DATA AVAILABILITY STATEMENT

The National Alzheimer’s Coordinating Center Uniform Data Set is publicly accessible via request at the following web address: https://naccdata.org/requesting-data/submit-data-request

FIGURE 1 Process for sample selection

FIGURE 2 Effect sizes of individual cognitive tests using robust and conventional norms. Note: DR, delayed recall; IR, immediate recall; MINT, Multilingual Naming Test; Numbers Backward, Number Span Backward; Numbers Forward, Number Span Forward

FIGURE 3 Comparison of ROC curves between conventional and robust norms

TABLE 1 Demographic and cognitive characteristics of the conventional and robust normative samples at baseline

	Conventional (n = 4273)	Robust (n = 602)	Incident CI (n = 410)	t or Chia, p-value	
Age, mean (SD)	69.70 (8.01)	71.40 (7.07)	72.26 (7.89)	−1.82, p = .07	
	
Education, mean (SD)	16.36 (2.50)	16.48 (2.40)	16.03 (2.77)	2.70, **	
	
Female, %	66.02%	62.29%	58.54%	1.29, p = .26	
	
White, %	76.92%	78.57%	74.88%	1.90, p = .17	
	
Cognitive variable, mean (SD)					
 Benson Copy	15.45 (1.38)	15.76 (1.29)	15.21 (1.56)	6.07, ***	
 Benson Recall	11.16 (2.99)	11.51 (2.93)	10.20 (3.13)	6.72, ***	
 Animal Naming	21.05 (5.64)	21.75 (5.62)	18.68 (5.32)	8.65, ***	
 Vegetable Naming	14.70 (4.18)	14.95 (4.04)	13.16 (4.20)	6.75, ***	
 Trail Making Part A	32.56 (13.37)	31.08 (11.86)	36.78 (15.68)	−6.52, ***	
 Trail Making Part B	86.27 (45.91)	80.42 (38.45)	108.8 (60.30)	−9.02, ***	
 Letter Fluency	27.71 (8.37)	28.43 (8.34)	25.49 (8.03)	5.51, ***	
 Craft Story IR	21.37 (6.63)	21.80 (6.28)	18.32 (7.10)	8.10, ***	
 Craft Story DR	18.53 (6.69)	19.01 (6.25)	15.65 (7.18)	7.78, ***	
 Numbers Forward	8.19 (2.34)	8.34 (2.32)	7.70 (2.45)	4.21, ***	
 Numbers Backward	6.91 (2.22)	7.09 (2.22)	6.19 (2.23)	6.23, ***	
 MINT	29.87 (2.54)	30.23 (1.90)	28.66 (4.25)	7.89, ***	
Note: Male-coded as 1, female-coded as 2. White-coded as 1, non-white-coded as 2.

Numbers Forward = Number Span Forward; Numbers Backward = Number Span Backward; IR = immediate recall; DR = delayed recall; MINT = Multilingual Naming Test.

Paired samples t-tests were used for continuous variables, while McNemar’s tests were used for categorical variables.

a Compared individuals in the robust normative group to those excluded due to incident cognitive impairment.

** p &lt; .01.;

*** p &lt; .001.

TABLE 2 Demographic and cognitive characteristics of the clinical validation (mild cognitive impairment and dementia) sample at baseline

	MCI (n = 3570)	Dementia (n = 1564)	t or χ2, p-value	95% CI	
Age, mean (SD)	71.06 (8.42)	70.55 (9.86)	1.91, p = .06	−0.01 to 1.04	
Age range, years	50.0–99.0	50.0–104.0			
	
Education, mean (SD)	16.00 (2.80)	15.53 (2.84)	5.37, ***	0.29 to 0.63	
	
Female, %	50.70%	50.45%	0.02, p = .89		
	
White, %	82.55%	87.85%	25.03, ***		
	
Cognitive variable, mean (SD)					
 Benson Copy	14.69 (2.45)	11.67 (5.06)	27.47, ***	[2.80, 3.23]	
 Benson Recall	7.25 (4.35)	2.88 (3.67)	31.22, ***	[4.10, 4.65]	
 Animal Naming	16.31 (5.76)	9.64 (5.38)	36.45, ***	[6.31, 7.03]	
 Vegetable Naming	10.68 (4.42)	5.80 (3.71)	35.29, ***	[4.61, 5.15]	
 Trail Making Part A	44.64 (26.15)	78.89 (43.43)	−31.88, ***	[−36.36, −32.14]	
 Trail Making Part B	132.93 (77.38)	208.17 (90.84)	−21.58, ***	[−82.08, −68.41]	
 Letter Fluency	23.43 (9.12)	15.71 (9.08)	25.59, ***	[7.12, 8.31]	
 Craft Story IR	14.89 (7.37)	7.50 (6.08)	31.75, ***	[6.93, 7.84]	
 Craft Story DR	10.94 (7.74)	3.79 (5.35)	29.72, ***	[6.68, 7.62]	
 Numbers Forward	7.38 (2.34)	6.15 (2.37)	16.23, ***	[1.09, 1.38]	
 Numbers Backward	5.70 (2.17)	3.73 (2.27)	27.51, ***	[1.83, 2.11]	
 MINT	27.89 (4.55)	23.22 (7.33)	25.90, ***	[4.32, 5.02]	
Note: Male-coded as 1, female-coded as 2. White-coded as 1, non-white-coded as 2.

Numbers Forward = Number Span Forward; Numbers Backward = Number Span Backward; IR = immediate recall; DR = delayed recall; MINT = Multilingual Naming Test.

Independent t-tests were used for continuous variables, while chi-square tests of independence were used for categorical variables.

*** p &lt; .001.

TABLE 3 Proportion of low scores in individuals with MCI and dementia using robust versus conventional norms

	MCI		Dementia		
	Conventional	Robust		Conventional	Robust		
	% low	% low	χ2, p-value	% low	% low	χ2, p-value	
Benson Copy	20.03	19.66	 4.11, *	39.45	39.58	  0.06, p = .80	
	
Benson Recall	42.77	47.34	161.01, ***	63.24	65.15	  28.03, ***	
	
Animal Naming	32.32	36.33	133.54, ***	64.13	66.75	  37.21, ***	
	
Vegetables	35.29	39.13	135.01, ***	62.92	66.56	  55.02, ***	
	
Trail Making Part A	24.82	30.34	195.01, ***	46.61	50.45	  58.02, ***	
	
Trail Making Part B	26.75	33.92	254.00, ***	26.60	29.67	  46.02, ***	
	
Letter Fluency	21.06	22.83	  48.66, ***	42.52	44.18	  20.83, ***	
	
Craft Story IR	37.11	41.43	142.74, ***	62.08	65.15	  40.91, ***	
	
Craft Story DR	43.45	46.86	109.26, ***	65.41	66.88	  19.36, ***	
	
Numbers Forward	16.47	22.13	181.99, ***	29.41	35.42	  81.59, ***	
	
Numbers Backward	25.88	23.19	  88.48, ***	51.28	49.81	  15.61, ***	
	
MINT	22.16	33.47	402.00, ***	45.20	53.84	133.01, ***	
Abbreviations: DR, delayed recall; IR, immediate recall; MINT, Multilingual Naming Test; Numbers Backward, Number Span Backward; Numbers Forward, Number Span Forward.

* p &lt; .05.;

*** p &lt; .001.

TABLE 4 Diagnostic classification accuracy using conventional and robust norms

	Conventional	Robust	
Number of low tests	Sensitivity	Specificity	Sensitivity	Specificity	
1+	.952	.397	.943	.438	
	
2+	.924	.527	.910	.565	
	
3+	.893	.635	.865	.681	
	
4+	.838	.724	.808	.763	
	
5+	.780	.789	.732	.840	
	
6+	.713	.845	.647	.877	
	
7+	.619	.895	.558	.927	
	
8+	.514	.939	.441	.964	
	
9+	.391	.971	.327	.981	
	
10+	.262	.988	.208	.992	
	
11+	.132	.997	.096	.998	

CONFLICTS OF INTEREST

There are no conflicts of interest to report.

SUPPORTING INFORMATION

Additional supporting information can be found online in the Supporting Information section at the end of this article.

Appendix S1.


REFERENCES

Albert MS , DeKosky ST , Dickson D , Dubois B , Feldman HH , Fox NC , Gamst A , Holtzman DM , Jagust WJ , Petersen RC , Snyder PJ , Carrillo MC , Thies B , &amp; Phelps CH (2011). The diagnosis of mild cognitive impairment due to Alzheimer’s disease: Recommendations from the National Institute on Aging-Alzheimer’s Association workgroups on diagnostic guidelines for Alzheimer’s disease. Alzheimer’s &amp; Dementia: The Journal of the Alzheimer’s Association, 7 (3 ), 270–279. 10.1016/j.jalz.2011.03.008
Alzheimer’s Association. (2018). 2018 Alzheimer’s disease facts and figures. Alzheimer’s &amp; Dementia, 14 (3 ), 367–429.
Alzheimer’s Association. (2020). 2020 Alzheimer’s disease facts and figures. Alzheimer’s &amp; Dementia, 16 (3 ), 391–460. 10.1002/alz.12068
Beekly DL , Ramos EM , Lee WW , Deitrich WD , Jacka ME , Wu J , Hubbard JL , Koepsell TD , Morris JC , Kukull WA , &amp; Centers TNAD (2007). The National Alzheimer’s Coordinating Center (NACC) Database: the uniform data set. Alzheimer Disease &amp; Associated Disorders, 21 (3 ), 249–258. 10.1097/WAD.0b013e318142774e 17804958
Besser L , Kukull W , Knopman DS , Chui H , Galasko D , Weintraub S , Jicha G , Carlsson C , Burns J , Quinn J , Sweet RA , Rascovsky K , Teylan M , Beekly D , Thomas G , Bollenbeck M , Monsell S , Mock C , Zhou XH , … Neuropsychology Work Group, Directors, and Clinical Core leaders of the National Institute on Aging-funded US Alzheimer’s Disease Centers. (2018). Version 3 of the National Alzheimer’s coordinating center’s uniform data set. Alzheimer Disease and Associated Disorders, 32 (4 ), 351–358. 10.1097/WAD.0000000000000279 30376508
Brooks BL , Iverson GL , Holdnack JA , &amp; Feldman HH (2008). Potential for misclassification of mild cognitive impairment: a study of memory scores on the Wechsler Memory Scale-III in healthy older adults. Journal of the International Neuropsychological Society, 14 (3 ), 463–478. 10.1017/S1355617708080521 18419845
Brooks BL , Iverson GL , &amp; White T (2007). Substantial risk of “Accidental MCI” in healthy older adults: base rates of low memory scores in neuropsychological assessment. Journal of the International Neuropsychological Society, 13 (3 ), 490–500. 10.1017/S1355617707070531 17445298
Caramazza A , &amp; McCloskey M (1988). The case for single-patient studies. Cognitive Neuropsychology, 5 (5 ), 517–527. 10.1080/02643298808253271
Clark LR , Koscik RL , Nicholas CR , Okonkwo OC , Engelman CD , Bratzke LC , Hogan KJ , Mueller KD , Bendlin BB , Carlsson CM , Asthana S , Sager MA , Hermann BP , &amp; Johnson SC (2016). Mild cognitive impairment in late middle age in the Wisconsin registry for Alzheimer’s prevention study: Prevalence and characteristics using robust and standard neuropsychological normative data. Archives of Clinical Neuropsychology: The Official Journal of the National Academy of Neuropsychologists, 31 (7 ), 675–688. 10.1093/arclin/acw024 27193363
Craft S , Newcomer J , Kanne S , Dagogo-Jack S , Cryer P , Sheline Y , Luby J , Dagogo-Jack A , &amp; Alderson A (1996). Memory improvement following induced hyperinsulinemia in Alzheimer’s disease. Neurobiology of Aging, 17 (1 ), 123–130. 10.1016/0197-4580(95)02002-0 8786794
Crompvoets EAV , Keuning J , &amp; Emons WHM (2021). Bias and precision of continuous norms obtained using quantile regression. Assessment, 28 (6 ), 1735–1750. 10.1177/1073191120910201 32483976
De Santi S , Pirraglia E , Barr W , Babb J , Williams S , Rogers K , Glodzik L , Brys M , Mosconi L , Reisberg B , Ferris S , &amp; de Leon MJ (2008). Robust and conventional neuropsychological norms: Diagnosis and prediction of age-related cognitive decline. Neuropsychology, 22 (4 ), 469–484. 10.1037/0894-4105.22.4.469 18590359
DeLong ER , DeLong DM , &amp; Clarke-Pearson DL (1988). Comparing the areas under two or more correlated receiver operating characteristic curves: A nonparametric approach. Biometrics, 44 (3 ), 837–845. 10.2307/2531595 3203132
Devora PV , Beevers S , Kiselica AM , &amp; Benge JF (2019). Normative data for derived measures and discrepancy scores for the uniform data set 3.0 neuropsychological battery. Archives of Clinical Neuropsychology: The Official Journal of the National Academy of Neuropsychologists, 35 (1 ), 75–89. 10.1093/arclin/acz025 31236576
Dubois B , Hampel H , Feldman HH , Scheltens P , Aisen P , Andrieu S , Bakardjian H , Benali H , Bertram L , Blennow K , Broich K , Cavedo E , Crutch S , Dartigues J-F , Duyckaerts C , Epelbaum S , Frisoni GB , Gauthier S , Genthon R , … Proceedings of the Meeting of the International Working Group (IWG) and the American Alzheimer’s Association on “The Preclinical State of AD”; July 23, 2015; Washington DC, USA. (2016). Preclinical Alzheimer’s disease: Definition, natural history, and diagnostic criteria. Alzheimer’s &amp; Dementia: The Journal of the Alzheimer’s Association, 12 (3 ), 292–323. 10.1016/j.jalz.2016.02.002
Fillenbaum GG , Peterson B , &amp; Morris JC (1996). Estimating the validity of the clinical Dementia Rating Scale: The CERAD experience. Consortium to establish a registry for Alzheimer’s disease. Aging, 8 (6 ), 379–385. 10.1007/BF03339599 9061124
Gollan TH , Weissberger GH , Runnqvist E , Montoya RI , &amp; Cera CM (2012). Self-ratings of Spoken Language Dominance: A Multi-Lingual Naming Test (MINT) and Preliminary Norms for Young and Aging Spanish-English Bilinguals. Bilingualism, 15 (3 ), 594–615. 10.1017/S1366728911000332 25364296
Grober E , Mowrey W , Katz M , Derby C , &amp; Lipton RB (2015). Conventional and Robust Norming in identifying Preclinical Dementia. Journal of Clinical and Experimental Neuropsychology, 37 (10 ), 1098–1106. 10.1080/13803395.2015.1078779 26325449
Hassenstab J , Chasse R , Grabow P , Benzinger TLS , Fagan AM , Xiong C , Jasielec M , Grant E , &amp; Morris JC (2016). Certified normal: Alzheimer’s disease biomarkers and normative estimates of cognitive functioning. Neurobiology of Aging, 43 , 23–33. 10.1016/j.neurobiolaging.2016.03.014 27255812
Holtzer R , Goldin Y , Zimmerman M , Katz M , Buschke H , &amp; Lipton RB (2008). Robust norms for selected neuropsychological tests in older adults. Archives of Clinical Neuropsychology: The Official Journal of the National Academy of Neuropsychologists, 23 (5 ), 531–541. 10.1016/j.acn.2008.05.004 18572380
Ivanova I , Salmon DP , &amp; Gollan TH (2013). The multilingual naming test in Alzheimer’s disease: Clues to the origin of naming impairments. Journal of the International Neuropsychological Society, 19 (3 ), 272–283. 10.1017/S1355617712001282 23298442
Kendall PC , Marrs-Garcia A , Nath SR , &amp; Sheldrick RC (1999). Normative comparisons for the evaluation of clinical significance. Journal of Consulting and Clinical Psychology, 67 (3 ), 285–299. 10.1037//0022-006x.67.3.285 10369049
Kiselica AM , &amp; Alzheimer’s Disease Neuroimaging Initiative. (2021). Empirically defining the preclinical stages of the Alzheimer’s continuum in the Alzheimer’s Disease Neuroimaging Initiative. Psychogeriatrics, 21 (4 ), 491–502. 10.1111/psyg12697 33890392
Kiselica AM , Johnson E , &amp; Benge JF (2021). How impaired is too impaired? Exploring futile neuropsychological test patterns as a function of dementia severity and cognitive screening scores. Journal of Neuropsychology, 15 , 410–427. 10.1111/jnp.12243 33655681
Kiselica AM , Kaser AN , Webber TA , Small BJ , &amp; Benge JF (2020). Development and preliminary validation of standardized regression-based change scores as measures of transitional cognitive decline. Archives of Clinical Neuropsychology, 35 (7 ), 1168–1181. 10.1093/arclin/acaa042
Kiselica AM , Webber TA , &amp; Benge JF (2020a). The uniform dataset 3.0 neuropsychological battery: Factor structure, invariance testing, and demographically adjusted factor score calculation. Journal of the International Neuropsychological Society, 26 (6 ), 576–586. 10.1017/S135561772000003X 32063246
Kiselica AM , Webber TA , &amp; Benge JF (2020b). Using multivariate base rates of low scores to understand early cognitive declines on the Uniform Data Set 3.0 neuropsychological battery. Neuropsychology, 34 (6 ), 629–640. 10.1037/neu0000640 32338945
Knopman DS , &amp; Petersen RC (2014). Mild cognitive impairment and mild dementia: A clinical perspective. Mayo Clinic Proceedings, 89 (10 ), 1452–1459. 10.1016/j.mayocp.2014.06.019 25282431
Kukull WA , &amp; Ganguli M (2012). Generalizability: The trees, the forest, and the low-hanging fruit. Neurology, 78 (23 ), 1886–1891. 10.1212/WNL.0b013e318258f812 22665145
Lenhard W , &amp; Lenhard A (2021). Improvement of norm score quality via regression-based continuous norming. Educational and Psychological Measurement, 81 (2 ), 229–261. 10.1177/0013164420928457
Lezak MD , Howieson DB , Bigler ED , &amp; Tranel D (2012). Neuropsychological assessment (5th ed.). Oxford University
Mandrekar JN (2010). Receiver operating characteristic curve in diagnostic test assessment. Journal of Thoracic Oncology: Official Publication of the International Association for the Study of Lung Cancer, 5 (9 ), 1315–1316. 10.1097/JTO.0b013e3181ec173d 20736804
Marcopulos BA , &amp; McLain CA (2003). Are our norms “normal”? A 4-year follow-up study of a biracial sample of rural elders with low education. The Clinical Neuropsychologist, 17 (1 ), 19–33. 10.1076/clin.17.1.19.15630 12854008
McKhann GM , Knopman DS , Chertkow H , Hyman BT , Jack CR , Kawas CH , Klunk WE , Koroshetz WJ , Manly JJ , Mayeux R , Mohs RC , Morris JC , Rossor MN , Scheltens P , Carrillo MC , Thies B , Weintraub S , &amp; Phelps CH (2011). The diagnosis of dementia due to Alzheimer’s disease: Recommendations from the National Institute on Aging-Alzheimer’s Association workgroups on diagnostic guidelines for Alzheimer’s disease. Alzheimer’s &amp; Dementia: The Journal of the Alzheimer’s Association, 7 (3 ), 263–269. 10.1016/j.jalz.2011.03.005
Morris JC (1993). The Clinical Dementia Rating (CDR): Current version and scoring rules. Neurology, 43 (11 ), 2412–2414. 10.1212/wnl.43.11.2412-a
Morris JC (1997). Clinical dementia rating: A reliable and valid diagnostic and staging measure for dementia of the Alzheimer type. International Psychogeriatrics, 9 (Suppl 1 ), 173–176; discussion 177-178. 10.1017/s1041610297004870 9447441
Morris JC , Weintraub S , Chui HC , Cummings J , Decarli C , Ferris S , Foster NL , Galasko D , Graff-Radford N , Peskind ER , Beekly D , Ramos EM , &amp; Kukull WA (2006). The Uniform Data Set (UDS): Clinical and cognitive variables and descriptive data from Alzheimer Disease Centers. Alzheimer Disease and Associated Disorders, 20 (4 ), 210–216. 10.1097/01.wad.0000213865.09806.92 17132964
Oltra-Cucarella J , Sánchez-SanSegundo M , Lipnicki DM , Sachdev PS , Crawford JD , Pérez-Vicente JA , Cabello-Rodríguez L , Ferrer-Cascales R , &amp; Alzheimer’s Disease Neuroimaging Initiative. (2018). Using base rate of low scores to identify progression from amnestic mild cognitive impairment to Alzheimer’s disease. Journal of the American Geriatrics Society, 66 (7 ), 1360–1366. 10.1111/jgs.15412 29745971
Partington JE , &amp; Leiter RG (1949). Partington’s pathways test. Psychological Service Center Journal, 1 , 11–20.
Pedraza O , Lucas JA , Smith GE , Petersen RC , Graff-Radford NR , &amp; Ivnik RJ (2010). Robust and expanded norms for the Dementia rating scale. Archives of Clinical Neuropsychology: The Official Journal of the National Academy of Neuropsychologists, 25 (5 ), 347–358. 10.1093/arclin/acq030 20427376
Possin KL , Laluz VR , Alcantar OZ , Miller BL , &amp; Kramer JH (2011). Distinct neuroanatomical substrates and cognitive mechanisms of figure copy performance in Alzheimer’s disease and behavioral variant frontotemporal dementia. Neuropsychologia, 49 (1 ), 43–48. 10.1016/j.neuropsychologia.2010.10.026 21029744
Ritchie LJ , Frerichs RJ , &amp; Tuokko H (2007). Effective normative samples for the detection of cognitive impairment in older adults. The Clinical Neuropsychologist, 21 (6 ), 863–874. 10.1080/13854040701557239 17853155
Robin X , Turck N , Hainard A , Tiberti N , Lisacek F , Sanchez J-C , &amp; Müller M (2011). pROC: An open source package for R and S+ to analyze and compare ROC curves. BMC Bioinformatics, 12 (1 ), 77. 10.1186/1471-2105-12-77 21414208
Sachs BC , Steenland K , Zhao L , Hughes TM , Weintraub S , Dodge HH , Barnes LL , Craft S , Parker ML , &amp; Goldstein FC (2020). Expanded demographic norms for Version 3 of the Alzheimer disease centers’ neuropsychological test battery in the uniform data set. Alzheimer Disease and Associated Disorders, 34 (3 ), 191–197. 10.1097/WAD.0000000000000388 32483017
Saxton J , Lopez OL , Ratcliff G , Dulberg C , Fried LP , Carlson MC , Newman AB , &amp; Kuller L (2004). Preclinical Alzheimer disease: Neuropsychological test performance 1.5 to 8 years prior to onset. Neurology, 63 (12 ), 2341–2347. 10.1212/01.WNL.0000147470.58328.50 15623697
Shallice T (1979). Case study approach in neuropsychological research. Journal of Clinical Neuropsychology, 1 (3 ), 183–211. 10.1080/01688637908414450
Sherwood B , Zhou AX-H , Weintraub S , &amp; Wang L (2016). Using quantile regression to create baseline norms for neuropsychological tests. Alzheimer’s &amp; Dementia: Diagnosis, Assessment &amp; Disease Monitoring, 2 , 12–18. 10.1016/j.dadm.2015.11.005
Shirk SD , Mitchell MB , Shaughnessy LW , Sherman JC , Locascio JJ , Weintraub S , &amp; Atri A (2011). A web-based normative calculator for the uniform data set (UDS) neuropsychological test battery. Alzheimer’s Research &amp; Therapy, 3 (6 ), 32. 10.1186/alzrt94
Sliwinski M , Lipton RB , Buschke H , &amp; Stewart W (1996). The effects of preclinical dementia on estimates of normal cognitive functioning in aging. The Journals of Gerontology. Series B, Psychological Sciences and Social Sciences, 51 (4 ), P217–P225. 10.1093/geronb/51b.4.p217 8673642
Stern RA , &amp; White T (2003). NAB, Neuropsychological assessment battery: Administration, scoring, and interpretation manual. Psychological Assessment Resources Lutz (FL).
Thomas KR , Edmonds EC , Eppig J , Salmon DP , Bondi MW , &amp; Alzheimer’s Disease Neuroimaging Initiative. (2018). Using neuropsychological process scores to identify subtle cognitive decline and predict progression to mild cognitive impairment. Journal of Alzheimer’s Disease, 64 (1 ), 195–204. 10.3233/JAD-180229
Wechsler D , Holdnack JA , &amp; Drozdick LW (2009). Wechsler Memory Scale: Fourth edition technical and interpretive manual. Pearson.
Weintraub S , Besser L , Dodge HH , Teylan M , Ferris S , Goldstein FC , Giordani B , Kramer J , Loewenstein D , Marson D , Mungas D , Salmon D , Welsh-Bohmer K , Zhou X-H , Shirk SD , Atri A , Kukull WA , Phelps C , &amp; Morris JC (2018). Version 3 of the Alzheimer disease centers’ neuropsychological test battery in the uniform data set (UDS). Alzheimer Disease and Associated Disorders, 32 (1 ), 10–17. 10.1097/WAD.0000000000000223 29240561
Wilson RS , Leurgans SE , Boyle PA , &amp; Bennett DA (2011). Cognitive decline in prodromal Alzheimer disease and mild cognitive impairment. Archives of Neurology, 68 (3 ), 351–356. 10.1001/archneurol.2011.31 21403020
