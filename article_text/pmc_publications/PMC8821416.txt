LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


8309633
3924
Geriatr Nurs
Geriatr Nurs
Geriatric nursing (New York, N.Y.)
0197-4572
1528-3984

34847509
8821416
10.1016/j.gerinurse.2021.11.008
NIHMS1757980
Article
Use of Robots to Encourage Social Engagement between Older Adults
Lin Yi-Chun MS, RN, APRN-CNS 1
Fan Jing PhD 2
Tate Judith A. PhD, RN 3
Sarkar Nilanjan PhD 4
Mion Lorraine C. PhD, RN 5
1 At the time of the study, Research Assistant at the Ohio State University College of Nursing, Columbus OH
2 At the time of the study, Research Assistant at Vanderbilt University Electrical and Engineering and Computer Science Department, Nashville TN
3 Associate Professor, College of Nursing, Ohio State University, Columbus OH
4 David K. Wilson Professor of Engineering at Vanderbilt University School of Engineering; Chair of Mechanical Engineering and Professor of Electrical and Computer Science
5 Research Professor, College of Nursing, Ohio State University, Columbus OH
* Corresponding Author: Lorraine C. Mion, The Ohio State University College of Nursing, 1585 Neil Avenue, Columbus OH 43210. Office phone: 614-688-3734, mion.3@osu.edu
21 11 2021
Jan-Feb 2022
27 11 2021
01 1 2023
43 97103
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
We designed a robotic architecture system within a commercially available socially assistive robot to engage pairs of older adults in multimodal activities over 3 weeks for 6 sessions. The study took place in two assisted living facilities. Seven pairs (14 individuals) completed the experiment. Ages ranged from 70 to 90 years with a mean age of 83.0 (± 6.1). Most were women (79%). Three adults were screened as having normal cognition, 10 had mild cognitive impairment, and 1 adult self-reported a diagnosis of Alzheimer’s disease. All sessions were video recorded and analyzed using Noldus Observer XT. Individuals demonstrated high levels of both human-human interaction and human-robot interaction, but the activity influenced the type of interaction. Engagement measures (visual, verbal, behavioral) also varied by type of activity. Future studies will focus on further development of activities that can engage older adults with varying levels of cognitive impairment and apathy.


pmcINTRODUCTION

Apathy is one of the most prevalent behavioral symptoms among older adults residing in long term care settings (LTCs), occurring in up to 72%.1 Apathy has significant consequences as it is associated with cognitive decline, functional deficits, reduced quality of life, social isolation, and increased mortality.1–4 Moreover, apathy produces major stress, burden, and frustration for formal and informal caregivers.5–7 Few pharmacologic options exist to treat apathy;4 a major non-pharmacologic strategy is to foster older adults’ engagement in social, physical, and cognitive activities.4,8 Activities with others are particularly effective because older adults are engaged both in the activity and the human contact.9 In addition, the combination of sensory and motor-based activity appears most effective for enhancing engagement and reducing apathy.8,10,11

The Centers for Medicare and Medicaid Services (CMS) mandate that LTCs provide individualized activity programs (§483.15(f)).12 Most LTCs provide activities for residents but they are often suboptimal in the degree of engagement, variety, stimulation or content.13 Many older adults have excessive unoccupied time and spend as much as 17 hours a day in bed.14 Barriers to engaging LTC older adults include cognitive and physical impairments.14–16 LTC caregivers frequently lack the time, skill, or resources to engage older adults in activities.17 This is problematic since multimodal strategies, which appear most successful in reducing apathy, are resource intensive.18

Socially assistive robots (SARs) show promise in addressing physical, cognitive, and/or social needs of older adults.19,20 In the past 10 years, a number of SAR approaches have emerged, for example, as pet companions,21 as mobility aids or navigational guides,22 and one-on-one human-robot interaction (HRI.)23 Early studies used a ‘Wizard of Oz’ experimental paradigm: a human operator controls the robot, analogous to a puppeteer. Thus, it is not the robot interacting with the individual.24 Open-loop platforms have been developed in which the robot has pre-programmed interactions. In these platforms, the robot does not process the individual’s actions or behaviors; the HRI is unidirectional and the robot’s behaviors do not adapt during the HRI.24,25 More advanced closed-loop robotic systems allow the robot to dynamically alter its interaction based on real-time human interaction. Commercially available robots, such as NAO, RoboPhilo, and Manoi-PF01, have been programmed to instruct older adults and correct their gestures during physical exercise routines.26–30 Others have experimented with closed loop platforms to engage older adults in eating,31,32 cognitive stimulation,32–34 and chair exercises.35 The majority of these SAR systems have focused on a) one type of activity and b) one individual and the human-robot interaction.

Our team of engineers, nurses and physicians designed a novel SAR architecture, ARIA (Adaptive Robot-mediated Intervention Architecture), utilizing input from key stakeholders.36–40 ARIA uses a humanoid robot to engage pairs of older adults simultaneously with cognitive impairment in multimodal activities (physical, cognitive and social) with and without virtual environments. As part of an engineering field study39 of ARIA in LTC settings, we conducted an observational study to examine a) whether our lab-tested SAR fostered human-human interaction (HHI) via robot mediation and b) whether the type of activity influenced human-human interaction (HHI) and/or human-robot interaction (HRI) among paired older adults residing in LTC settings.

METHODS

Design

A one-group observational study was conducted incorporating 6 sessions over three weeks. The study was reviewed and approved by the Vanderbilt University Institutional Review Board.

Settings and Participants

The study took place at two LTC settings in the greater Nashville area. One setting consisted of independent living and assisted living apartments; the other provided independent to long-term care living arrangements. Eligibility criteria included 70 years or older, able to hear and see with corrective aids, able to move arms, and able to cognitively participate in the various robot activities. Older adults were randomly assigned to pairs using a random number generator; participants were asked to maintain the same partner throughout the study.

Equipment and Set Up

We used a humanoid robot NAO (SoftBank Robotics), a widely used programmable robot in education and research. It is 22.8 inches tall with a variety of sensors ranging from tactile to audio microphone arrays for interaction with humans. NAO was set on a table to the side of a 32-inch computer monitor. A Kinect system was placed on the edge of the table. An E4 wristband to monitor physiological responses was placed on the participants’ non-dominant wrists. Two participants sat approximately 6 feet from the table. One of the authors (JF) operated the computer system in an area visually separated from the participants. A second researcher was on-site to assist in monitoring the participants’ reactions, such as anxiety, and intervene as necessary. At Site 1, we used a vacant apartment; participants were in the living room and JF was in the bedroom. At Site 2, we used a section of the facility’s library with a screen divider behind which JF operated the system (See Figure 1 photos).

SAR Activities and Procedures

We developed activities using Cohen-Mansfield’s framework of engagement, which postulates multimodal activities that encourage human-to-human interaction are most successful in engaging older adults.41Thus, each activity had a physical, cognitive and social component. Table 1 displays the activities and corresponding sessions. Details of the activity development and testing are available elsewhere.36–40,42

Activities.

In the Simon Says activity, the robot acted as a co-player with the two older adults. The robot started the session and then would ask each older adult to take the lead as ‘Simon’. The two other activities used the virtual reality (VR) environment with books and bins of different colors; the robot acted as a coach in these activities. In the VR environment, each older adult had a hand cursor colored green or red to correspond with the books. The objective was to gather the books and place them into the correct bin. The Book Sorting Level 1 activity consisted of older adults taking turns to gather a book and place it in the correct bin. The Book Sorting Level 2 activity allowed the older adults to collect their books simultaneously. In the last part of the Book Sorting Level 2 activity, yellow books were added but without instruction that in order to move the yellow books, participants needed to move those books together. Our intent was to determine if the older adults would discuss how to move those books. The robot would provide hints partway through the session if they had not moved any yellow books.

For each activity, we designed the robot to encourage the older adults and when necessary to provide additional instructions. The robot had a number of gestures, such as clapping, raising arms, waving, and gazing at older adults, in order to facilitate human-human interaction (HHI) and human-robot interaction (HRI). Additionally, we programmed the robot to provide encouragement through verbalizations, such as “good job”, and HHI by using the participants’ names and asking one to help the other or encouraging them to collaborate.

Procedures.

Each pair participated in the activities in the same order over a three-week period (Table 1). All older adults participated in an orientation and training session before the start of the experiment. Two sessions a week were conducted for a total of 6 sessions. Before each session, the robot would greet each individual by name followed by a brief introduction and re-orientation to that session’s activity. Once the re-orientation was completed, the researchers removed themselves from the participants’ sight and started the robotic interaction. Robotic interactions lasted 9 minutes for Simon Says and Book Sorting Level 1; the robotic interaction lasted 12 minutes for the Book Sorting Level 2. Time for each full session ranged from 25 to 30 minutes. All sessions were video recorded and downloaded into Noldus Observer XT software for coding and analyses.

Variables and Measurements

Coding Scheme

We developed a behavioral codebook and manual adapted from Cohen-Mansfield’s framework41 and Jones et al. Video Coding Protocol – Incorporating Emotion (VC-IOE)43 scheme for coding the older adults’ behaviors during the robotic sessions. We pilot tested the instrument with one video and made refinements.

Subsequently, we met with Noldus Observer XT (Version 14.0) trainers to convert the paper coding scheme to an electronic one. The Noldus Observer XT software is designed specifically for coding behavior directly from the video that integrates various data modalities, allows visualization of patterns, and analyzes the results. Two of the authors (YL and LM) underwent 2 hours of intensive training on using the Noldus software to apply the codes to the various behaviors and made final revisions to the coding manual. Table 2 provides the behaviors associated with each category. Behaviors were coded as either state events (duration of time) or as point events (a frequency count that the event had occurred). For all variable behaviors, a code of ‘undetermined’ was included.

A single trained rater coded all videos (YL). Weekly discussions were held with a gerontological nurse expert (LM) to a) view portions of videos together and b) review coding for accuracy. Disagreement with code assignments were discussed and interpretation of behaviors refined. The expert oversight occurred throughout the video coding to minimize single-rater drift. Intra-rater reliability was measured using the Noldus software. Six months after the initial coding, 4 (10%) videos were subsequently recoded by the same researcher; each activity type was included. We used a conservative approach for evaluating the intra-rater reliability by examining the full video with all events, state and point. We set a tolerance window of three seconds to indicate agreement. Intra-rater agreement for all video events ranged from 73% to 79%. Kappa coefficients ranged from 0.72 to 0.78 with an average kappa coefficient of 0.74, indicating substantial agreement.44

Participant Characteristics

Participant Characteristics included gender, age, and the Montreal Cognitive Assessment Scale (MoCA), a well known screening tool for cognitive impairment.45 We used cut-off scores to classify the individual as possible mild cognitive impairment (19 – 25) or dementia (&lt;19).46 Dementia was also indicated if the individual self-reported a dementia diagnosis.

Observed Engagement Indices

The Noldus software was used to measure the frequency and/or duration of several observed engagement indices for each activity, outlined in Table 2. Measurements included emotional, behavioral, verbal and visual engagement indices.

Overall Session Engagement Measures

Cohen-Mansfield’s Observational Measurement of Engagement tool was used to classify the individual’s overall engagement behaviors for each session using Likert scales.41 At the end of each activity session, the observer rated the participant on duration of attendance in the activity (0- none to 6-all the time) and three domains of ‘engagement’: a) attentiveness (0-none to 5-most of the time), b) active participation in the activity (0-not at all to 4-very much), and c) attitude (1-very negative to 7-very positive). One item, boredom or sleep-like behaviors (0-none of the time to 6-all of the time), represents a potentially explanatory variable for lack of engagement. High intercorrelation coefficients (0.65–0.79) are present among the three engagement domains, high inverse correlation between the three engagement domains and boredom (−0.51 to −0.85), and low correlation of attendance duration with all other items (0.10 to 0.19), providing construct validity.41

Data Analysis.

Analyses were conducted using the Noldus software tools and exported to excel files. Descriptive statistics were conducted for all variables, mean and standard deviation for continuous (state) variables and frequency for the categorical (point) variables. To address variation in session lengths, we standardized the engagement variables as mean duration/episode (for continuous state variables) or as mean episodes/minute (for categorical variables point variables). Given the small sample size (7 pairs), inferential statistics were not conducted.

RESULTS

Participant profile

Fifteen older adults were recruited. One dropped out early because of inability to hear the robot, even when wearing a hearing aid. This person’s partner was paired with another individual and restarted the series of sessions with the new partner. Adults ranged in age from 70 to 90 years with a mean age of 83.0 (± 6.1). Most were women (79%). Based on MoCA cut-off scores, 3 adults were considered as having normal cognition, 10 had mild cognitive impairment, and 1 adult self-reported a diagnosis of Alzheimer’s disease. Two videos were damaged, leaving a total of 40 video episodes to analyze.

Emotional and Behavioral Engagement

The mean duration/episode and number of episodes by activity type for emotional engagement indices revealed that participants were primarily in a neutral emotional state (Table 3). Participants displayed a greater number and duration of pleasure episodes in the Simon Says activity as compared to the book sorting activities. Frustration occurred on occasion for all three types of activities and lasted a minute or less for each event. Boredom occurred only 11 times; almost half the episodes were with Simon Says and lasted longer (2.7 minutes versus 1.0 and 0.3 minutes) compared to the two book sorting activities.

Partners showed more helping behaviors with the Book Sorting Level 2 activity (n = 35 episodes) than Book Sorting Level 1 (n = 17) and Simon Says (n = 9). Duration of help per episode was similar across activities. Participants were physically engaged in the tasks with 185 episodes for Book Sorting Level 1, 167 episodes for Book Sorting Level 2, and 367 episodes for the Simon Says activity. (Table 3)

Verbal Engagement

The frequency of talking to one’s partner or to the robot were standardized as number of speaking episodes/minute and examined by type of activity. The amount of talking to the other person was lower for the Simon Says activity (median 0.33 episodes/minute; interquartile range (IQR): 0.20–0.59) as compared to the Book Sorting Level 1 (median 0.82 episodes/minute; IQR:0.43–1.8) and Book Sorting Level 2 (median episodes/minute 0.89 episodes/minute; IQR: 0.38–1.70). The amount of talking to the robot was higher for the Simon Says activity (median 1.63 episodes/minute; IQR: 1.40–1.64) as compared to the Book Sorting Level 1 activity (median 0.12 episodes/minute; IQR: 0.10–0.25) and Book Sorting Level 2 activity (median 0.09 episodes/minute; IQR: 0.08–0.19).

Visual Engagement

The percentage of time the participants looked at the robot, at their partner, or other direction was examined by activity. For all three activities, more than 90% of the time was spent gazing in the direction of the robot: 93% for the Simon Says activity time, 96% for the Book Sorting Level 2 activity time, and 99% for the Book Sorting Level 1 activity time.

Overall Session Engagement Measures

The proportion of sessions rated at the two highest Likert-ratings for each engagement measure were: attentive (94%), attended (90%), participation (95%), and absence of boredom (96%). Attitude was more varied with positive attitude apparent among 69%, 25% appeared neutral and 6% had a negative attitude. Further examination of attitude revealed the following distribution by activity type: Simon Says 71% positive, 25% neutral and 4% negative; Book Sorting Level 1 activity 63% positive, 26% neutral and 11% negative; and Book Sorting Level 2 activity 64% positive, 32% neutral and 4% negative.

DISCUSSION

Older adults often present with apathy that requires multimodal strategies comprised of social, physical, and cognitive activities. Our team designed a novel socially assistive robot (SAR) architecture using a commercially available humanoid robot to engage pairs of older adults in activities with or without virtual environment. In this study we measured engagement during the sessions as a reflection of both human-human interaction (HHI) and human-robot interaction (HRI) through verbal, visual, behavioral and emotional measures, among paired older adults participating in three types of SAR activities over a three-week period. We found that the SAR activities had positive impact on engagement overall but that the type of activity influenced the results by type of engagement as well as type of engagement interaction, HRI versus HHI. For instance, visual engagement towards one’s partner was much shorter in the two book sorting activities as compared to the Simon Says activities; on the other hand, verbal engagement between the participants was greater with the book sorting activities.

These findings deserve comment. First is the need for a priori selection of engagement measures based on the desired engagement, HHI and/or HRI, when developing SAR activities. Others have reported on the necessity to include a variety of engagement measures (e.g., observational, physiological) for individual-based and group-based activities in LTC settings.41,47–50 We found that the emotional and behavioral engagement measures demonstrated variability with the type of activity, but we were unable to determine whether these measures varied by HHI or HRI. Second is the importance of the activity characteristics to facilitate engagement, including the meaning of the activity and whether the activity consists of multiple domains.11,13,14 Most humanoid SARs have been designed to focus on one individual and one activity, such as eating or playing cards, for limited sessions.25,27,32,51 More recently, SARs have been developed to provide a variety of activities. The MARIO project has been a multi-disciplinary and multi-country endeavor to develop and test a social robot for HRI among individual older adults in long term care, residential and home settings.52,53 MARIO provides several apps that allow the older adults to engage in reminiscing, music, news, and games and was tested for 12 sessions over 4 weeks. Similar to results from the MARIO field test, our participants’ engagement remained high throughout the three-week period.

Last, we designed the activities with and without virtual reality (VR) that also influenced findings. The VR book sorting activities were more complicated, both physically and cognitively. We found that the Simon Says (non-VR) activity had a greater frequency of activity behaviors but the duration of engagement was greater in the two VR Book Sorting activities. There were also more behaviors of helping one another in the Book Sorting activities, reflecting the purposeful design. On the other hand, at times, helping behaviors were followed by an expression of frustration.

There are several limitations to our study. First, the study participants were volunteers and not examined for apathy, our long term target. This selection bias should also be taken into consideration when interpreting independent variables, such as attendance, attentiveness and sleepiness. Second, the pairs remained the same throughout the three weeks; familiarity with one another may have impacted the engagement level over time. Third, one participant opted out due to a physical limitation and two video tapes were unusable; the smaller sample size might affect not only our findings but also generalizability. The activities themselves may have lacked the ability to trigger interest for some participants. Therefore, more research needs to be done on designing participant-centered activities. With the advancement of SAR-ARIA, a greater array of activities can be designed to facilitate engagement among older adults with varying cognitive and physical capabilities. Future research should also examine ways that SAR-ARIA can foster care and outcomes for those with other behavioral conditions, such as anxiety or agitation. Finally, further study is needed to investigate the cost-effectiveness of the socially robotic activities, considering the costs of saving staff time in the delivery of multimodal activities versus the costs of the design, deployment and sustainability of this technology into LTC settings.

In conclusion, SAR-mediated activities can encourage human-human interaction as well as human-robot interaction with the long- term goal of fostering engagement among older adults with apathy. The results shown in our study clearly demonstrate positive impact on various engagement measures among older adults utilizing SAR-ARIA. Ultimately, SAR-ARIA may help to implement activities targeting visual, verbal, emotional and behavioral engagement to complement LTC staff time.

Research reported in this publication was supported by the National Institute on Aging of the National Institutes of Health under award number R21AG050483.

Figure 1. Participants at two sites interacting with robot on Book Sorting activity (top) and with Simon Says activity (bottom).

Table 1. Socially Assistive Robotic Activities and Sessions

Session Number	Activity Name	Activity Description	
1	Simon Says	Robot participates as a co-player with 2 adults for 4 rounds of play, each taking turns as “Simon”. Robot could perform/copy arm raising, waving and extending arms to side.	
2 - VR*	Book Sorting Level 1 “Take Turns”	Robot is a coach. 2 adults interact with the system. Only one adult can move the books in the Virtual Reality at a time, but other adult can verbally help the partner.	
3 - VR	Book Sorting Level 2 “Simultaneous”	Robot is coach. 2 adults interact with the system at same time. Each adult has color-coded (red and green) hand cursor to move assigned color books to assigned color bin. Extra points allotted if they help one another move books closer to the color-designated bins. Yellow books added, but adults not told that to move yellow, both had to move it together. Robot would provide hints half-way through.	
4	Simon Says	Repeat Session 1.	
5 - VR	Book Sorting Level 1 “Take Turns”	Repeat Session 2.	
6 - VR	Book Sorting Level 2 “Simultaneous”	Same as Session 3.	
* VR = virtual reality

Table 2. Coding Scheme for Engagement Behaviors

Emotional Engagement (State Event)	
Pleasure	Smiling, laughing, singing, responding to robot activity, nodding, clapping.	
Frustration/anger	Drawing eyebrows together, clenched teeth, pursed lips, narrowing eyes.	
Anxiety/fear	Voice shaking, repetitive calling out, lines across forehead, tight facial muscles.	
Sadness	Crying, sighing, moaning, frowning, eyes/head turned down.	
Apathy/boredom	Staring away, yawning, sighs, slumped position, head held down, drooping shoulders.	
Neutral	Relaxed, no sign of facial expression.	
Missing emotion	Cannot see emotional response properly.	
Verbal Engagement (Point Event)	
Talk to person	Participating and maintaining conversation with partner or facilitator.
Modifiers include positive, negative, neutral of undetermined.	
Talk to robot	Answering robot’s questions and maintaining conversation with robot.	
Talk to self	Talking to self (e.g., murmuring).	
Target undetermined.	No audio or distorted audio/video.	
Visual Engagement (State Event) Participant is gazing at:	
Monitor screen	Appears alert and maintaining visual engagement to screen/robot.	
Human partner	Appears alert and maintaining eye contact with partner.	
Another person	Appears alert and gazing at facilitator.	
Gaze down	Does not appear alert and gazing downwards.	
Target undetermined	Distorted video; undetermined target.	
Behavioral Engagement (State Event)	
On task	Attempting to participate in the activities; actively participating. Modifiers include correct or incorrect.	
Off task	Not attempting to participate in the activities or displaying no movement or being prepared for the next task.	
Helping other	Participants helping each other with verbal engagement and/or visual engagement. Content related to the activities.	
Undetermined	Distorted audio/video or undetermined behavior (e.g., playing with fingers which is not related to the activities).	
Robot Behaviors (Point Event)	
Greeting	Robot says ‘hi’/‘hello’ to participant.	
General question	Example: Robot asks if participants have met a robot.	
Cheering	Robot cheers for good results or teamwork.	
Task demand	Robot directly requests participants to do an activity; e.g., robot asks participants to raise hands or say hello to other participant.	
Intervention	Robot intervenes in the activities. Provides feedback and guidance.	
Instruction	Robot explains how the activity works or provides tips.	
Incorrect response	Robot did not receive signal from participants and provides an incorrect response.	
Researcher Rating of Engagement Measures for Each Session (Likert Scales)	
Attendance	Level of attendance for the participant for the specific group activity (0-none to 6-all the time).	
Attentiveness	How much of the group activity was the participant attentive (0-none to 5-most of the time).	
Participation	The extent to which the participant actively participated (0-not at all to 4-very much).	
Attitude	Attitude towards the activity (1-very negative to 7-very positive).	
Asleep	Sleep like symptoms; boredom (0-none of the time to 6-all of the time).	
State events = continuous variables. Point events = frequency.

Table 3. Emotional and Behavioral Engagement Indices of Paired Older Adults Participating in Three Types of Robotic Activities (N = 7 pairs)

Variable	Book Sorting Level 1	Book Sorting Level 2	Simon Says	
	Mean Duration/Episode†	Mean Duration/Episode	Mean Duration/Episode	
Emotional Engagement	
Neutral	4.9 min (50 episodes)	4.6 min (40 episodes)	2.9 min (43 episodes)	
Pleasure	1.2 min (24 episodes)	1.7 min (19 episodes)	2.7 min (37 episodes)	
Frustration	1.0 min (30 episodes)	0.8 min (17 episodes)	1.0 min (30 episodes)	
Boredom	1.0 min (5 episodes)	0.3 min (1 episode)	2.7 min (5 episodes)	
Behavioral Engagement	
Helping partner	0.6 min (17 episodes)	0.4 min (35 episodes)	0.8 min (9 episodes)	
On task*	1.1 (185 episodes)	0.4 (167 episodes)	0.1 (367 episodes)	
* On task refers to the person actively involved in the activity.

† Mean duration/episode = total sum minutes and seconds/number of observed episodes.

Highlights

Socially assistive robots (SAR) can deliver activities to older adults in long term care.

Older adults had high human-human interactions and human-robot interactions.

The type of SAR activity influenced the type of interaction.

Engagement measures (visual, verbal, behavioral) also varied by activity type.

This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and review of the resulting proof before it is published in its final form. Please note that during the production process errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.


References

1. Volicer L Behavioral Problems and Dementia. Clin Geriatr Med. 2018;34 (4 ):637–651.30336992
2. Tierney SM , Woods SP , Weinborn M , Bucks RS . Real-world implications of apathy among older adults: Independent associations with activities of daily living and quality of life. Journal of clinical and experimental neuropsychology. 2018;40 (9 ):895–903.29532707
3. Nijsten JMH , Leontjevas R , Smalbrugge M , Koopmans R , Gerritsen DL . Apathy and health-related quality of life in nursing home residents. Qual Life Res. 2019;28 (3 ):751–759.30406574
4. Lanctot KL , Aguera-Ortiz L , Brodaty H , Apathy associated with neurocognitive disorders: Recent progress and future directions. Alzheimer’s &amp; Dementia 2017; 13 (1 ):84–100.
5. Caga J , Hsieh S , Highton-Williamson E , The burden of apathy for caregivers of patients with amyotrophic lateral sclerosis. Amyotrophic Lateral Sclerosis &amp; Frontotemporal Degeneration. 2018:1–7.
6. Kolanowski A , Boltz M , Galik E , Determinants of behavioral and psychological symptoms of dementia: A scoping review of the evidence. Nursing Outlook. 2017;65 (5 ):515–529.28826872
7. Terum TM , Andersen JR , Rongve A , Aarsland D , Svendsboe EJ , Testad I . The relationship of specific items on the Neuropsychiatric Inventory to caregiver burden in dementia: a systematic review. Int J Geriatr Psychiatry. 2017;32 (7 ):703–717.28317166
8. Brodaty H , Burns K . Nonpharmacological Management of Apathy in Dementia: A Systematic Review. The American Journal of Geriatric Psychiatry. 2012;20 (7 ):549–564.21860324
9. Cohen-Mansfield J The impact of group activities and their content on persons with dementia attending them. Alzheimer’s Research &amp; Therapy. 2018;10 (1 ):37.
10. Ellis JM , Doyle CJ , Selvarajah S . The relationship between apathy and participation in therapeutic activities in nursing home residents with dementia: Evidence for an association and directions for further research. Dementia. 2016;15 (4 ):494–509.24670286
11. Kolanowski A , Buettner L . Prescribing activities that engage passive residents. An innovative method. J Gerontol Nurs. 2008;34 (1 ):13–18.18274300
12. Centers for Medicare &amp; Medicaid Services, DHHS § 483.15 (f) Activities. CMS Manual System. Vol Pub. 100–07. Washington, DC.
13. Mansbach WE , Mace RA , Clark KM , Firth IM . Meaningful Activity for Long-Term Care Residents With Dementia: A Comparison of Activities and Raters. The Gerontologist. 2017;57 (3 ):461–468.26884063
14. Tak SH , Kedia S , Tongumpun TM , Hong SH . Activity Engagement: Perspectives from Nursing Home Residents with Dementia. Educ Gerontol. 2015;41 (3 ):182–192.25489122
15. Harmer BJ , Orrell M . What is meaningful activity for people with dementia living in care homes? A comparison of the views of older people with dementia, staff and family carers. Aging &amp; Mental Health. 2008;12 (5 ):548–558.18855170
16. Cohen-Mansfield J Activity groups for persons with dementia: Personal predictors of participation, engagement and mood. Psychiatry Research. 2017;257 :375–380.28806713
17. Long Term Care Coalition. Nursing Home Staffing 2018 Q4. https://nursinghome411.org/nursing-home-staffing-2018-q4/. Published 2019. Accessed May 15, 2021.
18. Cohen-Mansfield J , Marx MS , Dakheel-Ali M , Thein K . The use and utility of specific nonpharmacological interventions for behavioral symptoms in dementia: an exploratory study. The American Journal of Geriatric Psychiatry. 2015;23 (2 ):160–170.25081819
19. Pruchno R . Technology and Aging: An Evolving Partnership. The Gerontologist. 2019;59 (1 ):1–5.30629258
20. Abdi J , Al-Hindawi A , Ng T , Vizcaychipi MP . Scoping review on the use of socially assistive robot technology in elderly care. BMJ Open. 2018;8 (2 ):e018815.
21. Leng M , Liu P , Zhang P , Pet robot intervention for people with dementia: A systematic review and meta-analysis of randomized controlled trials. Psychiatry Research. 2019;271 :516–525.30553098
22. Wandosell JMH , Graf B . Non-holonomic navigation system of a walking-aid robot. Paper presented at: Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication; 27–27 Sept. 2002.
23. Broadbent E Interactions With Robots: The Truths We Reveal About Ourselves. Annual Review of Psychology. 2017;68 :627–652.
24. Riek LD . Wizard of Oz studies in HRI: a systematic review and new reporting guidelines. J Hum-Robot Interact. 2012;1 (1 ):119–136.
25. Matsusaka Y , Fujii H , Okano T , Hara I . Health exercise demonstration robot TAIZO and effects of using voice command in robot-human collaborative demonstration. RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication; 2009. doi: 10.1109/ROMAN.2009.5326042
26. Diehl JJ , Schmitt LM , Villano M , Crowell CR . The Clinical Use of Robots for Individuals with Autism Spectrum Disorders: A Critical Review. Research in Autism Spectrum Disorders. 2012;6 (1 ):249–262.22125579
27. Görer B , Salah AA , Akın HL (2013) A Robotic Fitness Coach for the Elderly. In: Augusto JC , Wichert R , Collier R , Keyson D , Salah AA , Tan AH (eds) Ambient Intelligence. AmI 2013. Lecture Notes in Computer Science, vol 8309 . Springer, Cham. 10.1007/978-3-319-03647-2_9
28. Simonov M , Delconte G . Humanoid assessing rehabilitative exercises. Methods of Information in Medicine. 2015;54 (2 ):114–121.24986076
29. Gadde P , Kharrazi H , Patel H , MacDorman KF . Toward Monitoring and Increasing Exercise Adherence in Older Adults by Robotic Intervention: A Proof of Concept Study. Journal of Robotics. 2011;2011 :11.
30. Yoshino K , Kouda M , Zhang S . Correct Motion Advice on Rehabilitation Instruction Robot by Superimposing Instructor CG Model. Paper presented at: 2012 Fifth International Conference on Intelligent Networks and Intelligent Systems; 1–3 Nov. 2012, 2012.
31. McColl D , Louie WG , Nejat G . Brian 2.1: A socially assistive robot for the elderly and cognitively impaired. IEEE Robotics &amp; Automation Magazine. 2013; 20 (1 ):74–83.
32. McColl D , Nejat G . Meal-time with a socially assistive robot and older adults at a long-term care facility. J Hum-Robot Interact. 2013; 2 (1 ):152–171.
33. Tapus A , Tapus C , Matarić M . Long Term Learning and Online Robot Behavior Adaptation for Individuals with Physical and Cognitive Impairments. Field and Service Robotics. 2010; Berlin, Heidelberg.
34. Louie WG , Vaquero T , Nejat G , Beck JC . An autonomous assistive robot for planning, scheduling and facilitating multi-user activities. Paper presented at: 2014 IEEE International Conference on Robotics and Automation (ICRA); 31 May-7 June 2014, 2014.
35. Fasola J , Matari MJ . A socially assistive robot exercise coach for the elderly. J Hum-Robot Interact. 2013;2 (2 ):3–32.
36. Fan J , Beuscher L , Newhouse PA , Mion LC , Sarkar N . A robotic coach architecture for multi-user human-robot interaction (RAMU) with the elderly and cognitively impaired. 2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), 2016, pp. 445–450, doi: 10.1109/ROMAN.2016.7745157.
37. Fan J , Beuscher L , Newhouse P , Mion LC , Sarkar N . A Collaborative Virtual Game to Support Activity and Social Engagement for Older Adults. In: Antona M , Stephanidis C (eds) Universal Access in Human-Computer Interaction. Methods, Technologies, and Users. UAHCI 2018. Lecture Notes in Computer Science, vol 10907. Springer, Cham. 10.1007/978-3-319-92049-8_14
38. Fan J , Mion LC , Beuscher L , Ullal A , Newhouse PA , Sarkar N . SAR-Connect: A socially assistive robotic system to support activity and social engagement of older adults. IEEE Transactions on Robotics. 2021. doi:1109/TRO.2021.3092162
39. Fan J , Ullal A , Beuscher L , Mion LC , Newhouse P , Sarkar N . Field Testing of Ro-Tri, a Robot-Mediated Triadic Interaction for Older Adults. International Journal of Social Robotics. 2021. 10.1007/s12369-021-00760-2
40. Fan J , Bian D , Zheng Z , A Robotic Coach Architecture for Elder Care (ROCARE) based on multi-user engagement models. IEEE Transactions on Neural Systems and Rehabilitation Engineering 2017. 25 (8 ):1153–1163. doi:10.1109/TNSRE.2016.2608791 28113672
41. Cohen-Mansfield J , Hai T , Comishen M . Group engagement in persons with dementia: The concept and its measurement. Psychiatry Rresearch. 2017;251 :237–243.
42. Beuscher LM , Fan J , Sarkar N , Socially Assistive Robots: Measuring Older Adults’Perceptions. J Gerontol Nurs. 2017;43 (12 ):35–43.
43. Jones C , Sung B , Moyle W . Assessing engagement in people with dementia: a new approach to assessment using video analysis. Archives of Psychiatric Nursing. 2015;29 (6 ):377–382.26577550
44. McHugh ML . Interrater reliability: the kappa statistic. Biochem Med (Zagreb). 2012;22 (3 ):276–282.23092060
45. Nasreddine ZS , Phillips NA , Bédirian V , The Montreal Cognitive Assessment, MoCA: a brief screening tool for mild cognitive impairment. J Am Geriatr Soc. 2005;53 (4 ):695–699.15817019
46. Milani SA , Marsiske M , Cottler LB , Chen X , Striley CW . Optimal cutoffs for the Montreal Cognitive Assessment vary by race and ethnicity. Alzheimers Dement (Amst). 2018;10 :773–781.30505927
47. Cohen-Mansfield J , Dakheel-Ali M , Marx MS . Engagement in persons with dementia: the concept and its measurement. American Journal of Geriatric Psychiatry. 2009;17 (4 ):299–307.
48. Heerink M , Krose B , Evers V , Wielinga B , Ieee . Measuring acceptance of an assistive social robot: a suggested toolkit. RO-MAN 2009 -- The 18th IEEE International Symposium on Robot and Human Interactive Communication, Vols 1 and 2; 2009, pp. 528–533. doi:1109/ROMAN.2009.5326320.
49. Jones C , Sung B , Moyle W . Engagement of a Person with Dementia Scale: Establishing content validity and psychometric properties. J Adv Nurs. 2018. 74 :2227–2240. doi.10.1111/jan.13717
50. Joosse M , Lohse M , Evers V , Sardar A . BEHAVE-II: The Revised Set of Measures to Assess Users’ Attitudinal and Behavioral Responses to a Social Robot. Int J Soc Rob International Journal of Social Robotics. 2013;5 (3 ):379–388.
51. Gerling K , Hebesberger D , Dondrup C , Kortner T , Hanheide M . Robot deployment in long-term care : Case study on using a mobile robot to support physiotherapy. Zeitschrift fur Gerontologie und Geriatrie. 2016;49 (4 ):288–297.27259706
52. Casey D , Barrett E , Kovacic T , The Perceptions of People with Dementia and Key Stakeholders Regarding the Use and Impact of the Social Robot MARIO. International Journal of Environmental Research and Public Health. 2020;17 (22 ).
53. Barrett E , Burke M , Whelan S , Evaluation of a Companion Robot for Individuals With Dementia: Quantitative Findings of the MARIO Project in an Irish Residential Care Setting. J Gerontol Nurs. 2019;45 (7 ):36–45.31237660
