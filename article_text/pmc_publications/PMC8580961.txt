LICENSE: This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.


0012737
4157
IEEE Trans Biomed Eng
IEEE Trans Biomed Eng
IEEE transactions on bio-medical engineering
0018-9294
1558-2531

33819146
8580961
10.1109/TBME.2021.3070875
NIHMS1749631
Article
Improved Prediction of Cognitive Outcomes via Globally Aligned Imaging Biomarker Enrichments Over Progressions
Lu Lyujian Department of Computer Science, Colorado School of Mines, Golden, CO 80401, USA

Elbeleidy Saad Department of Computer Science, Colorado School of Mines, Golden, CO 80401, USA

Baker Lauren Department of Computer Science, Colorado School of Mines, Golden, CO 80401, USA

Wang Hua Department of Computer Science, Colorado School of Mines, Golden, CO 80401, USA

Shen Li Department of Biostatistics, Epidemiology and Informatics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA 19104, USA

Heng Huang Department of Biomedical Informatics and Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA 15261, USA

ADNI
Corresponding author: Hua Wang. huawangcs@gmail.com
29 10 2021
19 10 2021
11 2021
01 11 2022
68 11 33363346
This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
Objective:

Longitudinal neuroimaging data have been widely used to predict clinical scores for automatic diagnosis of Alzheimer’s Disease (AD) in recent years. However, incomplete temporal neuroimaging records of the patients pose a major challenge to use these data for accurately diagnosing AD. In this paper, we propose a novel method to learn an enriched representation for imaging biomarkers, which simultaneously captures the information conveyed by both the baseline neuroimaging records of all the participants in a studied cohort and the progressive variations of the available follow-up records of every individual participant.

Methods:

Taking into account that different participants usually take different numbers of medical records at different time points, we develop a robust learning objective that minimizes the summations of a number of not-squared ℓ2-norm distances, which, though, is difficult to efficiently solve in general. Thus we derive a new efficient iterative algorithm with rigorously proved convergence.

Results:

We have conducted extensive experiments using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset. Clear performance gains have been achieved when we predict different cognitive scores using the enriched biomarker representations learned by our new method. We further observe that the top selected biomarkers by our proposed method are in perfect accordance with the known knowledge in existing clinical AD studies.

Conclusion:

All these promising experimental results have demonstrated the effectiveness of our new method.

Significance:

We anticipate that our new method is of interest to biomedical engineering communities beyond AD research and have open-sourced the code of our method online.1

Alzheimer’s Disease
Longitudinal Study
Representation Enrichment
Imaging Biomarker

pmcI. Introduction

ALZHEIMER’S Disease (AD), the most common form of dementia, is characterized by progressive impairment of cognitive and memory functions. A recent research [1] reports that AD is the sixth-leading cause of death in the United States of America, rising significantly every year in terms of the proportion of cause of death. It is also reported that there are 40-50 million AD suffers worldwide, and 1 in 85 people will be affected by AD by 2050 [2]. As a result, an effective presymptomatic diagnosis and treatment of AD would have enormous public health benefits.

Over the past decade, neuroimaging measures have been widely studied to predict disease status of AD and/or cognitive performance. However, there exist several critical limitations in existing predictive models, because many of them routinely perform learning at every time point separately, ignoring the longitudinal variations characterized by the temporal brain phenotypes. First, since AD is a progressive neurodegenerative disorder, multiple consecutive neuroimaging records are usually required to monitor the disease progressions. It is apparently beneficial to explore the temporal relations among the longitudinal measurements of the biomarkers for AD studies. Second, the records of neuroimaging biomarkers are often missing at some time points for some participants during the period when AD develops, because it is difficult to conduct medical scans consistently across a large group of participants. This is because higher mortality risk and cognitive impairment hinder older adults from staying in the studies that require multiple visits, which thereby results in incomplete data.

To overcome the first limitation, many studies [3]–[6] explored the temporal data structures of brain phenotypes over time. However, these models often formulate the longitudinal data as a tensor, which inevitably complicates the prediction problem in mathematics. To address the second limitation of data inconsistency, most longitudinal models for AD studies [5]–[7] only make use of the samples with complete temporal records and ignore the samples with fewer time points, which, however, may potentially neglects substantially valuable information in the data. To solve this problem, data imputation methods [8], [9] were developed to generate missing records over AD progressions. Then the completed data are used for temporal regression analyses. However, missing data imputation methods may introduce undesirable artifacts, which in turn can worsen the predictive power of the longitudinal models.

To fully exploit longitudinal data with incomplete temporal records, in this paper we propose a novel method to learn an enriched biomarker representation to integrate the baseline records of the neuroimaging biomarkers of all the participants in a studied cohort and the dynamic records of each individual taken across the follow-up time points. Instead of solving the missing data problem using imputation, we tackle this challenging problem from a brand new perspective by learning a set of fixed-length vector representations of the imaging biomarkers from varied number of brain scans of the participants over time, which is schematically illustrated in Fig. 1. First, our model learns a global projection from the baseline records of the biomarkers of all the participants to preserve as much information of a studied cohort as possible. Second, we learn a local projection from the available follow-up medical records of every participant in the later couple of years to maintain the local data structures. Finally, a soft constraint is used to ensure that the global and local projections are well aligned. Using the learned projections, we can transform the medical records with inconsistent sizes in a neuroimaging dataset into a set of fixed-length vectors, which can be readily used by conventional machine learning models to predict cognitive outcomes for automatic diagnosis of AD.

We have conducted extensive experiments on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset [10]. We compare the predictive power of the baseline biomarker measurements against the enriched biomarker representations learned by our new method, using four different broadly used prediction models in statistical learning, including Ridge Regression (RR), Lasso regression (Lasso), Support Vector Regression (SVR) and Convolutional Neural Network (CNN). In our experiments, we have achieved clear performance gains when we predict ten cognitive scores by using both Voxel-Based Morphometry (VBM) biomarkers [11] and FreeSurfer biomarkers [12] as inputs. In addition, top 10 weighted biomarker features are selected through the project matrix learned by our proposed formulation, which are highly suggestive and nicely agree with the existing clinical research findings.

This paper is an extension of our recent work [13] originally reported in the Proceedings of the Twenty-Second International Conference on Medical Image Computing and Computing Assisted Intervention (MICCAI 2019). In this extended journal manuscript, we provide the following expansions over its conference version: We present a complete optimization framework of the smoothed iterative reweighted method, by which our proposed objective can be efficiently solved with theoretically guaranteed convergence (Section II-B.1).

We provide the mathematical details to derive the algorithm to solve our objective (Section II-B.2).

Experimental evaluations have been significantly expanded for demonstrating the benefits of using the enriched biomarker representations learned by our new method (Section III). We report new experimental results by using 1 additional type of neuroimaging markers (the FreeSurfer biomarkers) as input and 9 additional cognitive scores as output predictive targets (Section III).

We compare our proposed method against two different longitudinal feature based methods in the tasks of predicting cognitive scores, where we experiment with both VBM and FreeSurfer biomarkers (Section III-B).

We provide a thorough analysis of the identified disease relevant biomarkers to justify the correctness of our new method from the clinical perspective, which is new in this extended journal manuscript (Section III-C).

II. Method

As the participants in a studied cohort usually take different numbers of brain scans at different time points, different participant has to be represented by different number of vectors. Specifically, we denote the observed imaging measurements of a participant as: Xi={xi,Xi} , where i = 1, 2, ⋯ , n is the index of the participant in a longitudinal dataset. In every Xi,xi∈ℜd denotes the imaging measurements of the i-th participant at the baseline time point, where d counts the number of the imaging biomarkers; and Xi=[x1i,…,xnii]∈ℜd×ni collects all available follow-up imaging records of the same participant after the baseline time point, where ni denotes the number of available follow-up imaging records. Here we emphasize that ni varies with respect to i in a given dataset due to the presence of missing medical records. As a result, one cannot directly use traditional machine learning models, such as RR, Lasso, SVR, CNN, etc., to perform data analyses, because these models can only work with the datasets in which every subject sample is represented by one single fixed-length vector. To tackle this difficulty, our goal for biomarker representation learning is to learn a fixed-length vector for every participant that can integrate the baseline record and all available follow-up records of the participant.

A. Our Objective

First, because the neuroimaging measures usually reside in a high-dimensional space, they can be redundant and noisy [3]–[5], [14], [15]. To address this, we aim to learn a compact representation of these measures via a global projection to keep the most useful information in all the baseline records of a given input dataset. To achieve this, we can use the Principal Component Analysis (PCA) [16] method that learns from the input data a linear projection to preserve as much information as possible in a low-dimensional projected subspace. Mathematically, PCA minimizes the reconstruction error via a projection W∈ℜd×r (usually r &lt;&lt; d) by minimizing the following objective [16]: (1) JGlobal(W)=∑i=1n‖xi−WWTxi‖22,s.t.WTW=I.

Second, because the neuroimaging measurements of every participant usually do not develop drastic change over a short interval, we need maximize the data smoothness in the projected data space for every participant, for which Locality Preserving Projections (LPP) [17] is the right tool to use. Given the pairwise similarity matrix Si∈ℜni×ni of the i-th subject, LPP preserves the local relationships and maximizes the smoothness of the data in the embedding space by minimizing the following objective [17]: (2) JLocal(Wi)=∑xji,xki∈Xisjki‖WiTxji−WiTxki‖22,s.t.WiTWi=I,

where sjki assesses the pairwise affinity between the available records of the i-th participant at the j-th and k-th time points.

Now we integrate the global and local projections learned above by developing a combined objective that minimizes: (3) Jℓ22(W)=∑i=1n‖xi−WWTxi‖22+α∑i=1n∑xji,xki∈Xisjki‖WiTxji−WiTxki‖22+β∑i=1n‖W−Wi‖F2,s.t.WTW=I,WiTWi=I,

where we denote W={W,W1,…,Wn}. Through the third term of Eq. (3), the projections {Wi}i=1n learned from the each individual participant separately are aligned with the projection W learned globally from the baseline measurements of all the participants of the entire dataset. As a result, the information encoded by the global projection W learned from all the participants as a whole can be transferred to the biomarker representations of each individual participant, which we call as “enrichment”. Here we note that our model can also benefit from the subject with less than two longitudinal observations. If the subject has less than two longitudinal observations, the second term α∑xji,xki∈Xisjki‖WiTxji−WiTxki‖22 of our objective in Eq. (3) will become 0. Namely, the enriched the representation of this participant will be learned from the global projection of the entire dataset.

Finally, because the follow-up neuroimaging records of different participants may be taken at different time points, as illustrated in Fig. 1, it can happen that one participant have the imaging scans at the 12th and 24th months, while another participant visits the doctor at the 6th, 12th and 36th months. That is, the follow-up medical records of the participants in a studied cohort are not well aligned in terms of time by nature. Therefore, it is critical to improve our model for better robustness. To this end, we substitute the first two squared ℓ2-norm terms in Eq. (3) by their not-squared counterparts for improved robustness against outliers [18]–[20] as follows: (4) Jℓ2(W)=∑i=1n‖xi−WWTxi‖2+α∑i=1n∑xji,xki∈Xisjki‖WiTxji−WiTxki‖2+β∑i=1n‖W−Wi‖F2,s.t.WTW=I,WiTWi=I.

By solving Eq. (4), we can obtain the fixed-length biomarker representation for every participant computing {yi=WiTxi}i=1n, which can be readily fed into traditional machine learning models for subsequent data analyses.

B. The Solution Algorithm and Its Convergence Analysis

Although the motivations of the proposed objective in Eq. (4) are clearly justified, it is a non-smooth optimization problem. Thus, it is difficult to efficiently solve in general. To tackle this difficulty, in this section we use the algorithm introduced in our earlier work [19] to solve our objective.

1) The Smoothed Iterative Reweighted Method:

First, we introduce a general optimization framework, which solve the following general optimization problem: (5) minxf(x)+∑i||gi(x)||2,

where gi(x) is a vector output function. Apparently, our objective in Eq. (4) is a special case of the problem in Eq. (5).

Because the problem in Eq. (5) is non-smooth, we turn to solve the following smooth problem: (6) minxf(x)+∑igiT(x)gi(x)+δ,

where δ &gt; 0 is a small positive constant. It can be verified that, when δ → 0, Eq. (6) is reduced to Eq. (5). By setting the derivative of Eq. (6) with respect to x to zero, we have: (7) f′(x)+∑​igi(x)giT(x)gi(x)+δ=0.

Denote (8) si=12giT(x)gi(x)+δ,

we can rewrite Eq. (7) as follows: (9) f′(x)+∑​i2sigi(x)=0.

Because si is dependent on x, Eq. (9) is generally difficult to solve. However, if si is given for a specific i, solving Eq. (9) is equivalent to solving the following optimization problem: (10) minf(x)+∑​isigiT(x)gi(x).

With the above observation, we propose an iterative algorithm, as summarized in Algorithm 1, to find the solution of Eq. (7), which is also the optimal solution of the problem in Eq. (6).

Because Algorithm 1 is an iterative algorithm, it is critical to rigorously prove its convergence in mathematics, for which we first prove the following lemma.

Lemma 1: For any vectors x, x˜ with the same size, the following inequality holds: (11) x˜Tx˜+δ−x˜Tx˜2xTx+δ≤xTx+δ−xTx2xTx+δ.

Proof. We begin with an obvious inequality as follows: (12) −(x˜Tx˜+δ−xTx+δ)2≤0,

by which we can derive: (13) −(x˜Tx˜+δ−xTx+δ)2≤0⇒2x˜Tx˜+δxTx+δ−(x˜Tx˜+δ)≤xTx+δ⇒x˜Tx˜+δ−x˜Tx˜+δ2xTx+δ≤xTx+δ2⇒x˜Tx˜+δ−x˜Tx˜+δ2xTx+δ≤xTx+δ−xTx+δ2xTx+δ⇒x˜Tx˜+δ−x˜Tx˜2xTx+δ≤xTx+δ−xTx2xTx+δ,

which completes the proof. □

Equipped with Lemma 1, we can now prove the following theorem that guarantees the convergence of Algorithm 1.

Theorem 1: Algorithm 1 monotonically decreases the objective in Eq. (6) in each iteration.

Proof. In step 2 of Algorithm 1, we denote the updated x as x˜ . According to step 2, we know that: (14) f(x˜)+∑isigiT(x˜)gi(x˜)≤f(x)+∑isigiT(x)gi(x).

According to Eq. (8), we have: (15) f(x˜)+∑igiT(x˜)gi(x˜)2giT(x)gi(x)+δ≤f(x)+∑igiT(x)gi(x)2giT(x)gi(x)+δ.

According to Lemma 1, we have: (16) ∑​igiT(x˜)gi(x˜)+δ−∑​igiT(x˜)gi(x˜)2giT(x)gi(x)+δ≤∑​igiT(x)gi(x)+δ−∑​igiT(x)gi(x)2giT(x)gi(x)+δ.

By summing the above two equations on the both sides, we have: (17) f(x˜)+∑igiT(x˜)gi(x˜)+δ≤f(x)+∑igiT(x)gi(x)+δ,

which completes the proof that Algorithm 1 monotonically decreases the objective of the problem in Eq. (6) in each iteration, until the algorithm converges. □

Here we note that the iterative reweighted method introduced [21], [22] solves the nonsmooth ℓ1-norm or ℓ2,1-norm minimization problems. However, the method described in [21], [22] do not explicitly use the smoothness constant (i.e, σ in Eq. (6)). Without this smoothness term, the algorithm is heavily impacted by the singularity problem due to inverted matrices that divide 0s, which result in inferior performances of the learning models. To improve the numerical stability, we formally add a smoothness term (i.e, σ in Eq. (6)) and theoretically prove the convergence of our algorithm in which the smoothness term leads to much more numerically stable solutions. We call Algorithm 1 as the proposed Smoothed Iterative Reweighted Method, which can be broadly used to solve a variety of difficult machine learning problems that minimize the objectives using ℓ1-norm or ℓ2,1-norm minimization problems.

Using the proposed smoothed iterative reweighted method to solve our objective in Eq. (4), we need solve the optimization problem in Step 2 of Algorithm 1 (i.e., the problem in Eq. (10)) in every iteration, which, in our case, is to minimize the following objective: (18) Jℓ2R(W)=tr(X−WWTX)Γ(X−WWTX)T+α∑​i=1ntr(WiTXiLiXiTWi)+β∑i=1n‖W−Wi‖F2,s.t.WTW=I,WiTWi=I,

where X=[x1,x2,…,xm]∈ℜd×n summarizes the baseline imaging measurements of all the participants, and Γ∈ℜn×n is a diagonal matrix and its i-th element is γi=12‖xi−WWTxi‖22+δ. Defining θjki=12‖WiTxji−WiTxki‖22+δ and S˜i∈ℜni×ni whose element value is s˜jki=θjkisjki, in Eq. (18) we compute Li=Di−S˜i, where Di is a diagonal matrix whose diagonal entries are the column (or row) sums of S˜i, i.e., djj=∑js˜jk.

2) The Algorithm to Minimize the Objective in Eq. (18):

Now we derive the algorithm to solve the problem in Eq. (18) using the Alternating Direction Method of Multipliers (ADMM), which was proposed in [23] to solve convex optimization problems by breaking them into smaller pieces that are easier to handle. Specifically, given the following objective with the equality constraint: (19) minx,zf(x)+g(z),s.t.h(x,z)=0,

Algorithm 2 solves the problem in Eq. (19) by decoupling it into subproblems and optimizing each variable while fixing the others, where y is the Lagrangian multiplier to the constraint function h. It is worth noting that Algorithm 2 has been proved to converge Q-linearly to the optimal solution [23].

Using the ADMM framework in Algorithm 2, we can rewrite our objective in Eq. (18) as follows: (20) Jℓ2ADMM(W,P)=tr(X−WWTX)Γ(X−WWTX)T+α∑i=1ntr(WiTXiLiXiTWi)+β∑i=1n‖P−Pi‖F2+μ2‖W−P+1μΛ‖F2+∑i=1nμ2‖Wi−Pi+1μΛi‖F2,s.t.PTP=I,PiTPi=I,

where P={P,P1,P2,⋯,Pn}, Λ∈ℜd×r is the Lagrangian multiplier for the constraint of W = P, and Λi∈ℜd×r is the Lagrangian multiplier for the constraint of Wi = Pi. Now we solve the problem in Eq. (20) as following.

Step 1. When W, P, Pi, Λ and Λi are fixed, the objective in Eq. (20) with respect to Wi can be rewritten as follows: (21) Jℓ2ADMM(Wi)=α∑i=1ntr(WiTXiLiXiTWi)+μ2‖W−P+1μΛ‖F2+∑i=1nμ2‖Wi−Pi+1μΛi‖F2.

Taking the derivative of Eq. (21) with respect to Wi and setting it to 0, we can get the solution by computing the following: (22) Wi=(2αXiLiXiT+μI)−1(μPi−Λi).

Step 2. When W, Wi, P, Λ and Λi are fixed, the objective in Eq. (20) with respect to Pi can be rewritten as: (23) maxPiTr(PiNi),s.t.Pi⊤Pi=I,

where Ni = 2βP + μWi + Λi. The problem in Eq. (20) can be solved by computing SVD of Ni:if svd(Ni)=UiΣiViT, the solution of Eq. (23) is given by UiViT according to [24, Theorem 1].

Step 3. When Wi, P, Pi, Λ and Λi are fixed, the objective in Eq. (20) with respect to W can be rewritten as follows: (24) Jℓ2ADMM(W)=tr(X−WWTX)Γ(X−WWTX)T+μ2‖W−P+1μΛ‖F2.

Taking the derivative of Eq. (24) with respect to W and seting it to 0, we can get the solution by computing the following: (25) W=(μI−2XΓXT)−1(μP−Λ).

Step 4. When W, Wi, Pi, Λ and Λi are fixed, the objective in Eq. (20) with respect to P can be rewritten as follows: (26) maxPTr(PN),s.t.P⊤P=I,

where N=2β∑i=1nPi+μW+Λ. Similar to Step 2, we compute the SVD of N : if svd(N) = UΣVT, the solution of Eq. (26) is given by UVT according to [24, Theorem 1].

Step 5. Update Λi by Λi = Λi + μ (Wi − Pi).

Step 6. Update Λ by Λ = Λ + μ (W − P).

Step 7. Update μ by μ = ρμ.

Finally, we summarize the solution algorithm to minimize the objective in Eq. (20) in Algorithm 3. The most computationally intensive steps in our algorithm are computing SVDs in step 2 and step 4 in our algorithm, with a complexity of O(dr) [25]. Thus the overall complexity of our proposed algorithm is O(ndrm), where m denotes the iteration times. Empirically our optimization algorithm converge very fast, usually within less than 50 iterations.

III. Experiment Results

The data used in our experiments were obtained from the ADNI database [10]. We downloaded 1.5T MRI scans and demographic information for 821 ADNI-1 participants. We performed VBM and FreeSurfer on the MRI data following [26] and extracted mean modulated gray matter measures for 90 target regions of interest. These measures are adjusted for the baseline intracranial volume using regression weights derived from the Health Control (HC) participants at the baseline. We also downloaded the longitudinal scores of the participants in five independent cognitive assessments including Alzheimer’s Disease Assessment Scale (ADAS-cog), Mini-Mental State Examination (MMSE), Fluency test (FLU), Rey’s Auditory Verbal Learning Test (RAVLT) and Trail making test (TRAILS). Details about these cognitive assessments are available in the ADNI procedure manuals.

We use 10 cognitive scores as predictive targets in our studies: (1) ADAS TOTAL scores from ADAS-cog; (2) FLU ANIM and (3) FLU VEG scores from FLU; (4) MMSE score from MMSE; (5) RAVLT TOTAL, (6) RAVLT 30 and (7) RAVLT 30 RECOG scores from RAVLT; (8) TRAIL A, (9) TRAIL B and (10) TRAIL B-A scores from TRAILS. The time points examined in this study for both imaging biomarkers and cognitive assessments include the baseline (BL), the 6th month (M6), the 12th month (M12), the 18th month (M18), the 24th month (M24) and the 36th month (M36). All the participants’ data used in studying our enriched biomarker representation are required to have a BL MRI measurement, BL cognitive score and at least two available measures from M6/M12/M18/M24/M36. As a result, a total of 544 sample subjects are selected in our study, among which 92 samples are diagnosed with AD, 205 samples are diagnosed to be with Mild Cognitive Impairment (MCI), and 177 samples are HC.

A. Predictive Power of the Enriched Biomarker Representations

We first experimentally evaluate the proposed method by applying it to the ADNI database, where we compare the predictive power of the enriched biomarker representations learned by our new method against the BL MRI measurements using both VBM and FreeSurfer biomarkers respectively.

To validate the effectiveness of our proposed method, we compare the predictive capabilities of the two types of biomarker representations, the enriched representations learned by our new method and the BL biomarker measurements, in the tasks of predicting cognitive outcomes. In our experiments, we implement four most broadly used regression models, including RR, Lasso, SVR, and CNN, to evaluate the predictive power of the two compared biomarker representations. RR is a regularized version of linear regression that uses regularization for the better generalization capability. Lasso regression performs both variable selection and regularization in order to enhance the prediction accuracy. SVR is the regression version of support vector machine, which is broadly used in may different real-world applications. When CNN is used to perform regression, it has demonstrated the superior performance compared to many classical machine learning models.

For all these regression models, we randomly select 70% samples as the training set, 20% samples as the validation set, and the remaining 10% samples as the testing set. The validation set in our experimental setting is designed to to tune the hyperparameters of the model. The test dataset is used to provide an unbiased evaluation of a final model fit on the training dataset. For RR and Lasso models, we fine tune the regularization parameters by searching the grid of {10−10, … , 10−1, 1, 10, ⋯ , 1010}. For SVR model, the Gaussian kernel is used and we fine tune the parameters via a grid search in {10−5, … , 10−1, 1, 10, ⋯ , 105}. In the CNN model, we construct a two layer convolution architecture for the cognitive outcomes prediction: (1) 16 1 × 5 convolutions (unpadded convolutions), followed by a Rectified Linear Unit (ReLU) and a 1 × 2 max pooling operation; (2) 32 1 × 10 convolutions (unpadded convolutions) with ReLU and a 1 × 2 max pooling operation. The dropout technique is leveraged to reduce overfitting in the CNN model and prevent complex co-adaptations on training data. The dropout probability is set to be 0.3 and the batch size is set to be 16. The reported performance are based on the results on the testing set.

To evaluate the predictive power of the enriched biomarker representations learned by our new method, we use them as input to predict the 10 cognitive scores by the 4 regression models as listed above. We compare the prediction performances of the enriched biomarker representations against the original biomarker representations at the baseline time point and ℓ1-norm enriched biomarker representations. Beside the comparison between enriched biomarker representations against its degenerative counterparts, we also compare our proposed enriched biomarker representation with enriched biomarker representations learned from LPP [17]. As a result, for each of the two types of input neuroimaging biomarkers, VBM and FreeSurfer, we end up with prediction 160 tasks. The detailed prediction performance comparisons are reported in Fig. 2 for VBM biomarkers and in Fig. 3 for FreeSurfer biomarkers, which show that our the learned biomarker representations with enrichments outperform the their counterparts in al prediction tasks. The comparisons in these figures show that the predictive capability of the biomarkers have been apparently improved by the enrichments using the information of temporal developments of AD, sometimes very significantly. For example, when we use VBM biomarkers to predict FLU ANIM by RR, the predictive performance of the enriched representations are better than the original ones by about 55%.

While it is exciting to see the clearly improved predictive capability of the enriched biomarker representations, it is more important to study why the temporal enrichments learned by our new method can improve the performance for predicting cognitive outcomes, for which we attribute the enhanced predictive capability of the learned biomarker representations with enrichments to the following two reasons. Firstly, the original baseline neuroimaging biomarker representations are static measurements at one single time point, therefore they cannot benefit from the longitudinal correlations of the neuroimaging measurements when they change over time. In contrast, the enriched representations learned by our new method aim to characterize not only the brain statuses of the participants atthe baseline time point, but also the temporal variations of the same set of measures in AD progressions. Because the cognitive capabilities of AD patients progressively degenerate, integrating longitudinal information of the subjects by our new method is critical for developing prediction models and can improve the predictive power of enriched representations of the biomarkers. Secondly, the original baseline neuroimaging measurements may contain redundant and potentially noisy information [3], [5], [7], [15]. Therefore, by transforming the raw biomarker representations over time via using the projections learned by our new method, we map the baseline cognitive measurements into a lower-dimensional subspace that can mitigate the issues of raw neuroimaging data. This hypothesis is confirmed by all our experimental results in that, compared to the original higher-dimensional neuroimaging measurements, our enriched representations in the projected subspace can achieve significantly better results for predicting cognitive outcomes.

B. Comparison of Our New Method to State-of-the-Art Longitudinal Learning Models

In the previous empirical studies, we compared the enriched biomarker representations learned by our new method against their BL counterparts. The latter, however, are static measurements and only characterize the brain status at the baseline time point, but do not have the information encoded at the follow-up time points. To further demonstrate the advantage of the our new method, we compare its predictive performance against two recent longitudinal learning models, including (1) the temporal group feature (TGF) method [27]; (2) the longitudinal spatial features (LSF) method [28]; one multi-task based longitudinal methods: Joint Multi-Modal Longitudinal Regression and Classification for Alzheimer’s Disease Prediction (JMMLRC) [29], and one RNN model filling based imputation method (RNNMF) [30]. Different from RR, Lasso, SVR and CNN regression models, these methods are able to use the longitudinal data over all the examined time points. In our experiments, after we learn the enriched biomarker representations by our new method, we use CNN for the regression analyses. For these competing methods, we fine tune their parameters following the procedures described in the respective papers. We report the comparison results in Table I, which show that our new method achieves the best performance when predicting different clinical scores via VBM and FreeSurfer biomarkers respectively, which again firmly confirms the advantage of our new method.

C. Identifying Disease-Relevant Imaging Biomarkers

Apart from better predicting the cognitive outcomes, another important goal of our regression analyses is to identify a subset of neuroimaging markers which are highly correlated to AD progressions. Therefore, we examine the neuroimaging markers identified by our new method. As can be seen in our proposed objective in Eq. (4), while we do not use W to compute the enriched biomarker representations, it is learned from the baseline biomarker representations of all the participants and is balanced by the projections learned from all the participants individually. Thus, W encodes the relevances of the input biomarkers to cognitive outcomes and disease status. We use the ∓2-norm of every row of W to quantify the relevances of the biomarkers and visualize them in Fig. 4 for the VBM biomarkers and in Fig. 5 for the FreeSurfer biomarkers.

From Fig. 4 we can see that the VBM biomarkers with highest weights are in perfect accordance with the knowledge documented in existing clinical findings. Specifically, we observe that the bilateral hippocampus are among the top selected biomarkers. The hippocampus is a small organ located within the brain’s medial temporal lobe and forms an important part of the limbic system and it is the region that regulates emotions. The hippocampus is mainly associated with memory, in particular long-term memory. This brain region also plays an important role in spatial navigation. Emerging evidence has indicated that altered neurogenesis in the adult hippocampus represents an early critical event in the course of AD [31]. Therefore, this observation firmly confirms the effectiveness of our new method from the clinical perspective. In addition, the bilateral amygdala is also among the top selected biomarkers. We know that the amygdala performs a primary role in the processing of memory, decision-making and emotional response. Thus amygdala is an important subcortical region that is severely and consistently affected by pathology in AD [32]. Finally, We notice that the bilateral putamen are also among the top selected biomarkers. The putamen is a large structure, involved in a very complex feedback loop that prepares and aids in movement of the limbs. It is known in [33] that the volumes of putamen will decrease as AD progresses, which is one more indication of the correctness our new method.

Visualized in Fig. 5 is the significance of the FreeSurfer biomarkers, which again nicely agree with many evidences documented in existing literature. For example, Cerebellar White Matter is among the most significant biomarkers as rated by our new method. It is generally recognized that cerebellar white matter is composed of bundles, which connect various gray matter areas (the locations of nerve cell bodies) of the brain to each other, and carry nerve impulses between neurons. It has been confirmed in existing studies [39] that white matter abnormalities has complex interaction with AD. Another biomarker with top significance is cerebellar cortex, which is supported by [37] in that the processes of aging and AD patients have both differential and partially overlapping effects on specific regions of the cerebellar cortex. Finally, it is broadly accepted in neuroimaging studies that the lateral ventricles are structures within the brain that contain cerebrospinal fluid, a clear, watery fluid that provides cushioning for the brain while also helping to circulate nutrients and remove waste. Fig. 5 shows that the weights of the biomarkers of Lateral Ventricle Volumes are among the top that is consistent with the discovery in [38], in that the lateral ventricle volume will experience a longitudinal change during different periods of AD.

In summary, the identified imaging biomarkers are highly suggestive and strongly agree with existing medical research findings with regard to AD, which warrants the correctness of the discovered imaging cognition associations to reveal the complex relationships between MRI measures and cognitive scores. This is important for both theoretical research and clinical practices for a better understanding of AD mechanism.

IV. Conclusion

Missing data pose a critical challenge in longitudinal AD studies. In this paper, we propose a new method to learn a fixed-length biomarker representation for an input neuroimaging dataset. The enriched biomarker representations simultaneously capture both the global consistency from baseline measurements and local pairwise pattern from available follow-up measurements of each participant. Our experimental results show that the learned biomarker representations with enrichments outperform the baseline biomarker measurements when we predict the cognitive scores. Furthermore, the identified biomarkers are highly suggestive and strongly agree with the existing research findings, which warrants the correctness of our approach and adds to its values for the usage in clinical practices for a better understanding of AD mechanisms.

Acknowledgement

Data collection and sharing for this project was funded by the Alzheimer’s Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie, Alzheimer’s Association; Alzheimer’s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research &amp; Development, LLC.; Johnson &amp; Johnson Pharmaceutical Research &amp; Development LLC.; Lumosity; Lundbeck; Merck &amp; Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer’s Disease Cooperative Study at the University of California, San Diego. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.

The work of L. Lu, S. Elbeleidy, L. Baker, and H. Wang was supported in part by the National Science Foundation (NSF) under the grants of IIS 1652943, IIS 1849359, CNS 1932482 and CCF 2029543. The work of L. Shen was supported in part by the NSF under the grant of IIS 1837964, and by the National Institutes of Health (NIH) under the grants of R01 EB022574, U01 AG068057, and R01 LM013463. The work of H. Huang was supported in part by the NSF under the grants of IIS 1845666, IIS 1852606, IIS 1838627, IIS 1837956, IIS 1956002, IIS 2040588, and by the NIH under the grants of R01 AG049371, R01 AG071243, U01 AG068057.

Fig. 1. Illustration of the proposed model to learn the enriched biomarker representations. First, our model learns a global projection W from the baseline imaging records of all the participants in a studied cohort. Second, it learns a local projection Wi from the available follow-up records of the i-th participant, which is repeated for every participant. The blank brain plots denote the absence of the brain scans of a participant. Third, the global projection and local projections learned in the above two steps are aligned via a soft constraint. Finally, we get the enriched biomarker representations by projecting the original baseline biomarker representations into subspaces by computing {yi=WiTxi}i=1n, which are a set of fixed-length vectors and can be readily used in traditional machine learning models.

Fig. 2. Comparisons of the predictive performances of the original representations at the baseline time point, ℓ1-norm enriched representations, squared ℓ2-norm enriched representations and LPP enriched representations of the VBM biomarkers, when they are used to predict the 10 different baseline cognitive outcomes using the 4 different regression models (RR, Lasso, SVR, and CNN). The RMSEs (smaller is better ↓) for predicting each cognitive outcome by each type of representations are shown for comparison, where the vertical bars show the standard deviations.

Fig. 3. Comparisons of the predictive performances of the original representations at the baseline time point, ℓ1-norm enriched representations, squared ℓ2-norm enriched representations and LPP enriched representations of the FreeSurfer biomarkers, when they are used to predict the 10 different baseline cognitive outcomes using the 4 different regression models (RR, Lasso, SVR, and CNN). The RMSEs (smaller is better ↓) for predicting each cognitive outcome by each type of representations are shown for comparison, where the vertical bars show the standard deviations.

Fig. 4. Visualization of the top 10 VBM biomarkers in the brain map ranked by the relevances to cognitive outcomes learned by our method: LHippocampus and RHippocampus [31], LAmygdala and RAmygdala [32], LPutamen and RPutamen [33], LHeschl and RHeschl [34], LFusiform [33], RParahipp [35].

Fig. 5. Visualization of the top 10 FreeSurfer biomarkers in the brain map ranked by the relevances to cognitive outcomes learned by our method: LCerebWM and RCerebWM [36], LCerebCtx and RCerebCtx [37], LCerebellCtx and RCerebellCtx [37], LLatVent and RLatVent [38], LInfLatVent and RInfLatVent [38].

TABLE I Performance comparisons of our method (CNN is used for regression) against three methods, TGF [27], LSF [28], JMMLRC [29] and RNNMF [30] measured by RMSE (smaller is better ↓), where VBM and FreeSurfer (FS) biomarkers are used as inputs.

Clinical Score	Biomarker	TGF	LSF	JMMLRC	RNNMF	Our Method	
ADAS	VBM	4.524 ± 0.213	2.403 ± 0.126	3.871 ± 0.236	1.703 ± 0.141	1.669 ± 0.132	
FreeSurfer	4.300 ± 0.175	2.246 ± 0.223	4.139 ± 0.244	2.027 ± 0.106	0.775 ± 0.105	
MMSE	VBM	2.178 ± 0.083	1.723 ± 0.147	1.719 ± 0.098	0.185 ± 0.022	0.163 ± 0.023	
FreeSurfer	2.074 ± 0.057	0.627 ± 0.086	1.425 ± 0.086	0.854 ± 0.016	0.140 ± 0.015	
FLU_ANIM	VBM	2.553 ± 0.124	1.509 ± 0.113	1.681 ± 0.083	0.456 ± 0.045	0.445 ± 0.044	
FreeSurfer	2.638 ± 0.102	1.358 ± 0.132	1.714 ± 0.089	0.617 ± 0.042	0.385 ± 0.046	
FLU_VEG	VBM	2.649 ± 0.103	1.439 ± 0.151	1.390 ± 0.082	0.480 ± 0.051	0.266 ± 0.048	
FreeSurfer	2.918 ± 0.093	1.513 ± 0.183	1.376 ± 0.069	0.571 ± 0.050	0.502 ± 0.054	
RAVLT_TOTAL	VBM	3.879 ± 0.241	1.514 ± 0.133	1.481 ± 0.095	0.911 ± 0.200	0.857 ± 0.202	
FreeSurfer	3.581 ± 0.182	1.431 ± 0.107	1.486 ± 0.127	1.862 ± 0.206	1.158 ± 0.222	
RAVLT_30	VBM	2.513 ± 0.063	1.713 ± 0.143	1.749 ± 0.128	0.469 ± 0.092	0.467 ± 0.087	
FreeSurfer	2.644 ± 0.051	1.665 ± 0.113	1.467 ± 0.124	0.410 ± 0.048	0.306 ± 0.048	
RAVLT_RECOG	VBM	3.395 ± 0.097	2.213 ± 0.137	2.706 ± 0.114	0.648 ± 0.103	0.611 ± 0.113	
FreeSurfer	2.907 ± 0.217	2.318 ± 0.108	2.825 ± 0.130	0.631 ± 0.041	0.111 ± 0.030	
TRAILA	VBM	15.183 ± 1.017	18.417 ± 1.617	14.819 ± 1.371	2.259 ± 0.710	2.077 ± 0.677	
FreeSurfer	12.983 ± 1.317	18.943 ± 1.471	11.521 ± 1.314	3.749 ± 0.645	3.605 ± 0.703	
TRAILB	VBM	36.714 ± 4.317	38.137 ± 3.717	28.902 ± 3.891	4.469 ± 0.550	4.467 ± 0.508	
FreeSurfer	37.714 ± 4.461	43.614 ± 4.471	31.493 ± 4.176	9.975 ± 1.651	8.134 ± 1.550	
TRAILB-A	VBM	27.371 ± 2.571	28.253 ± 3.751	19.493 ± 3.295	3.370 ± 0.535	3.186 ± 0.487	
FreeSurfer	31.708 ± 3.651	36.572 ± 2.981	24.487 ± 2.263	8.782 ± 1.028	5.988 ± 1.040	

1 The code package of this paper have been made publicly available online at https://github.com/lyujian/Improved-Prediction-of-Cognitive-Outcomes.


References

[1] Association A , “2018 alzheimer’s disease facts and figures,” Alzheimer’s &amp; Dementia, vol. 14 , no. 3 , pp. 367–429, 2018.
[2] Nichols E , Szoeke CE , Vollset SE , Abbasi N , Abd-Allah F , Abdela J , Aichour MTE , Akinyemi RO , Alahdab F , Asgedom SW , “Global, regional, and national burden of alzheimer’s disease and other dementias, 1990–2016: a systematic analysis for the global burden of disease study 2016,” The Lancet Neurology, vol. 18 , no. 1 , pp. 88–106, 2019.30497964
[3] Brand L , Wang H , Huang H , Risacher S , Saykin A , Shen L , “Joint high-order multi-task feature learning to predict the progression of alzheimer’s disease,” in MICCAI, 2018, pp. 555–562.
[4] Lu L , Wang H , Yao X , Risacher S , Saykin A , and Shen L , “Predicting progressions of cognitive outcomes via high-order multi-modal multi-task feature learning,” in 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018). IEEE, 2018, pp. 545–548.
[5] Wang H , Nie F , Huang H , Yan J , Kim S , Risacher S , Saykin A , and Shen L , “High-order multi-task feature learning to identify longitudinal phenotypic markers for alzheimer’s disease progression prediction,” in Advances in neural information processing systems, 2012, pp. 1277–1285.
[6] Wang H , Nie F , Huang H , Yan J , Kim S , Nho K , Risacher SL , Saykin AJ , Shen L , and ADNI, “From phenotype to genotype: an association study of longitudinal phenotypic markers to alzheimer’s disease relevant SNPs,” Bioinformatics, vol. 28 , no. 18 , pp. i619–i625, 2012.22962490
[7] Wang X , Yan J , Yao X , Kim S , Nho K , Risacher SL , Saykin AJ , Shen L , Huang H , “Longitudinal genotype-phenotype association study via temporal structure auto-learning predictive model,” in International Conference on Research in Computational Molecular Biology. Springer, 2017, pp. 287–302.
[8] Xiang S , Yuan L , Fan W , Wang Y , Thompson PM , Ye J , Initiative ADN , “Bi-level multi-source learning for heterogeneous block-wise missing data,” NeuroImage, vol. 102 , pp. 192–206, 2014.23988272
[9] Li Y , Wang L , Zhou J , and Ye J , “Multi-task learning based survival analysis for multi-source block-wise missing data,” Neurocomputing, vol. 364 , pp. 95–107, 2019.
[10] Weiner MW , Aisen PS , Jack CR Jr , Jagust WJ , Trojanowski JQ , Shaw L , Saykin AJ , Morris JC , Cairns N , Beckett LA , “The alzheimer’s disease neuroimaging initiative: progress report and future plans,” Alzheimer’s &amp; Dementia, vol. 6 , no. 3 , pp. 202–211, 2010.
[11] Ashburner J and Friston KJ , “Voxel-based morphometry—the methods,” Neuroimage, vol. 11 , no. 6 , pp. 805–821, 2000.10860804
[12] Fischl B , “Freesurfer,” Neuroimage, vol. 62 , no. 2 , pp. 774–781, 2012.22248573
[13] Lu L , Elbeleidy S , Baker L , Wang H , Huang H , Shen L , “Improved prediction of cognitive outcomes via globally aligned imaging biomarker enrichments over progressions,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2019, pp. 140–148.
[14] Yan J , Li T , Wang H , Huang H , Wan J , Nho K , Kim S , Risacher SL , Saykin AJ , Shen L , “Cortical surface biomarkers for predicting cognitive outcomes using group l2, 1 norm,” Neurobiology of aging, vol. 36 , pp. S185–S193, 2015.25444599
[15] Hao X , Li C , Yan J , Yao X , Risacher SL , Saykin AJ , Shen L , Zhang D , and Initiative ADN , “Identification of associations between genotypes and longitudinal phenotypes via temporally-constrained group sparse canonical correlation analysis,” Bioinformatics, vol. 33 , no. 14 , pp. i341–i349, 2017.28881979
[16] Jolliffe I , “Principal component analysis,” in International encyclopedia of statistical science. Springer, 2011, pp. 1094–1096.
[17] He X and Niyogi P , “Locality preserving projections,” in Advances in neural information processing systems, 2004, pp. 153–160.
[18] Wang H , Nie F , and Huang H , “Learning robust locality preserving projection via p-order minimization,” in Twenty-Ninth AAAI Conference on Artificial Intelligence, 2015.
[19] Liu Y , Guo Y , Wang H , Nie F , and Huang H , “Semi-supervised classifications via elastic and robust embedding,” in Thirty-First AAAI Conference on Artificial Intelligence, 2017.
[20] Liu K , Brand L , Wang H , and Nie F , “Learning robust distance metric with side information via ratio minimization of orthogonally constrained l21-norm distances.” in IJCAI, 2019, pp. 3008–3014.
[21] Candes EJ , Wakin MB , and Boyd SP , “Enhancing sparsity by reweighted ℓ1 minimization,” Journal of Fourier analysis and applications, vol. 14 , no. 5-6 , pp. 877–905, 2008.
[22] Nie F , Huang H , Cai X , and Ding CH , “Efficient and robust feature selection via joint ℓ2,1-norms minimization,” in Advances in neural information processing systems, 2010, pp. 1813–1821.
[23] Bertsekas DP , Constrained optimization and Lagrange multiplier methods. Athena Scientific, 1996.
[24] Wang H , Nie F , Huang H , and Makedon F , “Fast nonnegative matrix tri-factorization for large-scale data co-clustering,” in Twenty-Second International Joint Conference on Artificial Intelligence, 2011.
[25] Golub GH and Van Loan CF , Matrix computations. JHU press, 2013, vol. 3 .
[26] Risacher SL , Shen L , West JD , Kim S , McDonald BC , Beckett LA , Harvey DJ , Jack CR Jr , Weiner MW , Saykin AJ , “Longitudinal mri atrophy biomarkers: relationship to conversion in the adni cohort,” Neurobiology of aging, vol. 31 , no. 8 , pp. 1401–1418, 2010.20620664
[27] Zhang D , Shen D , Initiative ADN , “Predicting future clinical changes of mci patients using longitudinal and multimodal biomarkers,” PloS one, vol. 7 , no. 3 , p. e33182, 2012.22457741
[28] Zhang J , Liu M , An L , Gao Y , and Shen D , “Alzheimer’s disease diagnosis using landmark-based features from longitudinal structural mr images,” IEEE journal of biomedical and health informatics, vol. 21 , no. 6 , pp. 1607–1616, 2017.28534798
[29] Brand L , Nichols K , Wang H , Shen L , and Huang H , “Joint multi-modal longitudinal regression and classification for alzheimer’s disease prediction,” IEEE transactions on medical imaging, vol. 39 , no. 6 , pp. 1845–1855, 2019.31841400
[30] Nguyen M , He T , An L , Alexander DC , Feng J , Yeo BT , Initiative ADN , “Predicting alzheimer’s disease progression using deep recurrent neural networks,” NeuroImage, vol. 222 , p. 117203, 2020.
[31] Mu Y and Gage FH , “Adult hippocampal neurogenesis and its role in alzheimer’s disease,” Mol. neurodegeneration, vol. 6 , no. 1 , p. 85, 2011.
[32] Poulin SP , Dautoff R , Morris JC , Barrett LF , Dickerson BC , Initiative ADN , “Amygdala atrophy is prominent in early alzheimer’s disease and relates to symptom severity,” Psychiatry Research: Neuroimaging, vol. 194 , no. 1 , pp. 7–13, 2011.
[33] De Jong L , Van der Hiele K , Veer I , Houwing J , Westendorp R , Bollen E , De Bruin P , Middelkoop H , Van Buchem M , and Van Der Grond J , “Strongly reduced volumes of putamen and thalamus in alzheimer’s disease: an mri study,” Brain, vol. 131 , no. 12 , pp. 3277–3285, 2008.19022861
[34] Esiri MM , Pearson R , and Powell T , “The cortex of the primary auditory area in alzheimer’s disease,” Brain Research, vol. 366 , no. 1-2 , pp. 385–387, 1986.3697692
[35] Echávarri C , Aalten P , Uylings HB , Jacobs H , Visser PJ , Gronenschild E , Verhey F , and Burgmans S , “Atrophy in the parahippocampal gyrus as an early biomarker of alzheimer’s disease,” Brain Structure and Function, vol. 215 , no. 3-4 , pp. 265–271, 2011.20957494
[36] Acosta-Cabronero J , Williams GB , Pengas G , and Nestor PJ , “Absolute diffusivities define the landscape of white matter degeneration in alzheimer’s disease,” Brain, vol. 133 , no. 2 , pp. 529–539, 2010.19914928
[37] Bakkour A , Morris JC , Wolk DA , and Dickerson BC , “The effects of aging and alzheimer’s disease on cerebral cortical anatomy: specificity and differential relationships with cognition,” Neuroimage, vol. 76 , pp. 332–344, 2013.23507382
[38] DeCarli C , Haxby JV , Gillette J , Teichberg D , Rapoport S , and Schapiro M , “Longitudinal changes in lateral ventricular volume in datients with dementia of the alzheimer type,” Neurology, vol. 42 , no. 10 , pp. 2029–2029, 1992.1407587
[39] Moghekar A , Kraut M , Elkins W , Troncoso J , Zonderman AB , Resnick SM , and O’Brien RJ , “Cerebral white matter disease is associated with alzheimer pathology in a prospective cohort,” Alzheimer’s &amp; Dementia, vol. 8 , no. 5 , pp. S71–S77, 2012.
